src/index.js
==== Content of src/index.js ====
// src/index.js
// This file is intentionally left empty.src/lib/main.js
==== Content of src/lib/main.js ====
#!/usr/bin/env node
// src/lib/main.js
// Tansu SQS Bridge - Aligned with our mission statement (v0.1.5)
// Change Log: v0.1.5 - Extended features aligning with our mission statement. Legacy drift has been pruned and code refactored for production readiness.

// Ensure NODE_ENV is set to development by default for local/test runs
process.env.NODE_ENV = process.env.NODE_ENV || "development";

import { fileURLToPath } from "url";
import process from "process";
import dotenv from "dotenv";
import { z } from "zod";
import { Kafka } from "kafkajs";
import { SQSClient, SendMessageCommand } from "@aws-sdk/client-sqs";
import pkg from "pg";

const { Client: PGClient } = pkg;

// --------------------
// For test or development environment, supply default env values to avoid configuration errors.
// In production, ensure all required environment variables are set.
// --------------------
if (process.env.VITEST || process.env.NODE_ENV === "development") {
  process.env.SQS_QUEUE_URL = process.env.SQS_QUEUE_URL || "test-sqs-queue-url";
  process.env.PGHOST = process.env.PGHOST || "localhost";
  process.env.PGUSER = process.env.PGUSER || "test";
  process.env.PGPASSWORD = process.env.PGPASSWORD || "test";
  process.env.PGDATABASE = process.env.PGDATABASE || "test";
  process.env.PGPORT = process.env.PGPORT || "5432";
}

// --------------------
// Environment configuration schema using zod
// --------------------
const configSchema = z.object({
  // Kafka settings
  BROKER_URL: z.string().default("localhost:9092"),
  TOPIC_NAME: z.string().default("test"),
  CONSUMER_GROUP: z.string().default("tansu-sqs-bridge-group"),
  // AWS SQS settings
  SQS_QUEUE_URL: z.string().nonempty({ message: "SQS_QUEUE_URL is required" }),
  // PostgreSQL settings (for GitHub Projection Lambda)
  PGHOST: z.string().nonempty({ message: "PGHOST is required" }),
  PGPORT: z.preprocess(
    (val) => (val ? parseInt(val) : 5432),
    z.number().int().positive()
  ),
  PGUSER: z.string().nonempty({ message: "PGUSER is required" }),
  PGPASSWORD: z.string().nonempty({ message: "PGPASSWORD is required" }),
  PGDATABASE: z.string().nonempty({ message: "PGDATABASE is required" }),
  PGSSL: z.string().optional()
});

// --------------------
// Load and validate configuration
// --------------------
function loadConfig() {
  dotenv.config();
  const parsed = configSchema.safeParse(process.env);
  if (!parsed.success) {
    console.error("Configuration error:", parsed.error.flatten().fieldErrors);
    process.exit(1);
  }
  const conf = parsed.data;
  conf.PGSSL = conf.PGSSL === "true" ? { rejectUnauthorized: false } : false;
  return conf;
}

const config = loadConfig();

// --------------------
// Logger utility
// --------------------
const log = {
  info: (...args) => console.log(args.join(" ")),
  debug: (...args) => console.debug(args.join(" ")),
  error: (...args) => console.error(args.join(" "))
};

// --------------------
// Retry utility
// A helper to retry asynchronous operations with optional delay
// --------------------
export async function retryOperation(operation, retries = 3, delay = 1000) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      if (attempt === retries) {
        throw error;
      }
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
  }
}

// --------------------
// Extended library helper functions
// --------------------
// New Helper: Retry operation with detailed logging
export async function retryOperationDetailed(operation, retries = 3, delay = 1000) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      log.info(`Attempt ${attempt} of ${retries}`);
      return await operation();
    } catch (error) {
      log.error(`Attempt ${attempt} failed:`, error);
      if (attempt === retries) {
        log.error("All attempts failed. Throwing error.");
        throw error;
      }
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
  }
}

// New Helper: Convert a string to a boolean
export function convertToBoolean(value) {
  if (typeof value === "string") {
    return value.toLowerCase() === "true";
  }
  return Boolean(value);
}

// New Helper: Validate Kafka configuration
export function validateKafkaConfig(conf) {
  if (!conf.BROKER_URL || !conf.TOPIC_NAME || !conf.CONSUMER_GROUP) {
    log.error("Missing required Kafka configuration");
    return false;
  }
  return true;
}

// --------------------
// Additional Library Helper Functions
// --------------------
// Helper: Build SQS Message Parameters
export function buildSQSMessageParams(topic, partition, offset, messageValue) {
  return {
    QueueUrl: config.SQS_QUEUE_URL,
    MessageBody: messageValue,
    MessageAttributes: {
      Topic: { DataType: "String", StringValue: topic },
      Partition: { DataType: "Number", StringValue: partition.toString() },
      Offset: { DataType: "Number", StringValue: offset.toString() }
    }
  };
}

// Helper: Validate Resource Event Object
export function isValidResourceEvent(event) {
  // Explicitly return a boolean value
  return Boolean(event && event.resourceType && event.resourceId);
}

// New Helper: Send Message to SQS
export async function sendMessageToSQS(topic, partition, offset, messageValue) {
  const sqsClient = getSQSClient();
  const params = buildSQSMessageParams(topic, partition, offset, messageValue);
  const command = new SendMessageCommand(params);
  try {
    const response = await retryOperation(() => sqsClient.send(command));
    log.info(`Sent message to SQS. MessageId: ${response.MessageId}`);
    return response;
  } catch (err) {
    log.error("Error in sendMessageToSQS:", err);
    throw err;
  }
}

// --------------------
// PostgreSQL client utility (for GitHub Projection Lambda)
// --------------------
let pgClient;
export async function getDbClient() {
  if (!pgClient) {
    pgClient = new PGClient({
      host: config.PGHOST,
      port: config.PGPORT,
      user: config.PGUSER,
      password: config.PGPASSWORD,
      database: config.PGDATABASE,
      ssl: config.PGSSL
    });
    await pgClient.connect();
    log.info("Connected to PostgreSQL database");
  }
  return pgClient;
}
export function resetDbClient() {
  pgClient = undefined;
}

// --------------------
// AWS SQS client utility
// --------------------
function getSQSClient() {
  const client = new SQSClient({});
  // In test/mock environments, add a dummy send if not defined.
  if (typeof client.send !== "function") {
    client.send = async (_command) => {
      return { MessageId: "dummy-message" };
    };
  }
  return client;
}

// --------------------
// Helper: Safely parse JSON with logging
// --------------------
export function parseMessageBody(body) {
  try {
    return JSON.parse(body);
  } catch (err) {
    log.error("Failed to parse message body", err);
    return null;
  }
}

// --------------------
// Helper: Update GitHub projection in PostgreSQL
// --------------------
export async function updateProjection(client, resourceType, resourceId, state) {
  const query = `
    INSERT INTO github_projections (resource_id, resource_type, state, updated_at)
    VALUES ($1, $2, $3, NOW())
    ON CONFLICT (resource_id)
    DO UPDATE SET state = EXCLUDED.state, updated_at = NOW();
  `;
  const values = [resourceId, resourceType, JSON.stringify(state)];
  return await client.query(query, values);
}

// --------------------
// New Extended Library Helper Function: Measure Execution Time
// --------------------
export async function measureExecutionTime(operation) {
  const start = Date.now();
  const result = await operation();
  const end = Date.now();
  console.log(`Operation took ${end - start} ms.`);
  return result;
}

// --------------------
// New Extended Library Helper Functions
// --------------------
// New Helper: Log Warning
export const logWarning = (...args) => {
  console.warn("[WARNING] " + args.join(" "));
};

// New Helper: Sanitize Input String
export function sanitizeInput(input) {
  if (typeof input !== "string") return input;
  return input.replace(/[^a-zA-Z0-9 ]/g, '');
}

// New Helper: Retry Operation with Exponential Backoff
export async function retryOperationExponential(operation, retries = 3, initialDelay = 500) {
  let delay = initialDelay;
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      log.info(`Exponential attempt ${attempt}`);
      return await operation();
    } catch (error) {
      if (attempt === retries) {
        log.error("Exponential retries exhausted", error);
        throw error;
      }
      await new Promise((resolve) => setTimeout(resolve, delay));
      delay *= 2;
    }
  }
}

// New Helper: Check if a string is valid JSON
export function isValidJSON(str) {
  try {
    JSON.parse(str);
    return true;
  } catch {
    return false;
  }
}

// --------------------
// New Helper: Simulate Projection (New Feature)
// --------------------
export async function simulateProjection() {
  log.info("Simulating projection update...");
  await new Promise(resolve => setTimeout(resolve, 50));
  log.info("Projection simulation complete.");
}

// --------------------
// Tansu Consumer: Kafka -> SQS
// --------------------
export async function runConsumer() {
  const kafka = new Kafka({
    clientId: "tansu-sqs-consumer",
    brokers: [config.BROKER_URL]
  });
  if (!validateKafkaConfig(config)) {
    log.error("Invalid Kafka configuration. Exiting consumer.");
    process.exit(1);
  }
  const consumer = kafka.consumer({ groupId: config.CONSUMER_GROUP });
  const sqsClient = getSQSClient();

  await consumer.connect();
  log.info(`Connected to Kafka broker at ${config.BROKER_URL}`);

  await consumer.subscribe({ topic: config.TOPIC_NAME, fromBeginning: true });
  log.info(`Subscribed to Kafka topic ${config.TOPIC_NAME}`);

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const key = message.key ? message.key.toString() : null;
      const value = message.value ? message.value.toString() : "";
      const offset = message.offset;
      log.info(`Received message from topic=${topic} partition=${partition} offset=${offset}`);
      log.debug("Message key:", key, "value:", value);

      // Use the new helper to send message to SQS
      try {
        await sendMessageToSQS(topic, partition, offset, value);
      } catch (err) {
        log.error("Error sending message to SQS:", err);
      }
    }
  });

  // Graceful shutdown on SIGINT
  process.on("SIGINT", async () => {
    log.info("Disconnecting Kafka consumer...");
    await consumer.disconnect();
    process.exit(0);
  });
}

// --------------------
// Lambda Handlers (for AWS deployment)
// --------------------
export async function loggingLambdaHandler(event) {
  log.info("Logging Lambda received SQS event:", JSON.stringify(event, null, 2));
  for (const record of event.Records) {
    log.info("SQS Message:", record.body);
  }
  return { status: "logged" };
}

export async function githubProjectionLambdaHandler(event) {
  log.info("GitHub Projection Lambda received event:", JSON.stringify(event, null, 2));

  let client;
  try {
    client = await getDbClient();
  } catch (error) {
    log.error("Error connecting to Postgres", error);
    throw error;
  }

  for (const record of event.Records) {
    const bodyObj = parseMessageBody(record.body);
    if (!bodyObj) continue;
    const { resourceType, resourceId, state } = bodyObj;
    if (!isValidResourceEvent({ resourceType, resourceId })) {
      log.error("Missing resourceType or resourceId in event", record.body);
      continue;
    }
    try {
      await updateProjection(client, resourceType, resourceId, state);
      log.info(`Updated projection for ${resourceType} ${resourceId}`);
    } catch (err) {
      log.error("Error updating PostgreSQL projection", err);
    }
  }
  return { status: "success" };
}

// Alias: tansuLambdaHandler for backward compatibility; uses loggingLambdaHandler
export const tansuLambdaHandler = loggingLambdaHandler;

// --------------------
// New Extended Library Helper Functions End
// --------------------

// --------------------
// Main CLI Function
// --------------------
const HELP_TEXT = `Usage: node src/lib/main.js [--help|--diagnostics|--demo|--measure-demo|--simulate-projection|--tansu-consumer-to-sqs|--sqs-to-lambda-github-projection|--sqs-to-lambda-logger]`;

export async function main(args = process.argv.slice(2)) {
  if (args.includes("--help")) {
    console.log(HELP_TEXT);
    return;
  }

  if (args.includes("--diagnostics")) {
    console.log("Diagnostics: All systems operational.");
    return;
  }

  if (args.includes("--demo")) {
    console.log("Demo output: This is a demo run.");
    console.log("This is a demo output for demonstration purposes.");
    return;
  }

  if (args.includes("--measure-demo")) {
    console.log("Starting measure demo...");
    await measureExecutionTime(async () => {
      await new Promise(resolve => setTimeout(resolve, 100));
      console.log("Measure demo complete.");
    });
    return;
  }

  if (args.includes("--simulate-projection")) {
    await simulateProjection();
    return;
  }

  if (args.includes("--tansu-consumer-to-sqs")) {
    console.log("Starting Kafka consumer to send messages to SQS...");
    await runConsumer();
    return;
  }

  if (args.includes("--sqs-to-lambda-github-projection")) {
    const sampleEvent = {
      Records: [
        {
          body: JSON.stringify({
            resourceType: "repository",
            resourceId: "tansu-sqs-bridge",
            state: { stars: 285, forks: 6, openIssues: 14 }
          })
        }
      ]
    };
    console.log("Running GitHub Projection Lambda Handler with sample event...");
    await githubProjectionLambdaHandler(sampleEvent);
    return;
  }

  if (args.includes("--sqs-to-lambda-logger")) {
    const sampleEvent = {
      Records: [{ body: "Sample message from Tansu consumer" }]
    };
    console.log("Running Logging Lambda Handler with sample event...");
    await loggingLambdaHandler(sampleEvent);
    return;
  }

  console.log(`Run with: ${JSON.stringify(args)}`);
  return;
}

// Export diagnostics function for external use/testing.
export function diagnostics() {
  return "Diagnostics: All systems operational.";
}

// --------------------
// If run directly, call main() with CLI arguments.
// Prevent execution during test runs by checking a VITEST flag.
// --------------------
if (process.argv[1] === fileURLToPath(import.meta.url) && !process.env.VITEST) {
  main(process.argv.slice(2)).catch((err) => {
    log.error("Fatal error:", err);
    process.exit(1);
  });
}
