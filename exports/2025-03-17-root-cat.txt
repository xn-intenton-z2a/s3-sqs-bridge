./README.md
==== Content of ./README.md ====
# S3 SQS Bridge (Versioned Event Replay Solution)

This repository provides a production-ready, event-driven architecture designed for replaying versioned events stored in an AWS S3 bucket. The solution leverages AWS SQS for reliable event delivery, AWS Lambda for real-time processing, and AWS DynamoDB for durable offset tracking. It is built to run seamlessly in both AWS and local environments (via Docker Compose with MinIO and LocalStack) and has been hardened for security, cost optimization, and operational resilience.

---

## Overview

The **S3 SQS Bridge** is engineered to support use cases that require reliable event sourcing and replay capabilities. It ensures that events stored as different versions in S3 can be processed in strict chronological order, making it ideal for audit trails, data reprocessing, and rebuilding application state. Key architectural elements include:

- **Versioned Storage (S3):** All events are stored as versions in an S3 bucket.
- **Event Replay (Reseed):** Historical events can be replayed in exact order to restore system state.
- **Real-Time Event Processing:** Incoming events are immediately forwarded to SQS for near real-time processing.
- **Offset Tracking:** DynamoDB is used to record processing progress for resumable and fault-tolerant replay.

---

## Key Features

- **Reliable Storage:** Uses an AWS S3 bucket with versioning enabled to persist events.
- **Event Replay Mechanism:** Supports a reseed job that lists, sorts, and replays S3 object versions in chronological order.
- **Real-Time Processing:** Forwards S3 events to an SQS queue with built-in exponential backoff and retry logic.
- **Low Idle Cost:** Designed to run on Fargate Spot with zero desired instances until needed.
- **Enhanced Security:** Containers run as non-root users; IAM policies follow a least-privilege principle.
- **Robust Logging and Monitoring:** Structured JSON logs facilitate monitoring and troubleshooting.

---

## Project Structure

```text
.
├── Dockerfile
├── package.json
├── cdk.json
├── pom.xml
├── compose.yml
├── entrypoint.sh
├── src/lib/main.js
├── aws/main/java/com/intention/S3SqsBridge/S3SqsBridgeStack.java
├── aws/test/java/com/intentïon/S3SqsBridge/S3SqsBridgeStackTest.java
└── tests/unit/main.test.js
```

Additional files include GitHub workflows (for CI/CD and maintenance scripts) and various helper scripts under the `scripts/` directory.

---

## Getting Started Locally

### Prerequisites

- [Docker Compose](https://docs.docker.com/compose/)
- [MinIO Client (mc)](https://docs.min.io/docs/minio-client-quickstart-guide.html)

### Start Local Services

1. **Launch MinIO and LocalStack:**

   ```bash
   docker compose up --detach
   ```

   The Compose file sets up:
   - **MinIO:** Simulates AWS S3 at [http://localhost:9000](http://localhost:9000) (console at port 9001).
   - **LocalStack:** Simulates AWS S3 and SQS endpoints at [http://localhost:4566](http://localhost:4566).

2. **Create a Bucket in MinIO:**

   ```bash
   mc alias set local http://localhost:9000 minioadmin minioadmin
   mc mb local/s3-sqs-bridge-bucket
   mc version enable local/s3-sqs-bridge-bucket
   ```

3. **Run the Consumer Service:**

   ```bash
   docker compose up --build --detach consumer
   ```

   The consumer service listens for S3 events and forwards them to SQS using environment variables configured to target MinIO and LocalStack.

4. **Trigger the Reseed Job:**

   ```bash
   docker compose run --rm consumer node src/lib/main.js --reseed
   ```

   This command replays all S3 events (i.e. object versions) in chronological order by sending messages to SQS.

---

## Deployment to AWS

### Prerequisites

- [Node.js 20+](https://nodejs.org/)
- [AWS CDK v2](https://docs.aws.amazon.com/cdk/latest/guide/home.html)
- [Maven](https://maven.apache.org/)

### Deploy the Stack

1. **Install Dependencies:**

   ```bash
   npm install
   mvn install
   ```

2. **Bootstrap the CDK Environment:**

   ```bash
   cdk bootstrap
   ```

3. **Deploy the Infrastructure:**

   ```bash
   cdk deploy S3SqsBridgeStack
   ```

   This deployment provisions:
   - A versioned S3 bucket.
   - An SQS queue for event delivery.
   - A DynamoDB table for offset tracking.
   - A Docker-based consumer and reseed job running on Fargate Spot (or AppRunner).
   - (Optional) AWS Lambda functions for real-time event processing.

4. **Test the CDK Stack:**

   ```bash
   mvn test
   ```

---

## Source Implementation Details

The core logic is implemented in the unified CLI entry at `src/lib/main.js`. It supports multiple modes of operation:

- **Real-Time Lambda Handler:** For use as an AWS Lambda function.
- **Reseed Job:** For replaying all historical events.
- **Health Check Server:** For container health monitoring.

### Pseudocode Example: Core Reseed Algorithm

Below is a pseudocode fragment that introduces the actual implementation of the reseed algorithm:

```javascript
// Pseudocode: List and sort all object versions from the bucket.
async function listAndSortAllObjectVersions() {
  let versions = [];
  let params = { Bucket: BUCKET_NAME };
  do {
    const response = await s3.send(new ListObjectVersionsCommand(params));
    versions.push(...response.Versions);
    // Set markers for pagination.
    params.KeyMarker = response.NextKeyMarker;
    params.VersionIdMarker = response.NextVersionIdMarker;
  } while (response.IsTruncated);

  // Sort versions by last modified date (chronologically).
  return versions.sort((a, b) => new Date(a.LastModified) - new Date(b.LastModified));
}
```

### Actual Implementation Snippets

- **Reseed Logic:**

  ```javascript
  export async function reseed() {
    logInfo(`Starting reseed job for bucket ${config.BUCKET_NAME}`);
    const versions = await listAndSortAllObjectVersions();
    logInfo(`Processing ${versions.length} versions...`);
    for (const version of versions) {
      const event = {
        bucket: config.BUCKET_NAME,
        key: version.Key,
        versionId: version.VersionId,
        eventTime: version.LastModified
      };
      await sendEventToSqs(event);
    }
    logInfo('Reseed job complete.');
  }
  ```

- **Real-Time Event Handler:**

  ```javascript
  export async function realtimeLambdaHandler(event) {
    logInfo(`Received realtime event: ${JSON.stringify(event)}`);
    for (const record of event.Records) {
      const { s3 } = record;
      const eventDetail = {
        bucket: s3.bucket.name,
        key: s3.object.key,
        eventTime: record.eventTime,
        versionId: s3.object.versionId,
        sequencer: s3.object.sequencer
      };
      await sendEventToSqs(eventDetail);
    }
  }
  ```

These fragments, along with robust retry logic and structured logging, ensure that events are processed reliably under production conditions.

---

## Running Integration Tests

- **Unit Tests (JavaScript):**

  ```bash
  npm run test:unit
  ```

- **CDK Stack Tests (Java):**

  ```bash
  mvn test
  ```

Tests have been enhanced to cover event ordering, replay functionality, configuration validation, and error handling.

---

## Cost Analysis

| Resource            | Idle Cost         | Active Cost          | Notes                           |
|---------------------|-------------------|----------------------|---------------------------------|
| **S3**              | Near-zero         | $0.023/GB            | Highly cost-effective           |
| **Lambda**          | Near-zero         | $0.20/million calls  | Efficient and event-driven      |
| **SQS**             | Near-zero         | $0.40/million msgs   | Economical for high-volume msgs |
| **Fargate (Spot)**  | Zero (when idle)  | ~$0.012/hour         | Optimal for non-constant loads  |
| **DynamoDB**        | Near-zero         | Minimal ($1/million) | Very low cost                   |

---

## Due Diligence & Throughput Considerations

### Performance

- **High Throughput:** Leverages AWS-managed services (Lambda, SQS) for scalable, low-latency processing.
- **Optimized Reseed:** Fargate/AppRunner tasks for reseed jobs are optimized for quick start and minimal overhead.

### Resilience

- **Offset Tracking:** Uses DynamoDB to maintain replay progress, ensuring continuity.
- **Retry Mechanisms:** Exponential backoff for AWS SDK calls improves resilience against transient errors.

### Scalability

- **Serverless Architecture:** Automatically scales with demand, suitable for enterprise workloads.
- **Cost-Effective:** Utilizes Fargate Spot and low-cost AWS services to minimize idle costs.

---

## Quick Deployment Guide

1. **Clone the Repository and Install Dependencies:**

   ```bash
   git clone <repository-url>
   cd s3-sqs-bridge
   npm install
   mvn install
   ```

2. **Deploy the AWS Infrastructure:**

   ```bash
   cdk bootstrap
   cdk deploy S3SqsBridgeStack
   ```

3. **Build and Run the Docker Image:**

   ```bash
   docker build -t s3-sqs-bridge .
   ```

4. **Run Locally (using Docker Compose):**

   ```bash
   docker compose up --detach
   ```

5. **Trigger the Reseed Job:**

   ```bash
   docker compose run --rm consumer node src/lib/main.js --reseed
   ```

---

## Contributing

We welcome contributions from the community. Please review the [CONTRIBUTING.md](CONTRIBUTING.md) file for guidelines on:

- Code quality and style (modern JavaScript using Node 20 with ESM)
- Testing and continuous integration requirements
- Commit message conventions and branching strategies

Whether you’re looking to use the solution as-is or fork it to build new features, your feedback and contributions help us improve the robustness and utility of the S3 SQS Bridge.

---

## License

Distributed under the [MIT License](LICENSE).

---

This README provides a thorough guide for users and contributors alike, covering all aspects from local development and testing to production deployment on AWS. The included pseudocode fragments illustrate the core logic of the solution while the detailed instructions ensure that you can deploy, run, and extend the solution with confidence../CONTRIBUTING.md
==== Content of ./CONTRIBUTING.md ====
# s3-sqs-bridge

`s3-sqs-bridge` S3 SQS Bridge for integrating Kafka and AWS SQS/Lambda/Postgres projections.

## Mission Statement

S3 SQS Bridge is an open source bridge between a S3 Kafka‑compatible broker and AWS SQS. This lightweight solution includes:

- A Dockerized Node.js s3ConsumerToSqs that listens to S3 messages and forwards them to an SQS queue.
- A Lambda function that processes S3 messages from SQS.
- A new Lambda function that listens to GitHub event messages from a separate SQS queue and creates projections of GitHub resources, storing them in a PostgresDB table for use by other Lambdas.
- All AWS infrastructure is provisioned using AWS CDK (Java, CDK 2.x).

## Guidelines

- **Code Quality:**  
  Write modern, maintainable JavaScript using Node 20 and ESM. Consider edge cases when handling container lifecycle events.

- **Testing:**  
  Robust testing is essential—please add unit and integration tests for all new features.

- **Commit Messages:**  
  Use clear, descriptive commit messages that summarize your changes effectively.

- **Collaboration:**  
  Engage actively in GitHub discussions, issues, and PR reviews. Your feedback helps us continually refine s3-sqs-bridge.

## Agentic contribution house choice options (programmatically parsed): START

Workflow schedule: schedule-1

## Issue House Choice Options

generic activities:
- Create, vary or extend a feature in the source file as you can inline with the Mission Statement if it's useful to do so. Update the Change Log in README.md (or say what was checked).
- Create, vary or extend a test in the test file if it's useful to do so. Update the Change Log in README.md (or say what was checked).
- Update the source file by applying the Mission Statement to prune any "drift" from the source file. Update the Change Log in README.md (or say what was checked).
- Ensure the source is consistently styled and arranged in a way that makes it easy to follow the flow of execution. Update the Change Log in README.md (or say what was checked).

undocumented chores:
- Refresh the README, consulting the guidance in CONTRIBUTING.md while retaining any relevant content and pruning irrelevant content.
- Create detailed examples in the README showing how the features would be deployed and used.
- Dry run the code and ensure both; any primary flows and likely exception paths are tested.
- Ensure the test coverage is consistent and the tests organised with tests for similar areas grouped together.

## Agentic contribution house choice options (programmatically parsed): END

unused repository specific activities:
- Create, vary or extend as many library functions as you can that deliver the spirit of this CONTRIBUTING.md Update the Change Log in README.md (or say what was checked).

unused generic activities:
- Find anything that might be a "simulated" or "demo" implementation and switch to a real implementation. Update the Change Log in README.md (or say what was checked).
- Consider alternate code paths that could be explicitly handled to improve the range of supported behaviours. Update the Change Log in README.md (or say what was checked).
- Look for code that could be simplified using a library and introduce that library. Update the Change Log in README.md (or say what was checked).

unused undocumented chores:
- Look for any duplicated code that could be usefully abstracted out to become shared code and implement that abstraction.
- Dry-run any examples in comments or the README against the current code and if they are not accurate or if they could cover more features, update the docs or code to be accurate.
- Ensure the main function so that it generates some demo output without an over the wire call, and hint a CLI switch that will do the real call.

### Deploying the AWS Infrastructure

From the `cdk/` directory:

```bash
cd cdk
mvn clean package
cdk deploy
```

This deploys the SQS queue, Lambda functions, PostgresDB table, and App Runner service.

## Contributing

We welcome contributions! Please review our [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines on how to contribute effectively.

## License

Released under the MIT License (see [LICENSE](./LICENSE)).
./package.json
==== Content of ./package.json ====
{
  "name": "@xn-intenton-z2a/s3-sqs-bridge",
  "version": "0.1.5",
  "description": "S3 SQS Bridge for integrating Kafka, AWS SQS, Lambda, and Postgres projections.",
  "type": "module",
  "main": "src/lib/main.js",
  "scripts": {
    "build": "echo 'Nothing to build'",
    "formatting": "prettier --check .",
    "formatting-fix": "prettier --write .",
    "linting": "eslint .",
    "linting-json": "eslint --format=@microsoft/eslint-formatter-sarif .",
    "linting-fix": "eslint --fix .",
    "update-to-minor": "npx ncu --upgrade --enginesNode --target minor --verbose --install always",
    "update-to-greatest": "npx ncu --upgrade --enginesNode --target greatest --verbose --install always --reject 'alpha'",
    "test": "vitest",
    "test:unit": "vitest --coverage",
    "start": "node src/lib/main.js",
    "diagnostics": "node src/lib/main.js",
    "sqs-to-lambda-logger": "node src/lib/main.js --sqs-to-lambda-logger",
    "sqs-to-lambda-github-projection": "node src/lib/main.js --sqs-to-lambda-github-projection",
    "s3-consumer-to-sqs": "node src/lib/main.js --s3-consumer-to-sqs"
  },
  "keywords": [
    "kafka",
    "sqs",
    "lambda",
    "postgres",
    "aws"
  ],
  "author": "Your Name",
  "license": "MIT",
  "dependencies": {
    "@aws-sdk/client-dynamodb": "^3.307.0",
    "@aws-sdk/client-s3": "^3.307.0",
    "@aws-sdk/client-sqs": "^3.307.0",
    "dotenv": "^16.4.7",
    "express": "^4.21.2",
    "kafkajs": "^2.2.4",
    "pg": "^8.13.3",
    "zod": "^3.24.2"
  },
  "devDependencies": {
    "@microsoft/eslint-formatter-sarif": "^3.1.0",
    "@vitest/coverage-v8": "^3.0.8",
    "aws-cdk": "^2.1004.0",
    "esbuild": "^0.25.1",
    "eslint": "^9.22.0",
    "eslint-config-google": "^0.14.0",
    "eslint-config-prettier": "^10.1.1",
    "eslint-plugin-import": "^2.31.0",
    "eslint-plugin-prettier": "^5.2.3",
    "eslint-plugin-promise": "^7.2.1",
    "eslint-plugin-react": "^7.37.4",
    "eslint-plugin-security": "^3.0.1",
    "eslint-plugin-sonarjs": "^3.0.2",
    "markdown-it": "^14.1.0",
    "markdown-it-github": "^0.5.0",
    "npm-check-updates": "^17.1.15",
    "prettier": "^3.5.2",
    "vitest": "^3.0.7"
  },
  "overrides": {
    "rimraf": "^4.0.0",
    "glob": "^9.3.0",
    "@humanwhocodes/config-array": "^0.13.0",
    "@humanwhocodes/object-schema": "^2.0.3"
  },
  "engines": {
    "node": ">=20.0.0"
  },
  "files": [
    "package.json"
  ],
  "publishConfig": {
    "registry": "https://npm.pkg.github.com"
  }
}
./vitest.config.js
==== Content of ./vitest.config.js ====
import { defineConfig } from "vitest/config";

export default defineConfig({
  resolve: {
    alias: {
      "@dist": "/dist",
      "@src": "/src",
      "@tests": "/tests",
    },
  },
  test: {
    environment: "node",
    include: ["tests/unit/*.test.js"],
    coverage: {
      provider: "v8",
      reportsDirectory: "./coverage",
      reporter: ["text", "json", "html"],
      include: ["src/**/*.js"],
      exclude: ["**/dist/**", "**/entrypoint/**", "**/tests/**", "**/node_modules/**", "src/index.js", "**/exports/**"],
      threshold: {
        statements: 85,
        branches: 80,
        functions: 75,
        lines: 85,
        perFile: {
          statements: 70,
          branches: 60,
          functions: 40,
          lines: 70,
        },
      },
    },
  },
});
./jsconfig.json
==== Content of ./jsconfig.json ====
{
  "compilerOptions": {
    "baseUrl": ".",
    "// Also make path changes in vitest.config.js": "",
    "paths": {
      "@dist/*": ["dist/*"],
      "@src/*": ["src/*"],
      "@tests/*": ["tests/*"]
    }
  }
}
./eslint.config.js
==== Content of ./eslint.config.js ====
import js from "@eslint/js";
import google from "eslint-config-google";
import eslintPluginPrettierRecommended from "eslint-plugin-prettier/recommended";
import globals from "globals";
import promise from "eslint-plugin-promise";
import security from "eslint-plugin-security";
import sonarjs from "eslint-plugin-sonarjs";
import react from "eslint-plugin-react";
import importPlugin from "eslint-plugin-import";

const modifiedGoogleConfig = { ...google, rules: { ...google.rules } };
delete modifiedGoogleConfig.rules["valid-jsdoc"];
delete modifiedGoogleConfig.rules["require-jsdoc"];

/** @type {import('eslint').Linter.FlatConfig[]} */
export default [
  js.configs.recommended,
  modifiedGoogleConfig,
  eslintPluginPrettierRecommended,
  {
    plugins: {
      promise,
      security,
      sonarjs,
      react,
      import: importPlugin,
    },
    languageOptions: {
      ecmaVersion: 2023,
      sourceType: "module",
      globals: {
        ...globals.node,
      },
    },
    rules: {
      "prettier/prettier": "error",
      ...promise.configs.recommended.rules,
      ...sonarjs.configs.recommended.rules,
      "sonarjs/os-command": "off",

      // Formatting and organisation
      "no-unused-vars": ["error", { argsIgnorePattern: "^_" }],
      "no-extra-semi": 2,
      "object-curly-newline": ["error", { consistent: true }],
      "array-element-newline": ["error", "consistent", { multiline: true, minItems: 10 }],
      "import/newline-after-import": ["error", { count: 1 }],
      "camelcase": "off",

      // ESM import rules
      "import/no-amd": "error",
      "import/no-commonjs": "error",
      "import/no-import-module-exports": "error",
      "import/no-cycle": "error",
      "import/no-dynamic-require": "error",
      "import/no-self-import": "off",
      "import/no-unresolved": "off",
      "import/no-useless-path-segments": "error",
      "import/no-duplicates": "error",
      "sonarjs/fixme-tag": "warn",
    },
  },
  {
    files: ["**/*.js"],
    ignores: ["**/tests/**/*.js", "**/*.test.js", "eslint.config.js"],
    rules: {
      ...security.configs.recommended.rules,
      "security/detect-non-literal-fs-filename": "off",
      "security/detect-non-literal-regexp": "off",
      "security/detect-object-injection": "off",
    },
  },
  {
    settings: {
      react: {
        version: "18",
      },
    },
  },
  {
    ignores: ["build/", "coverage/", "dist/", "exports/", "node_modules/", "eslint.config.js"],
  },
];
./.prettierrc
==== Content of ./.prettierrc ====
{
  "singleQuote": false,
  "trailingComma": "all",
  "printWidth": 120,
  "tabWidth": 2,
  "useTabs": false,
  "quoteProps": "consistent",
  "overrides": [
    {
      "files": ".prettierrc",
      "options": { "parser": "json" }
    }
  ]
}
./LICENSE
==== Content of ./LICENSE ====
MIT License

Copyright (c) 2025 intentïon

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
./.prettierrc
==== Content of ./.prettierrc ====
{
  "singleQuote": false,
  "trailingComma": "all",
  "printWidth": 120,
  "tabWidth": 2,
  "useTabs": false,
  "quoteProps": "consistent",
  "overrides": [
    {
      "files": ".prettierrc",
      "options": { "parser": "json" }
    }
  ]
}
