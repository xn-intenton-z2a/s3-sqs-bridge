Thanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.What is the AWS CDK?The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and
    provisioning it through AWS CloudFormation.The AWS CDK consists of two primary parts:
     
     
  
      AWS CDK Construct Library – A collection
        of pre-written modular and reusable pieces of code, called constructs, that you can use, modify, and integrate to
        develop your infrastructure quickly. The goal of the AWS CDK Construct Library is to reduce the complexity required to
        define and integrate AWS services together when building applications on AWS.
    
      AWS CDK Command Line Interface (AWS CDK CLI) – A
        command line tool for interacting with CDK apps. Use the CDK CLI to create, manage, and deploy your
        AWS CDK projects. The CDK CLI is also referred to as the CDK Toolkit.
    The AWS CDK supports TypeScript, JavaScript, Python, Java,
      C#/.Net, and Go. You can use any of these supported programming languages to define
    reusable cloud components known as constructs. You compose these together into stacks and apps. Then, you deploy your CDK applications to
    AWS CloudFormation to provision or update your resources.
     
      
     
  TopicsBenefits of the AWS CDKExample of the AWS CDKAWS CDK featuresNext stepsLearn more
    Benefits of the AWS CDK
    Use the AWS CDK to develop reliable, scalable, cost-effective applications in the cloud with the considerable
      expressive power of a programming language. This approach yields many benefits, including:
    
      
       
      
       
       
       
    
        Develop and manage your infrastructure as code (IaC)
        
          Practice infrastructure as code to create, deploy, and maintain infrastructure in a
            programmatic, descriptive, and declarative way. With IaC, you treat infrastructure the same way developers treat
            code. This results in a scalable and structured approach to managing infrastructure. To learn more about IaC, see
              
              Infrastructure as code in the Introduction to DevOps on AWS Whitepaper.
          With the AWS CDK, you can put your infrastructure, application code, and configuration all in one place,
            ensuring that you have a complete, cloud-deployable system at every milestone. Employ software engineering best
            practices such as code reviews, unit tests, and source control to make your infrastructure more robust.
        
      
        Define your cloud infrastructure using general-purpose programming languages
        
          With the AWS CDK, you can use any of the following programming languages to define your cloud infrastructure:
              TypeScript, JavaScript, Python, Java,
              C#/.Net, and Go. Choose your preferred language and use programming elements like
            parameters, conditionals, loops, composition, and inheritance to define the desired outcome of your
            infrastructure.
          Use the same programming language to define your infrastructure and your application logic.
          Receive the benefits of developing infrastructure in your preferred IDE (Integrated Development Environment),
            such as syntax highlighting and intelligent code completion.
          
             
              
             
          
        
      
        Deploy infrastructure through AWS CloudFormation
        
          AWS CDK integrates with AWS CloudFormation to deploy and provision your infrastructure on AWS. AWS CloudFormation is a managed
            AWS service that offers extensive support of resource and property configurations for provisioning services on
            AWS. With AWS CloudFormation, you can perform infrastructure deployments predictably and repeatedly, with rollback on error.
            If you are already familiar with AWS CloudFormation, you don’t have to learn a new IaC management service when getting started
            with the AWS CDK.
        
      
        Get started developing your application quickly with constructs
        
          Develop faster by using and sharing reusable components called constructs. Use low-level constructs to define
            individual AWS CloudFormation resources and their properties. Use high-level constructs to quickly define larger components of
            your application, with sensible, secure defaults for your AWS resources, defining more infrastructure with less
            code.
          Create your own constructs that are customized for your unique use cases and share them across your
            organization or even with the public.
        
      
   
    Example of the AWS CDK
    The following is an example of using the AWS CDK Constructs Library to create an Amazon Elastic Container Service (Amazon ECS) service with
      AWS Fargate launch type. For more details of this example, see Example: Create an AWS Fargate service using the AWS CDK.
    
      TypeScript
          export class MyEcsConstructStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}
        

      JavaScript
          class MyEcsConstructStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is false
    });
  }
}

module.exports = { MyEcsConstructStack }
        

      Python
          class MyEcsConstructStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is False
        
      Java
          public class MyEcsConstructStack extends Stack {

    public MyEcsConstructStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public MyEcsConstructStack(final Construct scope, final String id,
            StackProps props) {
        super(scope, id, props);

        Vpc vpc = Vpc.Builder.create(this, "MyVpc").maxAzs(3).build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                .vpc(vpc).build();

        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                .cluster(cluster)
                .cpu(512)
                .desiredCount(6)
                .taskImageOptions(
                       ApplicationLoadBalancedTaskImageOptions.builder()
                               .image(ContainerImage
                                       .fromRegistry("amazon/amazon-ecs-sample"))
                               .build()).memoryLimitMiB(2048)
                .publicLoadBalancer(true).build();
    }
}
        
      C#
          public class MyEcsConstructStack : Stack
{
    public MyEcsConstructStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
    {
        var vpc = new Vpc(this, "MyVpc", new VpcProps
        {
            MaxAzs = 3
        });

        var cluster = new Cluster(this, "MyCluster", new ClusterProps
        {
            Vpc = vpc
        });

        new ApplicationLoadBalancedFargateService(this, "MyFargateService", 
            new ApplicationLoadBalancedFargateServiceProps
        {
            Cluster = cluster,
            Cpu = 512,
            DesiredCount = 6,
            TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
            {
                Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
            },
            MemoryLimitMiB = 2048,
            PublicLoadBalancer = true,
        });
    }
}
        
      Go
          func NewMyEcsConstructStack(scope constructs.Construct, id string, props *MyEcsConstructStackProps) awscdk.Stack {

	var sprops awscdk.StackProps

	if props != nil {
		sprops = props.StackProps
	}

	stack := awscdk.NewStack(scope, &id, &sprops)

	vpc := awsec2.NewVpc(stack, jsii.String("MyVpc"), &awsec2.VpcProps{
		MaxAzs: jsii.Number(3), // Default is all AZs in region
	})

	cluster := awsecs.NewCluster(stack, jsii.String("MyCluster"), &awsecs.ClusterProps{
		Vpc: vpc,
	})

	awsecspatterns.NewApplicationLoadBalancedFargateService(stack, jsii.String("MyFargateService"),
		&awsecspatterns.ApplicationLoadBalancedFargateServiceProps{
			Cluster:        cluster,           // required
			Cpu:            jsii.Number(512),  // default is 256
			DesiredCount:   jsii.Number(5),    // default is 1
			MemoryLimitMiB: jsii.Number(2048), // Default is 512
			TaskImageOptions: &awsecspatterns.ApplicationLoadBalancedTaskImageOptions{
				Image: awsecs.ContainerImage_FromRegistry(jsii.String("amazon/amazon-ecs-sample"), nil),
			},
			PublicLoadBalancer: jsii.Bool(true), // Default is false
		})

	return stack

}
        
    

    This class produces an AWS CloudFormation template of more than
        500 lines. Deploying the AWS CDK app produces more than 50 resources of the following types.

    
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
    
        
          AWS::EC2::EIP
        
      
        
          AWS::EC2::InternetGateway
        
      
        
          AWS::EC2::NatGateway
        
      
        
          AWS::EC2::Route
        
      
        
          AWS::EC2::RouteTable
        
      
        
          AWS::EC2::SecurityGroup
        
      
        
          AWS::EC2::Subnet
        
      
        
          AWS::EC2::SubnetRouteTableAssociation
        
      
        
          AWS::EC2::VPCGatewayAttachment
        
      
        
          AWS::EC2::VPC
        
      
        
          AWS::ECS::Cluster
        
      
        
          AWS::ECS::Service
        
      
        
          AWS::ECS::TaskDefinition
        
      
        
          AWS::ElasticLoadBalancingV2::Listener
        
      
        
          AWS::ElasticLoadBalancingV2::LoadBalancer
        
      
        
          AWS::ElasticLoadBalancingV2::TargetGroup
        
      
        
          AWS::IAM::Policy
        
      
        
          AWS::IAM::Role
        
      
        
          AWS::Logs::LogGroup
        
      
   
    AWS CDK features

    
     
      The AWS CDK GitHub repository
      For the official AWS CDK GitHub repository, see 
          aws-cdk. Here, you can submit issues, view our
          license, track releases, and more.
      Because the AWS CDK is open-source, the team encourages you to contribute to make it an even better tool. For
        details, see Contributing to the
          AWS Cloud Development Kit (AWS CDK).
     

    
     
      The AWS CDK API reference
      The AWS CDK Construct Library provides APIs to define your CDK application and add CDK constructs to
        the application. For more information, see the AWS CDK API Reference.
     

    
     
      The Construct Programming Model
      The Construct Programming Model (CPM) extends the concepts behind the AWS CDK into additional domains. Other tools
        using the CPM include:
      
         
         
         
      
          CDK for Terraform (CDKtf)
        
          CDK for Kubernetes (CDK8s)
        
          Projen, for building project configurations
        
     

    
     
      The Construct Hub
      The Construct Hub is an online registry where you can find, publish,
        and share open-source AWS CDK libraries.
     

   
    Next steps
    To get started with using the AWS CDK, see Getting started with the AWS CDK.
   
    Learn more
    To continue learning about the AWS CDK, see the following:
    
       
       
       
       
       
       
       
       
       
       
    
        Learn AWS CDK core concepts –
          Important concepts and terms for the AWS CDK.
      
        AWS CDK Workshop – Hands-on
          workshop to learn and use the AWS CDK.
      
        AWS CDK Patterns –
          Open-source collection of AWS serverless architecture patterns, built for the AWS CDK by AWS experts.
      
        AWS CDK code examples
           – GitHub repository of example AWS CDK projects.
      
        cdk.dev – Community-driven hub
          for the AWS CDK, including a community Slack workspace.
      
        Awesome
            CDK – GitHub repository containing a curated list of AWS CDK
          open-source projects, guides, blogs, and other resources.
      
        AWS Solutions
              Constructs
           – Vetted, configuration infrastructure as code (IaC) patterns that can easily be assembled into
          production-ready applications.
      
        AWS Developer Tools Blog – Blog posts filtered for the AWS CDK.
      
        AWS CDK on Stack
                Overflow – Questions tagged with  aws-cdk
          on Stack Overflow.
      
        AWS CDK tutorial
              for AWS Cloud9 – Tutorial on using the AWS CDK with the AWS Cloud9 development
          environment.
      
    To learn more about related topics to the AWS CDK, see the following:
    
       
       
    
        AWS CloudFormation concepts –
          Since the AWS CDK is built to work with AWS CloudFormation, we recommend that you learn and understand key AWS CloudFormation concepts.
      
        AWS Glossary
           – Definitions of key terms used across AWS.
      
    To learn more about tools related to the AWS CDK that can be used to simplify serverless application development and
      deployment, see the following:
    
       
       
    
        AWS Serverless Application Model – An
          open-source developer tool that simplifies and improves the experience of building and running serverless
          applications on AWS.
      
        AWS Chalice – A framework for writing serverless apps in
            Python.
      
  Document ConventionsCDK core conceptsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideCDK CLI commandsSpecify options and their valuesBuilt-in helpVersion reportingAuthentication with AWSSpecify Region and other configurationSpecify the app commandSpecify stacksBootstrap your AWS environmentCreate a new appList stacksSynthesize stacksDeploy stacksCompare stacksImport existing resources into a stackConfiguration (cdk.json)This is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK CLI referenceThe AWS Cloud Development Kit (AWS CDK) Command Line Interface (AWS CDK CLI), also known as the CDK Toolkit, is the primary
		tool for interacting with your AWS CDK app. It executes your app, interrogates the application model you defined, and
		produces and deploys the AWS CloudFormation templates generated by the AWS CDK. It also provides other features useful for creating and
		working with AWS CDK projects. This topic contains information about common use cases of the CDK CLI.The CDK CLI is installed with the Node Package Manager. In most cases, we recommend installing it
		globally.npm install -g aws-cdk             # install latest version
npm install -g aws-cdk@X.YY.Z      # install specific versionTipIf you regularly work with multiple versions of the AWS CDK, consider installing a matching version of the
			CDK CLI in individual CDK projects. To do this, omit -g from the npm install
			command. Then use npx aws-cdk to invoke it. This runs the local version if one exists, falling back to a
			global version if not.
		CDK CLI commands

		All CDK CLI commands start with cdk, which is followed by a subcommand (list,
				synthesize, deploy, etc.). Some subcommands have a shorter version (ls,
				synth, etc.) that is equivalent. Options and arguments follow the subcommand in any order.

		For a description of all subcommands, options, and arguments, see AWS CDK CLI command reference.

	 
		Specify options and their values

		Command line options begin with two hyphens (--). Some frequently used options have single-letter
			synonyms that begin with a single hyphen (for example, --app has a synonym -a). The order of
			options in an CDK CLI command is not important.

		All options accept a value, which must follow the option name. The value may be separated from the name by white
			space or by an equals sign =. The following two options are equivalent.

		--toolkit-stack-name MyBootstrapStack
--toolkit-stack-name=MyBootstrapStack

		Some options are flags (Booleans). You may specify true or false as their value. If you
			do not provide a value, the value is taken to be true. You may also prefix the option name with
				no- to imply false.

		# sets staging flag to true
--staging
--staging=true
--staging true

# sets staging flag to false
--no-staging
--staging=false
--staging false

		A few options, namely --context, --parameters, --plugin,
			--tags, and --trust, may be specified more than once to specify multiple values. These are
			noted as having [array] type in the CDK CLI help. For example:

		cdk bootstrap --tags costCenter=0123 --tags responsibleParty=jdoe

	 
		Built-in help
		The CDK CLI has integrated help. You can see general help about the utility and a list of the provided
			subcommands by issuing:
		cdk --help
		To see help for a particular subcommand, for example deploy, specify it before the --help
			flag.
		cdk deploy --help
		Issue cdk version to display the version of the CDK CLI. Provide this information when
			requesting support.
	 
		Version reporting
		To gain insight into how the AWS CDK is used, the constructs used by AWS CDK applications are collected and reported by
			using a resource identified as AWS::CDK::Metadata. To learn more, see Configure AWS CDK usage data reporting.
	 
		Authentication with AWS

		 There are different ways in which you can configure programmatic access to AWS resources, depending on the
			environment and the AWS access available to you.

		To choose your method of authentication and configure it for the CDK CLI, see Configure security credentials for the AWS CDK CLI.

		The recommended approach for new users developing locally, who are not given a method of authentication by their
			employer, is to set up AWS IAM Identity Center. This method includes installing the AWS CLI for ease of configuration and for regularly
			signing in to the AWS access portal. If you choose this method, your environment should contain the following
			elements after you complete the procedure for IAM Identity Center
				authentication in the AWS SDKs and Tools Reference Guide:

		
			 
			 
			 
			 

		
				The AWS CLI, which you use to start an AWS access portal session before you run your application.
			
				A shared AWSconfig file having a [default]
					profile with a set of configuration values that can be referenced from the AWS CDK. To find the location of this
					file, see Location of the shared files in the
						AWS SDKs and Tools Reference Guide.
			
				 The shared config file sets the region
					setting. This sets the default AWS Region the AWS CDK and CDK CLI use for AWS requests. 
			
				 The CDK CLI uses the profile's SSO token provider configuration to acquire credentials before sending requests to AWS. The
						sso_role_name value, which is an IAM role connected to an IAM Identity Center permission set, should allow
					access to the AWS services used in your application.
				The following sample config file shows a default profile set up with SSO token provider configuration.
					The profile's sso_session setting refers to the named sso-session section. The
						sso-session section contains settings to initiate an AWS access portal session.
				[default]
sso_session = my-sso
sso_account_id = 111122223333
sso_role_name = SampleRole
region = us-east-1
output = json

[sso-session my-sso]
sso_region = us-east-1
sso_start_url = https://provided-domain.awsapps.com/start
sso_registration_scopes = sso:account:access
			

		 
			Start an AWS access portal session
			Before accessing AWS services, you need an active AWS access portal session for the CDK CLI to use
				IAM Identity Center authentication to resolve credentials. Depending on your configured session lengths, your access will
				eventually expire and the CDK CLI will encounter an authentication error. Run the following command in the
				AWS CLI to sign in to the AWS access portal.
			aws sso login
			 If your SSO token provider configuration is using a named profile instead of the default profile, the command is
					aws sso login --profile NAME. Also specify this profile when issuing
					cdk commands using the --profile option or the AWS_PROFILE
				environment variable.
			To test if you already have an active session, run the following AWS CLI command.
			aws sts get-caller-identity
			The response to this command should report the IAM Identity Center account and permission set configured in the shared
					config file.
			NoteIf you already have an active AWS access portal session and run aws sso login, you will not be
					required to provide credentials. The sign in process may prompt you to allow the AWS CLI access to your data. Since the AWS CLI is built on top of
					the SDK for Python, permission messages may contain variations of the botocore name.
		 
	 
		Specify Region and other configuration
		The CDK CLI needs to know the AWS Region that you're deploying into and how to authenticate with AWS.
			This is needed for deployment operations and to retrieve context values during synthesis. Together, your account and
			Region make up the environment.

		Region may be specified using environment variables or in configuration files. These are the same variables and
			files used by other AWS tools such as the AWS CLI and the various AWS SDKs. The CDK CLI looks for this
			information in the following order.

		
			 
			 
			 
		
				The AWS_DEFAULT_REGION environment variable.
			
				A named profile defined in the standard AWS config file and specified using the
						--profile option on cdk commands.
			
				The [default] section of the standard AWS config file.
			

		Besides specifying AWS authentication and a Region in the [default] section, you can also add one or
			more [profile NAME] sections, where NAME is the name
			of the profile. For more information about named profiles, see Shared
				config and credentials files in the AWS SDKs and Tools Reference Guide.
		The standard AWS config file is located at ~/.aws/config (macOS/Linux)
			or %USERPROFILE%\.aws\config (Windows). For details and alternate locations, see Location of the shared config and credentials files in the
				AWS SDKs and Tools Reference Guide

		The environment that you specify in your AWS CDK app by using the stack's env property is used during
			synthesis. It's used to generate an environment-specific AWS CloudFormation template, and during deployment, it overrides the
			account or Region specified by one of the preceding methods. For more information, see Environments for the AWS CDK.

		NoteThe AWS CDK uses credentials from the same source files as other AWS tools and SDKs, including the AWS Command Line Interface. However, the AWS CDK might
				behave somewhat differently from these tools. It uses the AWS SDK for JavaScript under the hood. For complete details on setting
				up credentials for the AWS SDK for JavaScript, see Setting credentials.

		You may optionally use the --role-arn (or -r) option to specify the ARN of an IAM role
			that should be used for deployment. This role must be assumable by the AWS account being used.

	 
		Specify the app command

		Many features of the CDK CLI require one or more AWS CloudFormation templates be synthesized, which in turn requires
			running your application. The AWS CDK supports programs written in a variety of languages. Therefore, it uses a
			configuration option to specify the exact command necessary to run your app. This option can be specified in two
			ways.
		First, and most commonly, it can be specified using the app key inside the file
				cdk.json. This is in the main directory of your AWS CDK project. The CDK CLI provides an
			appropriate command when creating a new project with cdk init. Here is the cdk.json
			from a fresh TypeScript project, for instance.

		{
  "app": "npx ts-node bin/hello-cdk.ts"
}

		The CDK CLI looks for cdk.json in the current working directory when attempting to run
			your app. Because of this, you might keep a shell open in your project's main directory for issuing CDK CLI
			commands.

		The CDK CLI also looks for the app key in ~/.cdk.json (that is, in your home
			directory) if it can't find it in ./cdk.json. Adding the app command here can be useful if you usually
			work with CDK code in the same language.

		If you are in some other directory, or to run your app using a command other than the one in
				cdk.json, use the --app (or -a) option to specify it.

		cdk --app "npx ts-node bin/hello-cdk.ts" ls

		When deploying, you may also specify a directory containing synthesized cloud assemblies, such as
				cdk.out, as the value of --app. The specified stacks are deployed from this
			directory; the app is not synthesized.

	 
		Specify stacks

		Many CDK CLI commands (for example, cdk deploy) work on stacks defined in your app. If your
			app contains only one stack, the CDK CLI assumes you mean that one if you don't specify a stack
			explicitly.

		Otherwise, you must specify the stack or stacks you want to work with. You can do this by specifying the desired
			stacks by ID individually on the command line. Recall that the ID is the value specified by the second argument when
			you instantiate the stack.

		cdk synth PipelineStack LambdaStack

		You may also use wildcards to specify IDs that match a pattern.

		
			 
			 
			 
		
				? matches any single character
			
				* matches any number of characters (* alone matches all stacks)
			
				** matches everything in a hierarchy
			

		You may also use the --all option to specify all stacks.

		If your app uses CDK Pipelines, the CDK CLI understands your
			stacks and stages as a hierarchy. Also, the --all option and the * wildcard only match
			top-level stacks. To match all the stacks, use **. Also use ** to indicate all the stacks
			under a particular hierarchy.

		When using wildcards, enclose the pattern in quotes, or escape the wildcards with \. If you don't,
			your shell may try to expand the pattern to the names of files in the current directory. At best, this won't do what
			you expect; at worst, you could deploy stacks you didn't intend to. This isn't strictly necessary on Windows because
				cmd.exe does not expand wildcards, but is good practice nonetheless.

		cdk synth "*Stack"    # PipelineStack, LambdaStack, etc.
cdk synth 'Stack?'    # StackA, StackB, Stack1, etc.
cdk synth \*          # All stacks in the app, or all top-level stacks in a CDK Pipelines app
cdk synth '**'        # All stacks in a CDK Pipelines app
cdk synth 'PipelineStack/Prod/**'   # All stacks in Prod stage in a CDK Pipelines app

		NoteThe order in which you specify the stacks is not necessarily the order in which they will be processed. The
				CDK CLI accounts for dependencies between stacks when deciding the order in which to process them. For
				example, let's say that one stack uses a value produced by another (such as the ARN of a resource defined in the
				second stack). In this case, the second stack is synthesized before the first one because of this dependency. You can
				add dependencies between stacks manually using the stack's addDependency()
				method.

	 
		Bootstrap your AWS environment

		Deploying stacks with the CDK requires special dedicated AWS CDK resources to be provisioned. The cdk
				bootstrap command creates the necessary resources for you. You only need to bootstrap if you are deploying a
			stack that requires these dedicated resources. See AWS CDK bootstrapping for details.

		cdk bootstrap

		If issued with no arguments, as shown here, the cdk bootstrap command synthesizes the current app and
			bootstraps the environments its stacks will be deployed to. If the app contains environment-agnostic stacks, which
			don't explicitly specify an environment, the default account and Region are bootstrapped, or the environment specified
			using --profile.

		Outside of an app, you must explicitly specify the environment to be bootstrapped. You may also do so to bootstrap
			an environment that's not specified in your app or local AWS profile. Credentials must be configured (e.g. in
				~/.aws/credentials) for the specified account and Region. You may specify a profile that
			contains the required credentials.

		cdk bootstrap ACCOUNT-NUMBER/REGION # e.g.
cdk bootstrap 1111111111/us-east-1
cdk bootstrap --profile test 1111111111/us-east-1

		ImportantEach environment (account/region combination) to which you deploy such a stack must be bootstrapped
				separately.

		You may incur AWS charges for what the AWS CDK stores in the bootstrapped resources. Additionally, if you use
				-bootstrap-customer-key, an AWS KMS key will be created, which also incurs charges per
			environment.

		NoteEarlier versions of the bootstrap template created a KMS key by default. To avoid charges, re-bootstrap using
					--no-bootstrap-customer-key. 

		NoteCDK CLI v2 does not support the original bootstrap template, dubbed the legacy template, used by default
				with CDK v1.
		
    ImportantThe modern bootstrap template effectively grants the permissions implied by
        the --cloudformation-execution-policies to any AWS account in the
        --trust list. By default, this extends permissions to read and
        write to any resource in the bootstrapped account. Make sure to configure the bootstrapping stack with
        policies and trusted accounts that you are comfortable with.

	 
		Create a new app

		To create a new app, create a directory for it, then, inside the directory, issue cdk init.

		mkdir my-cdk-app
cd my-cdk-app
cdk init TEMPLATE --language LANGUAGE

		The supported languages (LANGUAGE) are:

		
					
						Code
						Language
					
				
					
						typescript
						TypeScript
					
					
						javascript
						JavaScript
					
					
						python
						Python
					
					
						java
						Java
					
					
						csharp
						C#
					
				

		TEMPLATE is an optional template. If the desired template is app,
			the default, you may omit it. The available templates are:

		
					
						Template
						Description
					
				
					
						app (default)
						
							Creates an empty AWS CDK app.
						
					
					
						sample-app
						
							Creates an AWS CDK app with a stack containing an Amazon SQS queue and an Amazon SNS topic.
						
					
				

		The templates use the name of the project folder to generate names for files and classes inside your new
			app.

	 
		List stacks

		To see a list of the IDs of the stacks in your AWS CDK application, enter one of the following equivalent
			commands:

		cdk list
cdk ls

		If your application contains CDK Pipelines stacks, the CDK CLI
			displays stack names as paths according to their location in the pipeline hierarchy. (For example,
				PipelineStack, PipelineStack/Prod, and
				PipelineStack/Prod/MyService.)

		If your app contains many stacks, you can specify full or partial stack IDs of the stacks to be listed. For more
			information, see Specify stacks.

		Add the --long flag to see more information about the stacks, including the stack names and their
			environments (AWS account and Region).

	 
		Synthesize stacks

		The cdk synthesize command (almost always abbreviated synth) synthesizes a stack defined
			in your app into a CloudFormation template.

		cdk synth         # if app contains only one stack
cdk synth MyStack
cdk synth Stack1 Stack2
cdk synth "*"     # all stacks in app

		NoteThe CDK CLI actually runs your app and synthesizes fresh templates before most operations (such as when
				deploying or comparing stacks). These templates are stored by default in the cdk.out directory.
				The cdk synth command simply prints the generated templates for one or more specified stacks.

		See cdk synth --help for all available options. A few of the most frequently used options are covered
			in the following section.

		 
			Specify context values
			Use the --context or -c option to pass runtime context
				values to your CDK app.

			# specify a single context value
cdk synth --context key=value MyStack

# specify multiple context values (any number)
cdk synth --context key1=value1 --context key2=value2 MyStack

			When deploying multiple stacks, the specified context values are normally passed to all of them. If you want, you
				can specify different values for each stack by prefixing the stack name to the context value.

			# different context values for each stack
cdk synth --context Stack1:key=value Stack2:key=value Stack1 Stack2

		 

		 
			Specify display format
			By default, the synthesized template is displayed in YAML format. Add the --json flag to display it
				in JSON format instead.

			cdk synth --json MyStack

		 
		 
			Specify the output directory
			Add the --output (-o) option to write the synthesized templates to a directory other
				than cdk.out.
			cdk synth --output=~/templates
		 

	 
		Deploy stacks

		The cdk deploy subcommand deploys one or more specified stacks to your AWS account.

		cdk deploy        # if app contains only one stack
cdk deploy MyStack
cdk deploy Stack1 Stack2
cdk deploy "*"    # all stacks in app

		NoteThe CDK CLI runs your app and synthesizes fresh AWS CloudFormation templates before deploying anything. Therefore,
				most command line options you can use with cdk synth (for example, --context) can also be
				used with cdk deploy.

		See cdk deploy --help for all available options. A few of the most useful options are covered in the
			following section.

		 
			Skip synthesis

			The cdk deploy command normally synthesizes your app's stacks before deploying to make sure
				that the deployment reflects the latest version of your app. If you know that you haven't changed your code since
				your last cdk synth, you can suppress the redundant synthesis step when deploying. To do so,
				specify your project's cdk.out directory in the --app option.

			cdk deploy --app cdk.out StackOne StackTwo

		 
		 
			Disable rollback

			AWS CloudFormation has the ability to roll back changes so that deployments are atomic. This means that they either succeed or
				fail as a whole. The AWS CDK inherits this capability because it synthesizes and deploys AWS CloudFormation templates. 

			Rollback makes sure that your resources are in a consistent state at all times, which is vital for production
				stacks. However, while you're still developing your infrastructure, some failures are inevitable, and rolling back
				failed deployments can slow you down.

			For this reason, the CDK CLI lets you disable rollback by adding --no-rollback to your
					cdk deploy command. With this flag, failed deployments are not rolled back. Instead, resources
				deployed before the failed resource remain in place, and the next deployment starts with the failed resource. You'll
				spend a lot less time waiting for deployments and a lot more time developing your infrastructure.

		 

		 
			Hot swapping

			Use the --hotswap flag with cdk deploy to attempt to update your AWS resources
				directly instead of generating an AWS CloudFormation change set and deploying it. Deployment falls back to AWS CloudFormation deployment if hot
				swapping is not possible.

			Currently hot swapping supports Lambda functions, Step Functions state machines, and Amazon ECS container images. The
					--hotswap flag also disables rollback (i.e., implies --no-rollback).

			ImportantHot-swapping is not recommended for production deployments.

		 


		 
			Watch mode

			The CDK CLI's watch mode ( cdk deploy --watch, or cdk watch for
				short) continuously monitors your CDK app's source files and assets for changes. It immediately performs a
				deployment of the specified stacks when a change is detected.

			By default, these deployments use the --hotswap flag, which fast-tracks deployment of changes to
				Lambda functions. It also falls back to deploying through AWS CloudFormation if you have changed infrastructure configuration. To
				have cdk watch always perform full AWS CloudFormation deployments, add the --no-hotswap flag to
					cdk watch.

			Any changes made while cdk watch is already performing a deployment are combined into a single
				deployment, which begins as soon as the in-progress deployment is complete.

			Watch mode uses the "watch" key in the project's cdk.json to determine which
				files to monitor. By default, these files are your application files and assets, but this can be changed by modifying
				the "include" and "exclude" entries in the "watch" key. The following
					cdk.json file shows an example of these entries.

			{
  "app": "mvn -e -q compile exec:java",
  "watch": {
    "include": "src/main/**",
    "exclude": "target/*"
  }
}

			cdk watch executes the "build" command from cdk.json to build your
				app before synthesis. If your deployment requires any commands to build or package your Lambda code (or anything else
				that's not in your CDK app), add it here.

			Git-style wildcards, both * and **, can be used in the "watch" and
					"build" keys. Each path is interpreted relative to the parent directory of
					cdk.json. The default value of include is **/*, meaning all files
				and directories in the project root directory. exclude is optional.

			ImportantWatch mode is not recommended for production deployments.

		 


		 
			Specify AWS CloudFormation parameters
			The CDK CLI supports specifying AWS CloudFormation parameters at deployment. You may
				provide these on the command line following the --parameters flag.

			cdk deploy MyStack --parameters uploadBucketName=UploadBucket

			To define multiple parameters, use multiple --parameters flags.

			cdk deploy MyStack --parameters uploadBucketName=UpBucket --parameters downloadBucketName=DownBucket

			If you are deploying multiple stacks, you can specify a different value of each parameter for each stack. To do
				so, prefix the name of the parameter with the stack name and a colon. Otherwise, the same value is passed to all
				stacks.

			cdk deploy MyStack YourStack --parameters MyStack:uploadBucketName=UploadBucket --parameters YourStack:uploadBucketName=UpBucket

			By default, the AWS CDK retains values of parameters from previous deployments and uses them in later deployments
				if they are not specified explicitly. Use the --no-previous-parameters flag to require all parameters to
				be specified.
		 

		 
			Specify outputs file
			If your stack declares AWS CloudFormation outputs, these are normally displayed on the screen at the conclusion of deployment.
				To write them to a file in JSON format, use the --outputs-file flag.

			cdk deploy --outputs-file outputs.json MyStack
		 

		 
			Approve security-related changes
			To protect you against unintended changes that affect your security posture, the CDK CLI prompts you to
				approve security-related changes before deploying them. You can specify the level of change that requires
				approval:
			cdk deploy --require-approval LEVEL
			LEVEL can be one of the following:

			
						
							Term
							Meaning
						
					
						
							never
							Approval is never required
						
						
							any-change
							Requires approval on any IAM or security-group-related change
						
						
							broadening (default)
							Requires approval when IAM statements or traffic rules are added; removals don't require
								approval
						
					

			The setting can also be configured in the cdk.json file.
			{
  "app": "...",
  "requireApproval": "never"
}
		 

	 
		Compare stacks

		The cdk diff command compares the current version of a stack (and its dependencies) defined in your
			app with the already-deployed versions, or with a saved AWS CloudFormation template, and displays a list of changes.

		Stack HelloCdkStack
IAM Statement Changes
┌───┬──────────────────────────────┬────────┬──────────────────────────────┬──────────────────────────────┬───────────┐
│   │ Resource                     │ Effect │ Action                       │ Principal                    │ Condition │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${Custom::S3AutoDeleteObject │ Allow  │ sts:AssumeRole               │ Service:lambda.amazonaws.com │           │
│   │ sCustomResourceProvider/Role │        │                              │                              │           │
│   │ .Arn}                        │        │                              │                              │           │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${MyFirstBucket.Arn}         │ Allow  │ s3:DeleteObject*             │ AWS:${Custom::S3AutoDeleteOb │           │
│   │ ${MyFirstBucket.Arn}/*       │        │ s3:GetBucket*                │ jectsCustomResourceProvider/ │           │
│   │                              │        │ s3:GetObject*                │ Role.Arn}                    │           │
│   │                              │        │ s3:List*                     │                              │           │
└───┴──────────────────────────────┴────────┴──────────────────────────────┴──────────────────────────────┴───────────┘
IAM Policy Changes
┌───┬────────────────────────────────────────────────────────┬────────────────────────────────────────────────────────┐
│   │ Resource                                               │ Managed Policy ARN                                     │
├───┼────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
│ + │ ${Custom::S3AutoDeleteObjectsCustomResourceProvider/Ro │ {"Fn::Sub":"arn:${AWS::Partition}:iam::aws:policy/serv │
│   │ le}                                                    │ ice-role/AWSLambdaBasicExecutionRole"}                 │
└───┴────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘
(NOTE: There may be security-related changes not in this list. See https://github.com/aws/aws-cdk/issues/1299)

Parameters
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3Bucket AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3BucketBF7A7F3F: {"Type":"String","Description":"S3 bucket for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3VersionKey AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3VersionKeyFAF93626: {"Type":"String","Description":"S3 key for asset version \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/ArtifactHash AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392ArtifactHashE56CD69A: {"Type":"String","Description":"Artifact hash for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}

Resources
[+] AWS::S3::BucketPolicy MyFirstBucket/Policy MyFirstBucketPolicy3243DEFD
[+] Custom::S3AutoDeleteObjects MyFirstBucket/AutoDeleteObjectsCustomResource MyFirstBucketAutoDeleteObjectsCustomResourceC52FCF6E
[+] AWS::IAM::Role Custom::S3AutoDeleteObjectsCustomResourceProvider/Role CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
[+] AWS::Lambda::Function Custom::S3AutoDeleteObjectsCustomResourceProvider/Handler CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F
[~] AWS::S3::Bucket MyFirstBucket MyFirstBucketB8884501
 ├─ [~] DeletionPolicy
 │   ├─ [-] Retain
 │   └─ [+] Delete
 └─ [~] UpdateReplacePolicy
     ├─ [-] Retain
     └─ [+] Delete

		To compare your app's stacks with the existing deployment:

		cdk diff MyStack

		To compare your app's stacks with a saved CloudFormation template:

		cdk diff --template ~/stacks/MyStack.old MyStack

	 
		Import existing resources into a stack

		You can use the cdk import command to bring resources under the management of CloudFormation for a
			particular AWS CDK stack. This is useful if you are migrating to AWS CDK, or are moving resources between stacks or
			changing their logical id. cdk import uses  CloudFormation resource imports. See the list of resources that can be imported here. 

		To import an existing resource into a AWS CDK stack, follow the following steps:

		
			 
			 
			 
			 
			 
			 
			 
		
				Make sure the resource is not currently being managed by any other CloudFormation stack. If it is, first set the
					removal policy to RemovalPolicy.RETAIN in the stack the resource is currently in and perform a
					deployment. Then, remove the resource from the stack and perform another deployment. This process will make sure
					that the resource is no longer managed by CloudFormation but does not delete it.
			
				Run a cdk diff to make sure there are no pending changes to the AWS CDK stack you want to import
					resources into. The only changes allowed in an "import" operation are the addition of new resources which you want
					to import.
			
				Add constructs for the resources you want to import to your stack. For example, if you want to import an Amazon S3
					bucket, add something like new s3.Bucket(this, 'ImportedS3Bucket', {});. Do not make any modifications
					to any other resource.

				You must also make sure to exactly model the state that the resource currently has into the definition. For the
					example of the bucket, be sure to include AWS KMS keys, life cycle policies, and anything else that's relevant about
					the bucket. If you do not, subsequent update operations may not do what you expect.

				You can choose whether or not to include the physical bucket name. We usually recommend to not include resource
					names into your AWS CDK resource definitions so that it becomes easier to deploy your resources multiple
					times.
			
				Run cdk import STACKNAME.
			
				If the resource names are not in your model, the CLI will prompt you to pass in the actual names of the
					resources you are importing. After this, the import starts.
			
				When cdk import reports success, the resource is now managed by AWS CDK and CloudFormation. Any
					subsequent changes you make to the resource properties in your AWS CDK app the construct configuration will be
					applied on the next deployment.
			
				To confirm that the resource definition in your AWS CDK app matches the current state of the resource, you can
					start an CloudFormation drift detection
						operation.
			

		This feature currently does not support importing resources into nested stacks.
	 
		Configuration (cdk.json)

		Default values for many CDK CLI command line flags can be stored in a project's
				cdk.json file or in the .cdk.json file in your user directory. Following is
			an alphabetical reference to the supported configuration settings.

		
					
						Key
						Notes
						CDK CLI option
					
				
					
						app
						The command that executes the CDK application.
						--app
					
					
						assetMetadata
						If false, CDK does not add metadata to resources that use assets.
						--no-asset-metadata
					
					
						bootstrapKmsKeyId
						Overrides the ID of the AWS KMS key used to encrypt the Amazon S3 deployment bucket.
						--bootstrap-kms-key-id
					
					
						build
						The command that compiles or builds the CDK application before synthesis. Not permitted in
								~/.cdk.json.
						--build
					
					
						browser
						The command for launching a Web browser for the cdk docs subcommand.
						--browser
					
					
						context
						See Context values and the AWS CDK. Context values in a configuration file will not be erased by cdk
								context --clear. (The CDK CLI places cached context values in
								cdk.context.json.)
						--context
					
					
						debug
						If true, CDK CLI emits more detailed information useful for debugging.
						--debug
					
					
						language
						The language to be used for initializing new projects.
						--language
					
					
						lookups
						If false, no context lookups are permitted. Synthesis will fail if any context lookups need
							to be performed.
						--no-lookups
					
					
						notices
						If false, suppresses the display of messages about security vulnerabilities, regressions, and
							unsupported versions.
						--no-notices
					
					
						output
						The name of the directory into which the synthesized cloud assembly will be emitted (default
								"cdk.out").
						--output
					
					
						outputsFile
						The file to which AWS CloudFormation outputs from deployed stacks will be written (in JSON format).
						--outputs-file
					
					
						pathMetadata
						If false, CDK path metadata is not added to synthesized templates.
						--no-path-metadata
					
					
						plugin
						JSON array specifying the package names or local paths of packages that extend the CDK
						--plugin
					
					
						profile
						Name of the default AWS profile used for specifying Region and account credentials.
						--profile
					
					
						progress
						If set to "events", the CDK CLI displays all AWS CloudFormation events during deployment, rather
							than a progress bar.
						--progress
					
					
						requireApproval
						Default approval level for security changes. See Approve security-related changes
						--require-approval
					
					
						rollback
						If false, failed deployments are not rolled back.
						--no-rollback
					
					
						staging
						If false, assets are not copied to the output directory (use for local debugging of the
							source files with AWS SAM).
						--no-staging
					
					
						tags
						JSON object containing tags (key-value pairs) for the stack.
						--tags
					
					
						toolkitBucketName
						The name of the Amazon S3 bucket used for deploying assets such as Lambda functions and container images (see
								Bootstrap your AWS environment.
						--toolkit-bucket-name
					
					
						toolkitStackName
						The name of the bootstrap stack (see Bootstrap your AWS environment.
						--toolkit-stack-name
					
					
						versionReporting
						If false, opts out of version reporting.
						--no-version-reporting
					
					
						watch
						JSON object containing "include" and "exclude" keys that indicate which files
							should (or should not) trigger a rebuild of the project when changed. See Watch mode.
						--watch
					
				

	Document ConventionsBuildingAWS CDK CLI command referenceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideAbout the stack APIWorking with stacksThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Introduction to AWS CDK stacksAn AWS CDK stack is the smallest single unit of deployment. It represents a collection of AWS resources that you
		define using CDK constructs. When you deploy CDK apps, the resources within a CDK stack are deployed
		together as an AWS CloudFormation stack. To learn more about AWS CloudFormation stacks, see Managing AWS resources as a single unit with AWS CloudFormation stacks
		in the AWS CloudFormation User Guide.You define a stack by extending or inheriting from the Stack construct. The following example is a common
		pattern for defining a CDK stack on a separate file, known as a stack file. Here, we extend
		or inherit the Stack class and define a constructor that accepts scope, id, and
			props. Then, we invoke the base Stack class constructor using super with the
		received scope, id, and props:

		TypeScript
				import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';

export class MyCdkStack extends cdk.Stack { 
  constructor(scope: Construct, id: string, props?: cdk.StackProps) { 
    super(scope, id, props); 
    
    // Define your constructs here

  }
}
			

		JavaScript
				const { Stack } = require('aws-cdk-lib');

class MyCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    // Define your constructs here

  }
}

module.exports = { MyCdkStack }
			

		Python
				from aws_cdk import (
  Stack,
)
from constructs import Construct

class MyCdkStack(Stack):

  def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
    super().__init__(scope, construct_id, **kwargs)

    # Define your constructs here
			

		Java
				package com.myorg;

import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;

public class MyCdkStack extends Stack {
  public MyCdkStack(final Construct scope, final String id) {  
    this(scope, id, null);
  }
  
  public MyCdkStack(final Construct scope, final String id, final StackProps props) {
    super(scope, id, props);

    // Define your constructs here
  }
}
			

		C#
				using Amazon.CDK; 
using Constructs;

namespace MyCdk
{
  public class MyCdkStack : Stack
  {
    internal MyCdkStack(Construct scope, string id, IStackProps props = null) : base(scope, id, props)
    {
      // Define your constructs here
    }
  }
}
			

		Go
				package main

import (
	"github.com/aws/aws-cdk-go/awscdk/v2"
	"github.com/aws/constructs-go/constructs/v10"
	"github.com/aws/jsii-runtime-go"
)

type CdkDemoAppStackProps struct {
	awscdk.StackProps
}

func NewCdkDemoAppStack(scope constructs.Construct, id string, props *CdkDemoAppStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	// The code that defines your stack goes here

	return stack
}

func main() {
	defer jsii.Close()

	app := awscdk.NewApp(nil)

	NewCdkDemoAppStack(app, "CdkDemoAppStack", &CdkDemoAppStackProps{
		awscdk.StackProps{
			Env: env(),
		},
	})

	app.Synth(nil)
} 

//...
			

	The previous example has only defined a stack. To create the stack, it must be instantiated within the context of your
		CDK app. A common pattern is to define your CDK app and initialize your stack on a separate file, known as
		an application file.The following is an example that creates a CDK stack named MyCdkStack. Here, the CDK app
		is created and MyCdkStack is instantiated in the context of the app:

		TypeScript
				#!/usr/bin/env node
import 'source-map-support/register';
import * as cdk from 'aws-cdk-lib';
import { MyCdkStack } from '../lib/my-cdk-stack';

const app = new cdk.App();
new MyCdkStack(app, 'MyCdkStack', {
});
			

		JavaScript
				#!/usr/bin/env node

const cdk = require('aws-cdk-lib');
const { MyCdkStack } = require('../lib/my-cdk-stack');

const app = new cdk.App();
new MyCdkStack(app, 'MyCdkStack', {
});
			

		Python
				Located in app.py:
				#!/usr/bin/env python3
import os

import aws_cdk as cdk

from my_cdk.my_cdk_stack import MyCdkStack


app = cdk.App()
MyCdkStack(app, "MyCdkStack",)

app.synth()
			

		Java
				package com.myorg;

import software.amazon.awscdk.App;
import software.amazon.awscdk.Environment;
import software.amazon.awscdk.StackProps;

import java.util.Arrays;

public class MyCdkApp {
  public static void main(final String[] args) {
    App app = new App();

    new MyCdkStack(app, "MyCdkStack", StackProps.builder()
      .build());

    app.synth();
  }
}
			

		C#
				using Amazon.CDK;
using System;
using System.Collections.Generic;
using System.Linq;

namespace MyCdk
{
  sealed class Program
  {
    public static void Main(string[] args)
    {
      var app = new App();
      new MyCdkStack(app, "MyCdkStack", new StackProps
      {});
      app.Synth();
    }
  }
}
			

		Go
				package main

import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/constructs-go/constructs/v10"
  "github.com/aws/jsii-runtime-go"
)

// ...

func main() {
  defer jsii.Close()

  app := awscdk.NewApp(nil)

  NewMyCdkStack(app, "MyCdkStack", &MyCdkStackProps{
    awscdk.StackProps{
      Env: env(),
    },
  })

  app.Synth(nil)
}

// ...
			

	The following example creates a CDK app that contains two stacks:
		TypeScript
				const app = new App();

new MyFirstStack(app, 'stack1');
new MySecondStack(app, 'stack2');

app.synth();
			
		JavaScript
				const app = new App();

new MyFirstStack(app, 'stack1');
new MySecondStack(app, 'stack2');

app.synth();
			
		Python
				app = App()

MyFirstStack(app, 'stack1')
MySecondStack(app, 'stack2')

app.synth()
			
		Java
				App app = new App();

new MyFirstStack(app, "stack1");
new MySecondStack(app, "stack2");

app.synth();
			
		C#
				var app = new App();

new MyFirstStack(app, "stack1");
new MySecondStack(app, "stack2");

app.Synth();
			
		Go
				package main

import (
	"github.com/aws/aws-cdk-go/awscdk/v2"
	"github.com/aws/constructs-go/constructs/v10"
	"github.com/aws/jsii-runtime-go"
)

type MyFirstStackProps struct {
	awscdk.StackProps
}

func NewMyFirstStack(scope constructs.Construct, id string, props *MyFirstStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	myFirstStack := awscdk.NewStack(scope, &id, &sprops)

	// The code that defines your stack goes here

	return myFirstStack
}

type MySecondStackProps struct {
	awscdk.StackProps
}

func NewMySecondStack(scope constructs.Construct, id string, props *MySecondStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	mySecondStack := awscdk.NewStack(scope, &id, &sprops)

	// The code that defines your stack goes here

	return mySecondStack
}

func main() {
	defer jsii.Close()

	app := awscdk.NewApp(nil)

	NewMyFirstStack(app, "MyFirstStack", &MyFirstStackProps{
		awscdk.StackProps{
			Env: env(),
		},
	})

	NewMySecondStack(app, "MySecondStack", &MySecondStackProps{
		awscdk.StackProps{
			Env: env(),
		},
	})

	app.Synth(nil)
}

// ...
			
	
		About the stack API
		The Stack object
			provides a rich API, including the following:
		
			 
			 
			 
			 
			 
			 
			 
			 
			 
			 
		
				Stack.of(construct) – A static method that returns the Stack in which a construct is defined. This is useful if you need to interact with a stack from
					within a reusable construct. The call fails if a stack cannot be found in scope.
			
				stack.stackName (Python: stack_name) – Returns the physical name of the stack.
					As mentioned previously, all AWS CDK stacks have a physical name that the AWS CDK can resolve during synthesis.
			
				stack.region and stack.account – Return the AWS Region and account,
					respectively, into which this stack will be deployed. These properties return one of the following:
				
					 
					 
				
						The account or Region explicitly specified when the stack was defined
					
						A string-encoded token that resolves to the AWS CloudFormation pseudo parameters for account and Region to indicate that
							this stack is environment agnostic
					
				For information about how environments are determined for stacks, see Environments for the AWS CDK.
			
				stack.addDependency(stack) (Python: stack.add_dependency(stack) – Can be used
					to explicitly define dependency order between two stacks. This order is respected by the cdk
						deploy command when deploying multiple stacks at once.
			
				stack.tags – Returns a TagManager that you can use to add or remove
					stack-level tags. This tag manager tags all resources within the stack, and also tags the stack itself when it's
					created through AWS CloudFormation.
			
				stack.partition, stack.urlSuffix (Python: url_suffix),
						stack.stackId (Python: stack_id), and stack.notificationArn (Python:
						notification_arn) – Return tokens that resolve to the respective AWS CloudFormation pseudo parameters,
					such as { "Ref": "AWS::Partition" }. These tokens are associated with the specific stack object so
					that the AWS CDK framework can identify cross-stack references.
			
				stack.availabilityZones (Python: availability_zones) – Returns the set of
					Availability Zones available in the environment in which this stack is deployed. For environment-agnostic stacks,
					this always returns an array with two Availability Zones. For environment-specific stacks, the AWS CDK queries the
					environment and returns the exact set of Availability Zones available in the Region that you specified.
			
				stack.parseArn(arn) and stack.formatArn(comps) (Python: parse_arn,
						format_arn) – Can be used to work with Amazon Resource Names (ARNs).
			
				stack.toJsonString(obj) (Python: to_json_string) – Can be used to format an
					arbitrary object as a JSON string that can be embedded in an AWS CloudFormation template. The object can include tokens,
					attributes, and references, which are only resolved during deployment.
			
				stack.templateOptions (Python: template_options) – Use to specify AWS CloudFormation
					template options, such as Transform, Description, and Metadata, for your stack.
			
	 
		Working with stacks

		Stacks are deployed as an AWS CloudFormation stack into an AWS environment. The environment covers a specific AWS account and AWS Region.

		When you run the cdk synth command for an app with multiple stacks, the cloud assembly includes a
			separate template for each stack instance. Even if the two stacks are instances of the same class, the AWS CDK emits them
			as two individual templates.

		You can synthesize each template by specifying the stack name in the cdk synth command. The following
			example synthesizes the template for stack1:

		$ cdk synth stack1

		This approach is conceptually different from how AWS CloudFormation templates are normally used, where a template can be
			deployed multiple times and parameterized through AWS CloudFormation parameters. Although AWS CloudFormation parameters can be
			defined in the AWS CDK, they are generally discouraged because AWS CloudFormation parameters are resolved only during deployment. This
			means that you cannot determine their value in your code.

		For example, to conditionally include a resource in your app based on a parameter value, you must set up an AWS CloudFormation condition and tag the
			resource with it. The AWS CDK takes an approach where concrete templates are resolved at synthesis time. Therefore, you
			can use an if statement to check the value to determine whether a resource should be
			defined or some behavior should be applied.

		NoteThe AWS CDK provides as much resolution as possible during synthesis time to enable idiomatic and natural usage of
				your programming language.

		Like any other construct, stacks can be composed together into groups. The following code shows an example of a
			service that consists of three stacks: a control plane, a data plane, and monitoring stacks. The service construct is
			defined twice: once for the beta environment and once for the production environment.
		
			TypeScript
					import { App, Stack } from 'aws-cdk-lib';
import { Construct } from 'constructs';

interface EnvProps {
  prod: boolean;
}

// imagine these stacks declare a bunch of related resources
class ControlPlane extends Stack {}
class DataPlane extends Stack {}
class Monitoring extends Stack {}

class MyService extends Construct {

  constructor(scope: Construct, id: string, props?: EnvProps) {
  
    super(scope, id);
  
    // we might use the prod argument to change how the service is configured
    new ControlPlane(this, "cp");
    new DataPlane(this, "data");
    new Monitoring(this, "mon");  }
}

const app = new App();
new MyService(app, "beta");
new MyService(app, "prod", { prod: true });

app.synth();
				
			JavaScript
					const { App, Stack } = require('aws-cdk-lib');
const { Construct } = require('constructs');

// imagine these stacks declare a bunch of related resources
class ControlPlane extends Stack {}
class DataPlane extends Stack {}
class Monitoring extends Stack {}

class MyService extends Construct {

  constructor(scope, id, props) {
  
    super(scope, id);
  
    // we might use the prod argument to change how the service is configured
    new ControlPlane(this, "cp");
    new DataPlane(this, "data");
    new Monitoring(this, "mon");
  }
}

const app = new App();
new MyService(app, "beta");
new MyService(app, "prod", { prod: true });

app.synth();
				
			Python
					from aws_cdk import App, Stack
from constructs import Construct

# imagine these stacks declare a bunch of related resources
class ControlPlane(Stack): pass
class DataPlane(Stack): pass
class Monitoring(Stack): pass

class MyService(Construct):

  def __init__(self, scope: Construct, id: str, *, prod=False):
  
    super().__init__(scope, id)
  
    # we might use the prod argument to change how the service is configured
    ControlPlane(self, "cp")
    DataPlane(self, "data")
    Monitoring(self, "mon")
    
app = App();
MyService(app, "beta")
MyService(app, "prod", prod=True)

app.synth()  
				
			Java
					package com.myorg;

import software.amazon.awscdk.App;
import software.amazon.awscdk.Stack;
import software.constructs.Construct;

public class MyApp {

    // imagine these stacks declare a bunch of related resources
    static class ControlPlane extends Stack {
        ControlPlane(Construct scope, String id) {
            super(scope, id);
        }
    }

    static class DataPlane extends Stack {
        DataPlane(Construct scope, String id) {
            super(scope, id);
        }
    }

    static class Monitoring extends Stack {
        Monitoring(Construct scope, String id) {
            super(scope, id);
        }
    }

    static class MyService extends Construct {
        MyService(Construct scope, String id) {
            this(scope, id, false);
        }
        
        MyService(Construct scope, String id, boolean prod) {
            super(scope, id);
            
            // we might use the prod argument to change how the service is configured
            new ControlPlane(this, "cp");
            new DataPlane(this, "data");
            new Monitoring(this, "mon");         
        }
    }
    
    public static void main(final String argv[]) {
        App app = new App();

        new MyService(app, "beta");
        new MyService(app, "prod", true);
        
        app.synth();
    }
}
				
			C#
					using Amazon.CDK;
using Constructs;

// imagine these stacks declare a bunch of related resources
public class ControlPlane : Stack {
    public ControlPlane(Construct scope, string id=null) : base(scope, id) { }
}

public class DataPlane : Stack {
    public DataPlane(Construct scope, string id=null) : base(scope, id) { }
}

public class Monitoring : Stack
{
    public Monitoring(Construct scope, string id=null) : base(scope, id) { }
}

public class MyService : Construct
{
    public MyService(Construct scope, string id, Boolean prod=false) : base(scope, id)
    {
        // we might use the prod argument to change how the service is configured
        new ControlPlane(this, "cp");
        new DataPlane(this, "data");
        new Monitoring(this, "mon");
    }
}

class Program
{
    static void Main(string[] args)
    {

        var app = new App();
        new MyService(app, "beta");
        new MyService(app, "prod", prod: true);
        app.Synth();
    }
}
				

			Go
					package main

import (
	"github.com/aws/aws-cdk-go/awscdk/v2"
	"github.com/aws/constructs-go/constructs/v10"
	"github.com/aws/jsii-runtime-go"
)

type ControlPlaneStackProps struct {
	awscdk.StackProps
}

func NewControlPlaneStack(scope constructs.Construct, id string, props *ControlPlaneStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	ControlPlaneStack := awscdk.NewStack(scope, jsii.String(id), &sprops)

	// The code that defines your stack goes here

	return ControlPlaneStack
}

type DataPlaneStackProps struct {
	awscdk.StackProps
}

func NewDataPlaneStack(scope constructs.Construct, id string, props *DataPlaneStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	DataPlaneStack := awscdk.NewStack(scope, jsii.String(id), &sprops)

	// The code that defines your stack goes here

	return DataPlaneStack
}

type MonitoringStackProps struct {
	awscdk.StackProps
}

func NewMonitoringStack(scope constructs.Construct, id string, props *MonitoringStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	MonitoringStack := awscdk.NewStack(scope, jsii.String(id), &sprops)

	// The code that defines your stack goes here

	return MonitoringStack
}

type MyServiceStackProps struct {
	awscdk.StackProps
	Prod bool
}

func NewMyServiceStack(scope constructs.Construct, id string, props *MyServiceStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	MyServiceStack := awscdk.NewStack(scope, jsii.String(id), &sprops)

	NewControlPlaneStack(MyServiceStack, "cp", &ControlPlaneStackProps{
		StackProps: sprops,
	})
	NewDataPlaneStack(MyServiceStack, "data", &DataPlaneStackProps{
		StackProps: sprops,
	})
	NewMonitoringStack(MyServiceStack, "mon", &MonitoringStackProps{
		StackProps: sprops,
	})

	return MyServiceStack
}

func main() {
	defer jsii.Close()

	app := awscdk.NewApp(nil)

	betaProps := MyServiceStackProps{
		StackProps: awscdk.StackProps{
			Env: env(),
		},
		Prod: false,
	}

	NewMyServiceStack(app, "beta", &betaProps)

	prodProps := MyServiceStackProps{
		StackProps: awscdk.StackProps{
			Env: env(),
		},
		Prod: true,
	}

	NewMyServiceStack(app, "prod", &prodProps)

	app.Synth(nil)
}

// ...
				
		

		This AWS CDK app eventually consists of six stacks, three for each environment:
		$ cdk ls
    
betacpDA8372D3
betadataE23DB2BA
betamon632BD457
prodcp187264CE
proddataF7378CE5
prodmon631A1083

		The physical names of the AWS CloudFormation stacks are automatically determined by the AWS CDK based on the stack's construct
			path in the tree. By default, a stack's name is derived from the construct ID of the Stack object.
			However, you can specify an explicit name by using the stackName prop (in Python,
			stack_name), as follows.
		
			TypeScript
					new MyStack(this, 'not:a:stack:name', { stackName: 'this-is-stack-name' });
				
			JavaScript
					new MyStack(this, 'not:a:stack:name', { stackName: 'this-is-stack-name' });
				
			Python
					MyStack(self, "not:a:stack:name", stack_name="this-is-stack-name")
				
			Java
					new MyStack(this, "not:a:stack:name", StackProps.builder()
    .StackName("this-is-stack-name").build());
				
			C#
					new MyStack(this, "not:a:stack:name", new StackProps
{
    StackName = "this-is-stack-name"
});
				
		

		
		 
			Working with nested stacks

			A nested stack is a CDK stack that you create inside another stack, known as the
				parent stack. You create nested stacks using the NestedStack construct.

			By using nested stacks, you can organize resources across multiple stacks. Nested stacks also offer a way around
				the AWS CloudFormation 500-resource limit for stacks. A nested stack counts as only one resource in the stack that contains it.
				However, it can contain up to 500 resources, including additional nested stacks.

			The scope of a nested stack must be a Stack or NestedStack construct. The nested stack
				doesn't need to be declared lexically inside its parent stack. It is necessary only to pass the parent stack as the
				first parameter (scope) when instantiating the nested stack. Aside from this restriction, defining
				constructs in a nested stack works exactly the same as in an ordinary stack.

			At synthesis time, the nested stack is synthesized to its own AWS CloudFormation template, which is uploaded to the AWS CDK
				staging bucket at deployment. Nested stacks are bound to their parent stack and are not treated as independent
				deployment artifacts. They aren't listed by cdk list, and they can't be deployed by cdk
					deploy.

			References between parent stacks and nested stacks are automatically translated to stack parameters and outputs
				in the generated AWS CloudFormation templates, as with any cross-stack reference.

			WarningChanges in security posture are not displayed before deployment for nested stacks. This information is
					displayed only for top-level stacks.

		 

	Document ConventionsAppsCDK stagesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideHow to create a CDK appThe construct treeThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK appsThe AWS Cloud Development Kit (AWS CDK) application or app is a collection of one or more CDK stacks. Stacks are a collection of one or more constructs,
    which define AWS resources and properties. Therefore, the overall grouping of your stacks and constructs are known as
    your CDK app.
    How to create a CDK app

    You create an app by defining an app instance in the application file of your project. To do this, you import and use the App construct from the AWS Construct Library. The
        App construct doesn't require any initialization arguments. It is the only construct that can be used as
      the root.

    The App and
          Stack classes from
      the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
      own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS resources
      must be defined, directly or indirectly, within the scope of a Stack construct. Stack
      constructs are defined within the scope of an App construct.

    Apps are then synthesized to create AWS CloudFormation templates for your stacks. The following is an example:

    

      TypeScript
          const app = new App();
new MyFirstStack(app, 'hello-cdk');
app.synth();
        

      JavaScript
          const app = new App();
new MyFirstStack(app, 'hello-cdk');
app.synth();
        

      Python
          app = App()
MyFirstStack(app, "hello-cdk")
app.synth()
        

      Java
          App app = new App();
new MyFirstStack(app, "hello-cdk");
app.synth();
        

      C#
          var app = new App();
new MyFirstStack(app, "hello-cdk");
app.Synth();
        

      Go
          app := awscdk.NewApp(nil)
            
MyFirstStack(app, "MyFirstStack", &MyFirstStackProps{
  awscdk.StackProps{
    Env: env(),
  },
})

app.Synth(nil)
        
    

    Stacks within a single app can easily refer to each other's resources and properties. The AWS CDK infers dependencies
      between stacks so that they can be deployed in the correct order. You can deploy any or all of the stacks within an app
      with a single cdk deploy command.

   
    The construct tree

    Constructs are defined inside of other constructs using the scope argument that is passed to every
      construct, with the App class as the root. In this way, an AWS CDK app defines a hierarchy of constructs
      known as the construct tree.

    The root of this tree is your app, which is an instance of the App class. Within the app, you
      instantiate one or more stacks. Within stacks, you instantiate constructs, which may themselves instantiate resources
      or other constructs, and so on down the tree.

    Constructs are always explicitly defined within the scope of another construct, which creates
      relationships between constructs. Almost always, you should pass this (in Python, self) as
      the scope, indicating that the new construct is a child of the current construct. The intended pattern is that you
      derive your construct from Construct, then instantiate the constructs it uses in its constructor.

    Passing the scope explicitly allows each construct to add itself to the tree, with this behavior entirely contained
      within the Construct base
        class. It works the same way in every language supported by the AWS CDK and does not require additional
      customization.

    ImportantTechnically, it's possible to pass some scope other than this when instantiating a construct. You
        can add constructs anywhere in the tree, or even in another stack in the same app. For example, you could write a
        mixin-style function that adds constructs to a scope passed in as an argument. The practical difficulty here is that
        you can't easily ensure that the IDs you choose for your constructs are unique within someone else's scope. The
        practice also makes your code more difficult to understand, maintain, and reuse. Therefore, we recommend that you use
        the general structure of the construct tree.

    The AWS CDK uses the IDs of all constructs in the path from the tree's root to each child construct to generate the
      unique IDs required by AWS CloudFormation. This approach means that construct IDs only need to be unique within their scope, rather
      than within the entire stack as in native AWS CloudFormation. However, if you move a construct to a different scope, its generated
      stack-unique ID changes, and AWS CloudFormation won't consider it the same resource.

    The construct tree is separate from the constructs that you define in your AWS CDK code. However, it's accessible
      through any construct's node attribute, which is a reference to the node that represents that construct in
      the tree. Each node is a Node instance, the attributes of which provide access to the tree's root and to the node's
      parent scopes and children.

    
       
       
       
       
       
       
       
    
        node.children – The direct children of the construct.
      
        node.id – The identifier of the construct within its scope.
      
        node.path – The full path of the construct including the IDs of all of its parents.
      
        node.root – The root of the construct tree (the app).
      
        node.scope – The scope (parent) of the construct, or undefined if the node is the
          root.
      
        node.scopes – All parents of the construct, up to the root.
      
        node.uniqueId – The unique alphanumeric identifier for this construct within the tree (by
          default, generated from node.path and a hash).
      

    The construct tree defines an implicit order in which constructs are synthesized to resources in the final AWS CloudFormation
      template. Where one resource must be created before another, AWS CloudFormation or the AWS Construct Library generally infers the
      dependency. They then make sure that the resources are created in the right order.
    You can also add an explicit dependency between two nodes by using node.addDependency(). For more
      information, see Dependencies in the AWS CDK API Reference.

    The AWS CDK provides a simple way to visit every node in the construct tree and perform an operation on each one. For
      more information, see Aspects and the AWS CDK.

  Document ConventionsProjectsCDK stacksDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS WhitepapersAWS WhitepaperInfrastructure as code
      A fundamental principle of DevOps is to treat infrastructure the same way developers treat code. 
      Application code has a defined format and syntax. If the code is not written according to the 
      rules of the programming language, applications cannot be created. Code is stored in a version 
      management or source control system that logs a history of code development, changes, and bug 
      fixes. When code is compiled or built into applications, we expect a consistent application to 
      be created, and the build is repeatable and reliable.
     Practicing infrastructure as code means applying the
    same rigor of application code development to infrastructure provisioning. All configurations
    should be defined in a declarative way and stored in a source control system such as AWS CodeCommit, the same as application code.
    Infrastructure provisioning, orchestration, and deployment should also support the use of the
    infrastructure as code. Infrastructure was traditionally provisioned using a combination of scripts and manual
    processes. Sometimes these scripts were stored in version control systems or documented step by
    step in text files or run-books. Often the person writing the run books is not the same person
    executing these scripts or following through the run-books. If these scripts or runbooks are not
    updated frequently, they can potentially become a show-stopper in deployments. This results in
    the creation of new environments not always being repeatable, reliable, or consistent.In contrast, AWS provides a DevOps-focused way of creating and maintaining infrastructure.
    Similar to the way software developers write application code, AWS provides services that
    enable the creation, deployment and maintenance of infrastructure in a programmatic,
    descriptive, and declarative way. These services provide rigor, clarity, and reliability. The
    AWS services discussed in this paper are core to a DevOps methodology and form the
    underpinnings of numerous higher-level AWS DevOps principles and practices.AWS offers the following services to define infrastructure as code.ServicesAWS CloudFormationAWS Serverless Application ModelAWS Cloud Development Kit (AWS CDK)AWS Cloud Development Kit for KubernetesAWS Cloud Development Kit for TerraformAWS Cloud Control APIDocument ConventionsAWS Elastic Beanstalk deployment strategiesAWS CloudFormationDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideCreate a CDK projectCreate a Fargate serviceClean upThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Example: Create an AWS Fargate service using the AWS CDKIn this example, we show you how to create an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster that's
		fronted by an internet-facing Application Load Balancer from an image on Amazon ECR.Amazon ECS is a highly scalable, fast, container management service that makes it easy to run, stop, and manage
			Docker containers on a cluster. You can host your cluster on serverless infrastructure that's managed by
		Amazon ECS by launching your services or tasks using the Fargate launch type. For more control, you can host your tasks on a
		cluster of Amazon Elastic Compute Cloud (Amazon EC2) instances that you manage by using the Amazon EC2 launch type.In this example, we launch some services using the Fargate launch type. If you've used the AWS Management Console to create a
		Fargate service, you know that there are many steps to follow to accomplish that task. AWS has several tutorials and
		documentation topics that walk you through creating a Fargate service, including:
		 

		 

		 
	
			How to Deploy Docker
					Containers - AWS
		
			Setting Up with Amazon
					ECS
		
			Getting Started with Amazon ECS Using
					Fargate
		This example creates a similar Fargate service using the AWS CDK.The Amazon ECS construct used in this example helps you use AWS services by providing the following benefits:
		 

		 

		 

		 

		 

		 

		 

		 
	
			Automatically configures a load balancer.
		
			Automatically opens a security group for load balancers. This enables load balancers to communicate with
				instances without having to explicitly create a security group.
		
			Automatically orders dependency between the service and the load balancer attaching to a target group, where the
				AWS CDK enforces the correct order of creating the listener before an instance is created.
		
			Automatically configures user data on automatically scaling groups. This creates the correct configuration to
				associate a cluster to AMIs.
		
			Validates parameter combinations early. This exposes AWS CloudFormation issues earlier, thus saving deployment time. For
				example, depending on the task, it's easy to improperly configure the memory settings. Previously, we would not
				encounter an error until we deployed our app. But now the AWS CDK can detect a misconfiguration and emit an error when
				we synthesize our app.
		
			Automatically adds permissions for Amazon Elastic Container Registry (Amazon ECR) if we use an image from Amazon ECR.
		
			Automatically scales. The AWS CDK supplies a method so we can auto scale instances when we use an Amazon EC2 cluster.
				This happens automatically when we use an instance in a Fargate cluster.

			In addition, the AWS CDK prevents an instance from being deleted when automatic scaling tries to stop an instance,
				but either a task is running or is scheduled on that instance.

			Previously, we had to create a Lambda function to have this functionality.
		
			Provides asset support, so that we can deploy a source from our machine to Amazon ECS in one step. Previously, to use
				an application source, we had to perform several manual steps, such as uploading to Amazon ECR and creating a
					Docker image.
		ImportantThe ApplicationLoadBalancedFargateService constructs we'll be using includes numerous AWS
			components, some of which have non-trivial costs if left provisioned in our AWS account, even if we don't use them.
			Be sure to clean up (cdk destroy) if you follow along with this example.
		Create a CDK project

		We start by creating a CDK project. This is a directory that stores our AWS CDK code, including our CDK
			app.

		
			TypeScript
					mkdir MyEcsConstruct
cd MyEcsConstruct
cdk init --language typescript
				
			JavaScript
					mkdir MyEcsConstruct
cd MyEcsConstruct
cdk init --language javascript
				
			Python
					mkdir MyEcsConstruct
cd MyEcsConstruct
cdk init --language python
source .venv/bin/activate # On Windows, run '.\venv\Scripts\activate' instead
pip install -r requirements.txt
				
			Java
					mkdir MyEcsConstruct
cd MyEcsConstruct
cdk init --language java
					We may now import the Maven project into our IDE.
				
			C#
					mkdir MyEcsConstruct
cd MyEcsConstruct
cdk init --language csharp
					We may now open src/MyEcsConstruct.sln in Visual Studio.
				
		

		Next, we run the app and confirm that it creates an empty stack.
		
cdk synth

	 
		Create a Fargate service

		There are two different ways that we can run our container tasks with Amazon ECS:

		
			 

			 
		
				Use the Fargate launch type, where Amazon ECS manages the physical machines that oour containers are
					running on for us.
			
				Use the EC2 launch type, where we do the managing, such as specifying automatic scaling.
			

		For this example, we'll create a Fargate service running on an Amazon ECS cluster, fronted by an internet-facing
			Application Load Balancer.

		We add the following AWS Construct Library module imports to our stack file:

		
			TypeScript
					File: lib/my_ecs_construct-stack.ts
					import * as ec2 from "aws-cdk-lib/aws-ec2";
import * as ecs from "aws-cdk-lib/aws-ecs";
import * as ecs_patterns from "aws-cdk-lib/aws-ecs-patterns";
				
			JavaScript
					File: lib/my_ecs_construct-stack.js
					const ec2 = require("aws-cdk-lib/aws-ec2");
const ecs = require("aws-cdk-lib/aws-ecs");
const ecs_patterns = require("aws-cdk-lib/aws-ecs-patterns");
				
			Python
					File: my_ecs_construct/my_ecs_construct_stack.py
					from aws_cdk import (aws_ec2 as ec2, aws_ecs as ecs,
                     aws_ecs_patterns as ecs_patterns)
				
			Java
					File: src/main/java/com/myorg/MyEcsConstructStack.java
					import software.amazon.awscdk.services.ec2.*;
import software.amazon.awscdk.services.ecs.*;
import software.amazon.awscdk.services.ecs.patterns.*;

				
			C#
					File: src/MyEcsConstruct/MyEcsConstructStack.cs
					using Amazon.CDK.AWS.EC2;
using Amazon.CDK.AWS.ECS;
using Amazon.CDK.AWS.ECS.Patterns;
				
		

		Within our stack, we add the following code:

		
			TypeScript
					    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is true
    });
				
			JavaScript
					    const vpc = new ec2.Vpc(this, "MyVpc", {
      maxAzs: 3 // Default is all AZs in region
    });

    const cluster = new ecs.Cluster(this, "MyCluster", {
      vpc: vpc
    });

    // Create a load-balanced Fargate service and make it public
    new ecs_patterns.ApplicationLoadBalancedFargateService(this, "MyFargateService", {
      cluster: cluster, // Required
      cpu: 512, // Default is 256
      desiredCount: 6, // Default is 1
      taskImageOptions: { image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample") },
      memoryLimitMiB: 2048, // Default is 512
      publicLoadBalancer: true // Default is true
    });
					
				
			Python
					        vpc = ec2.Vpc(self, "MyVpc", max_azs=3)     # default is all AZs in region

        cluster = ecs.Cluster(self, "MyCluster", vpc=vpc)

        ecs_patterns.ApplicationLoadBalancedFargateService(self, "MyFargateService",
            cluster=cluster,            # Required
            cpu=512,                    # Default is 256
            desired_count=6,            # Default is 1
            task_image_options=ecs_patterns.ApplicationLoadBalancedTaskImageOptions(
                image=ecs.ContainerImage.from_registry("amazon/amazon-ecs-sample")),
            memory_limit_mib=2048,      # Default is 512
            public_load_balancer=True)  # Default is True
				
			Java
					        Vpc vpc = Vpc.Builder.create(this, "MyVpc")
                            .maxAzs(3)  // Default is all AZs in region
                            .build();

        Cluster cluster = Cluster.Builder.create(this, "MyCluster")
                            .vpc(vpc).build();

        // Create a load-balanced Fargate service and make it public
        ApplicationLoadBalancedFargateService.Builder.create(this, "MyFargateService")
                    .cluster(cluster)           // Required
                    .cpu(512)                   // Default is 256
                     .desiredCount(6)            // Default is 1
                     .taskImageOptions(
                             ApplicationLoadBalancedTaskImageOptions.builder()
                                     .image(ContainerImage.fromRegistry("amazon/amazon-ecs-sample"))
                                     .build())
                     .memoryLimitMiB(2048)       // Default is 512
                     .publicLoadBalancer(true)   // Default is true
                     .build();
				
			C#
					            var vpc = new Vpc(this, "MyVpc", new VpcProps
            {
                MaxAzs = 3 // Default is all AZs in region
            });

            var cluster = new Cluster(this, "MyCluster", new ClusterProps
            {
                Vpc = vpc
            });

            // Create a load-balanced Fargate service and make it public
            new ApplicationLoadBalancedFargateService(this, "MyFargateService",
                new ApplicationLoadBalancedFargateServiceProps
                {
                    Cluster = cluster,          // Required
                    DesiredCount = 6,           // Default is 1
                    TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
                    {
                        Image = ContainerImage.FromRegistry("amazon/amazon-ecs-sample")
                    },
                    MemoryLimitMiB = 2048,      // Default is 256
                    PublicLoadBalancer = true   // Default is true
                }
            );
				
		

		Next, we validate our code by running the following to synthesize our stack:
		
cdk synth

		The stack is hundreds of lines, so we won't show it here. The stack should contain one default instance, a private
			subnet and a public subnet for the three Availability Zones, and a security group.

		To deploy the stack, we run the following:

		cdk deploy

		AWS CloudFormation displays information about the dozens of steps that it takes as it deploys our app.

		Once deployment completes, we have successfully created a Fargate powered Amazon ECS service to run a
				Docker image.
		
	 
		Clean up
		
		As a general maintenance best practice, and to minimize unnecessary costs, we delete our stack when complete:
		
		cdk destroy

	Document ConventionsExample: CDK app with multiple
			stacksUse tools with the CDKDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::EC2::EIPSpecifies an Elastic IP (EIP) address and can, optionally, associate it with an Amazon
            EC2 instance.You can allocate an Elastic IP address from an address pool owned by AWS or from an address pool created from a public IPv4 address range that you have brought
            to AWS for use with your AWS resources using bring your
            own IP addresses (BYOIP). For more information, see Bring Your Own IP Addresses (BYOIP)
            in the Amazon EC2 User Guide.For more information, see Elastic IP Addresses
            in the Amazon EC2 User Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::EIP",
  "Properties" : {
      "Address" : String,
      "Domain" : String,
      "InstanceId" : String,
      "IpamPoolId" : String,
      "NetworkBorderGroup" : String,
      "PublicIpv4Pool" : String,
      "Tags" : [ Tag, ... ],
      "TransferAddress" : String
    }
}
YAMLType: AWS::EC2::EIP
Properties:
  Address: String
  Domain: String
  InstanceId: String
  IpamPoolId: String
  NetworkBorderGroup: String
  PublicIpv4Pool: String
  Tags: 
    - Tag
  TransferAddress: String
PropertiesAddress
                    An Elastic IP address or a carrier IP address in a Wavelength Zone.
                Required: NoType: StringUpdate requires: ReplacementDomain
                    The network (vpc).
                    If you define an Elastic IP address and associate it with a VPC that is defined in the
            same template, you must declare a dependency on the VPC-gateway attachment by using the
             DependsOn
                Attribute on this resource.
                Required: NoType: StringAllowed values: vpc | standardUpdate requires: ReplacementInstanceId
                    The ID of the instance.
                    ImportantUpdates to the InstanceId property may require some
                interruptions. Updates on an EIP reassociates the address on its
                associated resource.
                Required: NoType: StringUpdate requires: No interruptionIpamPoolId
                    
          The ID of an IPAM pool which has an Amazon-provided or BYOIP public IPv4 CIDR provisioned to it. For more information, see Allocate sequential Elastic IP addresses from an IPAM pool in the Amazon VPC IPAM User Guide.
                Required: NoType: StringUpdate requires: ReplacementNetworkBorderGroup
                     A unique set of Availability Zones, Local Zones, or Wavelength Zones from which AWS
      advertises IP addresses. Use this parameter to limit the IP address to this location. IP
      addresses cannot move between network border groups.
                    Use DescribeAvailabilityZones to view the network border groups.
                Required: NoType: StringUpdate requires: ReplacementPublicIpv4Pool
                    The ID of an address pool that you own. Use this parameter to let Amazon EC2 select an
            address from the address pool.
                    ImportantUpdates to the PublicIpv4Pool property may require some
                interruptions. Updates on an EIP reassociates the address on its
                associated resource.
                Required: NoType: StringUpdate requires: No interruptionTags
                    Any tags assigned to the Elastic IP address.
                    ImportantUpdates to the Tags property may require some
                interruptions. Updates on an EIP reassociates the address on its
                associated resource.
                Required: NoType: Array of TagUpdate requires: No interruptionTransferAddress
                    The Elastic IP address you are accepting for transfer. You can only accept one transferred address. For more information on Elastic IP address transfers, see Transfer Elastic IP addresses in the Amazon Virtual Private Cloud User Guide.
                Required: NoType: StringUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Elastic IP address.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.AllocationId
                            The ID that AWS assigns to represent the allocation of the address for
            use with Amazon VPC. This is returned only for VPC elastic IP addresses. For example,
            eipalloc-5723d13e.
                        PublicIp
                            The Elastic IP address.
                        Examples
            Allocate an Elastic IP addressThis example shows how to allocate an Elastic IP address and assign it
                    to an Amazon EC2 instance with the logical name myInstance.JSON"Resources": {
  "myEIP" : {
      "Type" : "AWS::EC2::EIP",
      "Properties" : {
          "InstanceId" : { "Ref" : "myInstance" }
      }
  }
}YAMLResources:
  myEIP:
    Type: AWS::EC2::EIP
    Properties:
      InstanceId: !Ref myInstance
        Document ConventionsAWS::EC2::EgressOnlyInternetGatewayTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::InternetGatewayAllocates an internet gateway for use with a VPC. After creating the Internet gateway,
         you then attach it to a VPC.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::InternetGateway",
  "Properties" : {
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::EC2::InternetGateway
Properties:
  Tags: 
    - Tag
PropertiesTags
                    Any tags to assign to the internet gateway.
                Required: NoType: Array of TagUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the internet gateway.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.InternetGatewayId
                            The ID of the internet gateway.
                        Examples
            Create an internet gatewayThe following example creates an internet gateway and assigns it a tag.JSON"Resources" : {
   "myInternetGateway" : {
      "Type" : "AWS::EC2::InternetGateway",
      "Properties" : {
        "Tags" : [ {"Key" : "stack", "Value" : "production"}]
      }
   }
}YAML  myInternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
      - Key: stack
        Value: production
        See also
                 
                 
                 
            
                    
                     CreateInternetGateway in the Amazon EC2 API
                        Reference
                
                    Internet gateways
                  in the Amazon VPC User Guide
                
                    Use the  AWS::EC2::VPCGatewayAttachment resource to associate an internet
                  gateway with a VPC
                Document ConventionsTagTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::EC2::NatGatewaySpecifies a network address translation (NAT) gateway in the specified subnet. You can
         create either a public NAT gateway or a private NAT gateway. The default is a public NAT
         gateway. If you create a public NAT gateway, you must specify an elastic IP address.With a NAT gateway, instances in a private subnet can connect to the internet, other
            AWS services, or an on-premises network using the IP address of the NAT
         gateway. For more information, see NAT gateways in the Amazon VPC User Guide.If you add a default route (AWS::EC2::Route resource) that points to a NAT
         gateway, specify the NAT gateway ID for the route's NatGatewayId
         property.ImportantWhen you associate an Elastic IP address or secondary Elastic IP address with a 
         public NAT gateway, the network border group of the Elastic IP address must match the network
         border group of the Availability Zone (AZ) that the public NAT gateway is in. Otherwise, the 
         NAT gateway fails to launch. You can see the network border group for the AZ by viewing the 
         details of the subnet. Similarly, you can view the network border group for the Elastic IP 
         address by viewing its details. For more information, see Allocate an Elastic IP address 
         in the Amazon VPC User Guide.
      SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::NatGateway",
  "Properties" : {
      "AllocationId" : String,
      "ConnectivityType" : String,
      "MaxDrainDurationSeconds" : Integer,
      "PrivateIpAddress" : String,
      "SecondaryAllocationIds" : [ String, ... ],
      "SecondaryPrivateIpAddressCount" : Integer,
      "SecondaryPrivateIpAddresses" : [ String, ... ],
      "SubnetId" : String,
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::EC2::NatGateway
Properties:
  AllocationId: String
  ConnectivityType: String
  MaxDrainDurationSeconds: Integer
  PrivateIpAddress: String
  SecondaryAllocationIds: 
    - String
  SecondaryPrivateIpAddressCount: Integer
  SecondaryPrivateIpAddresses: 
    - String
  SubnetId: String
  Tags: 
    - Tag
PropertiesAllocationId
                    [Public NAT gateway only] The allocation ID of the Elastic IP address that's associated with the NAT gateway.
           This property is required for a public NAT gateway and cannot be specified with a private NAT gateway.
                Required: ConditionalType: StringUpdate requires: ReplacementConnectivityType
                    Indicates whether the NAT gateway supports public or private connectivity. 
          The default is public connectivity.
                Required: NoType: StringAllowed values: private | publicUpdate requires: ReplacementMaxDrainDurationSeconds
                    The maximum amount of time to wait (in seconds) before forcibly releasing the IP addresses if connections are still in progress. Default value is 350 seconds.
                Required: NoType: IntegerMinimum: 1Maximum: 4000Update requires: No interruptionPrivateIpAddress
                    The private IPv4 address to assign to the NAT gateway. If you don't provide an address, a private IPv4 address will be automatically assigned.
                Required: NoType: StringUpdate requires: ReplacementSecondaryAllocationIds
                    Secondary EIP allocation IDs. For more information, see Create a NAT gateway 
            in the Amazon VPC User Guide.
                Required: NoType: Array of StringUpdate requires: No interruptionSecondaryPrivateIpAddressCount
                    [Private NAT gateway only] The number of secondary private IPv4 addresses you want to assign to the NAT gateway. For more information about secondary addresses, see Create a NAT gateway in the Amazon Virtual Private Cloud User Guide.
                    SecondaryPrivateIpAddressCount and SecondaryPrivateIpAddresses cannot be set at the same time.
                Required: NoType: IntegerMinimum: 1Update requires: No interruptionSecondaryPrivateIpAddresses
                    Secondary private IPv4 addresses. For more information about secondary addresses, see Create a NAT gateway in the Amazon Virtual Private Cloud User Guide.
                    SecondaryPrivateIpAddressCount and SecondaryPrivateIpAddresses cannot be set at the same time.
                Required: NoType: Array of StringUpdate requires: No interruptionSubnetId
                    The ID of the subnet in which the NAT gateway is located.
                Required: YesType: StringUpdate requires: ReplacementTags
                    The tags for the NAT gateway.
                Required: NoType: Array of TagUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the NAT gateway. For example,
            nat-0a12bc456789de0fg.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.NatGatewayId
                            The ID of the NAT gateway.
                        Examples
            
            NAT gatewayThe following example creates a public NAT gateway and a route that sends all 
               internet-bound traffic from the private subnet with EC2 instances to the NAT gateway. 
               A public NAT gateway uses an elastic IP address to provide it with a public IP address 
               that doesn't change. Note that the route table for the public subnet with the NAT gateway 
               must also have a route that sends all internet-bound traffic to an internet gateway,
               so that the NAT gateway can connect to the internet.JSON"NATGateway" : {
   "Type" : "AWS::EC2::NatGateway",
   "Properties" : {
      "AllocationId" : { 
          "Fn::GetAtt" : ["NATGatewayEIP", "AllocationId"] 
      },
      "SubnetId" : { 
          "Ref" : "PublicSubnet" 
      },
      "Tags" : [ 
          {"Key" : "stack", "Value" : "production" } 
      ]
     }
},
"NATGatewayEIP" : {
   "Type" : "AWS::EC2::EIP",
   "Properties" : {
      "Domain" : "vpc"
   }
},
"RouteNATGateway" : {
   "Type" : "AWS::EC2::Route",
   "Properties" : {
      "RouteTableId" : { "Ref" : "PrivateRouteTable" },
      "DestinationCidrBlock" : "0.0.0.0/0",
      "NatGatewayId" : { "Ref" : "NATGateway" }
   }
}YAMLNATGateway:
   Type: AWS::EC2::NatGateway
   Properties:
      AllocationId: !GetAtt NATGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet
      Tags:
      - Key: stack
        Value: production
NATGatewayEIP:
   Type: AWS::EC2::EIP
   Properties:
      Domain: vpc
RouteNATGateway:
   Type: AWS::EC2::Route
   Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: '0.0.0.0/0'
      NatGatewayId: !Ref NATGateway
        Document ConventionsTagTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::RouteSpecifies a route in a route table. For more information, see Routes 
         in the Amazon VPC User Guide.You must specify either a destination CIDR block or prefix list ID. You must also
         specify exactly one of the resources as the target.If you create a route that references a transit gateway in the same template where you
         create the transit gateway, you must declare a dependency on the transit gateway
         attachment. The route table cannot use the transit gateway until it has successfully
         attached to the VPC. Add a  DependsOn
            Attribute in the AWS::EC2::Route resource to explicitly declare a
         dependency on the AWS::EC2::TransitGatewayAttachment resource.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::Route",
  "Properties" : {
      "CarrierGatewayId" : String,
      "CoreNetworkArn" : String,
      "DestinationCidrBlock" : String,
      "DestinationIpv6CidrBlock" : String,
      "DestinationPrefixListId" : String,
      "EgressOnlyInternetGatewayId" : String,
      "GatewayId" : String,
      "InstanceId" : String,
      "LocalGatewayId" : String,
      "NatGatewayId" : String,
      "NetworkInterfaceId" : String,
      "RouteTableId" : String,
      "TransitGatewayId" : String,
      "VpcEndpointId" : String,
      "VpcPeeringConnectionId" : String
    }
}
YAMLType: AWS::EC2::Route
Properties:
  CarrierGatewayId: String
  CoreNetworkArn: String
  DestinationCidrBlock: String
  DestinationIpv6CidrBlock: String
  DestinationPrefixListId: String
  EgressOnlyInternetGatewayId: String
  GatewayId: String
  InstanceId: String
  LocalGatewayId: String
  NatGatewayId: String
  NetworkInterfaceId: String
  RouteTableId: String
  TransitGatewayId: String
  VpcEndpointId: String
  VpcPeeringConnectionId: String
PropertiesCarrierGatewayId
                    The ID of the carrier gateway.
                    You can only use this option when the VPC contains a subnet which is associated with a Wavelength Zone.
                Required: NoType: StringUpdate requires: No interruptionCoreNetworkArn
                    The Amazon Resource Name (ARN) of the core network.
                Required: NoType: StringUpdate requires: No interruptionDestinationCidrBlock
                    The IPv4 CIDR address block used for the destination match. Routing decisions are based on the most specific match. We modify the specified CIDR block to its canonical form; for example, if you specify 100.68.0.18/18, we modify it to 100.68.0.0/18.
                Required: ConditionalType: StringUpdate requires: ReplacementDestinationIpv6CidrBlock
                    The IPv6 CIDR block used for the destination match. Routing decisions are based on the most specific match.
                Required: ConditionalType: StringUpdate requires: ReplacementDestinationPrefixListId
                    The ID of a prefix list used for the destination match.
                Required: ConditionalType: StringUpdate requires: ReplacementEgressOnlyInternetGatewayId
                    [IPv6 traffic only] The ID of an egress-only internet gateway.
                Required: NoType: StringUpdate requires: No interruptionGatewayId
                    The ID of an internet gateway or virtual private gateway attached to your
			VPC.
                Required: NoType: StringUpdate requires: No interruptionInstanceId
                    The ID of a NAT instance in your VPC. The operation fails if you specify an instance ID unless exactly one network interface is attached.
                Required: NoType: StringUpdate requires: No interruptionLocalGatewayId
                    The ID of the local gateway.
                Required: NoType: StringUpdate requires: No interruptionNatGatewayId
                    [IPv4 traffic only] The ID of a NAT gateway.
                Required: NoType: StringUpdate requires: No interruptionNetworkInterfaceId
                    The ID of a network interface.
                Required: NoType: StringUpdate requires: No interruptionRouteTableId
                    The ID of the route table for the route.
                Required: YesType: StringUpdate requires: ReplacementTransitGatewayId
                    The ID of a transit gateway.
                Required: NoType: StringUpdate requires: No interruptionVpcEndpointId
                    The ID of a VPC endpoint. Supported for Gateway Load Balancer endpoints only.
                Required: NoType: StringUpdate requires: No interruptionVpcPeeringConnectionId
                    The ID of a VPC peering connection.
                Required: NoType: StringUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the route.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.CidrBlock
                            The IPv4 CIDR block.
                        Examples Create a route to a gatewayCreate a route to a carrier gateway
            
            Create a route to a gatewayThe following example adds a route that is added to an internet gateway.JSON
"myRoute" : {
   "Type" : "AWS::EC2::Route",
   "DependsOn" : "GatewayToInternet",
   "Properties" : {
      "RouteTableId" : { "Ref" : "myRouteTable" },
      "DestinationCidrBlock" : "0.0.0.0/0",
      "GatewayId" : { "Ref" : "myInternetGateway" }
   }
}YAML  myRoute:
    Type: AWS::EC2::Route
    DependsOn: GatewayToInternet
    Properties:
       RouteTableId:
         Ref: myRouteTable
       DestinationCidrBlock: 0.0.0.0/0
       GatewayId:
         Ref: myInternetGateway
            Create a route to a carrier gatewayThe following example creates a route to a carrier gateway.JSON"myCarrierRoute" : {
   "Type" : "AWS::EC2::Route",
   "DependsOn" : "GatewayToInternetAndCarrierNetwork",
   "Properties" : {
      "RouteTableId" : { "Ref" : "myRouteTable" },
      "DestinationCidrBlock" : "0.0.0.0/0",
      "GatewayId" : { "Ref" : "myCarrierGateway" }
   }
}   YAML myCarrierRoute:
    Type: AWS::EC2::Route
    DependsOn: GatewayToInternetAndCarrierNetwork
    Properties:
       RouteTableId:
         Ref: myRouteTable
       DestinationCidrBlock: 0.0.0.0/0
       GatewayId:
         Ref: myCarrierGateway   
        See also
                 
                 
            
                    CreateRoute in the Amazon EC2 API
                  Reference
                
                    Route
                     tables in the Amazon VPC User Guide
                Document ConventionsTagAWS::EC2::RouteServerDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::RouteTableSpecifies a route table for the specified VPC. After you create a route table, you can add
         routes and associate the table with a subnet.For more information, see Route tables 
         in the Amazon VPC User Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::RouteTable",
  "Properties" : {
      "Tags" : [ Tag, ... ],
      "VpcId" : String
    }
}
YAMLType: AWS::EC2::RouteTable
Properties:
  Tags: 
    - Tag
  VpcId: String
PropertiesTags
                    Any tags assigned to the route table.
                Required: NoType: Array of TagUpdate requires: No interruptionVpcId
                    The ID of the VPC.
                Required: YesType: StringUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the route table.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.RouteTableId
                            The ID of the route table.
                        Examples
            
            Route tableThe following example uses the VPC ID from a VPC named myVPC that was declared
               elsewhere in the same template.JSON"myRouteTable" : {
   "Type" : "AWS::EC2::RouteTable",
   "Properties" : {
      "VpcId" : { "Ref" : "myVPC" },
      "Tags" : [ { "Key" : "stack", "Value" : "production" } ]
   }
}YAML  myRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId:  
        Ref: myVPC
      Tags:
      - Key: stack
        Value: production
        See also
                 
                 
                 
                 
            
                    
                        AWS::EC2::Route
                    
                
                    CreateRouteTable in the Amazon EC2 API
                  Reference
                
                    Route
                     tables in the Amazon VPC User Guide
                
                    Tag your
                     Amazon EC2 resources in the Amazon EC2 User
                  Guide
                Document ConventionsAWS::EC2::RouteServerPropagationTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::SecurityGroupSpecifies a security group.You must specify ingress rules to allow inbound traffic. By default, no inbound 
         traffic is allowed.When you create a security group, if you do not add egress rules, we add egress
         rules that allow all outbound IPv4 and IPv6 traffic. Otherwise, we do not add them.
         After the security group is created, if you remove all egress rules that you added,
         we do not add egress rules, so no outbound traffic is allowed.If you modify a rule, CloudFormation removes the existing rule and then adds a new rule. 
         There is a brief period when neither the original rule or the new rule exists, so the 
         corresponding traffic is dropped.This type supports updates. For more information about updating stacks, see AWS CloudFormation Stacks Updates.ImportantTo cross-reference two security groups in the ingress and egress rules of those
            security groups, use the AWS::EC2::SecurityGroupEgress and AWS::EC2::SecurityGroupIngress resources to define your rules. Do not use
            the embedded ingress and egress rules in the AWS::EC2::SecurityGroup. Doing
            so creates a circular dependency, which AWS CloudFormation doesn't allow.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::SecurityGroup",
  "Properties" : {
      "GroupDescription" : String,
      "GroupName" : String,
      "SecurityGroupEgress" : [ Egress, ... ],
      "SecurityGroupIngress" : [ Ingress, ... ],
      "Tags" : [ Tag, ... ],
      "VpcId" : String
    }
}
YAMLType: AWS::EC2::SecurityGroup
Properties:
  GroupDescription: String
  GroupName: String
  SecurityGroupEgress: 
    - Egress
  SecurityGroupIngress: 
    - Ingress
  Tags: 
    - Tag
  VpcId: String
PropertiesGroupDescription
                    A description for the security group.
                    Constraints: Up to 255 characters in length
                    Valid characters: a-z, A-Z, 0-9, spaces, and ._-:/()#,@[]+=&;{}!$*
                Required: YesType: StringUpdate requires: ReplacementGroupName
                    The name of the security group. Names are case-insensitive and must be unique within the VPC.
                    Constraints: Up to 255 characters in length. Can't start with sg-.
                    Valid characters: a-z, A-Z, 0-9, spaces, and ._-:/()#,@[]+=&;{}!$*
                Required: NoType: StringUpdate requires: ReplacementSecurityGroupEgress
                    The outbound rules associated with the security group.
                Required: NoType: Array of EgressUpdate requires: Some interruptionsSecurityGroupIngress
                    The inbound rules associated with the security group.
                Required: NoType: Array of IngressUpdate requires: Some interruptionsTags
                    Any tags assigned to the security group.
                Required: NoType: Array of TagUpdate requires: No interruptionVpcId
                    The ID of the VPC for the security group. If you do not specify a VPC, the default is
             to use the default VPC for the Region. If there's no specified VPC and no default VPC, 
             security group creation fails.
                Required: ConditionalType: StringUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the security group if you specified the VpcId property.
            Otherwise, it returns the name of the security group. If you omit the VpcId property
            and need the ID of the security group, use Fn::GetAtt instead.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.GroupId
                            The ID of the security group, such as sg-94b3a1f6.
                        VpcId
                            The ID of the VPC, such as vpc-0669f8f9.
                        Examples Define basic ingress and egress rulesRemove the default ruleAllow ping requests
            
            Define basic ingress and egress rulesThe following example specifies a security group with an ingress and egress rule.
            JSON"InstanceSecurityGroup" : {
    "Type" : "AWS::EC2::SecurityGroup",
    "Properties" : {
        "GroupDescription" : "Allow http to client host",
        "VpcId" : {"Ref" : "myVPC"},
        "SecurityGroupIngress" : [{
            "IpProtocol" : "tcp",
            "FromPort" : 80,
            "ToPort" : 80,
            "CidrIp" : "0.0.0.0/0"
        }],
        "SecurityGroupEgress" : [{
            "IpProtocol" : "tcp",
            "FromPort" : 80,
            "ToPort" : 80,
            "CidrIp" : "0.0.0.0/0"
        }]
    }
}YAMLInstanceSecurityGroup:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: Allow http to client host
    VpcId: !Ref myVPC
    SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: 0.0.0.0/0
    SecurityGroupEgress:
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: 0.0.0.0/0
            Remove the default ruleWhen you specify a VPC security group, Amazon EC2 creates a default egress rule
               that allows egress traffic on all ports and IP protocols to any location. The default
               rule is removed only when you specify one or more egress rules. If you want to remove
               the default rule and limit egress traffic to just the localhost (127.0.0.1/32), use
               the following example. JSON"sgwithoutegress": {
    "Type": "AWS::EC2::SecurityGroup",
    "Properties": {
        "GroupDescription": "Limits security group egress traffic",
        "SecurityGroupEgress": [{
            "CidrIp": "127.0.0.1/32",
            "IpProtocol": "-1"
        }],
        "VpcId": { "Ref": "myVPC"}
    }
}YAMLsgwithoutegress:
  Type: AWS::EC2::SecurityGroup
  Properties:
    GroupDescription: Limits security group egress traffic
    SecurityGroupEgress:
      - CidrIp: 127.0.0.1/32
        IpProtocol: "-1"
    VpcId: !Ref myVPC
            Allow ping requestsTo allow ping requests, add the ICMP protocol type and specify 8 (echo request)
               for the ICMP type and either 0 or -1 (all) for the ICMP code. JSON"SGPing" : {
    "Type" : "AWS::EC2::SecurityGroup",
    "DependsOn": "VPC",
    "Properties" : {
        "GroupDescription" : "SG to test ping",
        "VpcId" : {"Ref" : "VPC"},
        "SecurityGroupIngress" : [ 
        { 
            "IpProtocol" : "tcp", 
            "FromPort" : 22, 
            "ToPort" : 22, 
            "CidrIp" : "10.0.0.0/24" 
        },
        { 
            "IpProtocol" : "icmp", 
            "FromPort" : 8, 
            "ToPort" : -1, 
            "CidrIp" : "10.0.0.0/24" 
        }]
    }
}YAMLSGPing:
  Type: AWS::EC2::SecurityGroup
  DependsOn: VPC
  Properties:
    GroupDescription: SG to test ping
    VpcId: !Ref VPC
    SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: 10.0.0.0/24
      - IpProtocol: icmp
        FromPort: 8
        ToPort: -1
        CidrIp: 10.0.0.0/24
        See also
                 
                 
            
                    Security groups for your VPC in the Amazon VPC User
                     Guide
                
                    Amazon EC2 security groups in the Amazon EC2 User Guide
                Document ConventionsTagEgressDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::SubnetSpecifies a subnet for the specified VPC.For an IPv4 only subnet, specify an IPv4 CIDR block. If the VPC has an IPv6 CIDR block, 
         you can create an IPv6 only subnet or a dual stack subnet instead. For an IPv6 only subnet, 
         specify an IPv6 CIDR block. For a dual stack subnet, specify both an IPv4 CIDR block and 
         an IPv6 CIDR block.For more information, see Subnets for your VPC in the Amazon VPC User Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::Subnet",
  "Properties" : {
      "AssignIpv6AddressOnCreation" : Boolean,
      "AvailabilityZone" : String,
      "AvailabilityZoneId" : String,
      "CidrBlock" : String,
      "EnableDns64" : Boolean,
      "EnableLniAtDeviceIndex" : Integer,
      "Ipv4IpamPoolId" : String,
      "Ipv4NetmaskLength" : Integer,
      "Ipv6CidrBlock" : String,
      "Ipv6IpamPoolId" : String,
      "Ipv6Native" : Boolean,
      "Ipv6NetmaskLength" : Integer,
      "MapPublicIpOnLaunch" : Boolean,
      "OutpostArn" : String,
      "PrivateDnsNameOptionsOnLaunch" : PrivateDnsNameOptionsOnLaunch,
      "Tags" : [ Tag, ... ],
      "VpcId" : String
    }
}
YAMLType: AWS::EC2::Subnet
Properties:
  AssignIpv6AddressOnCreation: Boolean
  AvailabilityZone: String
  AvailabilityZoneId: String
  CidrBlock: String
  EnableDns64: Boolean
  EnableLniAtDeviceIndex: Integer
  Ipv4IpamPoolId: String
  Ipv4NetmaskLength: Integer
  Ipv6CidrBlock: String
  Ipv6IpamPoolId: String
  Ipv6Native: Boolean
  Ipv6NetmaskLength: Integer
  MapPublicIpOnLaunch: Boolean
  OutpostArn: String
  PrivateDnsNameOptionsOnLaunch: 
    PrivateDnsNameOptionsOnLaunch
  Tags: 
    - Tag
  VpcId: String
PropertiesAssignIpv6AddressOnCreation
                    Indicates whether a network interface created in this subnet receives an IPv6 address.
         The default value is false.
                    If you specify AssignIpv6AddressOnCreation, you must also specify
        an IPv6 CIDR block.
                Required: NoType: BooleanUpdate requires: No interruptionAvailabilityZone
                    The Availability Zone of the subnet.
                    If you update this property, you must also update the CidrBlock
         property.
                Required: NoType: StringUpdate requires: ReplacementAvailabilityZoneId
                    The AZ ID of the subnet.
                Required: NoType: StringUpdate requires: ReplacementCidrBlock
                    The IPv4 CIDR block assigned to the subnet.
                    If you update this property, we create a new subnet, and then delete the existing
         one.
                Required: ConditionalType: StringUpdate requires: ReplacementEnableDns64
                    Indicates whether DNS queries made to the Amazon-provided DNS Resolver in this subnet 
         should return synthetic IPv6 addresses for IPv4-only destinations.
                    NoteYou must first configure a NAT gateway in a public subnet (separate from the subnet containing the IPv6-only workloads). For example, the subnet containing the NAT gateway should have a 0.0.0.0/0 route pointing to the internet gateway. For more information, see Configure DNS64 and NAT64 in the Amazon Virtual Private Cloud User Guide.
                Required: NoType: BooleanUpdate requires: No interruptionEnableLniAtDeviceIndex
                    
            Indicates the device position for local network interfaces in this subnet. For example, 
            1 indicates local network interfaces in this subnet are the secondary 
            network interface (eth1). 
        
                Required: NoType: IntegerUpdate requires: No interruptionIpv4IpamPoolId
                    An IPv4 IPAM pool ID for the subnet.
                Required: NoType: StringUpdate requires: ReplacementIpv4NetmaskLength
                    An IPv4 netmask length for the subnet.
                Required: NoType: IntegerUpdate requires: ReplacementIpv6CidrBlock
                    The IPv6 CIDR block.
                    If you specify AssignIpv6AddressOnCreation, you must also specify
         an IPv6 CIDR block.
                Required: ConditionalType: StringUpdate requires: Some interruptionsIpv6IpamPoolId
                    An IPv6 IPAM pool ID for the subnet.
                Required: NoType: StringUpdate requires: ReplacementIpv6Native
                    Indicates whether this is an IPv6 only subnet. For more information, see Subnet basics in the Amazon Virtual Private Cloud User Guide.
                Required: NoType: BooleanUpdate requires: ReplacementIpv6NetmaskLength
                    An IPv6 netmask length for the subnet.
                Required: NoType: IntegerUpdate requires: ReplacementMapPublicIpOnLaunch
                    Indicates whether instances launched in this subnet receive a public IPv4 address. The
         default value is false.
                    AWS charges for all public IPv4 addresses, including public IPv4 addresses 
         associated with running instances and Elastic IP addresses. For more information, see the Public IPv4 Address tab 
         on the VPC pricing page.
                Required: NoType: BooleanUpdate requires: No interruptionOutpostArn
                    The Amazon Resource Name (ARN) of the Outpost.
                Required: NoType: StringUpdate requires: ReplacementPrivateDnsNameOptionsOnLaunch
                    The hostname type for EC2 instances launched into this subnet and how DNS A and AAAA record queries to the instances should be handled. For more information, see Amazon EC2 instance hostname types in the Amazon Elastic Compute Cloud User Guide.
                    Available options:
                    
                         
                         
                         
                    
                            EnableResourceNameDnsAAAARecord (true | false)
                        
                            EnableResourceNameDnsARecord (true | false)
                        
                            HostnameType (ip-name | resource-name)
                        
                Required: NoType: PrivateDnsNameOptionsOnLaunchUpdate requires: No interruptionTags
                    Any tags assigned to the subnet.
                Required: NoType: Array of TagUpdate requires: No interruptionVpcId
                    The ID of the VPC the subnet is in.
                    If you update this property, you must also update the CidrBlock
         property.
                Required: YesType: StringUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the subnet.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.AvailabilityZone
                            The Availability Zone of this subnet. For example, us-east-1a.
                        AvailabilityZoneId
                            The Availability Zone ID of this subnet. For example, use1-az1.
                        CidrBlock
                            The IPv4 CIDR blocks that are associated with the subnet.
                        Ipv6CidrBlocks
                            The IPv6 CIDR blocks that are associated with the subnet.
                        NetworkAclAssociationId
                            The ID of the network ACL that is associated with the subnet's VPC, such as
         acl-5fb85d36.
                        OutpostArn
                            The Amazon Resource Name (ARN) of the Outpost.
                        SubnetId
                            The ID of the subnet.
                        VpcId
                            The ID of the subnet's VPC, such as vpc-11ad4878.
                        Examples Subnet with an IPv4 CIDRSubnet with an IPv6 CIDR
            
            Subnet with an IPv4 CIDRThe following example creates a subnet with an IPv4 CIDR in a VPC with an IPv4
               CIDR of 10.0.0.0/16. The VPC is declared elsewhere in the same template.JSON"mySubnet" : {
   "Type" : "AWS::EC2::Subnet",
   "Properties" : {
      "VpcId" : { "Ref" : "myVPC" },
      "CidrBlock" : "10.0.0.0/24",
      "AvailabilityZone" : "us-east-1a",
      "Tags" : [ { "Key" : "stack", "Value" : "production" } ]
   }
}YAML  mySubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref myVPC
      CidrBlock: 10.0.0.0/24
      AvailabilityZone: "us-east-1a"
      Tags:
      - Key: stack
        Value: production
            Subnet with an IPv6 CIDRThe following example creates a subnet with an IPv6 CIDR in a VPC with an IPv6
               CIDR provided by Amazon. The VPC is declared elsewhere in the same template. The
               example uses the Fn:Cidr intrinsic function to select an IPv6 range with a /64 netmask for
               the subnet.JSON"mySubnet": {
   "Type": "AWS::EC2::Subnet",
   "Properties": {
      "VpcId": { "Ref": "myVPC" },
      "Ipv6Native": "true",
      "Ipv6CidrBlock": { 
         "Fn::Select": 
            [ 0, { "Fn::Cidr": [{"Fn::Select": [0, {"Fn::GetAtt": ["myVpc", "Ipv6CidrBlocks"]}]}, 1, 64 ]}]
      },
      "AssignIpv6AddressOnCreation": "true"
   }
}YAML  mySubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref myVPC
      Ipv6Native: true
      Ipv6CidrBlock: !Select [ 0, !Cidr [ !Select [ 0, !GetAtt myVpc.Ipv6CidrBlocks], 1, 64 ]]
      AssignIpv6AddressOnCreation: true
        See also
                 
                 
            
                    CreateSubnet in the Amazon EC2 API
                  Reference
                
                    VPC and
                     subnets in the Amazon VPC User Guide
                Document ConventionsVCpuCountRangeRequestPrivateDnsNameOptionsOnLaunchDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::VPCGatewayAttachmentAttaches an internet gateway, or a virtual private gateway to a VPC, enabling
         connectivity between the internet and the VPC.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::VPCGatewayAttachment",
  "Properties" : {
      "InternetGatewayId" : String,
      "VpcId" : String,
      "VpnGatewayId" : String
    }
}
YAMLType: AWS::EC2::VPCGatewayAttachment
Properties:
  InternetGatewayId: String
  VpcId: String
  VpnGatewayId: String
PropertiesInternetGatewayId
                    The ID of the internet gateway.
                    You must specify either InternetGatewayId or VpnGatewayId, but
         not both.
                Required: NoType: StringUpdate requires: No interruptionVpcId
                    The ID of the VPC.
                Required: YesType: StringUpdate requires: ReplacementVpnGatewayId
                    The ID of the virtual private gateway.
                    You must specify either InternetGatewayId or VpnGatewayId, but
         not both.
                Required: NoType: StringUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the VPC gateway attachment.For more information about using the Ref function, see Ref.Examples
            
            VPN gateway attachmentTo attach both an Internet gateway and a VPN gateway to a VPC, you must specify
               two separate AWS::EC2::VPCGatewayAttachment resources: JSON"AttachGateway" : {
   "Type" : "AWS::EC2::VPCGatewayAttachment",
   "Properties" : {
      "VpcId" : { "Ref" : "VPC" },
      "InternetGatewayId" : { "Ref" : "myInternetGateway" }
    }
},
            
"AttachVpnGateway" : {
   "Type" : "AWS::EC2::VPCGatewayAttachment",
   "Properties" : {
      "VpcId" : { "Ref" : "VPC" },
      "VpnGatewayId" : { "Ref" : "myVPNGateway" }
   }
}YAMLAttachGateway:
  Type: AWS::EC2::VPCGatewayAttachment
  Properties:
    VpcId:
       Ref: VPC
    InternetGatewayId:
       Ref: myInternetGateway
AttachVpnGateway:
  Type: AWS::EC2::VPCGatewayAttachment
  Properties:
    VpcId:
       Ref: VPC
    VpnGatewayId:
       Ref: myVPNGateway
        See also
                 
                 
            
                    AttachVpnGateway in the Amazon EC2 API
                  Reference
                
                    Internet gateways
                  in the Amazon VPC User Guide
                Document ConventionsAWS::EC2::VPCEndpointServicePermissionsAWS::EC2::VPCPeeringConnectionDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::EC2::VPCSpecifies a virtual private cloud (VPC).To add an IPv6 CIDR block to the VPC, see AWS::EC2::VPCCidrBlock.For more information, see Virtual private clouds (VPC) 
         in the Amazon VPC User Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::EC2::VPC",
  "Properties" : {
      "CidrBlock" : String,
      "EnableDnsHostnames" : Boolean,
      "EnableDnsSupport" : Boolean,
      "InstanceTenancy" : String,
      "Ipv4IpamPoolId" : String,
      "Ipv4NetmaskLength" : Integer,
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::EC2::VPC
Properties:
  CidrBlock: String
  EnableDnsHostnames: Boolean
  EnableDnsSupport: Boolean
  InstanceTenancy: String
  Ipv4IpamPoolId: String
  Ipv4NetmaskLength: Integer
  Tags: 
    - Tag
PropertiesCidrBlock
                    The IPv4 network range for the VPC, in CIDR notation. For example,
         10.0.0.0/16. We modify the specified CIDR block to its canonical form; for example, if you specify 100.68.0.18/18, we modify it to 100.68.0.0/18.
                    You must specify eitherCidrBlock or Ipv4IpamPoolId.
                Required: ConditionalType: StringUpdate requires: ReplacementEnableDnsHostnames
                    Indicates whether the instances launched in the VPC get DNS hostnames. If enabled,
         instances in the VPC get DNS hostnames; otherwise, they do not. Disabled by default for
         nondefault VPCs. For more information, see DNS attributes in your
            VPC.
                    You can only enable DNS hostnames if you've enabled DNS support.
                Required: NoType: BooleanUpdate requires: No interruptionEnableDnsSupport
                    Indicates whether the DNS resolution is supported for the VPC. If enabled, queries to
         the Amazon provided DNS server at the 169.254.169.253 IP address, or the reserved IP
         address at the base of the VPC network range "plus two" succeed. If disabled, the Amazon
         provided DNS service in the VPC that resolves public DNS hostnames to IP addresses is not
         enabled. Enabled by default. For more information, see DNS attributes in your VPC.
                Required: NoType: BooleanUpdate requires: No interruptionInstanceTenancy
                    The allowed tenancy of instances launched into the VPC.
                    
                         
                         
                    
                            default: An instance launched into the VPC runs on shared hardware
               by default, unless you explicitly specify a different tenancy during instance
               launch.
                        
                            dedicated: An instance launched into the VPC runs on dedicated
               hardware by default, unless you explicitly specify a tenancy of host 
               during instance launch. You cannot specify a tenancy of default during 
               instance launch.
                        
                    Updating InstanceTenancy requires no replacement only if you are updating
         its value from dedicated to default. Updating
         InstanceTenancy from default to dedicated
         requires replacement.
                Required: NoType: StringAllowed values: default | dedicated | hostUpdate requires: Some interruptionsIpv4IpamPoolId
                    The ID of an IPv4 IPAM pool you want to use for allocating this VPC's CIDR. For more information, see 
         What is IPAM? in the Amazon VPC IPAM User Guide.
                    You must specify eitherCidrBlock or Ipv4IpamPoolId.
                Required: ConditionalType: StringUpdate requires: ReplacementIpv4NetmaskLength
                    The netmask length of the IPv4 CIDR you want to allocate to this VPC from an Amazon VPC IP Address Manager (IPAM) pool. For more information about IPAM, see What is IPAM? in the Amazon VPC IPAM User Guide.
                Required: NoType: IntegerUpdate requires: ReplacementTags
                    The tags for the VPC.
                Required: NoType: Array of TagUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the ID of the VPC.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.CidrBlock
                            The primary IPv4 CIDR block for the VPC. For example, 10.0.0.0/16.
                        CidrBlockAssociations
                            The association IDs of the IPv4 CIDR blocks for the VPC. For example, 
         [ vpc-cidr-assoc-0280ab6b ].
                        DefaultNetworkAcl
                            The ID of the default network ACL for the VPC. For example, acl-814dafe3.
                        DefaultSecurityGroup
                            The ID of the default security group for the VPC. For example, sg-b178e0d3.
                        Ipv6CidrBlocks
                            The IPv6 CIDR blocks for the VPC. For example, [ 2001:db8:1234:1a00::/56 ].
                        VpcId
                            The ID of the VPC.
                        Examples Create a VPC with an IPv4 CIDR blockCreate a VPC with an IPv4 CIDR block and an IPv6 CIDR block
            
            Create a VPC with an IPv4 CIDR blockThe following example specifies a VPC with an IPv4 address.JSON{
   "Resources": {
       "myVPC" : {
           "Type" : "AWS::EC2::VPC",
           "Properties" : {
               "CidrBlock" : "10.0.0.0/16",
               "EnableDnsSupport" : "true",
               "EnableDnsHostnames" : "true",
               "Tags" : [ 
                   {"Key" : "stack", "Value" : "production"} 
               ]
           }
       }
   }
}YAMLResources:
  myVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
       - Key: stack
         Value: production
            Create a VPC with an IPv4 CIDR block and an IPv6 CIDR blockThe following example specifies a VPC with an IPv4 address range and an IPv6 address range.JSON{
   "Resources": {
       "myVPC" : {
           "Type" : "AWS::EC2::VPC",
           "Properties" : {
               "CidrBlock" : "10.0.0.0/16",
               "EnableDnsSupport" : "true",
               "EnableDnsHostnames" : "true",
               "Tags" : [ 
                   {"Key" : "stack", "Value" : "production"} 
               ]
           }
       },
       "ipv6CidrBlock": {
           "Type": "AWS::EC2::VPCCidrBlock",
           "Properties": {
                "VpcId": {
                    "Ref": "myVPC"
                },
                "AmazonProvidedIpv6CidrBlock": true
            }
       }
   }
}YAMLResources:
  myVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: 'true'
      EnableDnsHostnames: 'true'
      Tags:
       - Key: stack
         Value: production
  ipv6CidrBlock:
    Type: AWS::EC2::VPCCidrBlock
    Properties:
      VpcId: !Ref myVPC
      AmazonProvidedIpv6CidrBlock: true
        See also
                 
                 
            
                    CreateVpc in the Amazon EC2 API Reference
                
                    VPC and
                     subnets in the Amazon VPC User Guide
                Document ConventionsAWS::EC2::VolumeAttachmentTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::ECS::ClusterThe AWS::ECS::Cluster resource creates an Amazon Elastic Container Service
         (Amazon ECS) cluster.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ECS::Cluster",
  "Properties" : {
      "CapacityProviders" : [ String, ... ],
      "ClusterName" : String,
      "ClusterSettings" : [ ClusterSettings, ... ],
      "Configuration" : ClusterConfiguration,
      "DefaultCapacityProviderStrategy" : [ CapacityProviderStrategyItem, ... ],
      "ServiceConnectDefaults" : ServiceConnectDefaults,
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::ECS::Cluster
Properties:
  CapacityProviders: 
    - String
  ClusterName: String
  ClusterSettings: 
    - ClusterSettings
  Configuration: 
    ClusterConfiguration
  DefaultCapacityProviderStrategy: 
    - CapacityProviderStrategyItem
  ServiceConnectDefaults: 
    ServiceConnectDefaults
  Tags: 
    - Tag
PropertiesCapacityProviders
                    The short name of one or more capacity providers to associate with the cluster. A
			capacity provider must be associated with a cluster before it can be included as part of
			the default capacity provider strategy of the cluster or used in a capacity provider
			strategy when calling the CreateService or
				RunTask actions.
                    If specifying a capacity provider that uses an Auto Scaling group, the capacity
			provider must be created but not associated with another cluster. New Auto Scaling group
			capacity providers can be created with the CreateCapacityProvider API operation.
                    To use a AWS Fargate capacity provider, specify either the FARGATE or
				FARGATE_SPOT capacity providers. The AWS Fargate capacity providers are
			available to all accounts and only need to be associated with a cluster to be
			used.
                    The PutCapacityProvider API operation is used to update the list of available
			capacity providers for a cluster after the cluster is created.
                Required: NoType: Array of StringUpdate requires: No interruptionClusterName
                    A user-generated string that you use to identify your cluster. If you don't specify a
         name, AWS CloudFormation generates a unique physical ID for the name.
                Required: NoType: StringUpdate requires: ReplacementClusterSettings
                    The settings to use when creating a cluster. This parameter is used to turn on CloudWatch
			Container Insights with enhanced observability or CloudWatch Container Insights for a
			cluster.
                    Container Insights with enhanced observability provides all the Container Insights
			metrics, plus additional task and container metrics. This version supports enhanced
			observability for Amazon ECS clusters using the Amazon EC2 and Fargate launch types. After you
			configure Container Insights with enhanced observability on Amazon ECS, Container Insights
			auto-collects detailed infrastructure telemetry from the cluster level down to the
			container level in your environment and displays these critical performance data in
			curated dashboards removing the heavy lifting in observability set-up. 
                    For more information, see Monitor
				Amazon ECS containers using Container Insights with enhanced observability in the
			Amazon Elastic Container Service Developer Guide.
                Required: NoType: Array of ClusterSettingsUpdate requires: No interruptionConfiguration
                    The execute command and managed storage configuration for the cluster.
                Required: NoType: ClusterConfigurationUpdate requires: No interruptionDefaultCapacityProviderStrategy
                    The default capacity provider strategy for the cluster. When services or tasks are run
			in the cluster with no launch type or capacity provider strategy specified, the default
			capacity provider strategy is used.
                Required: NoType: Array of CapacityProviderStrategyItemUpdate requires: No interruptionServiceConnectDefaults
                    Use this parameter to set a default Service Connect namespace. After you set a default 
	Service Connect namespace, any new services with Service Connect turned on that are created in the cluster are added as
	client services in the namespace. This setting only applies to new services that set the enabled parameter to
	true in the ServiceConnectConfiguration.
	You can set the namespace of each service individually in the ServiceConnectConfiguration to override this default
	parameter.
                    Tasks that run in a namespace can use short names to connect
	to services in the namespace. Tasks can connect to services across all of the clusters in the namespace.
	Tasks connect through a managed proxy container
	that collects logs and metrics for increased visibility.
	Only the tasks that Amazon ECS services create are supported with Service Connect.
	For more information, see Service Connect in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: ServiceConnectDefaultsUpdate requires: No interruptionTags
                    The metadata that you apply to the cluster to help you categorize and organize them.
			Each tag consists of a key and an optional value. You define both.
                    The following basic restrictions apply to tags:
                    
                         
                         
                         
                         
                         
                         
                         
                    
                            Maximum number of tags per resource - 50
                        
                            For each resource, each tag key must be unique, and each tag key can have only
                    one value.
                        
                            Maximum key length - 128 Unicode characters in UTF-8
                        
                            Maximum value length - 256 Unicode characters in UTF-8
                        
                            If your tagging schema is used across multiple services and resources,
                    remember that other services may have restrictions on allowed characters.
                    Generally allowed characters are: letters, numbers, and spaces representable in
                    UTF-8, and the following characters: + - = . _ : / @.
                        
                            Tag keys and values are case-sensitive.
                        
                            Do not use aws:, AWS:, or any upper or lowercase
                    combination of such as a prefix for either keys or values as it is reserved for
                    AWS use. You cannot edit or delete tag keys or values with this prefix. Tags with
                    this prefix do not count against your tags per resource limit.
                        
                Required: NoType: Array of TagMinimum: 0Maximum: 50Update requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the resource name.In the following example, the Ref function returns the name of the
            MyECSCluster cluster, such as
            MyStack-MyECSCluster-NT5EUXTNTXXD.
                        { "Ref": "MyECSCluster" }
                    For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Arn
                            The Amazon Resource Name (ARN) of the Amazon ECS cluster, such as
            arn:aws:ecs:us-east-2:123456789012:cluster/MyECSCluster.
                        Examples Create a cluster with Fargate capacity providers and a default
            capacity provider strategyCreate a cluster with the Amazon Linux 2023 ECS-Optimized-AMICreate an empty cluster with CloudWatch Container Insights enabled and defined
            tags
            
            Create a cluster with Fargate capacity providers and a default
            capacity provider strategyThe following example creates a cluster named MyFargateCluster with
               the FARGATE and FARGATE_SPOT capacity providers. A default
               capacity provider strategy is also created where tasks launched will be split evenly
               between the FARGATE and FARGATE_SPOT capacity providers.
               The template also enables ECS Exec using the default logging configuration. For more
               information, see Monitor Amazon ECS containers
                  with ECS Exec in the Amazon ECS Developer
               Guide.JSON{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Resources": {
    "ECSCluster": {
      "Type": "AWS::ECS::Cluster",
      "Properties": {
        "ClusterName": "MyFargateCluster",
        "CapacityProviders": ["FARGATE", "FARGATE_SPOT"],
        "DefaultCapacityProviderStrategy": [
          {
            "CapacityProvider": "FARGATE",
            "Weight": 1
          },
          {
            "CapacityProvider": "FARGATE_SPOT",
            "Weight": 1
          }
        ],
        "Configuration": {
          "ExecuteCommandConfiguration": {
            "Logging": "DEFAULT"
          }
        }
      }
    }
  }
}
YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: MyFargateCluster
      CapacityProviders:
        - FARGATE
        - FARGATE_SPOT
      DefaultCapacityProviderStrategy:
        - CapacityProvider: FARGATE
          Weight: 1
        - CapacityProvider: FARGATE_SPOT
          Weight: 1
      Configuration:
        ExecuteCommandConfiguration:
          Logging: DEFAULT

            Create a cluster with the Amazon Linux 2023 ECS-Optimized-AMIThe following example creates a cluster named MyCluster with a
               capacity provider that launches Amazon Linux 2023 t2.medium instances. Replace parameters with your own information.JSON{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Description": "EC2 ECS cluster that starts out empty, with no EC2 instances yet. An ECS capacity provider automatically launches more EC2 instances as required on the fly when you request ECS to launch services or standalone tasks.",
  "Parameters": {
      "InstanceType": {
          "Type": "String",
          "Description": "EC2 instance type",
          "Default": "t2.medium",
          "AllowedValues": [
              "t1.micro",
              "t2.2xlarge",
              "t2.large",
              "t2.medium",
              "t2.micro",
              "t2.nano",
              "t2.small",
              "t2.xlarge",
              "t3.2xlarge",
              "t3.large",
              "t3.medium",
              "t3.micro",
              "t3.nano",
              "t3.small",
              "t3.xlarge"
          ]
      },
      "DesiredCapacity": {
          "Type": "Number",
          "Default": "0",
          "Description": "Number of EC2 instances to launch in your ECS cluster."
      },
      "MaxSize": {
          "Type": "Number",
          "Default": "100",
          "Description": "Maximum number of EC2 instances that can be launched in your ECS cluster."
      },
      "ECSAMI": {
          "Description": "The Amazon Machine Image ID used for the cluster",
          "Type": "AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>",
          "Default": "/aws/service/ecs/optimized-ami/amazon-linux-2023/recommended/image_id"
      },
      "VpcId": {
          "Type": "AWS::EC2::VPC::Id",
          "Description": "VPC ID where the ECS cluster is launched",
          "Default": "vpc-1234567890abcdef0"
      },
      "SubnetIds": {
          "Type": "List<AWS::EC2::Subnet::Id>",
          "Description": "List of subnet IDs where the EC2 instances will be launched",
          "Default": "subnet-021345abcdef67890"
      }
  },
  "Resources": {
      "ECSCluster": {
          "Type": "AWS::ECS::Cluster",
          "Properties": {
              "ClusterSettings": [
                  {
                      "Name": "containerInsights",
                      "Value": "enabled"
                  }
              ]
          }
      },
      "ECSAutoScalingGroup": {
          "Type": "AWS::AutoScaling::AutoScalingGroup",
          "DependsOn": [
              "ECSCluster",
              "EC2Role"
          ],
          "Properties": {
              "VPCZoneIdentifier": {
                  "Ref": "SubnetIds"
              },
              "LaunchTemplate": {
                  "LaunchTemplateId": {
                      "Ref": "ContainerInstances"
                  },
                  "Version": {
                      "Fn::GetAtt": [
                          "ContainerInstances",
                          "LatestVersionNumber"
                      ]
                  }
              },
              "MinSize": 0,
              "MaxSize": {
                  "Ref": "MaxSize"
              },
              "DesiredCapacity": {
                  "Ref": "DesiredCapacity"
              },
              "NewInstancesProtectedFromScaleIn": true
          },
          "UpdatePolicy": {
              "AutoScalingReplacingUpdate": {
                  "WillReplace": "true"
              }
          }
      },
      "ContainerInstances": {
          "Type": "AWS::EC2::LaunchTemplate",
          "Properties": {
              "LaunchTemplateName": "asg-launch-template",
              "LaunchTemplateData": {
                  "ImageId": {
                      "Ref": "ECSAMI"
                  },
                  "InstanceType": {
                      "Ref": "InstanceType"
                  },
                  "IamInstanceProfile": {
                      "Name": {
                          "Ref": "EC2InstanceProfile"
                      }
                  },
                  "SecurityGroupIds": [
                      {
                          "Ref": "ContainerHostSecurityGroup"
                      }
                  ],
                  "UserData": {
                      "Fn::Base64": {
                          "Fn::Sub": "#!/bin/bash -xe\n echo ECS_CLUSTER=${ECSCluster} >> /etc/ecs/ecs.config\n yum install -y aws-cfn-bootstrap\n /opt/aws/bin/cfn-init -v --stack ${AWS::StackId} --resource ContainerInstances --configsets full_install --region ${AWS::Region} &\n"
                      }
                  },
                  "MetadataOptions": {
                      "HttpEndpoint": "enabled",
                      "HttpTokens": "required"
                  }
              }
          }
      },
      "EC2InstanceProfile": {
          "Type": "AWS::IAM::InstanceProfile",
          "Properties": {
              "Path": "/",
              "Roles": [
                  {
                      "Ref": "EC2Role"
                  }
              ]
          }
      },
      "CapacityProvider": {
          "Type": "AWS::ECS::CapacityProvider",
          "Properties": {
              "AutoScalingGroupProvider": {
                  "AutoScalingGroupArn": {
                      "Ref": "ECSAutoScalingGroup"
                  },
                  "ManagedScaling": {
                      "InstanceWarmupPeriod": 60,
                      "MinimumScalingStepSize": 1,
                      "MaximumScalingStepSize": 100,
                      "Status": "ENABLED",
                      "TargetCapacity": 100
                  },
                  "ManagedTerminationProtection": "ENABLED"
              }
          }
      },
      "CapacityProviderAssociation": {
          "Type": "AWS::ECS::ClusterCapacityProviderAssociations",
          "Properties": {
              "CapacityProviders": [
                  {
                      "Ref": "CapacityProvider"
                  }
              ],
              "Cluster": {
                  "Ref": "ECSCluster"
              },
              "DefaultCapacityProviderStrategy": [
                  {
                      "Base": 0,
                      "CapacityProvider": {
                          "Ref": "CapacityProvider"
                      },
                      "Weight": 1
                  }
              ]
          }
      },
      "ContainerHostSecurityGroup": {
          "Type": "AWS::EC2::SecurityGroup",
          "Properties": {
              "GroupDescription": "Access to the EC2 hosts that run containers",
              "VpcId": {
                  "Ref": "VpcId"
              }
          }
      },
      "EC2Role": {
          "Type": "AWS::IAM::Role",
          "Properties": {
              "AssumeRolePolicyDocument": {
                  "Statement": [
                      {
                          "Effect": "Allow",
                          "Principal": {
                              "Service": [
                                  "ec2.amazonaws.com"
                              ]
                          },
                          "Action": [
                              "sts:AssumeRole"
                          ]
                      }
                  ]
              },
              "Path": "/",
              "ManagedPolicyArns": [
                  "arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role",
                  "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
              ]
          }
      },
      "ECSTaskExecutionRole": {
          "Type": "AWS::IAM::Role",
          "Properties": {
              "AssumeRolePolicyDocument": {
                  "Statement": [
                      {
                          "Effect": "Allow",
                          "Principal": {
                              "Service": [
                                  "ecs-tasks.amazonaws.com"
                              ]
                          },
                          "Action": [
                              "sts:AssumeRole"
                          ],
                          "Condition": {
                              "ArnLike": {
                                  "aws:SourceArn": {
                                      "Fn::Sub": "arn:${AWS::Partition}:ecs:${AWS::Region}:${AWS::AccountId}:*"
                                  }
                              },
                              "StringEquals": {
                                  "aws:SourceAccount": {
                                        "Fn::Sub": "${AWS::AccountId}"
                                    }
                              }
                          }
                      }
                  ]
              },
              "Path": "/",
              "ManagedPolicyArns": [
                  "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
              ]
          }
      }
  },
  "Outputs": {
      "ClusterName": {
          "Description": "The ECS cluster into which to launch resources",
          "Value": "ECSCluster"
      },
      "ECSTaskExecutionRole": {
          "Description": "The role used to start up a task",
          "Value": "ECSTaskExecutionRole"
      },
      "CapacityProvider": {
          "Description": "The cluster capacity provider that the service should use to request capacity when it wants to start up a task",
          "Value": "CapacityProvider"
      }
  }
} YAMLAWSTemplateFormatVersion: 2010-09-09
Description: EC2 ECS cluster that starts out empty, with no EC2 instances yet.
  An ECS capacity provider automatically launches more EC2 instances as required
  on the fly when you request ECS to launch services or standalone tasks.
Parameters:
  InstanceType:
    Type: String
    Description: EC2 instance type
    Default: "t2.medium"
    AllowedValues:
      - t1.micro
      - t2.2xlarge
      - t2.large
      - t2.medium
      - t2.micro
      - t2.nano
      - t2.small
      - t2.xlarge
      - t3.2xlarge
      - t3.large
      - t3.medium
      - t3.micro
      - t3.nano
      - t3.small
      - t3.xlarge
  DesiredCapacity:
    Type: Number
    Default: "0"
    Description: Number of EC2 instances to launch in your ECS cluster.
  MaxSize:
    Type: Number
    Default: "100"
    Description: Maximum number of EC2 instances that can be launched in your ECS cluster.
  ECSAMI:
    Description: The Amazon Machine Image ID used for the cluster
    Type: AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>
    Default: /aws/service/ecs/optimized-ami/amazon-linux-2023/recommended/image_id
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID where the ECS cluster is launched
    Default: vpc-1234567890abcdef0
  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: List of subnet IDs where the EC2 instances will be launched
    Default: "subnet-021345abcdef67890"
Resources:
# This is authorizes ECS to manage resources on your
  # account on your behalf. This role is likely already created on your account
  # ECSRole:
  #  Type: AWS::IAM::ServiceLinkedRole
  #  Properties:
  #    AWSServiceName: 'ecs.amazonaws.com'
  
   # ECS Resources
  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterSettings:
        - Name: containerInsights
          Value: enabled
  
  # Autoscaling group. This launches the actual EC2 instances that will register
  # themselves as members of the cluster, and run the docker containers.
  ECSAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn:
      # This is to ensure that the ASG gets deleted first before these
    # resources, when it comes to stack teardown.
      - ECSCluster
      - EC2Role
    Properties:
      VPCZoneIdentifier:
        Ref: SubnetIds
      LaunchTemplate:
        LaunchTemplateId: !Ref ContainerInstances
        Version: !GetAtt ContainerInstances.LatestVersionNumber
      MinSize: 0
      MaxSize:
        Ref: MaxSize
      DesiredCapacity:
        Ref: DesiredCapacity
      NewInstancesProtectedFromScaleIn: true
    UpdatePolicy:
      AutoScalingReplacingUpdate:
        WillReplace: "true"
  # The config for each instance that is added to the cluster
  ContainerInstances:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: "asg-launch-template"
      LaunchTemplateData:
        ImageId:
          Ref: ECSAMI
        InstanceType:
          Ref: InstanceType
        IamInstanceProfile:
          Name: !Ref EC2InstanceProfile
        SecurityGroupIds:
          - !Ref ContainerHostSecurityGroup
        # This injected configuration file is how the EC2 instance
      # knows which ECS cluster on your AWS account it should be joining
        UserData:
          Fn::Base64: !Sub |
           #!/bin/bash -xe
            echo ECS_CLUSTER=${ECSCluster} >> /etc/ecs/ecs.config
            yum install -y aws-cfn-bootstrap
            /opt/aws/bin/cfn-init -v --stack ${AWS::StackId} --resource ContainerInstances --configsets full_install --region ${AWS::Region} &
         # Disable IMDSv1, and require IMDSv2
        MetadataOptions:
          HttpEndpoint: enabled
          HttpTokens: required
  EC2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles: 
      - !Ref EC2Role 
  # Create an ECS capacity provider to attach the ASG to the ECS cluster
  # so that it autoscales as we launch more containers
  CapacityProvider:
    Type: AWS::ECS::CapacityProvider
    Properties:
      AutoScalingGroupProvider:
        AutoScalingGroupArn: !Ref ECSAutoScalingGroup
        ManagedScaling:
          InstanceWarmupPeriod: 60
          MinimumScalingStepSize: 1
          MaximumScalingStepSize: 100
          Status: ENABLED
          # Percentage of cluster reservation to try to maintain
          TargetCapacity: 100
        ManagedTerminationProtection: ENABLED
   # Create a cluster capacity provider assocation so that the cluster
  # will use the capacity provider
  CapacityProviderAssociation:
    Type: AWS::ECS::ClusterCapacityProviderAssociations
    Properties:
      CapacityProviders:
        - !Ref CapacityProvider
      Cluster: !Ref ECSCluster
      DefaultCapacityProviderStrategy:
        - Base: 0
          CapacityProvider: !Ref CapacityProvider
          Weight: 1
  # A security group for the EC2 hosts that will run the containers.
  # This can be used to limit incoming traffic to or outgoing traffic
  # from the container's host EC2 instance.
  ContainerHostSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Access to the EC2 hosts that run containers
      VpcId:
        Ref: VpcId
  # Role for the EC2 hosts. This allows the ECS agent on the EC2 hosts
  # to communciate with the ECS control plane, as well as download the docker
  # images from ECR to run on your host.
  EC2Role:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      ManagedPolicyArns:
      # See reference: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/security-iam-awsmanpol.html#security-iam-awsmanpol-AmazonEC2ContainerServiceforEC2Role
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
      # This managed policy allows us to connect to the instance using SSM
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
  # This is a role which is used within Fargate to allow the Fargate agent
  # to download images, and upload logs.
  ECSTaskExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ecs-tasks.amazonaws.com
            Action:
              - sts:AssumeRole
            Condition:
              ArnLike:
                aws:SourceArn: !Sub arn:${AWS::Partition}:ecs:${AWS::Region}:${AWS::AccountId}:*
              StringEquals:
                aws:SourceAccount: !Sub ${AWS::AccountId}
      Path: /
      # This role enables all features of ECS. See reference:
    # https://docs.aws.amazon.com/AmazonECS/latest/developerguide/security-iam-awsmanpol.html#security-iam-awsmanpol-AmazonECSTaskExecutionRolePolicy
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
Outputs:
  ClusterName:
    Description: The ECS cluster into which to launch resources
    Value: ECSCluster
  ECSTaskExecutionRole:
    Description: The role used to start up a task
    Value: ECSTaskExecutionRole
  CapacityProvider:
    Description: The cluster capacity provider that the service should use to
      request capacity when it wants to start up a task
    Value: CapacityProvider
            Create an empty cluster with CloudWatch Container Insights enabled and defined
            tagsThe following example creates an empty cluster named MyCluster that
               has CloudWatch Container Insights enabled and is tagged with the key
                  environment and the value production.JSON{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Resources": {
    "ECSCluster": {
        "Type": "AWS::ECS::Cluster",
        "Properties": {
            "ClusterName": "MyCluster",
            "ClusterSettings": [
                {
                    "Name": "containerInsights",
                    "Value": "enabled"
                }
            ],
            "Tags": [
                {
                    "Key": "environment",
                    "Value": "production"
                }
            ]
        }
    }
  }
}
YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: MyCluster
      ClusterSettings:
        - Name: containerInsights
          Value: enabled
      Tags:
        - Key: environment
          Value: production

        Document ConventionsTagCapacityProviderStrategyItemDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::ECS::ServiceThe AWS::ECS::Service resource creates an Amazon Elastic Container Service
         (Amazon ECS) service that runs and maintains the requested number of tasks and associated
         load balancers.ImportantThe stack update fails if you change any properties that require replacement and at
            least one Amazon ECS Service Connect ServiceConnectConfiguration
            property is configured. This is because AWS CloudFormation creates
            the replacement service first, but each ServiceConnectService must have a
            name that is unique in the namespace.NoteStarting April 15, 2023, AWS; will not onboard new customers to Amazon
            Elastic Inference (EI), and will help current customers migrate their workloads to
            options that offer better price and performance. After April 15, 2023, new customers
            will not be able to launch instances with Amazon EI accelerators in Amazon SageMaker,
               Amazon ECS, or Amazon EC2. However, customers who have used Amazon EI
            at least once during the past 30-day period are considered current customers and will be
            able to continue using the service. SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ECS::Service",
  "Properties" : {
      "AvailabilityZoneRebalancing" : String,
      "CapacityProviderStrategy" : [ CapacityProviderStrategyItem, ... ],
      "Cluster" : String,
      "DeploymentConfiguration" : DeploymentConfiguration,
      "DeploymentController" : DeploymentController,
      "DesiredCount" : Integer,
      "EnableECSManagedTags" : Boolean,
      "EnableExecuteCommand" : Boolean,
      "HealthCheckGracePeriodSeconds" : Integer,
      "LaunchType" : String,
      "LoadBalancers" : [ LoadBalancer, ... ],
      "NetworkConfiguration" : NetworkConfiguration,
      "PlacementConstraints" : [ PlacementConstraint, ... ],
      "PlacementStrategies" : [ PlacementStrategy, ... ],
      "PlatformVersion" : String,
      "PropagateTags" : String,
      "Role" : String,
      "SchedulingStrategy" : String,
      "ServiceConnectConfiguration" : ServiceConnectConfiguration,
      "ServiceName" : String,
      "ServiceRegistries" : [ ServiceRegistry, ... ],
      "Tags" : [ Tag, ... ],
      "TaskDefinition" : String,
      "VolumeConfigurations" : [ ServiceVolumeConfiguration, ... ],
      "VpcLatticeConfigurations" : [ VpcLatticeConfiguration, ... ]
    }
}
YAMLType: AWS::ECS::Service
Properties:
  AvailabilityZoneRebalancing: String
  CapacityProviderStrategy: 
    - CapacityProviderStrategyItem
  Cluster: String
  DeploymentConfiguration: 
    DeploymentConfiguration
  DeploymentController: 
    DeploymentController
  DesiredCount: Integer
  EnableECSManagedTags: Boolean
  EnableExecuteCommand: Boolean
  HealthCheckGracePeriodSeconds: Integer
  LaunchType: String
  LoadBalancers: 
    - LoadBalancer
  NetworkConfiguration: 
    NetworkConfiguration
  PlacementConstraints: 
    - PlacementConstraint
  PlacementStrategies: 
    - PlacementStrategy
  PlatformVersion: String
  PropagateTags: String
  Role: String
  SchedulingStrategy: String
  ServiceConnectConfiguration: 
    ServiceConnectConfiguration
  ServiceName: String
  ServiceRegistries: 
    - ServiceRegistry
  Tags: 
    - Tag
  TaskDefinition: String
  VolumeConfigurations: 
    - ServiceVolumeConfiguration
  VpcLatticeConfigurations: 
    - VpcLatticeConfiguration
PropertiesAvailabilityZoneRebalancing
                    Indicates whether to use Availability Zone rebalancing for the service.
                    For more information, see Balancing an Amazon ECS service across Availability Zones in
			the 
                            Amazon Elastic Container Service Developer Guide
                        .
                Required: NoType: StringAllowed values: ENABLED | DISABLEDUpdate requires: No interruptionCapacityProviderStrategy
                    The capacity provider strategy to use for the service.
                    If a capacityProviderStrategy is specified, the launchType
			parameter must be omitted. If no capacityProviderStrategy or
				launchType is specified, the
				defaultCapacityProviderStrategy for the cluster is used.
                    A capacity provider strategy can contain a maximum of 20 capacity providers.
                    ImportantTo remove this property from your service resource, specify an empty CapacityProviderStrategyItem array.
                Required: NoType: Array of CapacityProviderStrategyItemUpdate requires: No interruptionCluster
                    The short name or full Amazon Resource Name (ARN) of the cluster that you run your service on.
			If you do not specify a cluster, the default cluster is assumed.
                Required: NoType: StringUpdate requires: ReplacementDeploymentConfiguration
                    Optional deployment parameters that control how many tasks run during the deployment
			and the ordering of stopping and starting tasks.
                Required: NoType: DeploymentConfigurationUpdate requires: No interruptionDeploymentController
                    The deployment controller to use for the service. If no deployment controller is
			specified, the default value of ECS is used.
                Required: NoType: DeploymentControllerUpdate requires: ReplacementDesiredCount
                    The number of instantiations of the specified task definition to place and keep running
         in your service.
                    For new services, if a desired count is not specified, a default value of 1
         is used. When using the DAEMON scheduling strategy, the desired count is not
         required.
                    For existing services, if a desired count is not specified, it is omitted from the
         operation.
                Required: ConditionalType: IntegerUpdate requires: No interruptionEnableECSManagedTags
                    Specifies whether to turn on Amazon ECS managed tags for the tasks within the service. For
			more information, see Tagging your Amazon ECS
				resources in the Amazon Elastic Container Service Developer Guide.
                    When you use Amazon ECS managed tags, you need to set the propagateTags
			request parameter.
                Required: NoType: BooleanUpdate requires: No interruptionEnableExecuteCommand
                    Determines whether the execute command functionality is turned on for the service. If
				true, the execute command functionality is turned on for all containers
			in tasks as part of the service.
                Required: NoType: BooleanUpdate requires: No interruptionHealthCheckGracePeriodSeconds
                    The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy
			Elastic Load Balancing, VPC Lattice, and container health checks after a task has first started. If you don't
			specify a health check grace period value, the default value of 0 is used.
			If you don't use any of the health checks, then
				healthCheckGracePeriodSeconds is unused.
                    If your service's tasks take a while to start and respond to health checks, you can
			specify a health check grace period of up to 2,147,483,647 seconds (about 69 years).
			During that time, the Amazon ECS service scheduler ignores health check status. This grace
			period can prevent the service scheduler from marking tasks as unhealthy and stopping
			them before they have time to come up.
                Required: NoType: IntegerUpdate requires: No interruptionLaunchType
                    The launch type on which to run your service. For more information, see Amazon ECS
      Launch Types in the Amazon Elastic Container Service Developer
        Guide.
                Required: NoType: StringAllowed values: EC2 | FARGATE | EXTERNALUpdate requires: ReplacementLoadBalancers
                    A list of load balancer objects to associate with the service. If you specify the
      Role property, LoadBalancers must be specified as well. For
      information about the number of load balancers that you can specify per service, see Service Load Balancing in the Amazon Elastic Container Service
          Developer Guide.
                    ImportantTo remove this property from your service resource, specify an empty LoadBalancer array.
                Required: NoType: Array of LoadBalancerUpdate requires: No interruptionNetworkConfiguration
                    The network configuration for the service. This parameter is required for task
      definitions that use the awsvpc network mode to receive their own elastic
      network interface, and it is not supported for other network modes. For more information,
      see Task Networking in the Amazon Elastic Container Service Developer
          Guide.
                Required: ConditionalType: NetworkConfigurationUpdate requires: No interruptionPlacementConstraints
                    An array of placement constraint objects to use for tasks in your service. You can specify a maximum
			of 10 constraints for each task. This limit includes constraints in the task definition and those
			specified at runtime.
                    ImportantTo remove this property from your service resource, specify an empty PlacementConstraint array.
                Required: NoType: Array of PlacementConstraintUpdate requires: No interruptionPlacementStrategies
                    The placement strategy objects to use for tasks in your service. You can specify a maximum of 5
			strategy rules for each service.
                    ImportantTo remove this property from your service resource, specify an empty PlacementStrategy array.
                Required: NoType: Array of PlacementStrategyUpdate requires: No interruptionPlatformVersion
                    The platform version that your tasks in the service are running on. A platform version
			is specified only for tasks using the Fargate launch type. If one isn't
			specified, the LATEST platform version is used. For more information, see
				AWS Fargate platform
				versions in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: StringUpdate requires: No interruptionPropagateTags
                    Specifies whether to propagate the tags from the task definition to the task. If no
			value is specified, the tags aren't propagated. Tags can only be propagated to the task
			during task creation. To add tags to a task after task creation, use the TagResource API action.
                    You must set this to a value other than NONE when you use Cost Explorer.
			For more information, see Amazon ECS usage reports
			in the Amazon Elastic Container Service Developer Guide.
                    The default is NONE.
                Required: NoType: StringAllowed values: SERVICE | TASK_DEFINITIONUpdate requires: No interruptionRole
                    The name or full Amazon Resource Name (ARN) of the IAM role that allows Amazon ECS to make calls to your
			load balancer on your behalf. This parameter is only permitted if you are using a load
			balancer with your service and your task definition doesn't use the awsvpc
			network mode. If you specify the role parameter, you must also specify a
			load balancer object with the loadBalancers parameter.
                    ImportantIf your account has already created the Amazon ECS service-linked role, that role is
				used for your service unless you specify a role here. The service-linked role is
				required if your task definition uses the awsvpc network mode or if the
				service is configured to use service discovery, an external deployment controller,
				multiple target groups, or Elastic Inference accelerators in which case you don't
				specify a role here. For more information, see Using
					service-linked roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide.
                    If your specified role has a path other than /, then you must either
			specify the full role ARN (this is recommended) or prefix the role name with the path.
			For example, if a role with the name bar has a path of /foo/
			then you would specify /foo/bar as the role name. For more information, see
				Friendly names and paths in the IAM User
			Guide.
                Required: NoType: StringUpdate requires: ReplacementSchedulingStrategy
                    The scheduling strategy to use for the service. For more information, see Services.
                    There are two service scheduler strategies available:
                    
                         
                         
                    
                            REPLICA-The replica scheduling strategy places and
					maintains the desired number of tasks across your cluster. By default, the
					service scheduler spreads tasks across Availability Zones. You can use task
					placement strategies and constraints to customize task placement decisions. This
					scheduler strategy is required if the service uses the CODE_DEPLOY
					or EXTERNAL deployment controller types.
                        
                            DAEMON-The daemon scheduling strategy deploys exactly one
					task on each active container instance that meets all of the task placement
					constraints that you specify in your cluster. The service scheduler also
					evaluates the task placement constraints for running tasks and will stop tasks
					that don't meet the placement constraints. When you're using this strategy, you
					don't need to specify a desired number of tasks, a task placement strategy, or
					use Service Auto Scaling policies.
                            NoteTasks using the Fargate launch type or the
							CODE_DEPLOY or EXTERNAL deployment controller
						types don't support the DAEMON scheduling strategy.
                        
                Required: NoType: StringAllowed values: DAEMON | REPLICAUpdate requires: ReplacementServiceConnectConfiguration
                    The configuration for this service to discover and connect to
	services, and be discovered by, and connected from, other services within a namespace.
                    Tasks that run in a namespace can use short names to connect
	to services in the namespace. Tasks can connect to services across all of the clusters in the namespace.
	Tasks connect through a managed proxy container
	that collects logs and metrics for increased visibility.
	Only the tasks that Amazon ECS services create are supported with Service Connect.
	For more information, see Service Connect in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: ServiceConnectConfigurationUpdate requires: No interruptionServiceName
                    The name of your service. Up to 255 letters (uppercase and lowercase), numbers,
         underscores, and hyphens are allowed. Service names must be unique within a cluster, but
         you can have similarly named services in multiple clusters within a Region or across
         multiple Regions.
                    ImportantThe stack update fails if you change any properties that require replacement and the
               ServiceName is configured. This is because AWS
            CloudFormation creates the replacement service first, but each ServiceName
            must be unique in the cluster.
                Required: NoType: StringUpdate requires: ReplacementServiceRegistries
                    The details of the service discovery registry to associate with this service. For more
			information, see Service
				discovery.
                    NoteEach service may be associated with one service registry. Multiple service
				registries for each service isn't supported.
                    ImportantTo remove this property from your service resource, specify an empty ServiceRegistry array.
                Required: NoType: Array of ServiceRegistryUpdate requires: No interruptionTags
                    The metadata that you apply to the service to help you categorize and organize them.
			Each tag consists of a key and an optional value, both of which you define. When a
			service is deleted, the tags are deleted as well.
                    The following basic restrictions apply to tags:
                    
                         
                         
                         
                         
                         
                         
                         
                    
                            Maximum number of tags per resource - 50
                        
                            For each resource, each tag key must be unique, and each tag key can have only
                    one value.
                        
                            Maximum key length - 128 Unicode characters in UTF-8
                        
                            Maximum value length - 256 Unicode characters in UTF-8
                        
                            If your tagging schema is used across multiple services and resources,
                    remember that other services may have restrictions on allowed characters.
                    Generally allowed characters are: letters, numbers, and spaces representable in
                    UTF-8, and the following characters: + - = . _ : / @.
                        
                            Tag keys and values are case-sensitive.
                        
                            Do not use aws:, AWS:, or any upper or lowercase
                    combination of such as a prefix for either keys or values as it is reserved for
                    AWS use. You cannot edit or delete tag keys or values with this prefix. Tags with
                    this prefix do not count against your tags per resource limit.
                        
                Required: NoType: Array of TagMinimum: 0Maximum: 50Update requires: No interruptionTaskDefinition
                    The family and revision (family:revision) or
			full ARN of the task definition to run in your service. If a revision
			isn't specified, the latest ACTIVE revision is used.
                    A task definition must be specified if the service uses either the ECS or
				CODE_DEPLOY deployment controllers.
                    For more information about deployment types, see Amazon ECS deployment
				types.
                Required: NoType: StringUpdate requires: No interruptionVolumeConfigurations
                    The configuration for a volume specified in the task definition as a volume that is configured at
			launch time. Currently, the only supported volume type is an Amazon EBS volume.
                    ImportantTo remove this property from your service resource, specify an empty ServiceVolumeConfiguration array.
                Required: NoType: Array of ServiceVolumeConfigurationUpdate requires: No interruptionVpcLatticeConfigurations
                    The VPC Lattice configuration for the service being created.
                Required: NoType: Array of VpcLatticeConfigurationUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Amazon Resource Name (ARN).In the following example, the Ref function returns the ARN of the
      MyECSService service, such as
      arn:aws:ecs:us-west-2:123456789012:service/sample-webapp.
                        { "Ref": "MyECSService" }
                    For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Name
                            The name of the Amazon ECS service, such as sample-webapp.
                        ServiceArn
                            Not currently supported in AWS CloudFormation.
                        Examples Create a service that uses a task definitionCreate a service with a volume configurationAssociate an Application Load Balancer with a serviceCreate a service with a health check grace periodCreate a service with ECS Exec enabled
            
            Create a service that uses a task definitionThe following example template creates a service, a cluster, and a task
               definition. The cluster contains the service. The service — with a
                  DesiredCount of 1 — uses the task definition defined in the
               template. Replace the ExecutionRoleArn, SecurityGroups, and
                  Subnets with your own information.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "ECSCluster": {
            "Type": "AWS::ECS::Cluster",
            "Properties": {
                "ClusterName": "CFNCluster"
            }
        },
        "ECSTaskDefinition": {
            "Type": "AWS::ECS::TaskDefinition",
            "Properties": {
                "ContainerDefinitions": [
                    {
                        "Command": [
                            "/bin/sh -c \"echo '<html> <head> <title>Amazon ECS Sample App</title> <style>body {margin-top: 40px; background-color: #333;} </style> </head><body> <div style=color:white;text-align:center> <h1>Amazon ECS Sample App</h1> <h2>Congratulations!</h2> <p>Your application is now running on a container in Amazon ECS.</p> </div></body></html>' >  /usr/local/apache2/htdocs/index.html && httpd-foreground\""
                        ],
                        "EntryPoint": [
                            "sh",
                            "-c"
                        ],
                        "Essential": true,
                        "Image": "public.ecr.aws/docker/library/httpd:2.4",
                        "LogConfiguration": {
                            "LogDriver": "awslogs",
                            "Options": {
                                "awslogs-group": "/ecs/fargate-task-definition",
                                "awslogs-region": "us-east-1",
                                "awslogs-stream-prefix": "ecs"
                            }
                        },
                        "Name": "sample-fargate-app",
                        "PortMappings": [
                            {
                                "ContainerPort": 80,
                                "HostPort": 80,
                                "Protocol": "tcp"
                            }
                        ]
                    }
                ],
                "Cpu": 256,
                "ExecutionRoleArn": "arn:aws:iam::111122223333:role/ecsTaskExecutionRole",
                "Family": "task-definition-cfn",
                "Memory": 512,
                "NetworkMode": "awsvpc",
                "RequiresCompatibilities": [
                    "FARGATE"
                ],
                "RuntimePlatform": {
                    "OperatingSystemFamily": "LINUX"
                }
            }
        },
        "ECSService": {
            "Type": "AWS::ECS::Service",
            "Properties": {
                "ServiceName": "cfn-service",
                "Cluster": {
                    "Ref": "ECSCluster"
                },
                "DesiredCount": 1,
                "LaunchType": "FARGATE",
                "NetworkConfiguration": {
                    "AwsvpcConfiguration": {
                        "AssignPublicIp": "ENABLED",
                        "SecurityGroups": [
                            "sg-abcdef01234567890"
                        ],
                        "Subnets": [
                            "subnet-021345abcdef67890"
                        ]
                    }
                },
                "TaskDefinition": {
                    "Ref": "ECSTaskDefinition"
                }
            }
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  ECSCluster:
    Type: 'AWS::ECS::Cluster'
    Properties:
      ClusterName: CFNCluster
  ECSTaskDefinition:
    Type: 'AWS::ECS::TaskDefinition'
    Properties:
      ContainerDefinitions:
        - Command:
            - >-
              /bin/sh -c "echo '<html> <head> <title>Amazon ECS Sample
              App</title> <style>body {margin-top: 40px; background-color:
              #333;} </style> </head><body> <div
              style=color:white;text-align:center> <h1>Amazon ECS Sample
              App</h1> <h2>Congratulations!</h2> <p>Your application is now
              running on a container in Amazon ECS.</p> </div></body></html>' > 
              /usr/local/apache2/htdocs/index.html && httpd-foreground"
          EntryPoint:
            - sh
            - '-c'
          Essential: true
          Image: 'public.ecr.aws/docker/library/httpd:2.4'
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: /ecs/fargate-task-definition
              awslogs-region: us-east-1
              awslogs-stream-prefix: ecs
          Name: sample-fargate-app
          PortMappings:
            - ContainerPort: 80
              HostPort: 80
              Protocol: tcp
      Cpu: 256
      ExecutionRoleArn: 'arn:aws:iam::111122223333:role/ecsTaskExecutionRole'
      Family: task-definition-cfn
      Memory: 512
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - FARGATE
      RuntimePlatform:
        OperatingSystemFamily: LINUX
  ECSService:
    Type: 'AWS::ECS::Service'
    Properties:
      ServiceName: cfn-service
      Cluster: !Ref ECSCluster
      DesiredCount: 1
      LaunchType: FARGATE
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups:
            - sg-abcdef01234567890
          Subnets:
            - subnet-021345abcdef67890
      TaskDefinition: !Ref ECSTaskDefinition
            Create a service with a volume configurationThe following example template creates a service that utilizes a pre-existing task
               that defers volume configuration to service creation. This example template provides
               volume configuration that Amazon ECS uses to create and attach an Amazon EBS volume to each
               task in the service. For more information about defering volume configuration and using Amazon EBS volumes with Amazon ECS, see Use Amazon EBS volumes with
                  Amazon ECS in the Amazon ECS Developer
                     Guide. Replace SubnetIDs, SecurityGroupIDs, TaskDefinition, and ManagedEBSVolume with your own information.
            JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "The template used to create an ECS Service that includes a volume configuration.",
    "Parameters": {
      "ECSClusterName": {
        "Type": "String",
        "Default": "volume-config-cluster"
      },
      "SecurityGroupIDs": {
        "Type": "CommaDelimitedList",
        "Default": "sg-1234567890abcdef0"
      },
      "SubnetIDs": {
        "Type": "CommaDelimitedList",
        "Default": "subnet-021345abcdef67890,subnet-abcdef01234567890"
      }
    },
    "Resources": {
      "ECSService": {
        "Type": "AWS::ECS::Service",
        "Properties": {
          "Cluster": "endpoint",
          "TaskDefinition": "arn:aws:ecs:us-east-1:111122223333:task-definition/ebs-task-attach-task-def-test:11",
          "LaunchType": "FARGATE",
          "ServiceName": "ebs",
          "SchedulingStrategy": "REPLICA",
          "DesiredCount": 1,
          "NetworkConfiguration": {
            "AwsvpcConfiguration": {
              "AssignPublicIp": "ENABLED",
              "SecurityGroups": {
                "Ref": "SecurityGroupIDs"
              },
              "Subnets": {
                "Ref": "SubnetIDs"
              }
            }
          },
          "PlatformVersion": "LATEST",
          "DeploymentConfiguration": {
            "MaximumPercent": 200,
            "MinimumHealthyPercent": 100,
            "DeploymentCircuitBreaker": {
              "Enable": true,
              "Rollback": true
            }
          },
          "DeploymentController": {
            "Type": "ECS"
          },
          "Tags": [],
          "EnableECSManagedTags": true,
          "VolumeConfigurations": [
            {
              "Name": "ebs-volume",
              "ManagedEBSVolume": {
                "RoleArn": "arn:aws:iam::111122223333:role/ecsInfrastructureRole",
                "VolumeType": "gp3",
                "Iops": "3000",
                "Throughput": "125",
                "SizeInGiB": "10",
                "FilesystemType": "xfs",
                "TagSpecifications": [
                  {
                    "ResourceType": "volume",
                    "PropagateTags": "TASK_DEFINITION"
                  }
                ]
              }
            }
          ]
        }
      }
    },
    "Outputs": {
      "ClusterName": {
        "Description": "The cluster used to create the service.",
        "Value": {
          "Ref": "ECSClusterName"
        }
      },
      "ECSService": {
        "Description": "The created service.",
        "Value": {
          "Ref": "ECSService"
        }
      }
    }
  }YAMLAWSTemplateFormatVersion: 2010-09-09
Description: The template used to create an ECS Service that includes a volume configuration.
Parameters:
  ECSClusterName:
    Type: String
    Default: volume-config-cluster
  SecurityGroupIDs:
    Type: CommaDelimitedList
    Default: sg-1234567890abcdef0
  SubnetIDs:
    Type: CommaDelimitedList
    Default: subnet-021345abcdef67890,subnet-abcdef01234567890
Resources:
  ECSService:
    Type: AWS::ECS::Service
    Properties:
      Cluster: endpoint
      TaskDefinition: arn:aws:ecs:us-east-1:111122223333:task-definition/ebs-task-attach-task-def-test:11
      LaunchType: FARGATE
      ServiceName: ebs
      SchedulingStrategy: REPLICA
      DesiredCount: 1
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups:
            Ref: SecurityGroupIDs
          Subnets:
            Ref: SubnetIDs
      PlatformVersion: LATEST
      DeploymentConfiguration:
        MaximumPercent: 200
        MinimumHealthyPercent: 100
        DeploymentCircuitBreaker:
          Enable: true
          Rollback: true
      DeploymentController:
        Type: ECS
      Tags: []
      EnableECSManagedTags: true
      VolumeConfigurations:
        - Name: ebs-volume
          ManagedEBSVolume:
            RoleArn: arn:aws:iam::111122223333:role/ecsInfrastructureRole
            VolumeType: gp3
            Iops: "3000"
            Throughput: "125"
            SizeInGiB: "10"
            FilesystemType: xfs
            TagSpecifications:
              - ResourceType: volume
                PropagateTags: TASK_DEFINITION
Outputs:
  ClusterName:
    Description: The cluster used to create the service.
    Value:
      Ref: ECSClusterName
  ECSService:
    Description: The created service.
    Value:
      Ref: ECSService  
            Associate an Application Load Balancer with a serviceThe following example associates an Application Load Balancer with an  Amazon ECS
               service by referencing an AWS::ElasticLoadBalancingV2::TargetGroup
               resource. Replace the SecurityGroupIDs, SubnetIDs,
                  VpcID, Cluster, and TaskDefinition with
               your own information. For more information about using Application Load Balancers
               with Amazon ECS, see Use an Application Load Balancer
                  for Amazon ECS in the Amazon ECS Developer
               Guide.NoteThe Amazon ECS service requires an explicit dependency on the Application Load
                  Balancer listener rule and the Application Load Balancer listener. This prevents
                  the service from starting before the listener is ready.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "The template used to create an ECS Service associated with an Application Load Balancer.",
    "Parameters": {
      "SecurityGroupIDs": {
        "Type": "CommaDelimitedList",
        "Default": "sg-1234567890abcdef0,sg-021345abcdef67890"
      },
      "SubnetIDs": {
        "Type": "CommaDelimitedList",
        "Default": "subnet-abcdef01234567890,subnet-fedcba01234567098,subnet-2135647890abcdef0"
      },
      "VpcID": {
        "Type": "String",
        "Default": "vpc-3214789650abcdef0"
      }
    },
    "Resources": {
        "ECSCluster": {
            "Type": "AWS::ECS::Cluster",
            "Properties": {
                "ClusterName": "ALBCluster"
            }
        },
      "ECSService": {
        "Type": "AWS::ECS::Service",
        "Properties": {
          "Cluster": {"Ref":"ECSCluster"},
          "TaskDefinition": "arn:aws:ecs:us-east-1:111122223333:task-definition/first-run-task:7",
          "LaunchType": "FARGATE",
          "ServiceName": "alb",
          "SchedulingStrategy": "REPLICA",
          "DesiredCount": 3,
          "LoadBalancers": [
            {
              "ContainerName": "first-run-task",
              "ContainerPort": 80,
              "LoadBalancerName": {
                "Ref": "AWS::NoValue"
              },
              "TargetGroupArn": {
                "Ref": "TargetGroup"
              }
            }
          ],
          "HealthCheckGracePeriodSeconds": "20",
          "NetworkConfiguration": {
            "AwsvpcConfiguration": {
              "AssignPublicIp": "ENABLED",
              "SecurityGroups": {
                "Ref": "SecurityGroupIDs"
              },
              "Subnets": {
                "Ref": "SubnetIDs"
              }
            }
          },
          "PlatformVersion": "LATEST",
          "DeploymentConfiguration": {
            "MaximumPercent": 200,
            "MinimumHealthyPercent": 100,
            "DeploymentCircuitBreaker": {
              "Enable": true,
              "Rollback": true
            }
          },
          "DeploymentController": {
            "Type": "ECS"
          },
          "ServiceConnectConfiguration": {
            "Enabled": false
          },
          "Tags": [],
          "EnableECSManagedTags": true
        },
        "DependsOn": [
          "Listener"
        ]
      },
      "LoadBalancer": {
        "Type": "AWS::ElasticLoadBalancingV2::LoadBalancer",
        "Properties": {
          "Type": "application",
          "Name": "alb-test",
          "SecurityGroups": {
            "Ref": "SecurityGroupIDs"
          },
          "Subnets": {
            "Ref": "SubnetIDs"
          }
        }
      },
      "TargetGroup": {
        "Type": "AWS::ElasticLoadBalancingV2::TargetGroup",
        "Properties": {
          "HealthCheckPath": "/",
          "Name": "ecs-task-m-alb",
          "Port": 80,
          "Protocol": "HTTP",
          "TargetType": "ip",
          "HealthCheckProtocol": "HTTP",
          "VpcId": {
            "Ref": "VpcID"
          },
          "TargetGroupAttributes": [
            {
              "Key": "deregistration_delay.timeout_seconds",
              "Value": "300"
            }
          ]
        }
      },
      "Listener": {
        "Type": "AWS::ElasticLoadBalancingV2::Listener",
        "Properties": {
          "DefaultActions": [
            {
              "Type": "forward",
              "TargetGroupArn": {
                "Ref": "TargetGroup"
              }
            }
          ],
          "LoadBalancerArn": {
            "Ref": "LoadBalancer"
          },
          "Port": 80,
          "Protocol": "HTTP"
        }
      }
    },
    "Outputs": {
      "ClusterName": {
        "Description": "The cluster used to create the service.",
        "Value": {
          "Ref": "ECSCluster"
        }
      },
      "ECSService": {
        "Description": "The created service.",
        "Value": {
          "Ref": "ECSService"
        }
      },
      "LoadBalancer": {
        "Description": "The created load balancer.",
        "Value": {
          "Ref": "LoadBalancer"
        }
      },
      "Listener": {
        "Description": "The created listener.",
        "Value": {
          "Ref": "Listener"
        }
      },
      "TargetGroup": {
        "Description": "The created target group.",
        "Value": {
          "Ref": "TargetGroup"
        }
      }
    }
  }YAMLAWSTemplateFormatVersion: 2010-09-09
Description: The template used to create an ECS Service associated with an
  Application Load Balancer.
Parameters:
  SecurityGroupIDs:
    Type: CommaDelimitedList
    Default: sg-1234567890abcdef0,sg-021345abcdef67890
  SubnetIDs:
    Type: CommaDelimitedList
    Default: subnet-abcdef01234567890,subnet-fedcba01234567098,subnet-2135647890abcdef0
  VpcID:
    Type: String
    Default: vpc-3214789650abcdef0
Resources:
  ECSCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: ALBCluster
  ECSService:
    Type: AWS::ECS::Service
    Properties:
      Cluster:
        Ref: ECSCluster
      TaskDefinition: arn:aws:ecs:us-east-1:111122223333:task-definition/first-run-task:7
      LaunchType: FARGATE
      ServiceName: alb
      SchedulingStrategy: REPLICA
      DesiredCount: 3
      LoadBalancers:
        - ContainerName: first-run-task
          ContainerPort: 80
          LoadBalancerName:
            Ref: AWS::NoValue
          TargetGroupArn:
            Ref: TargetGroup
      HealthCheckGracePeriodSeconds: "20"
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups:
            Ref: SecurityGroupIDs
          Subnets:
            Ref: SubnetIDs
      PlatformVersion: LATEST
      DeploymentConfiguration:
        MaximumPercent: 200
        MinimumHealthyPercent: 100
        DeploymentCircuitBreaker:
          Enable: true
          Rollback: true
      DeploymentController:
        Type: ECS
      ServiceConnectConfiguration:
        Enabled: false
      Tags: []
      EnableECSManagedTags: true
    DependsOn:
      - Listener
  LoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Type: application
      Name: alb-test
      SecurityGroups:
        Ref: SecurityGroupIDs
      Subnets:
        Ref: SubnetIDs
  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      HealthCheckPath: /
      Name: ecs-task-m-alb
      Port: 80
      Protocol: HTTP
      TargetType: ip
      HealthCheckProtocol: HTTP
      VpcId:
        Ref: VpcID
      TargetGroupAttributes:
        - Key: deregistration_delay.timeout_seconds
          Value: "300"
  Listener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn:
            Ref: TargetGroup
      LoadBalancerArn:
        Ref: LoadBalancer
      Port: 80
      Protocol: HTTP
Outputs:
  ClusterName:
    Description: The cluster used to create the service.
    Value:
      Ref: ECSCluster
  ECSService:
    Description: The created service.
    Value:
      Ref: ECSService
  LoadBalancer:
    Description: The created load balancer.
    Value:
      Ref: LoadBalancer
  Listener:
    Description: The created listener.
    Value:
      Ref: Listener
  TargetGroup:
    Description: The created target group.
    Value:
      Ref: TargetGroup

            Create a service with a health check grace periodThe following example creates a service with a parameter that enables users to
               specify how many seconds that the Amazon ECS service scheduler should ignore
               unhealthy Elastic Load Balancing target health checks after a task has first
               started.JSON{
  "AWSTemplateFormatVersion" : "2010-09-09",
  "Description" : "Creating ECS service",
  "Parameters": {
    "AppName": {
      "Type":"String",
      "Description": "Name of app requiring ELB exposure",
      "Default": "simple-app"
    },
    "AppContainerPort": {
      "Type":"Number",
      "Description": "Container port of app requiring ELB exposure",
      "Default": "80"
    },
    "AppHostPort": {
      "Type":"Number",
      "Description": "Host port of app requiring ELB exposure",
      "Default": "80"
    },
    "ServiceName": {
      "Type": "String"
    },
    "LoadBalancerName": {
      "Type": "String"
    },
    "HealthCheckGracePeriodSeconds": {
      "Type": "String"
    }
  },
  "Resources": {
    "ECSCluster": {
      "Type": "AWS::ECS::Cluster"
    },
    "taskdefinition": {
      "Type": "AWS::ECS::TaskDefinition",
      "Properties" : {
        "ContainerDefinitions" : [
          {
            "Name": {"Ref": "AppName"},
            "MountPoints": [
              {
                "SourceVolume": "my-vol",
                "ContainerPath": "/var/www/my-vol"
              }
            ],
            "Image":"amazon/amazon-ecs-sample",
            "Cpu": "10",
            "PortMappings":[
              {
                "ContainerPort": {"Ref":"AppContainerPort"},
                "HostPort": {"Ref":"AppHostPort"}
              }
            ],
            "EntryPoint": [
              "/usr/sbin/apache2",
              "-D",
              "FOREGROUND"
            ],
            "Memory":"500",
            "Essential": "true"
          },
          {
            "Name": "busybox",
            "Image": "busybox",
            "Cpu": "10",
            "EntryPoint": [
              "sh",
              "-c"
            ],
            "Memory": "500",
            "Command": [
              "/bin/sh -c \"while true; do /bin/date > /var/www/my-vol/date; sleep 1; done\""
            ],
            "Essential" : "false",
            "VolumesFrom": [
              {
                "SourceContainer": {"Ref":"AppName"}
              }
            ]
          }
        ],
        "Volumes": [
          {
            "Host": {
              "SourcePath": "/var/lib/docker/vfs/dir/"
            },
            "Name": "my-vol"
          }
        ]
      }
    },
    "ECSService": {
      "Type": "AWS::ECS::Service",
      "Properties" : {
        "Cluster": {"Ref": "ECSCluster"},
        "DeploymentConfiguration": {
          "MaximumPercent": 200,
          "MinimumHealthyPercent": 100
        },
        "DesiredCount": 1,
        "HealthCheckGracePeriodSeconds": {"Ref": "HealthCheckGracePeriodSeconds"},
        "LoadBalancers": [{
          "ContainerName": {"Ref" : "AppName"},
          "ContainerPort": {"Ref":"AppContainerPort"},
          "LoadBalancerName": {"Ref": "elb"}
        }],
        "PlacementStrategies": [{
          "Type" : "binpack",
          "Field": "memory"
        }, {
          "Type": "spread",
          "Field": "host"
        }],
        "PlacementConstraints": [{
          "Type": "memberOf",
          "Expression": "attribute:ecs.availability-zone != us-east-1d"
        }, {
          "Type": "distinctInstance"
        }],
        "TaskDefinition" : {"Ref":"taskdefinition"},
        "ServiceName": {"Ref": "ServiceName"},
        "Role": {"Ref": "Role"}
      }
    },
    "elb": {
      "Type": "AWS::ElasticLoadBalancing::LoadBalancer",
      "Properties": {
        "LoadBalancerName": {"Ref": "LoadBalancerName"},
        "Listeners": [{
          "InstancePort": {"Ref": "AppHostPort"},
          "LoadBalancerPort": "80",
          "Protocol": "HTTP"
        }],
        "Subnets": [{"Ref":"Subnet1"}]
      },
      "DependsOn": "GatewayAttachment"
    },
    "VPC": {
      "Type": "AWS::EC2::VPC",
      "Properties": {
        "CidrBlock": "10.0.0.0/24"
      }
    },
    "Subnet1": {
      "Type": "AWS::EC2::Subnet",
      "Properties": {
        "VpcId": { "Ref": "VPC" },
        "CidrBlock": "10.0.0.0/25"
      }
    },
    "InternetGateway": {
      "Type": "AWS::EC2::InternetGateway"
    },
    "GatewayAttachment": {
      "Type": "AWS::EC2::VPCGatewayAttachment",
      "Properties": {
        "InternetGatewayId": {"Ref": "InternetGateway"},
        "VpcId": {"Ref": "VPC"}
      }
    },
    "Role": {
      "Type": "AWS::IAM::Role",
      "Properties": {
        "AssumeRolePolicyDocument": {
          "Version": "2008-10-17",
          "Statement": [
            {
              "Sid": "",
              "Effect": "Allow",
              "Principal": {
                "Service": "ecs.amazonaws.com"
              },
              "Action": "sts:AssumeRole"
            }
          ]
        },
        "ManagedPolicyArns": ["arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceRole"]
      }
    }
  },
  "Outputs" : {
    "Cluster": {
      "Value": {"Ref" : "ECSCluster"}
    }
  }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Description: Creating ECS service
Parameters:
  AppName:
    Type: String
    Description: Name of app requiring ELB exposure
    Default: simple-app
  AppContainerPort:
    Type: Number
    Description: Container port of app requiring ELB exposure
    Default: '80'
  AppHostPort:
    Type: Number
    Description: Host port of app requiring ELB exposure
    Default: '80'
  ServiceName:
    Type: String
  LoadBalancerName:
    Type: String
  HealthCheckGracePeriodSeconds:
    Type: String
Resources:
  cluster:
    Type: AWS::ECS::Cluster
  taskdefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      ContainerDefinitions:
        - Name: !Ref AppName
          MountPoints:
            - SourceVolume: my-vol
              ContainerPath: /var/www/my-vol
          Image: amazon/amazon-ecs-sample
          Cpu: '10'
          PortMappings:
            - ContainerPort: !Ref AppContainerPort
              HostPort: !Ref AppHostPort
          EntryPoint:
            - /usr/sbin/apache2
            - '-D'
            - FOREGROUND
          Memory: '500'
          Essential: true
        - Name: busybox
          Image: busybox
          Cpu: '10'
          EntryPoint:
            - sh
            - '-c'
          Memory: '500'
          Command:
            - >-
              /bin/sh -c "while true; do /bin/date > /var/www/my-vol/date; sleep
              1; done"
          Essential: false
          VolumesFrom:
            - SourceContainer: !Ref AppName
      Volumes:
        - Host:
            SourcePath: /var/lib/docker/vfs/dir/
          Name: my-vol
  service:
    Type: AWS::ECS::Service
    Properties:
      Cluster: !Ref cluster
      DeploymentConfiguration:
        MaximumPercent: 200
        MinimumHealthyPercent: 100
      DesiredCount: 1
      HealthCheckGracePeriodSeconds: !Ref HealthCheckGracePeriodSeconds
      LoadBalancers:
        - ContainerName: !Ref AppName
          ContainerPort: !Ref AppContainerPort
          LoadBalancerName: !Ref elb
      PlacementStrategies:
        - Type: binpack
          Field: memory
        - Type: spread
          Field: host
      PlacementConstraints:
        - Type: memberOf
          Expression: 'attribute:ecs.availability-zone != us-east-1d'
        - Type: distinctInstance
      TaskDefinition: !Ref taskdefinition
      ServiceName: !Ref ServiceName
      Role: !Ref Role
  elb:
    Type: AWS::ElasticLoadBalancing::LoadBalancer
    Properties:
      LoadBalancerName: !Ref LoadBalancerName
      Listeners:
        - InstancePort: !Ref AppHostPort
          LoadBalancerPort: '80'
          Protocol: HTTP
      Subnets:
        - !Ref Subnet1
    DependsOn: GatewayAttachment
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/24
  Subnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.0.0/25
  InternetGateway:
    Type: AWS::EC2::InternetGateway
  GatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref VPC
  Role:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2008-10-17
        Statement:
          - Sid: ''
            Effect: Allow
            Principal:
              Service: ecs.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceRole'
Outputs:
  Cluster:
    Value: !Ref cluster
            Create a service with ECS Exec enabledThe following example defines a service with ECS Exec enabled that uses a task definition that is defined in the template and runs in a cluster that is defined in the template. Replace
                  ExecutionRoleArn, TaskRoleArn,
                  SecurityGroups, and Subnets with your own information.
               For more information, see Monitor Amazon ECS containers
                  with ECS Exec in the Amazon ECS Developer
               Guide.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "ECSCluster": {
            "Type": "AWS::ECS::Cluster",
            "Properties": {
                "ClusterName": "ExecCluster"
            }
        },
        "ECSTaskDefinition": {
            "Type": "AWS::ECS::TaskDefinition",
            "Properties": {
                "ContainerDefinitions": [
                    {
                        "Command": [
                            "/bin/sh -c \"echo '<html> <head> <title>Amazon ECS Sample App</title> <style>body {margin-top: 40px; background-color: #333;} </style> </head><body> <div style=color:white;text-align:center> <h1>Amazon ECS Sample App</h1> <h2>Congratulations!</h2> <p>Your application is now running on a container in Amazon ECS.</p> </div></body></html>' >  /usr/local/apache2/htdocs/index.html && httpd-foreground\""
                        ],
                        "EntryPoint": [
                            "sh",
                            "-c"
                        ],
                        "Essential": true,
                        "Image": "public.ecr.aws/docker/library/httpd:2.4",
                        "LogConfiguration": {
                            "LogDriver": "awslogs",
                            "Options": {
                                "awslogs-group": "/ecs/fargate-task-definition",
                                "awslogs-region": "us-east-1",
                                "awslogs-stream-prefix": "ecs"
                            }
                        },
                        "Name": "sample-fargate-app",
                        "PortMappings": [
                            {
                                "ContainerPort": 80,
                                "HostPort": 80,
                                "Protocol": "tcp"
                            }
                        ]
                    }
                ],
                "Cpu": 256,
                "ExecutionRoleArn": "arn:aws:iam::111122223333:role/ecsTaskExecutionRole",
                "TaskRoleArn":"arn:aws:iam::111122223333:role/execRole"
                "Family": "task-definition-exec",
                "Memory": 512,
                "NetworkMode": "awsvpc",
                "RequiresCompatibilities": [
                    "FARGATE"
                ],
                "RuntimePlatform": {
                    "OperatingSystemFamily": "LINUX"
                }
            }
        },
        "ECSService": {
            "Type": "AWS::ECS::Service",
            "Properties": {
                "ServiceName": "exec-service",
                "Cluster": {
                    "Ref": "ECSCluster"
                },
                "DesiredCount": 1,
                "LaunchType": "FARGATE",
                "EnableExecuteCommand": "true",
                "NetworkConfiguration": {
                    "AwsvpcConfiguration": {
                        "AssignPublicIp": "ENABLED",
                        "SecurityGroups": [
                            "sg-abcdef01234567890"
                        ],
                        "Subnets": [
                            "subnet-021345abcdef67890"
                        ]
                    }
                },
                "TaskDefinition": {
                    "Ref": "ECSTaskDefinition"
                }
            }
        }
    }
} YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  ECSCluster:
    Type: 'AWS::ECS::Cluster'
    Properties:
      ClusterName: ExecCluster
  ECSTaskDefinition:
    Type: 'AWS::ECS::TaskDefinition'
    Properties:
      ContainerDefinitions:
        - Command:
            - >-
              /bin/sh -c "echo '<html> <head> <title>Amazon ECS Sample
              App</title> <style>body {margin-top: 40px; background-color:
              #333;} </style> </head><body> <div
              style=color:white;text-align:center> <h1>Amazon ECS Sample
              App</h1> <h2>Congratulations!</h2> <p>Your application is now
              running on a container in Amazon ECS.</p> </div></body></html>' > 
              /usr/local/apache2/htdocs/index.html && httpd-foreground"
          EntryPoint:
            - sh
            - '-c'
          Essential: true
          Image: 'public.ecr.aws/docker/library/httpd:2.4'
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: /ecs/fargate-task-definition
              awslogs-region: us-east-1
              awslogs-stream-prefix: ecs
          Name: sample-fargate-app
          PortMappings:
            - ContainerPort: 80
              HostPort: 80
              Protocol: tcp
      Cpu: 256
      ExecutionRoleArn: 'arn:aws:iam::111122223333:role/ecsTaskExecutionRole'
      TaskRoleArn: arn:aws:iam::111122223333:role/execCommandRole
      Family: task-definition-exec
      Memory: 512
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - FARGATE
      RuntimePlatform:
        OperatingSystemFamily: LINUX
  ECSService:
    Type: 'AWS::ECS::Service'
    Properties:
      ServiceName: exec-service
      Cluster: !Ref ECSCluster
      DesiredCount: 1
      EnableExecuteCommand: "true"
      LaunchType: FARGATE
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups:
            - sg-abcdef01234567890
          Subnets:
            - subnet-021345abcdef67890
      TaskDefinition: !Ref ECSTaskDefinition
        Document ConventionsAWS::ECS::PrimaryTaskSetAwsVpcConfigurationDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::ECS::TaskDefinitionRegisters a new task definition from the supplied family and
				containerDefinitions. Optionally, you can add data volumes to your
			containers with the volumes parameter. For more information about task
			definition parameters and defaults, see Amazon ECS Task
				Definitions in the Amazon Elastic Container Service Developer Guide.You can specify a role for your task with the taskRoleArn parameter. When
			you specify a role for a task, its containers can then use the latest versions of the
			AWS CLI or SDKs to make API requests to the AWS services that are specified in the
			policy that's associated with the role. For more information, see IAM
				Roles for Tasks in the Amazon Elastic Container Service Developer Guide.You can specify a Docker networking mode for the containers in your task definition
			with the networkMode parameter. If you specify the awsvpc
			network mode, the task is allocated an elastic network interface, and you must specify a
				NetworkConfiguration when you create a service or run a task with the task
			definition. For more information, see Task Networking
			in the Amazon Elastic Container Service Developer Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ECS::TaskDefinition",
  "Properties" : {
      "ContainerDefinitions" : [ ContainerDefinition, ... ],
      "Cpu" : String,
      "EnableFaultInjection" : Boolean,
      "EphemeralStorage" : EphemeralStorage,
      "ExecutionRoleArn" : String,
      "Family" : String,
      "InferenceAccelerators" : [ InferenceAccelerator, ... ],
      "IpcMode" : String,
      "Memory" : String,
      "NetworkMode" : String,
      "PidMode" : String,
      "PlacementConstraints" : [ TaskDefinitionPlacementConstraint, ... ],
      "ProxyConfiguration" : ProxyConfiguration,
      "RequiresCompatibilities" : [ String, ... ],
      "RuntimePlatform" : RuntimePlatform,
      "Tags" : [ Tag, ... ],
      "TaskRoleArn" : String,
      "Volumes" : [ Volume, ... ]
    }
}
YAMLType: AWS::ECS::TaskDefinition
Properties:
  ContainerDefinitions: 
    - ContainerDefinition
  Cpu: String
  EnableFaultInjection: Boolean
  EphemeralStorage: 
    EphemeralStorage
  ExecutionRoleArn: String
  Family: String
  InferenceAccelerators: 
    - InferenceAccelerator
  IpcMode: String
  Memory: String
  NetworkMode: String
  PidMode: String
  PlacementConstraints: 
    - TaskDefinitionPlacementConstraint
  ProxyConfiguration: 
    ProxyConfiguration
  RequiresCompatibilities: 
    - String
  RuntimePlatform: 
    RuntimePlatform
  Tags: 
    - Tag
  TaskRoleArn: String
  Volumes: 
    - Volume
PropertiesContainerDefinitions
                    A list of container definitions in JSON format that describe the different containers
			that make up your task. For more information about container definition parameters and
			defaults, see Amazon ECS Task
				Definitions in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: Array of ContainerDefinitionUpdate requires: ReplacementCpu
                    The number of cpu units used by the task. If you use the EC2 launch type,
			this field is optional. Any value can be used. If you use the Fargate launch type, this
			field is required. You must use one of the following values. The value that you choose
			determines your range of valid values for the memory parameter.
                    If you're using the EC2 launch type or the external launch type, this
			field is optional. Supported values are between 128 CPU units
				(0.125 vCPUs) and 196608 CPU units (192
			vCPUs). The CPU units cannot be less than 1 vCPU when you use Windows containers on
			Fargate.
                    
                         
                         
                         
                         
                         
                         
                         
                    
                            256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)
                        
                            512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)
                        
                            1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)
                        
                            2048 (2 vCPU) - Available memory values: 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)
                        
                            4096 (4 vCPU) - Available memory values: 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)
                        
                            8192 (8 vCPU)  - Available memory values: 16 GB and 60 GB in 4 GB increments
                            This option requires Linux platform 1.4.0 or
                                        later.
                        
                            16384 (16vCPU)  - Available memory values: 32GB and 120 GB in 8 GB increments
                            This option requires Linux platform 1.4.0 or
                                        later.
                        
                Required: NoType: StringUpdate requires: ReplacementEnableFaultInjection
                    Enables fault injection and allows for fault injection requests to be accepted from
			the task's containers. The default value is false.
                Required: NoType: BooleanUpdate requires: ReplacementEphemeralStorage
                    The ephemeral storage settings to use for tasks run with the task definition.
                Required: NoType: EphemeralStorageUpdate requires: ReplacementExecutionRoleArn
                    The Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent
            permission to make AWS API calls on your behalf. For informationabout the required IAM roles for Amazon ECS, see IAM roles for Amazon ECS in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: StringUpdate requires: ReplacementFamily
                    The name of a family that this task definition is registered to. Up to 255 letters
         (uppercase and lowercase), numbers, hyphens, and underscores are allowed.
                    A family groups multiple versions of a task definition. Amazon ECS gives the first task
         definition that you registered to a family a revision number of 1. Amazon ECS gives
         sequential revision numbers to each task definition that you add.
                    NoteTo use revision numbers when you update a task definition, specify this property. If
            you don't specify a value, AWS CloudFormation generates a new task definition each
            time that you update it.
                Required: NoType: StringUpdate requires: ReplacementInferenceAccelerators
                    The Elastic Inference accelerators to use for the containers in the task.
                Required: NoType: Array of InferenceAcceleratorUpdate requires: ReplacementIpcMode
                    The IPC resource namespace to use for the containers in the task. The valid values are
                host, task, or none. If host is
            specified, then all containers within the tasks that specified the host IPC
            mode on the same container instance share the same IPC resources with the host Amazon EC2
            instance. If task is specified, all containers within the specified task
            share the same IPC resources. If none is specified, then IPC resources
            within the containers of a task are private and not shared with other containers in a
            task or on the container instance. If no value is specified, then the IPC resource
            namespace sharing depends on the Docker daemon setting on the container instance.
                    If the host IPC mode is used, be aware that there is a heightened risk of
            undesired IPC namespace expose.
                    If you are setting namespaced kernel parameters using systemControls for
            the containers in the task, the following will apply to your IPC resource namespace. For
            more information, see System
                Controls in the Amazon Elastic Container Service Developer Guide.
                    
                         
                         
                    
                            For tasks that use the host IPC mode, IPC namespace related
                        systemControls are not supported.
                        
                            For tasks that use the task IPC mode, IPC namespace related
                        systemControls will apply to all containers within a
                    task.
                        
                    NoteThis parameter is not supported for Windows containers or tasks run on AWS Fargate.
                Required: NoType: StringAllowed values: host | task | noneUpdate requires: ReplacementMemory
                    The amount (in MiB) of memory used by the task.
                    If your tasks runs on Amazon EC2 instances, you must specify either a task-level memory
			value or a container-level memory value. This field is optional and any value can be
			used. If a task-level memory value is specified, the container-level memory value is
			optional. For more information regarding container-level memory and memory reservation,
			see ContainerDefinition.
                    If your tasks runs on AWS Fargate, this field is required. You must use one of the
			following values. The value you choose determines your range of valid values for the
				cpu parameter.
                    
                         
                         
                         
                         
                         
                         
                         
                    
                            512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)
                        
                            1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)
                        
                            2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)
                        
                            Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)
                        
                            Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)
                        
                            Between 16 GB and 60 GB in 4 GB increments - Available cpu values: 8192 (8 vCPU)
                            This option requires Linux platform 1.4.0 or
                                        later.
                        
                            Between 32GB and 120 GB in 8 GB increments - Available cpu values: 16384 (16 vCPU)
                            This option requires Linux platform 1.4.0 or
                                        later.
                        
                Required: NoType: StringUpdate requires: ReplacementNetworkMode
                    The Docker networking mode to use for the containers in the task. The valid values are
                none, bridge, awsvpc, and host.
            If no network mode is specified, the default is bridge.
                    For Amazon ECS tasks on Fargate, the awsvpc network mode is required. 
            For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used.  For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network
            mode is set to none, you cannot specify port mappings in your container
            definitions, and the tasks containers do not have external connectivity. The
                host and awsvpc network modes offer the highest networking
            performance for containers because they use the EC2 network stack instead of the
            virtualized network stack provided by the bridge mode.
                    With the host and awsvpc network modes, exposed container
            ports are mapped directly to the corresponding host port (for the host
            network mode) or the attached elastic network interface port (for the
                awsvpc network mode), so you cannot take advantage of dynamic host port
            mappings. 
                    ImportantWhen using the host network mode, you should not run
                            containers using the root user (UID 0). It is considered best practice
                            to use a non-root user.
                    If the network mode is awsvpc, the task is allocated an elastic network
            interface, and you must specify a NetworkConfiguration value when you create
            a service or run a task with the task definition. For more information, see Task Networking in the
                Amazon Elastic Container Service Developer Guide.
                    If the network mode is host, you cannot run multiple instantiations of the
            same task on a single container instance when port mappings are used.
                Required: NoType: StringAllowed values: bridge | host | awsvpc | noneUpdate requires: ReplacementPidMode
                    The process namespace to use for the containers in the task. The valid
                            values are host or task. On Fargate for
                            Linux containers, the only valid value is task. For
                            example, monitoring sidecars might need pidMode to access
                            information about other containers running in the same task.
                    If host is specified, all containers within the tasks
                            that specified the host PID mode on the same container
                            instance share the same process namespace with the host Amazon EC2
                            instance.
                    If task is specified, all containers within the specified
                            task share the same process namespace.
                    If no value is specified, the
                            default is a private namespace for each container.
                    If the host PID mode is used, there's a heightened risk
                            of undesired process namespace exposure.
                    NoteThis parameter is not supported for Windows containers.
                    NoteThis parameter is only supported for tasks that are hosted on
        AWS Fargate if the tasks are using platform version 1.4.0 or later
        (Linux). This isn't supported for Windows containers on
        Fargate.
                Required: NoType: StringAllowed values: host | taskUpdate requires: ReplacementPlacementConstraints
                    An array of placement constraint objects to use for tasks.
                    NoteThis parameter isn't supported for tasks run on AWS Fargate.
                Required: NoType: Array of TaskDefinitionPlacementConstraintUpdate requires: ReplacementProxyConfiguration
                    The configuration details for the App Mesh proxy.
                    Your Amazon ECS container instances require at least version 1.26.0 of the container agent
			and at least version 1.26.0-1 of the ecs-init package to use a proxy
			configuration. If your container instances are launched from the Amazon ECS optimized AMI
			version 20190301 or later, they contain the required versions of the
			container agent and ecs-init. For more information, see Amazon ECS-optimized Linux AMI in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: ProxyConfigurationUpdate requires: ReplacementRequiresCompatibilities
                    The task launch types the task definition was validated against. The valid values are
				EC2, FARGATE, and EXTERNAL. For more
			information, see Amazon ECS launch types
			in the Amazon Elastic Container Service Developer Guide.
                Required: NoType: Array of StringUpdate requires: ReplacementRuntimePlatform
                    The operating system that your tasks definitions run on. A platform family is
			specified only for tasks using the Fargate launch type. 
                Required: NoType: RuntimePlatformUpdate requires: ReplacementTags
                    The metadata that you apply to the task definition to help you categorize and organize
			them. Each tag consists of a key and an optional value. You define both of them.
                    The following basic restrictions apply to tags:
                    
                         
                         
                         
                         
                         
                         
                         
                    
                            Maximum number of tags per resource - 50
                        
                            For each resource, each tag key must be unique, and each tag key can have only
                    one value.
                        
                            Maximum key length - 128 Unicode characters in UTF-8
                        
                            Maximum value length - 256 Unicode characters in UTF-8
                        
                            If your tagging schema is used across multiple services and resources,
                    remember that other services may have restrictions on allowed characters.
                    Generally allowed characters are: letters, numbers, and spaces representable in
                    UTF-8, and the following characters: + - = . _ : / @.
                        
                            Tag keys and values are case-sensitive.
                        
                            Do not use aws:, AWS:, or any upper or lowercase
                    combination of such as a prefix for either keys or values as it is reserved for
                    AWS use. You cannot edit or delete tag keys or values with this prefix. Tags with
                    this prefix do not count against your tags per resource limit.
                        
                Required: NoType: Array of TagMinimum: 0Maximum: 50Update requires: No interruptionTaskRoleArn
                    The short name or full Amazon Resource Name (ARN) of the AWS Identity and Access Management role that grants containers in the
			task permission to call AWS APIs on your behalf. For more information, see Amazon ECS
				Task Role in the Amazon Elastic Container Service Developer Guide.
                    IAM roles for tasks on Windows require that the -EnableTaskIAMRole
			option is set when you launch the Amazon ECS-optimized Windows AMI. Your containers must also run some
			configuration code to use the feature. For more information, see Windows IAM roles
				for tasks in the Amazon Elastic Container Service Developer Guide.
                    NoteString validation is done on the ECS side. If an invalid string value is given for TaskRoleArn, it 
       may cause the Cloudformation job to hang.
                Required: NoType: StringUpdate requires: ReplacementVolumes
                    The list of data volume definitions for the task. For more information, see Using data volumes in tasks in the Amazon Elastic Container Service Developer Guide.
                    NoteThe host and sourcePath parameters aren't supported for
				tasks run on AWS Fargate. 
                Required: NoType: Array of VolumeUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Amazon Resource Name (ARN).In the following example, the Ref function returns the ARN of the
            MyTaskDefinition task definition, such as
            arn:aws:ecs:us-west-2:123456789012:task-definition/TaskDefinitionFamily:1.
                        { "Ref": "MyTaskDefinition" }
                    For more information about using the Ref function, see Ref.Fn::GetAttTaskDefinitionArn
                            The ARN of the task definition.
                        Examples Create a task definition with 2 containersCreate a task definition that can be used for both the Fargate and the EC2 launch typesCreate an Amazon ECS task definition with an Amazon EFS
            volume
            
            Create a task definition with 2 containersThe following example defines an Amazon ECS task definition, which
               includes two container definitions and one volume definition.JSON{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Resources": {
    "taskdefinition": {
      "Type": "AWS::ECS::TaskDefinition",
      "Properties": {
        "ContainerDefinitions": [
          {
            "Name": "AppName",
            "MountPoints": [
              {
                "SourceVolume": "my-vol",
                "ContainerPath": "/var/www/my-vol"
              }
            ],
            "Image": "amazon/amazon-ecs-sample",
            "Cpu": 256,
            "PortMappings": [
              {
                "ContainerPort": 80,
                "HostPort": 80,
                "Protocol": "tcp"
              }
            ],
            "EntryPoint": ["/usr/sbin/apache2", "-D", "FOREGROUND"],
            "Memory": 512,
            "Essential": true
          },
          {
            "Name": "busybox",
            "Image": "busybox",
            "Cpu": 256,
            "EntryPoint": ["sh", "-c"],
            "Memory": 512,
            "Command": [
              "/bin/sh -c \"while true; do /bin/date > /var/www/my-vol/date; sleep 1; done\""
            ],
            "Essential": false,
            "VolumesFrom": [
              {
                "SourceContainer": "AppName"
              }
            ]
          }
        ],
        "Volumes": [
          {
            "Host": {
              "SourcePath": "/var/lib/docker/vfs/dir/"
            },
            "Name": "my-vol"
          }
        ]
      }
    }
  }
}
YAMLAWSTemplateFormatVersion: "2010-09-09"
Resources:
  taskdefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      ContainerDefinitions:
        - Name: AppName
          MountPoints:
            - SourceVolume: my-vol
              ContainerPath: "/var/www/my-vol"
          Image: amazon/amazon-ecs-sample
          Cpu: 256
          PortMappings:
            - ContainerPort: 80
              HostPort: 80
              Protocol: tcp
          EntryPoint:
            - "/usr/sbin/apache2"
            - "-D"
            - FOREGROUND
          Memory: 512
          Essential: true
        - Name: busybox
          Image: busybox
          Cpu: 256
          EntryPoint:
            - sh
            - "-c"
          Memory: 512
          Command:
            - "/bin/sh"
            - "-c"
            - "while true; do /bin/date > /var/www/my-vol/date; sleep 1; done"
          Essential: false
          VolumesFrom:
            - SourceContainer: AppName
      Volumes:
        - Host:
            SourcePath: "/var/lib/docker/vfs/dir/"
          Name: my-vol

            Create a task definition that can be used for both the Fargate and the EC2 launch typesThe following is an example task definition using a Linux container that sets up a
               web server and is tagged with the key environment and the value
                  webserver. This task definition is compatible across both the Fargate and EC2 launch types.JSON{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Description": "Create a task definition for a web server.",
  "Resources": {
    "ECSTaskDefinition": {
      "Type": "AWS::ECS::TaskDefinition",
      "Properties": {
        "ContainerDefinitions": [
          {
            "Name": "first-run-task",
            "Image": "public.ecr.aws/docker/library/httpd:2.4",
            "Essential": true,
            "PortMappings": [
              {
                "ContainerPort": 80,
                "Protocol": "tcp"
              }
            ],
             "EntryPoint": ["sh", "-c"],
             "Command":[
              "/bin/sh -c \"echo '<html> <head> <title>Amazon ECS Sample App</title> <style>body {margin-top: 40px; background-color: #333;} </style> </head><body> <div style=color:white;text-align:center> <h1>Amazon ECS Sample App</h1> <h2>Congratulations!</h2> <p>Your application is now running on a container in Amazon ECS.</p> </div></body></html>' >  /usr/local/apache2/htdocs/index.html && httpd-foreground\""
            ]
          }
        ],
        "Family": "first-run-task",
        "Cpu": "1 vCPU",
        "Memory": "3 GB",
        "NetworkMode": "awsvpc",
        "RequiresCompatibilities": ["EC2","FARGATE"],
         "Tags": [
            {
                "Key": "environment",
                "Value": "webserver"
            }
        ]
      }
    }
  },
  "Outputs": {
    "ECSTaskDefinition": {
      "Description": "The created Taskdefinition.",
      "Value": {
        "Ref": "ECSTaskDefinition"
      }
    }
  }
}          YAMLAWSTemplateFormatVersion: 2010-09-09
Description: Create a task definition for a web server.
Resources:
  ECSTaskDefinition:
    Type: 'AWS::ECS::TaskDefinition'
    Properties:
      ContainerDefinitions:
        - Name: first-run-task
          Image: 'public.ecr.aws/docker/library/httpd:2.4'
          Essential: true
          PortMappings:
            - ContainerPort: 80
              Protocol: tcp
          EntryPoint:
            - sh
            - -c
          Command:
            -   "/bin/sh -c \"echo '<html> <head> <title>Amazon ECS Sample
                App</title> <style>body {margin-top: 40px; background-color:
                #333;} </style> </head><body> <div
                style=color:white;text-align:center> <h1>Amazon ECS Sample
                App</h1> <h2>Congratulations!</h2> <p>Your application is now
                running on a container in Amazon ECS.</p> </div></body></html>'
                >  /usr/local/apache2/htdocs/index.html && httpd-foreground\""
      Family: first-run-task
      Cpu: 1 vCPU
      Memory: 3 GB
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - EC2
        - FARGATE
      Tags:
        - Key: environment
          Value: webserver
Outputs:
  ECSTaskDefinition:
    Description: The created Taskdefinition.
    Value: !Ref ECSTaskDefinition        
            Create an Amazon ECS task definition with an Amazon EFS
            volumeThe following example defines an Amazon ECS task definition that uses an
                  Amazon EFS volume. Replace the ExecutionRoleArn and
               FileSystemId with your own values. For more information about using Amazon EFS volumes with Amazon ECS, see Use Amazon EFS volumes with Amazon ECS in the Amazon ECS Developer Guide.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "Create a task definition for a web server.",
    "Resources": {
      "ECSTaskDefinition": {
        "Type": "AWS::ECS::TaskDefinition",
        "Properties": {
          "ExecutionRoleArn": "arn:aws:iam::123456789012:role/ecsTaskExecutionRole",
          "NetworkMode": "awsvpc",
          "RequiresCompatibilities": ["FARGATE"],
          "Family": "my-ecs-task",
          "Cpu": "256",
          "Memory": "512",
          "ContainerDefinitions": [
            {
              "Name": "nginx",
              "Image": "public.ecr.aws/nginx/nginx:latest",
              "Essential": true,
              "PortMappings": [
                {
                  "ContainerPort": 80,
                  "Protocol": "tcp"
                }
              ],
              "LinuxParameters": {
                "InitProcessEnabled": true
              },
              "MountPoints": [
                {
                  "SourceVolume": "efs-volume",
                  "ContainerPath": "/usr/share/nginx/html"
                }
            ],
                "LogConfiguration": {
                  "LogDriver": "awslogs",
                    "Options": {
                      "mode": "non-blocking",
                      "max-buffer-size": "25m",
                      "awslogs-group": "LogGroup",
                      "awslogs-region": "us-east-1",
                      "awslogs-create-group": "true",
                      "awslogs-stream-prefix": "efs-task"
                    }
                }
            }
        ],
          "Volumes": [
            {
              "Name": "efs-volume",
              "EFSVolumeConfiguration": {
                "FilesystemId": "fs-1234567890abcdef0",
                "RootDirectory": "/",
                "TransitEncryption": "ENABLED"
              }
          }
        ]
        }
      }
    }
  }YAMLAWSTemplateFormatVersion: 2010-09-09
Description: Create a task definition for a web server.
Resources:
  ECSTaskDefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      ExecutionRoleArn: arn:aws:iam::123456789012:role/ecsTaskExecutionRole
      NetworkMode: awsvpc
      RequiresCompatibilities:
        - FARGATE
      Family: my-ecs-task
      Cpu: "256"
      Memory: "512"
      ContainerDefinitions:
        - Name: nginx
          Image: public.ecr.aws/nginx/nginx:latest
          Essential: true
          PortMappings:
            - ContainerPort: 80
              Protocol: tcp
          LinuxParameters:
            InitProcessEnabled: true
          MountPoints:
            - SourceVolume: efs-volume
              ContainerPath: /usr/share/nginx/html
          LogConfiguration:
            LogDriver: awslogs
            Options:
              mode: non-blocking
              max-buffer-size: 25m
              awslogs-group: LogGroup
              awslogs-region: us-east-1
              awslogs-create-group: "true"
              awslogs-stream-prefix: efs-task
      Volumes:
        - Name: efs-volume
          EFSVolumeConfiguration:
            FilesystemId: fs-1234567890abcdef0
            RootDirectory: /
            TransitEncryption: ENABLED

        Document ConventionsVpcLatticeConfigurationAuthorizationConfigDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::ElasticLoadBalancingV2::ListenerSpecifies a listener for an Application Load Balancer, Network Load Balancer, or
         Gateway Load Balancer.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ElasticLoadBalancingV2::Listener",
  "Properties" : {
      "AlpnPolicy" : [ String, ... ],
      "Certificates" : [ Certificate, ... ],
      "DefaultActions" : [ Action, ... ],
      "ListenerAttributes" : [ ListenerAttribute, ... ],
      "LoadBalancerArn" : String,
      "MutualAuthentication" : MutualAuthentication,
      "Port" : Integer,
      "Protocol" : String,
      "SslPolicy" : String
    }
}
YAMLType: AWS::ElasticLoadBalancingV2::Listener
Properties:
  AlpnPolicy: 
    - String
  Certificates: 
    - Certificate
  DefaultActions: 
    - Action
  ListenerAttributes: 
    - ListenerAttribute
  LoadBalancerArn: String
  MutualAuthentication: 
    MutualAuthentication
  Port: Integer
  Protocol: String
  SslPolicy: String
PropertiesAlpnPolicy
                    [TLS listener] The name of the Application-Layer Protocol Negotiation (ALPN)
      policy.
                Required: NoType: Array of StringUpdate requires: No interruptionCertificates
                    The default SSL server certificate for a secure listener. You must provide exactly one
         certificate if the listener protocol is HTTPS or TLS.
                    To create a certificate list for a secure listener, use AWS::ElasticLoadBalancingV2::ListenerCertificate.
                Required: ConditionalType: Array of CertificateUpdate requires: No interruptionDefaultActions
                    The actions for the default rule. You cannot define a condition for a default
         rule.
                    To create additional rules for an Application Load Balancer, use AWS::ElasticLoadBalancingV2::ListenerRule.
                Required: YesType: Array of ActionUpdate requires: No interruptionListenerAttributes
                    The listener attributes.
                Required: NoType: Array of ListenerAttributeUpdate requires: No interruptionLoadBalancerArn
                    The Amazon Resource Name (ARN) of the load balancer.
                Required: YesType: StringUpdate requires: ReplacementMutualAuthentication
                    The mutual authentication configuration information.
                Required: NoType: MutualAuthenticationUpdate requires: No interruptionPort
                    The port on which the load balancer is listening. You can't specify a port for a Gateway
      Load Balancer.
                Required: NoType: IntegerMinimum: 1Maximum: 65535Update requires: No interruptionProtocol
                    The protocol for connections from clients to the load balancer. For Application Load
      Balancers, the supported protocols are HTTP and HTTPS. For Network Load Balancers, the
      supported protocols are TCP, TLS, UDP, and TCP_UDP. You can’t specify the UDP or TCP_UDP
      protocol if dual-stack mode is enabled. You can't specify a protocol for a Gateway Load
      Balancer.
                Required: NoType: StringAllowed values: HTTP | HTTPS | TCP | TLS | UDP | TCP_UDP | GENEVEUpdate requires: No interruptionSslPolicy
                    [HTTPS and TLS listeners] The security policy that defines which protocols and ciphers are supported.
                    Updating the security policy can result in interruptions if the load balancer is handling a high volume of traffic.
                    For more information, see Security policies 
         in the Application Load Balancers Guide and Security policies 
         in the Network Load Balancers Guide.
                Required: NoType: StringUpdate requires: Some interruptionsReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Amazon Resource Name (ARN) of the listener.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.ListenerArn
                            The Amazon Resource Name (ARN) of the listener.
                        ExamplesThe following example creates a listener with a default action that redirects HTTP
            requests on port 80 to HTTPS requests on port 443, retaining the original host name,
            path, and query string.
            
            YAMLHTTPlistener:
   Type: "AWS::ElasticLoadBalancingV2::Listener"
   Properties:
     DefaultActions:
       - Type: "redirect"
         RedirectConfig:
           Protocol: "HTTPS"
           Port: 443
           Host: "#{host}"
           Path: "/#{path}"
           Query: "#{query}"
           StatusCode: "HTTP_301"
     LoadBalancerArn: !Ref myLoadBalancer
     Port: 80
     Protocol: "HTTP"JSON"HTTPlistener": {
    "Type": "AWS::ElasticLoadBalancingV2::Listener",
    "Properties": {
        "DefaultActions": [
            {
                "Type": "redirect",
                "RedirectConfig": {
                    "Protocol": "HTTPS",
                    "Port": 443,
                    "Host": "#{host}",
                    "Path": "/#{path}",
                    "Query": "#{query}",
                    "StatusCode": "HTTP_301"
                }
            }
        ],
        "LoadBalancerArn": {
            "Ref": "myLoadBalancer"
        },
        "Port": 80,
        "Protocol": "HTTP"
    }
}
        See also
                 
                 
                 
                 
            
                    CreateListener in the Elastic Load Balancing API Reference
                     (version 2015-12-01)
                
                    Listeners in the User Guide for Application Load
                     Balancers
                
                    Listeners in the User Guide for Network Load
                     Balancers
                
                    Listeners in the User Guide for Gateway Load
                     Balancers
                Document ConventionsElastic Load Balancing V2ActionDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesSee alsoAWS::ElasticLoadBalancingV2::LoadBalancerSpecifies an Application Load Balancer, a Network Load Balancer, or a Gateway Load
         Balancer.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ElasticLoadBalancingV2::LoadBalancer",
  "Properties" : {
      "EnablePrefixForIpv6SourceNat" : String,
      "EnforceSecurityGroupInboundRulesOnPrivateLinkTraffic" : String,
      "IpAddressType" : String,
      "Ipv4IpamPoolId" : String,
      "LoadBalancerAttributes" : [ LoadBalancerAttribute, ... ],
      "MinimumLoadBalancerCapacity" : MinimumLoadBalancerCapacity,
      "Name" : String,
      "Scheme" : String,
      "SecurityGroups" : [ String, ... ],
      "SubnetMappings" : [ SubnetMapping, ... ],
      "Subnets" : [ String, ... ],
      "Tags" : [ Tag, ... ],
      "Type" : String
    }
}
YAMLType: AWS::ElasticLoadBalancingV2::LoadBalancer
Properties:
  EnablePrefixForIpv6SourceNat: String
  EnforceSecurityGroupInboundRulesOnPrivateLinkTraffic: String
  IpAddressType: String
  Ipv4IpamPoolId: String
  LoadBalancerAttributes: 
    - LoadBalancerAttribute
  MinimumLoadBalancerCapacity: 
    MinimumLoadBalancerCapacity
  Name: String
  Scheme: String
  SecurityGroups: 
    - String
  SubnetMappings: 
    - SubnetMapping
  Subnets: 
    - String
  Tags: 
    - Tag
  Type: String
PropertiesEnablePrefixForIpv6SourceNat
                    [Network Load Balancers with UDP listeners] Indicates whether to use an IPv6 prefix 
      from each subnet for source NAT. The IP address type must be dualstack.
      The default value is off.
                Required: NoType: StringAllowed values: on | offUpdate requires: No interruptionEnforceSecurityGroupInboundRulesOnPrivateLinkTraffic
                    Indicates whether to evaluate inbound security group rules for traffic sent to a 
      Network Load Balancer through AWS PrivateLink. The default is on.
                Required: NoType: StringAllowed values: on | offUpdate requires: No interruptionIpAddressType
                    The IP address type. Internal load balancers must use ipv4.
                    [Application Load Balancers] The possible values are ipv4 (IPv4 addresses), 
      dualstack (IPv4 and IPv6 addresses), and dualstack-without-public-ipv4 
      (public IPv6 addresses and private IPv4 and IPv6 addresses).
                    Application Load Balancer authentication supports IPv4 addresses only when 
      connecting to an Identity Provider (IdP) or Amazon Cognito endpoint. Without a public 
      IPv4 address the load balancer can't complete the authentication process, resulting 
      in HTTP 500 errors.
                    [Network Load Balancers and Gateway Load Balancers] The possible values are ipv4 
      (IPv4 addresses) and dualstack (IPv4 and IPv6 addresses).
                Required: NoType: StringAllowed values: ipv4 | dualstack | dualstack-without-public-ipv4Update requires: No interruptionIpv4IpamPoolIdProperty description not available.Required: NoType: StringUpdate requires: No interruptionLoadBalancerAttributes
                    The load balancer attributes.
                Required: NoType: Array of LoadBalancerAttributeMaximum: 20Update requires: No interruptionMinimumLoadBalancerCapacity
                    The minimum capacity for a load balancer.
                Required: NoType: MinimumLoadBalancerCapacityUpdate requires: No interruptionName
                    The name of the load balancer. This name must be unique per region per account, can have
         a maximum of 32 characters, must contain only alphanumeric characters or hyphens, must not
         begin or end with a hyphen, and must not begin with "internal-".
                    If you don't specify a name, AWS CloudFormation generates a unique
         physical ID for the load balancer. If you specify a name, you cannot perform updates that
         require replacement of this resource, but you can perform other updates. To replace the
         resource, specify a new name.
                Required: NoType: StringUpdate requires: ReplacementScheme
                    The nodes of an Internet-facing load balancer have public IP addresses. The DNS name of an
      Internet-facing load balancer is publicly resolvable to the public IP addresses of the nodes.
      Therefore, Internet-facing load balancers can route requests from clients over the
      internet.
                    The nodes of an internal load balancer have only private IP addresses. The DNS name of an
      internal load balancer is publicly resolvable to the private IP addresses of the nodes.
      Therefore, internal load balancers can route requests only from clients with access to the VPC
      for the load balancer.
                    The default is an Internet-facing load balancer.
                    You can't specify a scheme for a Gateway Load Balancer.
                Required: NoType: StringAllowed values: internet-facing | internalUpdate requires: ReplacementSecurityGroups
                    [Application Load Balancers and Network Load Balancers] The IDs of the security groups for
      the load balancer.
                Required: NoType: Array of StringUpdate requires: No interruptionSubnetMappings
                    The IDs of the subnets. You can specify only one subnet per Availability Zone. You
      must specify either subnets or subnet mappings, but not both.
                    [Application Load Balancers] You must specify subnets from at least two Availability
      Zones. You can't specify Elastic IP addresses for your subnets.
                    [Application Load Balancers on Outposts] You must specify one Outpost subnet.
                    [Application Load Balancers on Local Zones] You can specify subnets from one or more Local
      Zones.
                    [Network Load Balancers] You can specify subnets from one or more Availability Zones. You
      can specify one Elastic IP address per subnet if you need static IP addresses for your
      internet-facing load balancer. For internal load balancers, you can specify one private IP
      address per subnet from the IPv4 range of the subnet. For internet-facing load balancer, you
      can specify one IPv6 address per subnet.
                    [Gateway Load Balancers] You can specify subnets from one or more Availability Zones. You
      can't specify Elastic IP addresses for your subnets.
                Required: ConditionalType: Array of SubnetMappingUpdate requires: No interruptionSubnets
                    The IDs of the subnets. You can specify only one subnet per Availability Zone. You
      must specify either subnets or subnet mappings, but not both. To specify an Elastic IP
      address, specify subnet mappings instead of subnets.
                    [Application Load Balancers] You must specify subnets from at least two Availability
      Zones.
                    [Application Load Balancers on Outposts] You must specify one Outpost subnet.
                    [Application Load Balancers on Local Zones] You can specify subnets from one or more Local
      Zones.
                    [Network Load Balancers and Gateway Load Balancers] You can specify subnets from one or more 
      Availability Zones.
                Required: ConditionalType: Array of StringUpdate requires: No interruptionTags
                    The tags to assign to the load balancer.
                Required: NoType: Array of TagMinimum: 1Update requires: No interruptionType
                    The type of load balancer. The default is application.
                Required: NoType: StringAllowed values: application | network | gatewayUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Amazon Resource Name (ARN) of the load balancer.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.CanonicalHostedZoneID
                            The ID of the Amazon Route 53 hosted zone associated with the load balancer. For
         example, Z2P70J7EXAMPLE.
                        DNSName
                            The DNS name for the load balancer. For example,
            my-load-balancer-424835706.us-west-2.elb.amazonaws.com.
                        LoadBalancerArn
                            The Amazon Resource Name (ARN) of the load balancer.
                        LoadBalancerFullName
                            The full name of the load balancer. For example,
            app/my-load-balancer/50dc6c495c0c9188.
                        LoadBalancerName
                            The name of the load balancer. For example, my-load-balancer.
                        SecurityGroups
                            The IDs of the security groups for the load balancer.
                        See also
                 
                 
                 
                 
            
                    CreateLoadBalancer in the Elastic Load Balancing API
                     Reference (version 2015-12-01)
                
                    
                        User
                     Guide for Application Load Balancers
                    
                
                    
                        User Guide
                     for Network Load Balancers
                    
                
                    
                        User Guide
                     for Gateway Load Balancers
                    
                Document ConventionsTargetGroupTupleLoadBalancerAttributeDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::ElasticLoadBalancingV2::TargetGroupSpecifies a target group for an Application Load Balancer, a Network Load Balancer, or a 
         Gateway Load Balancer.Before you register a Lambda function as a target, you must create a
            AWS::Lambda::Permission resource that grants the Elastic Load Balancing
         service principal permission to invoke the Lambda function.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::ElasticLoadBalancingV2::TargetGroup",
  "Properties" : {
      "HealthCheckEnabled" : Boolean,
      "HealthCheckIntervalSeconds" : Integer,
      "HealthCheckPath" : String,
      "HealthCheckPort" : String,
      "HealthCheckProtocol" : String,
      "HealthCheckTimeoutSeconds" : Integer,
      "HealthyThresholdCount" : Integer,
      "IpAddressType" : String,
      "Matcher" : Matcher,
      "Name" : String,
      "Port" : Integer,
      "Protocol" : String,
      "ProtocolVersion" : String,
      "Tags" : [ Tag, ... ],
      "TargetGroupAttributes" : [ TargetGroupAttribute, ... ],
      "Targets" : [ TargetDescription, ... ],
      "TargetType" : String,
      "UnhealthyThresholdCount" : Integer,
      "VpcId" : String
    }
}
YAMLType: AWS::ElasticLoadBalancingV2::TargetGroup
Properties:
  HealthCheckEnabled: Boolean
  HealthCheckIntervalSeconds: Integer
  HealthCheckPath: String
  HealthCheckPort: String
  HealthCheckProtocol: String
  HealthCheckTimeoutSeconds: Integer
  HealthyThresholdCount: Integer
  IpAddressType: String
  Matcher: 
    Matcher
  Name: String
  Port: Integer
  Protocol: String
  ProtocolVersion: String
  Tags: 
    - Tag
  TargetGroupAttributes: 
    - TargetGroupAttribute
  Targets: 
    - TargetDescription
  TargetType: String
  UnhealthyThresholdCount: Integer
  VpcId: String
PropertiesHealthCheckEnabled
                    Indicates whether health checks are enabled. If the target type is lambda,
      health checks are disabled by default but can be enabled. If the target type is
        instance, ip, or alb, health checks are always
      enabled and can't be disabled.
                Required: NoType: BooleanUpdate requires: No interruptionHealthCheckIntervalSeconds
                    The approximate amount of time, in seconds, between health checks of an individual target. The range is 5-300.
      If the target group protocol is TCP, TLS, UDP, TCP_UDP, HTTP or HTTPS, the default is 30 seconds. 
      If the target group protocol is GENEVE, the default is 10 seconds. 
      If the target type is lambda, the default is 35 seconds.
                Required: NoType: IntegerMinimum: 5Maximum: 300Update requires: No interruptionHealthCheckPath
                    [HTTP/HTTPS health checks] The destination for health checks on the targets.
                    [HTTP1 or HTTP2 protocol version] The ping path. The default is /.
                    [GRPC protocol version] The path of a custom health check method with the format
      /package.service/method. The default is /AWS.ALB/healthcheck.
                Required: NoType: StringMinimum: 1Maximum: 1024Update requires: No interruptionHealthCheckPort
                    The port the load balancer uses when performing health checks on targets. If the protocol
      is HTTP, HTTPS, TCP, TLS, UDP, or TCP_UDP, the default is traffic-port, which is
      the port on which each target receives traffic from the load balancer. If the protocol is
      GENEVE, the default is port 80.
                Required: NoType: StringUpdate requires: No interruptionHealthCheckProtocol
                    The protocol the load balancer uses when performing health checks on targets. For
      Application Load Balancers, the default is HTTP. For Network Load Balancers and Gateway Load
      Balancers, the default is TCP. The TCP protocol is not supported for health checks if the
      protocol of the target group is HTTP or HTTPS. The GENEVE, TLS, UDP, and TCP_UDP protocols are
      not supported for health checks.
                Required: NoType: StringAllowed values: HTTP | HTTPS | TCP | TLS | UDP | TCP_UDP | GENEVEUpdate requires: No interruptionHealthCheckTimeoutSeconds
                    The amount of time, in seconds, during which no response from a target means a failed 
      health check. The range is 2–120 seconds. For target groups with a protocol of HTTP, the 
      default is 6 seconds. For target groups with a protocol of TCP, TLS or HTTPS, the default 
      is 10 seconds. For target groups with a protocol of GENEVE, the default is 5 seconds. If 
      the target type is lambda, the default is 30 seconds.
                Required: NoType: IntegerMinimum: 2Maximum: 120Update requires: No interruptionHealthyThresholdCount
                    The number of consecutive health check successes required before considering a target healthy. The range is 
      2-10. If the target group protocol is TCP, TCP_UDP, UDP, TLS, HTTP or HTTPS, the default is 5. For target groups 
      with a protocol of GENEVE, the default is 5. If the target type 
      is lambda, the default is 5.
                Required: NoType: IntegerMinimum: 2Maximum: 10Update requires: No interruptionIpAddressType
                    The IP address type. The default value is ipv4.
                Required: NoType: StringAllowed values: ipv4 | ipv6Update requires: ReplacementMatcher
                    [HTTP/HTTPS health checks] The HTTP or gRPC codes to use when checking for a successful 
      response from a target. For target groups with a protocol of TCP, TCP_UDP, UDP or TLS the range 
      is 200-599. For target groups with a protocol of HTTP or HTTPS, the range is 200-499. For target 
      groups with a protocol of GENEVE, the range is 200-399.
                Required: NoType: MatcherUpdate requires: No interruptionName
                    The name of the target group.
                    This name must be unique per region per account, can have a maximum of 32 characters, must
      contain only alphanumeric characters or hyphens, and must not begin or end with a
      hyphen.
                Required: NoType: StringUpdate requires: ReplacementPort
                    The port on which the targets receive traffic. This port is used unless you specify a port
      override when registering the target. If the target is a Lambda function, this parameter does
      not apply. If the protocol is GENEVE, the supported port is 6081.
                Required: ConditionalType: IntegerMinimum: 1Maximum: 65535Update requires: ReplacementProtocol
                    The protocol to use for routing traffic to the targets. For Application Load Balancers,
      the supported protocols are HTTP and HTTPS. For Network Load Balancers, the supported
      protocols are TCP, TLS, UDP, or TCP_UDP. For Gateway Load Balancers, the supported protocol is
      GENEVE. A TCP_UDP listener must be associated with a TCP_UDP target group. If the target is a
      Lambda function, this parameter does not apply.
                Required: ConditionalType: StringAllowed values: HTTP | HTTPS | TCP | TLS | UDP | TCP_UDP | GENEVEUpdate requires: ReplacementProtocolVersion
                    [HTTP/HTTPS protocol] The protocol version. The possible values are GRPC,
        HTTP1, and HTTP2.
                Required: NoType: StringUpdate requires: ReplacementTags
                    The tags.
                Required: NoType: Array of TagMinimum: 1Update requires: No interruptionTargetGroupAttributes
                    The target group attributes.
                Required: NoType: Array of TargetGroupAttributeUpdate requires: No interruptionTargets
                    The targets.
                Required: NoType: Array of TargetDescriptionUpdate requires: No interruptionTargetType
                    The type of target that you must specify when registering targets with this target group.
      You can't specify targets for a target group using more than one target type.
                    
                         
                         
                         
                         
                    
                            instance - Register targets by instance ID. This is the default
          value.
                        
                            ip - Register targets by IP address. You can specify IP addresses from
          the subnets of the virtual private cloud (VPC) for the target group, the RFC 1918 range
          (10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16), and the RFC 6598 range (100.64.0.0/10).
          You can't specify publicly routable IP addresses.
                        
                            lambda - Register a single Lambda function as a target.
                        
                            alb - Register a single Application Load Balancer as a target.
                        
                Required: NoType: StringAllowed values: instance | ip | lambda | albUpdate requires: ReplacementUnhealthyThresholdCount
                    The number of consecutive health check failures required before considering a target unhealthy. The range is 
      2-10. If the target group protocol is TCP, TCP_UDP, UDP, TLS, HTTP or HTTPS, the default is 2. For target groups 
      with a protocol of GENEVE, the default is 2. If the target type 
      is lambda, the default is 5.
                Required: NoType: IntegerMinimum: 2Maximum: 10Update requires: No interruptionVpcId
                    The identifier of the virtual private cloud (VPC). If the target is a Lambda function,
      this parameter does not apply. Otherwise, this parameter is required.
                Required: ConditionalType: StringUpdate requires: ReplacementReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the Amazon Resource Name (ARN) of the target group.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.LoadBalancerArns
                            The Amazon Resource Name (ARN) of the load balancer that routes traffic to this target group.
                        TargetGroupArn
                            The Amazon Resource Name (ARN) of the target group.
                        TargetGroupFullName
                            The full name of the target group. For example, targetgroup/my-target-group/cbf133c568e0d028.
                        TargetGroupName
                            The name of the target group. For example, my-target-group.
                        ExamplesThe following example creates a target group where the target is a Lambda
            function.
            
            YAMLResources:
  MyLambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt 
        - MyLambdaFunction
        - Arn
      Action: 'lambda:InvokeFunction'
      Principal: elasticloadbalancing.amazonaws.com

  MyTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      HealthCheckEnabled: false
      Name: MyTargets
      TargetType: lambda
      Targets:
      - Id: !GetAtt [ MyLambdaFunction, Arn ]

  MyLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Handler: "index.handler"
      Role: !GetAtt [ LambdaExecutionRole, Arn ]
      Code:
        ZipFile: !Sub |
          import json
          
          def handler(event, context):
            response = {
              "statusCode": 200,
              "statusDescription": "200 OK",
              "isBase64Encoded": False,
              "headers": {
                "Content-Type": "text/html; charset=utf-8"
              }
            }

            response['body'] = """<html>
            <head>
            <title>Hello World!</title>
            <style>
            html, body {
              margin: 0; padding: 0;
              font-family: arial; font-weight: 700; font-size: 3em;
              text-align: center;
            }
            </style>
            </head>
            <body>
            <p>Hello World from Lambda</p>
            </body>
            </html>"""
            return response      
      Runtime: "python3.6"
      Timeout: "25"

  LambdaExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
        See also
                 
                 
                 
                 
            
                    CreateTargetGroup in the Elastic Load Balancing API
                     Reference (version 2015-12-01)
                
                    Target groups in the User Guide for Application Load
                     Balancers
                
                    Target groups in the User Guide for Network Load
                     Balancers
                
                    Target groups in the User Guide for Gateway Load
                     Balancers
                Document ConventionsTagMatcherDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::IAM::PolicyAdds or updates an inline policy document that is embedded in the specified IAM group, user or role.An IAM user can also have a managed policy attached to it. For
         information about policies, see Managed Policies and Inline
            Policies in the IAM User Guide.The Groups, Roles, and Users properties are optional. However, you must specify at least
         one of these properties.For information about policy documents see Creating IAM
            policies  in the IAM User Guide.For information about limits on the number of inline policies that you can embed in an
         identity, see Limitations on IAM
            Entities in the IAM User Guide.ImportantThis resource does not support  drift detection
            . The following inline policy resource types support drift detection:
                     
                     
                     
                
                        
                            AWS::IAM::GroupPolicy
                        
                    
                        
                            AWS::IAM::RolePolicy
                        
                    
                        
                            AWS::IAM::UserPolicy
                        
                    SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::IAM::Policy",
  "Properties" : {
      "Groups" : [ String, ... ],
      "PolicyDocument" : Json,
      "PolicyName" : String,
      "Roles" : [ String, ... ],
      "Users" : [ String, ... ]
    }
}
YAMLType: AWS::IAM::Policy
Properties:
  Groups: 
    - String
  PolicyDocument: Json
  PolicyName: String
  Roles: 
    - String
  Users: 
    - String
PropertiesGroups
                    The name of the group to associate the policy with.
                    This parameter allows (through its regex pattern) a string of characters consisting of upper and lowercase alphanumeric 
    characters with no spaces. You can also include any of the following characters: _+=,.@-.
                Required: NoType: Array of StringPattern: [\w+=,.@-]+Minimum: 1Maximum: 128Update requires: No interruptionPolicyDocument
                    The policy document.
                    You must provide policies in JSON format in IAM. However, for AWS CloudFormation
            templates formatted in YAML, you can provide the policy in JSON or YAML format. AWS CloudFormation always converts a YAML policy to JSON format before submitting it to
            IAM.
                    The regex pattern 
    used to validate this parameter is a string of characters consisting of the following:
                    
                         
                         
                         
                    
                            Any printable ASCII 
    character ranging from the space character (\u0020) through the end of the ASCII character range
                        
                            The printable characters in the Basic Latin and  Latin-1 Supplement character set 
    (through \u00FF)
                        
                            The special characters tab (\u0009), line feed (\u000A), and 
    carriage return (\u000D)
                        
                Required: YesType: JsonMinimum: 1Maximum: 131072Update requires: No interruptionPolicyName
                    The name of the policy document.
                    This parameter allows (through its regex pattern) a string of characters consisting of upper and lowercase alphanumeric 
    characters with no spaces. You can also include any of the following characters: _+=,.@-
                Required: YesType: StringMinimum: 1Maximum: 128Update requires: No interruptionRoles
                    The name of the role to associate the policy with.
                    This parameter allows (per its regex
            pattern) a string of characters consisting of upper and lowercase alphanumeric
         characters with no spaces. You can also include any of the following characters:
         _+=,.@-
                    NoteIf an external policy (such as AWS::IAM::Policy or
               AWS::IAM::ManagedPolicy) has a Ref to a role and if a
            resource (such as AWS::ECS::Service) also has a Ref to the
            same role, add a DependsOn attribute to the resource to make the resource
            depend on the external policy. This dependency ensures that the role's policy is
            available throughout the resource's lifecycle. For example, when you delete a stack with
            an AWS::ECS::Service resource, the DependsOn attribute ensures
            that AWS CloudFormation deletes the AWS::ECS::Service resource before
            deleting its role's policy.
                Required: NoType: Array of StringUpdate requires: No interruptionUsers
                    The name of the user to associate the policy with.
                    This parameter allows (through its regex pattern) a string of characters consisting of upper and lowercase alphanumeric 
    characters with no spaces. You can also include any of the following characters: _+=,.@-
                Required: NoType: Array of StringPattern: [\w+=,.@-]+Minimum: 1Maximum: 128Update requires: No interruptionReturn valuesRefWhen the logical ID of this resource is provided to the Ref intrinsic function, Ref returns the resource name.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Id
                            The stable and unique string identifying the policy.
                            For more information about IDs, see IAM identifiers in the
            IAM User Guide.
                        Examples Policy with policy groupPolicy with specified role
            
            Policy with policy groupJSON{
    "Type": "AWS::IAM::Policy",
    "Properties": {
        "PolicyName": "CFNUsers",
        "PolicyDocument": {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                        "cloudformation:Describe*",
                        "cloudformation:List*",
                        "cloudformation:Get*"
                    ],
                    "Resource": "*"
                }
            ]
        },
        "Groups": [
            {
                "Ref": "CFNUserGroup"
            }
        ]
    }
}YAMLType: 'AWS::IAM::Policy'
Properties:
  PolicyName: CFNUsers
  PolicyDocument:
    Version: "2012-10-17"
    Statement:
      - Effect: Allow
        Action:
          - 'cloudformation:Describe*'
          - 'cloudformation:List*'
          - 'cloudformation:Get*'
        Resource: '*'
  Groups:
    - !Ref CFNUserGroup
            Policy with specified roleJSON{
    "Type": "AWS::IAM::Policy",
    "Properties": {
        "PolicyName": "root",
        "PolicyDocument": {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": "*",
                    "Resource": "*"
                }
            ]
        },
        "Roles": [
            {
                "Ref": "RootRole"
            }
        ]
    }
}YAMLType: 'AWS::IAM::Policy'
Properties:
  PolicyName: root
  PolicyDocument:
    Version: "2012-10-17"
    Statement:
      - Effect: Allow
        Action: '*'
        Resource: '*'
  Roles:
    - !Ref RootRole
        See also
                 
                 
                 
                 
                 
                 
            
                    
                        AWS::IAM::GroupPolicy
                    
                
                    
                        AWS::IAM::RolePolicy
                    
                
                    
                        AWS::IAM::UserPolicy
                    
                
                    PutGroupPolicy in the AWS Identity and Access Management API Reference
                
                    PutRolePolicy in the AWS Identity and Access Management API Reference
                
                    PutUserPolicy in the AWS Identity and Access Management API Reference
                Document ConventionsTagAWS::IAM::RoleDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::IAM::RoleCreates a new role for your AWS account. For more information about roles, see IAM roles in the
                IAM User Guide. For information about quotas for role names
            and the number of roles you can create, see IAM and AWS STS quotas in the
                IAM User Guide.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::IAM::Role",
  "Properties" : {
      "AssumeRolePolicyDocument" : Json,
      "Description" : String,
      "ManagedPolicyArns" : [ String, ... ],
      "MaxSessionDuration" : Integer,
      "Path" : String,
      "PermissionsBoundary" : String,
      "Policies" : [ Policy, ... ],
      "RoleName" : String,
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::IAM::Role
Properties:
  AssumeRolePolicyDocument: Json
  Description: String
  ManagedPolicyArns: 
    - String
  MaxSessionDuration: Integer
  Path: String
  PermissionsBoundary: String
  Policies: 
    - Policy
  RoleName: String
  Tags: 
    - Tag
PropertiesAssumeRolePolicyDocument
                    The trust policy that is associated with this role. Trust policies define which entities
         can assume the role. You can associate only one trust policy with a role. For an example of
         a policy that can be used to assume a role, see Template Examples. For more information about the elements that you can use in
         an IAM policy, see IAM Policy Elements Reference in the IAM User Guide.
                Required: YesType: JsonUpdate requires: No interruptionDescription
                    A description of the role that you provide.
                Required: NoType: StringPattern: [\u0009\u000A\u000D\u0020-\u007E\u00A1-\u00FF]*Maximum: 1000Update requires: No interruptionManagedPolicyArns
                    A list of Amazon Resource Names (ARNs) of the IAM managed policies that
         you want to attach to the role.
                    For more information about ARNs, see Amazon Resource Names (ARNs) and
               AWS Service Namespaces in the AWS General Reference.
                Required: NoType: Array of StringUpdate requires: No interruptionMaxSessionDuration
                    The maximum session duration (in seconds) that you want to set for the specified role.
            If you do not specify a value for this setting, the default value of one hour is
            applied. This setting can have a value from 1 hour to 12 hours.
                    Anyone who assumes the role from the AWS CLI or API can use the
                DurationSeconds API parameter or the duration-secondsAWS CLI parameter to request a longer session. The MaxSessionDuration setting
            determines the maximum duration that can be requested using the
                DurationSeconds parameter. If users don't specify a value for the
                DurationSeconds parameter, their security credentials are valid for one
            hour by default. This applies when you use the AssumeRole* API operations
            or the assume-role*AWS CLI operations but does not apply when you use those
            operations to create a console URL. For more information, see Using IAM
                roles in the IAM User Guide.
                Required: NoType: IntegerMinimum: 3600Maximum: 43200Update requires: No interruptionPath
                     The path to the role. For more information about paths, see IAM
                Identifiers in the IAM User Guide.
                    This parameter is optional. If it is not included, it defaults to a slash (/).
                    This parameter allows (through its regex pattern) a string of characters consisting 
    of either a forward slash (/) by itself or a string that must begin and end with forward slashes.
    In addition, it can contain any ASCII character from the ! (\u0021) through the DEL character (\u007F), including 
    most punctuation characters, digits, and upper and lowercased letters.
                Required: NoType: StringPattern: (\u002F)|(\u002F[\u0021-\u007E]+\u002F)Minimum: 1Maximum: 512Update requires: ReplacementPermissionsBoundary
                    The ARN of the policy used to set the permissions boundary for the role.
                    For more information about permissions boundaries, see Permissions boundaries for IAM
            identities  in the IAM User Guide.
                Required: NoType: StringUpdate requires: No interruptionPolicies
                    Adds or updates an inline policy document that is embedded in the specified IAM role.
                    When you embed an inline policy in a role, the inline policy is used as part of the
         role's access (permissions) policy. The role's trust policy is created at the same time as
         the role. You can update a role's trust policy later. For more information about IAM roles, go to Using Roles to Delegate Permissions and
            Federate Identities.
                    A role can also have an attached managed policy. For information about policies, see
            Managed Policies and Inline Policies in the IAM User Guide.
                    For information about limits on the number of inline policies that you can embed with a
         role, see Limitations on IAM Entities in the IAM User Guide.
                    NoteIf an external policy (such as AWS::IAM::Policy or
               AWS::IAM::ManagedPolicy) has a Ref to a role and if a
            resource (such as AWS::ECS::Service) also has a Ref to the
            same role, add a DependsOn attribute to the resource to make the resource
            depend on the external policy. This dependency ensures that the role's policy is
            available throughout the resource's lifecycle. For example, when you delete a stack with
            an AWS::ECS::Service resource, the DependsOn attribute ensures
            that AWS CloudFormation deletes the AWS::ECS::Service resource before
            deleting its role's policy.
                Required: NoType: Array of PolicyUpdate requires: No interruptionRoleName
                    A name for the IAM role, up to 64 characters in length. For valid values,
         see the RoleName parameter for the CreateRole action in the IAM User Guide.
                    This parameter allows (per its regex
            pattern) a string of characters consisting of upper and lowercase alphanumeric
         characters with no spaces. You can also include any of the following characters: _+=,.@-.
         The role name must be unique within the account. Role names are not distinguished by case.
         For example, you cannot create roles named both "Role1" and "role1".
                    If you don't specify a name, AWS CloudFormation generates a unique physical ID and
         uses that ID for the role name.
                    If you specify a name, you must specify the CAPABILITY_NAMED_IAM value to
         acknowledge your template's capabilities. For more information, see Acknowledging IAM Resources in AWS CloudFormation
         Templates.
                    ImportantNaming an IAM resource can cause an unrecoverable error if you reuse
            the same template in multiple Regions. To prevent this, we recommend using
               Fn::Join and AWS::Region to create a Region-specific name,
            as in the following example: {"Fn::Join": ["", [{"Ref": "AWS::Region"}, {"Ref":
               "MyResourceName"}]]}.
                Required: NoType: StringUpdate requires: ReplacementTags
                    A list of tags that are attached to the role. For more information about tagging, see Tagging IAM resources in the
      IAM User Guide.
                Required: NoType: Array of TagMaximum: 50Update requires: No interruptionReturn valuesRefWhen the logical ID of this resource is provided to the Ref intrinsic function, Ref returns the resource name.For example:
                        { "Ref": "RootRole" }
                    For the AWS::IAM::Role resource with the logical ID RootRole,
            Ref will return the role name.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Arn
                            Returns the Amazon Resource Name (ARN) for the role. For example:
                            
                                {"Fn::GetAtt" : ["MyRole", "Arn"] }
                            
                            This will return a value such as
            arn:aws:iam::1234567890:role/MyRole-AJJHDSKSDF.
                        RoleId
                            Returns the stable and unique string identifying the role. For example,
            AIDAJQABLZS4A3QDU576Q.
                            For more information about IDs, see IAM Identifiers in the IAM User Guide.
                        Examples Role with Embedded Policy and Instance ProfilesRole with External Policy and Instance Profiles
            
            Role with Embedded Policy and Instance ProfilesThis example shows an embedded policy in the AWS::IAM::Role. The
               policy is specified inline in the Policies property of the
                  AWS::IAM::Role.{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "RootRole": {
            "Type": "AWS::IAM::Role",
            "Properties": {
                "AssumeRolePolicyDocument": {
                    "Version": "2012-10-17",
                    "Statement": [
                        {
                            "Effect": "Allow",
                            "Principal": {
                                "Service": [
                                    "ec2.amazonaws.com"
                                ]
                            },
                            "Action": [
                                "sts:AssumeRole"
                            ]
                        }
                    ]
                },
                "Path": "/",
                "Policies": [
                    {
                        "PolicyName": "root",
                        "PolicyDocument": {
                            "Version": "2012-10-17",
                            "Statement": [
                                {
                                    "Effect": "Allow",
                                    "Action": "*",
                                    "Resource": "*"
                                }
                            ]
                        }
                    }
                ]
            }
        },
        "RootInstanceProfile": {
            "Type": "AWS::IAM::InstanceProfile",
            "Properties": {
                "Path": "/",
                "Roles": [
                    {
                        "Ref": "RootRole"
                    }
                ]
            }
        }
    }
}YAMLAWSTemplateFormatVersion: "2010-09-09"
Resources:
  RootRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action: '*'
                Resource: '*'
  RootInstanceProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      Path: /
      Roles:
        - !Ref RootRole
            Role with External Policy and Instance ProfilesIn this example, the Policy and InstanceProfile resources are specified externally
               to the IAM Role. They refer to the role by specifying its name,
               "RootRole", in their respective Roles properties.JSON{
   "AWSTemplateFormatVersion": "2010-09-09",
   "Resources": {
      "RootRole": {
         "Type": "AWS::IAM::Role",
         "Properties": {
            "AssumeRolePolicyDocument": {
               "Version" : "2012-10-17",
               "Statement": [ {
                  "Effect": "Allow",
                  "Principal": {
                     "Service": [ "ec2.amazonaws.com" ]
                  },
                  "Action": [ "sts:AssumeRole" ]
               } ]
            },
            "Path": "/"
         }
      },
      "RolePolicies": {
         "Type": "AWS::IAM::Policy",
         "Properties": {
            "PolicyName": "root",
            "PolicyDocument": {
               "Version" : "2012-10-17",
               "Statement": [ {
                  "Effect": "Allow",
                  "Action": "*",
                  "Resource": "*"
               } ]
            },
            "Roles": [ {
               "Ref": "RootRole"
            } ]
         }
      },
      "RootInstanceProfile": {
         "Type": "AWS::IAM::InstanceProfile",
         "Properties": {
            "Path": "/",
            "Roles": [ {
               "Ref": "RootRole"
            } ]
         }
      }
   }
}  YAMLAWSTemplateFormatVersion: "2010-09-09"
Resources: 
  RootRole: 
    Type: "AWS::IAM::Role"
    Properties: 
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Principal: 
              Service: 
                - "ec2.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
  RolePolicies: 
    Type: "AWS::IAM::Policy"
    Properties: 
      PolicyName: "root"
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Action: "*"
            Resource: "*"
      Roles: 
        - Ref: "RootRole"
  RootInstanceProfile: 
    Type: "AWS::IAM::InstanceProfile"
    Properties: 
      Path: "/"
      Roles: 
        - Ref: "RootRole"

        See also
                 
                 
                 
                 
            
                    To view AWS::IAM::User template example snippets, see IAM role template examples. 
                
                    
                        AWS Identity and Access Management Template Snippets
                    
                
                    CreateRole in the AWS Identity and Access Management API Reference
                
                    
                        AWS::IAM::InstanceProfile
                    
                Document ConventionsAWS::IAM::PolicyPolicyDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesAWS::Logs::LogGroupThe AWS::Logs::LogGroup resource specifies a log group. A log group defines common properties for log streams, 
         such as their retention and access control rules. Each log stream must belong to one log group.You can create up to 1,000,000 log groups per Region per account. You must use the following guidelines when naming a log group:
                 
                 
                 
            
                    Log group names must be unique within a Region for an AWS account.
                
                    Log group names can be between 1 and 512 characters long.
                
                    Log group names consist of the following characters: a-z, A-Z, 0-9, '_' (underscore), '-' (hyphen), 
          '/' (forward slash), and '.' (period).
                SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::Logs::LogGroup",
  "Properties" : {
      "DataProtectionPolicy" : Json,
      "FieldIndexPolicies" : [ {Key: Value, ...}, ... ],
      "KmsKeyId" : String,
      "LogGroupClass" : String,
      "LogGroupName" : String,
      "RetentionInDays" : Integer,
      "Tags" : [ Tag, ... ]
    }
}
YAMLType: AWS::Logs::LogGroup
Properties:
  DataProtectionPolicy: Json
  FieldIndexPolicies: 
    - 
    Key: Value
  KmsKeyId: String
  LogGroupClass: String
  LogGroupName: String
  RetentionInDays: Integer
  Tags: 
    - Tag
PropertiesDataProtectionPolicy
                    Creates a data protection policy and assigns it to the log group. A data protection policy can help safeguard sensitive 
         data that's ingested by the log group by auditing and masking the sensitive log data. When a user who does not have 
         permission to view masked data
         views a log event that includes masked data, the sensitive data is replaced by asterisks.
                    For more information, including a list of types of data that can be audited and masked, see
         Protect sensitive log data with masking.
                Required: NoType: JsonUpdate requires: No interruptionFieldIndexPolicies
                    Creates or updates a field index policy for the specified log group. Only log groups
         in the Standard log class support field index policies. For more information about log classes, see
         Log classes.
                    You can use field index policies to create field indexes on fields found in 
         log events in the log group. Creating field indexes lowers the costs for CloudWatch Logs Insights queries that reference
         those field indexes, because these queries attempt to skip the processing of log events that are known to not match the indexed field.
         Good fields to index are fields that you often need to query for and fields that have high cardinality of values
         Common examples of indexes
         include request ID, session ID, userID, and instance IDs. For more information, see Create field indexes to improve query performance and reduce costs.
                    Currently, this array supports only one field index policy object.
                Required: NoType: Array of ObjectUpdate requires: No interruptionKmsKeyId
                    The Amazon Resource Name (ARN) of the AWS KMS key to use when encrypting log data.
                    To associate an AWS KMS key with the log group, specify the ARN of that KMS key here. If you do so, 
      ingested data is encrypted using this key.  
      This association is stored as long as the data encrypted with the KMS key is still within CloudWatch Logs. 
      This enables CloudWatch Logs to decrypt this data whenever it is requested.
                    If you attempt to associate a KMS key with the log group but the KMS key doesn't exist or is deactivated, you will 
      receive an InvalidParameterException error.
                    Log group data is always encrypted in CloudWatch Logs. If you omit this key, the encryption does not use
      AWS KMS. For more information, see 
         Encrypt log data in CloudWatch Logs using AWS Key Management Service
                Required: NoType: StringPattern: ^arn:[a-z0-9-]+:kms:[a-z0-9-]+:\d{12}:(key|alias)/.+\ZMaximum: 256Update requires: No interruptionLogGroupClass
                    Specifies the log group class for this log group. There are two classes:
                    
                         
                         
                    
                            The Standard log class supports all CloudWatch Logs features.
                        
                            The Infrequent Access log class supports a subset of CloudWatch Logs features
            and incurs lower costs.
                        
                    For details about the features supported by each class, see 
         Log classes
                Required: NoType: StringAllowed values: STANDARD | INFREQUENT_ACCESS | DELIVERYUpdate requires: Updates are not supported.LogGroupName
                    The name of the log group. If you don't specify a name, AWS CloudFormation generates a unique ID for the log group.
                Required: NoType: StringPattern: ^[.\-_/#A-Za-z0-9]{1,512}\ZMinimum: 1Maximum: 512Update requires: ReplacementRetentionInDays
                    The number of days to retain the log events in the specified log group.
      Possible values are: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1096, 1827, 2192, 2557, 2922, 3288, and 3653.
                    To set a log group so that its log events do not expire, use DeleteRetentionPolicy. 
                Required: NoType: IntegerAllowed values: 1 | 3 | 5 | 7 | 14 | 30 | 60 | 90 | 120 | 150 | 180 | 365 | 400 | 545 | 731 | 1096 | 1827 | 2192 | 2557 | 2922 | 3288 | 3653Update requires: No interruptionTags
                    An array of key-value pairs to apply to the log group.
                    For more information, see Tag.
                Required: NoType: Array of TagUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the resource name.For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Arn
                            The ARN of the log group, such as 
         arn:aws:logs:us-west-1:123456789012:log-group:/mystack-testgroup-12ABC1AB12A1:*
                        Examples Create a log groupCreate a log group with a data protection policyCreate a log group with a field index policy
            
            Create a log groupThe following example creates a log group that retains events for seven days.JSON"myLogGroup": {
    "Type": "AWS::Logs::LogGroup",
    "Properties": {
        "RetentionInDays": 7
    }
}YAMLmyLogGroup: 
  Type: AWS::Logs::LogGroup
  Properties: 
    RetentionInDays: 7
            Create a log group with a data protection policyThe following example creates a log group that uses a data protection policy to 
               mask email addresses, and send audit findings to CloudWatch Logs, Firehose, 
               and Amazon S3.JSON"TestLogGroupDescription": {
  "Type": "AWS::Logs::LogGroup",
  "Properties": {
      "LogGroupName": "my-log-group",
      "DataProtectionPolicy": {
          "Name": "data-protection-policy",
          "Description": "test description",
          "Version": "2021-06-01",
          "Statement": [{
                  "Sid": "audit-policy test",
                  "DataIdentifier": [
                      "arn:aws:dataprotection::aws:data-identifier/EmailAddress",
                      "arn:aws:dataprotection::aws:data-identifier/DriversLicense-US"
                  ],
                  "Operation": {
                      "Audit": {
                          "FindingsDestination": {
                              "CloudWatchLogs": {
                                  "LogGroup": "EXISTING_LOG_GROUP_IN_YOUR_ACCOUNT"
                              },
                              "Firehose": {
                                  "DeliveryStream": "EXISTING_STREAM_IN_YOUR_ACCOUNT"
                              },
                              "S3": {
                                  "Bucket": "EXISTING_BUCKET"
                              }
                          }
                      }
                  }
              },
              {
                  "Sid": "redact-policy",
                  "DataIdentifier": [
                      "arn:aws:dataprotection::aws:data-identifier/EmailAddress",
                      "arn:aws:dataprotection::aws:data-identifier/DriversLicense-US"
                  ],
                  "Operation": {
                      "Deidentify": {
                          "MaskConfig": {}
                      }
                  }
              }
          ]
      }
  }
}YAMLTestLogGroupDescription:
  Type: AWS::Logs::LogGroup
  Properties:
    LogGroupName: my-log-group
    DataProtectionPolicy:
      Name: data-protection-policy
      Description: test description
      Version: '2021-06-01'
      Statement:
      - Sid: audit-policy test
        DataIdentifier:
        - arn:aws:dataprotection::aws:data-identifier/EmailAddress
        - arn:aws:dataprotection::aws:data-identifier/DriversLicense-US
        Operation:
          Audit:
            FindingsDestination:
              CloudWatchLogs:
                LogGroup: EXISTING_LOG_GROUP_IN_YOUR_ACCOUNT
              Firehose:
                DeliveryStream: EXISTING_STREAM_IN_YOUR_ACCOUNT
              S3:
                Bucket: EXISTING_BUCKET
      - Sid: redact-policy
        DataIdentifier:
        - arn:aws:dataprotection::aws:data-identifier/EmailAddress
        - arn:aws:dataprotection::aws:data-identifier/DriversLicense-US
        Operation:
          Deidentify:
            MaskConfig: {}
            Create a log group with a field index policyThe following example creates a log group that uses a field index policy to 
              index the RequestId and TransactionId fields in log events.JSON"TestFieldIndexingLogGroup": {
    "Type": "AWS::Logs::LogGroup", 
    "Properties": {
        "LogGroupName": "my-log-group",
        "FieldIndexPolicies": [{
            "Fields": [
                "RequestId",
                "TransactionId"
            ]
        }]
    }
}   YAMLTestFieldIndexingLogGroup:
  Type: AWS::Logs::LogGroup
  Properties:
    LogGroupName: my-log-group
    FieldIndexPolicies:
        - Fields:
            - RequestId
            - TransactionId  
        Document ConventionsAWS::Logs::LogAnomalyDetectorTagDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nModules
The AWS Construct Library is organized into several modules. They are
named like this:

aws-xxx: service package for the indicated service. This package will
contain constructs to work with the given service.
aws-xxx¹: a little superscript 1 indicates that his package only
contains CloudFormation Resources (for now).
aws-xxx-targets: integration package for the indicated service. This
package will contain classes to connect the constructs in the "aws-xxx"
package to other AWS services it can work with.
xxx: packages that don't start "aws-" are AWS CDK framework packages.

Module Contents
Modules contain the following types:

Constructs - All higher-level
constructs
in this library.
Other Types - All non-construct classes, interfaces, structs
and enums that exist to support the constructs.
CloudFormation Resources - All constructs that map directly onto
CloudFormation Resources. We recommend that you read the CloudFormation
Resource and Property Type
Reference
for details on these resources.
CloudFormation Property Types - All structs that are used by the
CloudFormation Resource constructs.

Constructs take a set of (input) properties in their constructor; the set of
properties (and which ones are required) can be seen on a construct's
documentation page.
The construct's documentation page also lists the available methods to call
and the properties which can be used to retrieve information about the
construct after it has been instantiated.
Every type's page has a table at the top with links to language-specific
documentation on the type.\n\nAPI ReferenceModules
The AWS Construct Library is organized into several modules. They are
named like this:

aws-xxx: service package for the indicated service. This package will
contain constructs to work with the given service.
aws-xxx¹: a little superscript 1 indicates that his package only
contains CloudFormation Resources (for now).
aws-xxx-targets: integration package for the indicated service. This
package will contain classes to connect the constructs in the "aws-xxx"
package to other AWS services it can work with.
xxx: packages that don't start "aws-" are AWS CDK framework packages.

Module Contents
Modules contain the following types:

Constructs - All higher-level
constructs
in this library.
Other Types - All non-construct classes, interfaces, structs
and enums that exist to support the constructs.
CloudFormation Resources - All constructs that map directly onto
CloudFormation Resources. We recommend that you read the CloudFormation
Resource and Property Type
Reference
for details on these resources.
CloudFormation Property Types - All structs that are used by the
CloudFormation Resource constructs.

Constructs take a set of (input) properties in their constructor; the set of
properties (and which ones are required) can be seen on a construct's
documentation page.
The construct's documentation page also lists the available methods to call
and the properties which can be used to retrieve information about the
construct after it has been instantiated.
Every type's page has a table at the top with links to language-specific
documentation on the type.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuidePrerequisitesInstall the AWS CDK CLIConfigure the AWS CDK CLI(Optional) Install additional AWS CDK toolsCreate your first CDK appThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Getting started with the AWS CDKGet started with the AWS Cloud Development Kit (AWS CDK) by installing and configuring the AWS CDK Command Line Interface (AWS CDK CLI). Then, use
		the CDK CLI to create your first CDK app, bootstrap your AWS environment, and deploy your
		application.
		Prerequisites

		Before getting started with the AWS CDK, complete all prerequisites. These prerequisites are required for those that
			are new to AWS or new to programming. For instructions, see AWS CDK prerequisites.

		We recommend that you have a basic understanding of what the AWS CDK is. For more information, see What is the AWS CDK? and Learn AWS CDK core concepts.

	 
		Install the AWS CDK CLI

		Use the Node Package Manager to install the CDK CLI. We recommend that you install it
			globally using the following command:

		$ npm install -g aws-cdk

		To install a specific version of the CDK CLI, use the following command structure:

		$ npm install -g aws-cdk@X.YY.Z

		If you want to use multiple versions of the AWS CDK, consider installing a matching version of the CDK CLI in
			individual CDK projects. To do this, remove the -g option from the npm install
			command. Then, use npx aws-cdk to invoke the CDK CLI. This will run a local version if it exists.
			Otherwise, the globally installed version will be used.

		
		 
			Troubleshoot a CDK CLI
					installation

			If you get a permission error, and have administrator access on your system, run the following:

			$ sudo npm install -g aws-cdk

			If you receive an error message, try uninstalling the CDK CLI by running the following:

			$ npm uninstall -g aws-cdk

			Then, repeat steps to reinstall the CDK CLI.

		 

		
		 
			Verify a successful CDK CLI
					installation

			Run the following command to verify a successful installation. The AWS CDK CLI should output the
				version number:

			$ cdk --version

		 

		

	 
		Configure the AWS CDK CLI

		After installing the CDK CLI, you can start using it to develop applications on your local machine. To
			interact with AWS, such as deploying applications, you must have security credentials configured on your local
			machine with permissions to perform any actions that you initiate.

		To configure security credentials on your local machine, you use the AWS CLI. How you configure security credentials
			depends on how you manage users. For instructions, see Authentication and access credentials in the
				AWS Command Line Interface User Guide.

		The CDK CLI will automatically use the security credentials that you configure with the AWS CLI. For example,
			if you are an IAM Identity Center user, you can use the aws configure sso command to configure security credentials. If
			you are an IAM user, you can use the aws configure command. The AWS CLI will guide you through configuring
			security credentials on your local machine and save the necessary information in your config and
				credentials files. Then, when you use the CDK CLI, such as deploying an application with
				cdk deploy, the CDK CLI will use your configured security credentials.

		Just like the AWS CLI, the CDK CLI will use your default profile by default. You can specify a
			profile using the CDK CLI --profile option. For
			more information on using security credentials with the CDK CLI, see Configure security credentials for the AWS CDK CLI.

	 
		(Optional) Install additional AWS CDK tools

		The AWS Toolkit for Visual Studio Code is an open source plug-in for
			Visual Studio Code that helps you create, debug, and deploy applications on AWS. The toolkit provides an integrated
			experience for developing AWS CDK applications. It includes the AWS CDK Explorer feature to list your AWS CDK projects and
			browse the various components of the CDK application. For instructions, see the following:

		
			 
			 
		
				Installing the
						AWS Toolkit for Visual Studio Code.
			
				AWS CDK for
						VS Code.
			

	 
		Create your first CDK app

		You're now ready to get started with using the AWS CDK by creating your first CDK app. For instructions, see
				Tutorial: Create your first AWS CDK app.

	Document ConventionsPrerequisitesCreate your first CDK appDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideAWS CDK and IaCAWS CDK and AWS CloudFormationAWS CDK and abstractionsLearn more about core AWS CDK conceptsThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Learn AWS CDK core conceptsLearn core concepts behind the AWS Cloud Development Kit (AWS CDK).
    AWS CDK and IaC

    The AWS CDK is an open-source framework that you can use to manage your AWS infrastructure using code. This
      approach is known as infrastructure as code (IaC). By managing and provisioning
      your infrastructure as code, you treat your infrastructure in the same way that developers treat code. This provides
      many benefits, such as version control and scalability. To learn more about IaC, see What is Infrastructure as Code?

   
    AWS CDK and AWS CloudFormation

    The AWS CDK is tightly integrated with AWS CloudFormation. AWS CloudFormation is a fully managed service that you can use to manage and
      provision your infrastructure on AWS. With AWS CloudFormation, you define your infrastructure in templates and deploy them to
      AWS CloudFormation. The AWS CloudFormation service then provisions your infrastructure according to the configuration defined on your
      templates.

    AWS CloudFormation templates are declarative, meaning they declare the desired state or outcome of your
      infrastructure. Using JSON or YAML, you declare your AWS infrastructure by defining AWS
        resources and properties. Resources represent the many services on AWS
      and properties represent your desired configuration of those services. When you deploy your template to AWS CloudFormation, your
      resources and their configured properties are provisioned as described on your template.

    With the AWS CDK, you can manage your infrastructure imperatively, using general-purpose
      programming languages. Instead of just defining a desired state declaratively, you can define the logic or sequence
      necessary to reach the desired state. For example, you can use if statements or conditional loops that
      determine how to reach a desired end state for your infrastructure.

    Infrastructure created with the AWS CDK is eventually translated, or synthesized into AWS CloudFormation
      templates and deployed using the AWS CloudFormation service. So while the AWS CDK offers a different approach to creating your
      infrastructure, you still receive the benefits of AWS CloudFormation, such as extensive AWS resource configuration support and
      robust deployment processes.

    To learn more about AWS CloudFormation, see 
        What is AWS CloudFormation? in the AWS CloudFormation User Guide.

   
    AWS CDK and abstractions

    With AWS CloudFormation, you must define every detail of how your resources are configured. This provides the benefit of having
      complete control over your infrastructure. However, this requires you to learn, understand, and create robust templates
      that contain resource configuration details and relationships between resources, such as permissions and event-driven
      interactions.

    With the AWS CDK, you can have the same control over your resource configurations. However, the AWS CDK also offers
      powerful abstractions, which can speed up and simplify the infrastructure development process. For example, the AWS CDK
      includes constructs that provide sensible default configurations and helper methods that generate boilerplate code for
      you. The AWS CDK also offers tools, such as the AWS CDK Command Line Interface (AWS CDK CLI), that perform
      infrastructure management actions for you.

   
    Learn more about core AWS CDK concepts

    
     
      Interacting with the AWS CDK

      When using with the AWS CDK, you will primarily interact with the AWS Construct Library and the AWS CDK
        CLI.

     

    
     
      Developing with the AWS CDK

      The AWS CDK can be written in any supported programming language. You start with a
          CDK project, which contains a structure of folders and files, including
          assets. Within the project, you create a CDK
          application. Within the app, you define a stack, which directly represents a
        CloudFormation stack. Within the stack, you define your AWS resources and properties using constructs.

     

    
     
      Deploying with the AWS CDK

      You deploy CDK apps into an AWS environment. Before deploying, you
        must perform a one-time bootstrapping to prepare your environment.
     

    
     
      Learn more

      To learn more about AWS CDK core concepts, see the topics in this section.

     

  Document ConventionsWhat is the AWS CDK?Programming languagesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud9User GuidePrerequisitesStep 1: Install required toolsStep 2: Add codeStep 3: Run the codeStep 4: Clean up AWS Cloud9 is no longer available to new customers. Existing customers of 
         AWS Cloud9 can continue to use the service as normal. 
         Learn moreAWS CDK tutorial for AWS Cloud9This tutorial shows you how to work with the AWS Cloud Development Kit (AWS CDK) in an AWS Cloud9 development environment. The AWS CDK is a set
      of software tools and libraries that developers can use to model AWS infrastructure
      components as code.The AWS CDK includes the AWS Construct Library that you can use to quickly resolve many
      tasks on AWS. For example, you can use the Fleet construct to fully and
      securely deploy code to a fleet of hosts. You can create your own constructs to model various
      elements of your architectures, share them with others, or publish them to the community. For
      more information, see the AWS Cloud Development Kit Developer
         Guide.Following this tutorial and creating this sample might result in charges to your AWS
      account. These include possible charges for services such as Amazon EC2, Amazon SNS, and Amazon SQS. For more
      information, see Amazon EC2 Pricing, Amazon SNS Pricing, and Amazon SQS Pricing.TopicsPrerequisitesStep 1: Install required toolsStep 2: Add codeStep 3: Run the codeStep 4: Clean up
      Prerequisites
      
   Before you use this sample, make sure that your setup meets the following
      requirements:
   
       
       
   
         You must have an existing AWS Cloud9 EC2 development environment. This sample
            assumes that you already have an EC2 environment that's connected to an Amazon EC2 instance that
            runs Amazon Linux or Ubuntu Server. If you have a different type of environment or
            operating system, you might need to adapt this sample's instructions to set up related
            tools. For more information, see Creating an environment in AWS Cloud9.
      
         You have the AWS Cloud9 IDE for the existing environment already
               open. When you open an environment, AWS Cloud9 opens the IDE for that environment in your
            web browser. For more information, see Opening an environment in AWS Cloud9.
      
 
    
      Step 1: Install required tools
      In this step, you install all of the tools in your environment that the AWS CDK needs to run a
         sample that is written in the TypeScript programming language.
      
          
          
          
          
      
            
               Node Version Manager, or 
                  nvm
               , which you use to install Node.js later.
         
            
               Node.js, which is required by the
               sample and contains Node Package Manager, or 
                  npm
               , which you use to install TypeScript and the AWS CDK later.
         
            
               TypeScript, which is required by
               this sample. (The AWS CDK also provides support for several other programming
               languages.)
         
            The AWS CDK.
         
       
         Step 1.1: Install Node Version Manager
               (nvm)
         
               In a terminal session in the AWS Cloud9 IDE, ensure the latest security updates and
                  bug fixes are installed. To do this, run the 
                     yum update
                   (for Amazon Linux) or 
                     apt update
                   command (for Ubuntu Server). (To start a new terminal session, on the
                  menu bar, choose Window, New
                  Terminal.)
               For Amazon Linux:
               sudo yum -y update
               For Ubuntu Server:
               sudo apt update
            
               Confirm whether 
                     nvm
                   is already installed. To do this, run the 
                     nvm
                   command with the 
                     --version
                   option.
               nvm --version
               If successful, the output contains the 
                     nvm
                   version number, and you can skip ahead to Step 1.2: Install Node.js.
            
               Download and install 
                     nvm
                  . To do this, run the install script. In this example, v0.33.0 is
                  installed, but you can check for the latest version of 
                     nvm
                  
                  here.
               curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash
            
               Start using 
                     nvm
                  . You can either close the terminal session and then restart it, or
                  source the ~/.bashrc file that contains the commands to load
                     
                     nvm
                  .
               . ~/.bashrc
            
       
       
         Step 1.2: Install Node.js
         
               Confirm whether you already have Node.js installed, and if you do, confirm that
                  the installed version is 16.17.0  or greater. This sample
                     has been tested with Node.js 16.17.0. To check, with the terminal
                  session still open in the IDE, run the 
                     node
                   command with the 
                     --version
                   option.
               node --version
               If you do have Node.js installed, the output contains the version number. If
                  the version number is v16.17.0 skip ahead to Step 1.3: Install TypeScript.
            
               Install Node.js 16 by running the 
                     nvm
                   command with the 
                     install
                   action.
               NoteYou can also run nvm install
                        node to install the long-term support (LTS) version of
                     Node.js. AWS Cloud9 support tracks the LTS version of Node.js. 
               nvm install v16
            
               Start using Node.js 16. To do this, run the 
                     nvm
                   command with the 
                     alias
                   action, the version number to alias, and the version to use for that
                  alias, as follows.
               nvm alias default 16
               NoteThe preceding command sets Node.js 16 as the default version of Node.js.
                     Alternatively, you can run the 
                        nvm
                      command along with the 
                        use
                      action instead of the 
                        alias
                      action (for example, 
                        nvm use 16.17.0
                     ). However, the 
                        use
                      action causes that version of Node.js to run only while the current
                     terminal session is running.
            
               To confirm that you're using Node.js 16 run the 
                     node --version
                   command again. If the correct version is installed, the output
                  contains version v16.
            
       
       
         Step 1.3: Install TypeScript
         
               Confirm whether you already have TypeScript installed. To do this, with the
                  terminal session still open in the IDE, run the command line TypeScript compiler
                  with the 
                     --version
                   option.
               tsc --version
               If you do have TypeScript installed, the output contains the TypeScript version
                  number. If TypeScript is installed, skip ahead to Step 1.4: Install the AWS CDK.
            
               Install TypeScript. To do this, run the 
                     npm
                   command with the 
                     install
                   action, the 
                     -g
                   option, and the name of the TypeScript package. This installs
                  TypeScript as a global package in the environment.
               npm install -g typescript
            
               Confirm that TypeScript is installed. To do this, run the command line
                  TypeScript compiler with the 
                     --version
                   option.
               tsc --version
               If TypeScript is installed, the output contains the TypeScript version
                  number.
            
       
       
         Step 1.4: Install the AWS CDK
         
               Confirm whether you already have the AWS CDK installed. To do this, with the
                  terminal session still open in the IDE, run the 
                     cdk
                   command with the 
                     --version
                   option.
               cdk --version
               If the AWS CDK is installed, the output contains the AWS CDK version and build
                  numbers. Skip ahead to Step 2: Add code.
            
               Install the AWS CDK by running the 
                     npm
                   command along with the install action, the name of the
                  AWS CDK package to install, and the -g option to install the package
                  globally in the environment.
               npm install -g aws-cdk
            
               Confirm that the AWS CDK is installed and correctly referenced. To do this, run
                  the 
                     cdk
                   command with the 
                     --version
                   option.
               cdk --version
               If successful, the AWS CDK version and build numbers are displayed.
            
       
    
      Step 2: Add code
      In this step, you create a sample TypeScript project that contains all of the source
         code you need for the AWS CDK to programmatically deploy an AWS CloudFormation stack. This stack
         creates an Amazon SNS topic and an Amazon SQS queue in your AWS account and then subscribes the
         queue to the topic.
      
            With the terminal session still open in the IDE, create a directory to store the
               project's source code, for example a ~/environment/hello-cdk
               directory in your environment. Then switch to that directory.
            rm -rf ~/environment/hello-cdk # Remove this directory if it already exists.
mkdir ~/environment/hello-cdk  # Create the directory.
cd ~/environment/hello-cdk     # Switch to the directory.
         
            Set up the directory as a TypeScript language project for the AWS CDK. To do this,
               run the 
                  cdk
                command with the 
                  init
                action, the 
                  sample-app
                template, and the 
                  --language
                option along with the name of the programming language.
            cdk init sample-app --language typescript
            This creates the following files and subdirectories in the directory.
            
                
                
                
                
                
                
                
                
                
                
            
                  A hidden .git subdirectory and a hidden
                        .gitignore file, which makes the project compatible
                     with source control tools such as Git.
               
                  A lib subdirectory, which includes a
                        hello-cdk-stack.ts file. This file contains the code
                     for your AWS CDK stack. This code is described in the next step in this
                     procedure.
               
                  A bin subdirectory, which includes a
                        hello-cdk.ts file. This file contains the entry point
                     for your AWS CDK app.
               
                  A node_modules subdirectory, which contains supporting
                     code packages that the app and stack can use as needed.
               
                  A hidden .npmignore file, which lists the types of
                     subdirectories and files that 
                        npm
                      doesn't need when it builds the code.
               
                  A cdk.json file, which contains information to make
                     running the 
                        cdk
                      command easier.
               
                  A package-lock.json file, which contains information
                     that 
                        npm
                      can use to reduce possible build and run errors.
               
                  A package.json file, which contains information to make
                     running the 
                        npm
                      command easier and with possibly fewer build and run errors.
               
                  A README.md file, which lists useful commands you can
                     run with 
                        npm
                      and the AWS CDK.
               
                  A tsconfig.json file, which contains information to
                     make running the 
                        tsc
                      command easier and with possibly fewer build and run errors.
               
         
            In the Environment window, open the
                  lib/hello-cdk-stack.ts file, and browse the following code in
               that file.
            import sns = require('@aws-cdk/aws-sns');
import sqs = require('@aws-cdk/aws-sqs');
import cdk = require('@aws-cdk/cdk');

export class HelloCdkStack extends cdk.Stack {
  constructor(parent: cdk.App, name: string, props?: cdk.StackProps) {
    super(parent, name, props);

    const queue = new sqs.Queue(this, 'HelloCdkQueue', {
      visibilityTimeoutSec: 300
    });

    const topic = new sns.Topic(this, 'HelloCdkTopic');

    topic.subscribeQueue(queue);
  }
}
            
                
                
            
                  The Stack, App, StackProps,
                        Queue, and Topic classes represent an AWS CloudFormation stack
                     and its properties, an executable program, an Amazon SQS queue, and an Amazon SNS topic,
                     respectively.
               
                  The HelloCdkStack class represents the AWS CloudFormation stack for this
                     application. This stack contains the new Amazon SQS queue and Amazon SNS topic for this
                     application.
               
         
            In the Environment window, open the
                  bin/hello-cdk.ts file, and browse the following code in that
               file.
            #!/usr/bin/env node
import cdk = require('@aws-cdk/cdk');
import { HelloCdkStack } from '../lib/hello-cdk-stack';

const app = new cdk.App();
new HelloCdkStack(app, 'HelloCdkStack');
app.run();
            This code loads, instantiates, and then runs the HelloCdkStack class
               from the lib/hello-cdk-stack.ts file.
         
            Use 
                  npm
                to run the TypeScript compiler to check for coding errors, and then
               enable the AWS CDK to execute the project's bin/hello-cdk.js file.
               To do this, from the project's root directory, run the 
                  npm
                command with the 
                  run
                action, specifying the 
                  build
                command value in the package.json file, as
               follows.
            npm run build
            The preceding command runs the TypeScript compiler, which adds supporting
                  bin/hello-cdk.d.ts and
                  lib/hello-cdk-stack.d.ts files. The compiler also transpiles
               the hello-cdk.ts and hello-cdk-stack.ts
               files into hello-cdk.js and
                  hello-cdk-stack.js files.
         
    
      Step 3: Run the code
      In this step, you instruct the AWS CDK to create a AWS CloudFormation stack template based on the code
         in the bin/hello-cdk.js file. You then instruct the AWS CDK to deploy
         the stack, which creates the Amazon SNS topic and Amazon SQS queue and then subscribes the queue to
         the topic. You then confirm that the topic and queue were successfully deployed by sending
         a message from the topic to the queue.
      
            Have the AWS CDK create the AWS CloudFormation stack template. To do this, with the terminal
               session still open in the IDE, from the project's root directory, run the 
                  cdk
                command with the 
                  synth
                action and the name of the stack.
            cdk synth HelloCdkStack
            If successful, the output displays the AWS CloudFormation stack template's
                  Resources section.
         
            The first time that you deploy an AWS CDK app into an environment for a specific
               AWS account and AWS Region combination, you must install a bootstrap
                  stack. This stack includes various resources that the AWS CDK needs to
               complete its various operations. For example, this stack includes an Amazon S3 bucket that
               the AWS CDK uses to store templates and assets during its deployment processes. To
               install the bootstrap stack, run the 
                  cdk
                command with the 
                  bootstrap
                action.
            cdk bootstrap
            NoteIf you run cdk bootstrap without specifying any options, the
                  default AWS account and AWS Region are used. You can also bootstrap a specific
                  environment by specifying a profile and account/Region combination. For
                  example:cdk bootstrap --profile test 123456789012/us-east-1
         
            Have the AWS CDK run the AWS CloudFormation stack template to deploy the stack. To do this, from
               the project's root directory, run the 
                  cdk
                command with the 
                  deploy
                action and the name of the stack.
            cdk deploy HelloCdkStack
            If successful, the output displays that the HelloCdkStack stack
               deployed without errors.
            NoteIf the output displays a message that the stack does not define an environment
                  and that AWS credentials could not be obtained from standard locations or no
                  region was configured, make sure that your AWS credentials are set correctly in
                  the IDE, and then run the 
                     cdk deploy
                   command again. For more information, see Calling AWS services from an environment in AWS Cloud9.
         
            To confirm that the Amazon SNS topic and Amazon SQS queue were successfully deployed, send a
               message to the topic, and then check the queue for the received message. To do this,
               you can use a tool such as the AWS Command Line Interface (AWS CLI) or the AWS CloudShell. For more
               information about these tools, see the AWS CLI
         and aws-shell tutorial for AWS Cloud9.
            For example, to send a message to the topic, with the terminal session still open
               in the IDE, use the AWS CLI to run the Amazon SNS
                  publish
                command, supplying the message's subject and body, the AWS Region for
               the topic, and the topic's Amazon Resource Name (ARN).
            aws sns publish --subject "Hello from the AWS CDK" --message "This is a message from the AWS CDK." --topic-arn arn:aws:sns:us-east-2:123456789012:HelloCdkStack-HelloCdkTopic1A234567-8BCD9EFGHIJ0K
            In the preceding command, replace
                  arn:aws:sns:us-east-2:123456789012:HelloCdkStack-HelloCdkTopic1A234567-8BCD9EFGHIJ0K
               with the ARN that AWS CloudFormation assigns to the topic. To get the ID, you can run the
                  Amazon SNS
                  list-topics
                command.
            aws sns list-topics --output table --query 'Topics[*].TopicArn'
            If successful, the output of the 
                  publish
                command displays the MessageId value for the message that
               was published.
            To check the queue for the received message, run the Amazon SQS
                  receive-message
                command, supplying the queue's URL.
            aws sqs receive-message --queue-url https://queue.amazonaws.com/123456789012/HelloCdkStack-HelloCdkQueue1A234567-8BCD9EFGHIJ0K
            In the preceding command, replace
                  https://queue.amazonaws.com/123456789012/HelloCdkStack-HelloCdkQueue1A234567-8BCD9EFGHIJ0K
               with the ARN that AWS CloudFormation assigns to the queue. To get the URL, you can run the
                  Amazon SQS
                  list-queues
                command.
            aws sqs list-queues --output table --query 'QueueUrls[*]'
            If successful, the output of the 
                  receive-message
                command displays information about the message that was received.
         
    
      Step 4: Clean up
      To prevent ongoing charges to your AWS account after you're done using this sample,
         you should delete the AWS CloudFormation stack. This deletes the the Amazon SNS topic and Amazon SQS queue. You
         should also delete the environment.
       
         Step 4.1: Delete the stack
         With the terminal session still open in the IDE, from the project's root directory,
            run the 
               cdk
             command with the 
               destroy
             action and the stack's name.
         cdk destroy HelloCdkStack
         When prompted to delete the stack, type y, and then press
               Enter.
         If successful, the output displays that the HelloCdkStack stack was
            deleted without errors.
       
       
         Step 4.2: Delete the environment
         To delete the environment, see Deleting an environment in AWS Cloud9.
       
   Document ConventionsAmazon DynamoDB tutorialLAMP tutorialDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideKey conceptsHow CloudFormation worksHow CloudFormation worksThis topic describes how CloudFormation works and introduces you to the key concepts you'll
         need to know about as you use it.TopicsKey conceptsHow CloudFormation works
  Key concepts

  When you use CloudFormation, you work with templates and
      stacks. You create templates to describe your AWS resources and their
    properties. Whenever you create a stack, CloudFormation provisions the resources that are described
    in your template.
  TopicsTemplatesStacksChange sets
   
    Templates

    A CloudFormation template is a YAML or JSON formatted text file. You can save these files with
      any extension, such as .yaml, .json,
        .template, or .txt. CloudFormation uses these
      templates as blueprints for building your AWS resources. For example, in a template, you can
      describe an Amazon EC2 instance, such as the instance type, the AMI ID, block device mappings, and
      its Amazon EC2 key pair name. Whenever you create a stack, you also specify a template that
      CloudFormation uses to create whatever you described in the template.
    For example, if you created a stack with the following template, CloudFormation provisions an
      instance with an ami-0ff8a91507f77f867 AMI ID, t2.micro instance
      type, testkey key pair name, and an Amazon EBS volume.
    
      YAML
      AWSTemplateFormatVersion: 2010-09-09
Description: A sample template
Resources:
  MyEC2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      ImageId: ami-0ff8a91507f77f867
      InstanceType: t2.micro
      KeyName: testkey
      BlockDeviceMappings:
        - DeviceName: /dev/sdm
          Ebs:
            VolumeType: io1
            Iops: 200
            DeleteOnTermination: false
            VolumeSize: 20

    
    
      JSON
      {
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "A sample template",
    "Resources": {
        "MyEC2Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "ImageId": "ami-0ff8a91507f77f867",
                "InstanceType": "t2.micro",
                "KeyName": "testkey",
                "BlockDeviceMappings": [
                    {
                        "DeviceName": "/dev/sdm",
                        "Ebs": {
                            "VolumeType": "io1",
                            "Iops": 200,
                            "DeleteOnTermination": false,
                            "VolumeSize": 20
                        }
                    }
                ]
            }
        }
    }
}
    
    You can also specify multiple resources in a single template and configure these resources
      to work together. For example, you can modify the previous template to include an Elastic IP
      address (EIP) and associate it with the Amazon EC2 instance, as shown in the following
      example:
    
      YAML
      AWSTemplateFormatVersion: 2010-09-09
Description: A sample template
Resources:
  MyEC2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      ImageId: ami-0ff8a91507f77f867
      InstanceType: t2.micro
      KeyName: testkey
      BlockDeviceMappings:
        - DeviceName: /dev/sdm
          Ebs:
            VolumeType: io1
            Iops: 200
            DeleteOnTermination: false
            VolumeSize: 20
  MyEIP:
    Type: 'AWS::EC2::EIP'
    Properties:
      InstanceId: !Ref MyEC2Instance

    
    
      JSON
      {
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "A sample template",
    "Resources": {
        "MyEC2Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "ImageId": "ami-0ff8a91507f77f867",
                "InstanceType": "t2.micro",
                "KeyName": "testkey",
                "BlockDeviceMappings": [
                    {
                        "DeviceName": "/dev/sdm",
                        "Ebs": {
                            "VolumeType": "io1",
                            "Iops": 200,
                            "DeleteOnTermination": false,
                            "VolumeSize": 20
                        }
                    }
                ]
            }
        },
        "MyEIP": {
            "Type": "AWS::EC2::EIP",
            "Properties": {
                "InstanceId": {
                    "Ref": "MyEC2Instance"
                }
            }
        }
    }
}
    
    The previous templates are centered around a single Amazon EC2 instance; however, CloudFormation
      templates have additional capabilities that you can use to build complex sets of resources and
      reuse those templates in multiple contexts. For example, you can add input parameters whose
      values are specified when you create a CloudFormation stack. In other words, you can specify a
      value like the instance type when you create a stack instead of when you create the template,
      making the template easier to reuse in different situations.
   
   
    Stacks

    When you use CloudFormation, you manage related resources as a single unit called a stack. You
      create, update, and delete a collection of resources by creating, updating, and deleting
      stacks. All the resources in a stack are defined by the stack's CloudFormation template. Suppose
      you created a template that includes an Auto Scaling group, Elastic Load Balancing load balancer, and an Amazon Relational Database Service
      (Amazon RDS) database instance. To create those resources, you create a stack by submitting the
      template that you created, and CloudFormation provisions all those resources for you.
   
   
    Change sets

    If you need to make changes to the running resources in a stack, you update the stack.
      Before making changes to your resources, you can generate a change set, which is a summary of
      your proposed changes. Change sets allow you to see how your changes might impact your running
      resources, especially for critical resources, before implementing them.
    For example, if you change the name of an Amazon RDS database instance, CloudFormation will create
      a new database and delete the old one. You will lose the data in the old database unless
      you've already backed it up. If you generate a change set, you will see that your change will
      cause your database to be replaced, and you will be able to plan accordingly before you update
      your stack. 
   
 
  How CloudFormation works
  When you use CloudFormation to create your stack, CloudFormation makes underlying service calls to
    AWS to provision and configure the resources described in your template. You need permission
    to create these resources. For example, to create EC2 instances by using CloudFormation, you need
    permissions to create instances. You manage these permissions with AWS Identity and Access Management (IAM).
  The calls that CloudFormation makes are all declared by your template. For example, suppose you
    have a template that describes an EC2 instance with a t2.micro instance type. When
    you use that template to create a stack, CloudFormation calls the Amazon EC2 create instance API and
    specifies the instance type as t2.micro. The following diagram summarizes the
    CloudFormation workflow for creating stacks.
  
     
      
     
     
  
  To create a stack
      Use a text editor to create a CloudFormation template in YAML or JSON format. The CloudFormation
        template describes the resources you want and their settings. Use Infrastructure Composer to visualize and
        validate your template. This helps you make sure that your template is properly structured
        and free of syntax errors. For more information, see Working with CloudFormation templates.
    
      Save the template locally or in an Amazon S3 bucket.
    
      Create a CloudFormation stack by specifying the location of your template file, such as a
        path on your local computer or an Amazon S3 URL. If the template contains parameters, you can
        specify input values when you create the stack. Parameters allow you to pass in values to
        your template so that you can customize your resources each time you create a stack.
      NoteIf you specify a template file stored locally, CloudFormation uploads it to an S3 bucket
          in your AWS account. CloudFormation creates a bucket for each region in which you upload a
          template file. The buckets are accessible to anyone with Amazon Simple Storage Service (Amazon S3) permissions in
          your AWS account. If a bucket created by CloudFormation is already present, the template is
          added to that bucket.You can use your own bucket and manage its permissions by manually uploading templates
          to Amazon S3. Then whenever you create or update a stack, specify the Amazon S3 URL of a template
          file.
    
  After all the resources have been created, CloudFormation reports that your stack has been
    created. You can then start using the resources in your stack. If stack creation fails,
    CloudFormation rolls back your changes by deleting the resources that it created.
  To create a hello world CloudFormation stack with the console, see Creating your first stack.
   
    Updating a stack with a change set
    When you need to update your stack's resources, you can modify the stack's template. You
      don't need to create a new stack and delete the old one. To update a stack, create a change
      set by submitting a modified version of the original stack template, different input parameter
      values, or both. CloudFormation compares the modified template with the original template and
      generates a change set. The change set lists the proposed changes. After reviewing the
      changes, you can start the change set to update your stack or you can create a new change set.
      The following diagram summarizes the workflow for updating a stack.
    
       
        
       
       
    
    To update a stack with a change set
        You can modify a CloudFormation stack template by using Infrastructure Composer or a text editor. For
          more information, see Update your stack template.
        As you update your template, keep in mind that updates can cause interruptions.
          Depending on the resource and properties that you are updating, an update might interrupt
          or even replace an existing resource. For more information, see Understand update behaviors of stack
         resources.
      
        Save the CloudFormation template locally or in an S3 bucket.
      
        Create a change set by specifying the stack that you want to update and the location
          of the modified template, such as a path on your local computer or an Amazon S3 URL. For more
          information about creating change sets, see Update CloudFormation stacks using change
      sets.
        NoteIf you specify a template that's stored on your local computer, CloudFormation
            automatically uploads your template to an S3 bucket in your AWS account.
      
        View the change set to check that CloudFormation will perform the changes that you expect.
          For example, check whether CloudFormation will replace any critical stack resources. You can
          create as many change sets as you need until you have included the changes that you
          want.
        ImportantChange sets don't indicate whether your stack update will be successful. For
            example, a change set doesn't check if you will surpass an account quota, if you're updating a resource that
            doesn't support updates, or if you have insufficient permissions to modify a resource, which can
            cause a stack update to fail.
      
        Initiate the change set that you want to apply to your stack. CloudFormation updates your
          stack by updating only the resources that you modified and signals that your stack has
          been successfully updated. If the stack updates fails, CloudFormation rolls back changes to
          restore the stack to the last known working state.
      
   

Document ConventionsGetting startedSigning up for an AWS accountDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationReferenceAWS Glossary
      Numbers and symbols | A | B | C |
         D | E | F | G |
         H | I | J | K |
         L | M | N | O |
         P | Q | R | S |
         T | U | V | W |
         X, Y, Z
   Numbers and symbols100-continue
            
            A method that gives a client the ability to see whether a server can accept a
               request before actually sending it. For large PUT requests, this method can save both
               time and bandwidth charges.
         A
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      AADSee additional authenticated
            data.access control list (ACL)
            
            A document that defines who can access a particular bucket or object. Each bucket
               and object in Amazon S3
               has an ACL. This document defines
               what each type of user can do, such as write and read permissions.
         access identifiersSee credentials.access key
            The combination of an access key ID
               (for example, AKIAIOSFODNN7EXAMPLE) and a secret access key (for example,
               wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY). You use access keys to
               sign API requests that you make to AWS.
         access key ID
            A unique identifier that's associated with a secret access key; the access key ID and secret access key are used
               together to sign programmatic AWS requests cryptographically.
         access key rotation
            A method to increase security by changing the AWS access key ID. You can use this
               method to retire an old key at your discretion.
         access policy language
            A language for writing documents (specifically, policies) that specify who can access a particular 
               AWS resource and under what
               conditions.
         account
            A formal relationship with AWS that's associated with all of the
               following:
            
                
                
                
            
                  The owner email address and password
               
                  The control of resources created
                     under its umbrella
               
                  Payment for the AWS activity related to those resources
               
            The AWS account has permission to do anything and everything with all the
               AWS account resources. This is in contrast to a user, which is an entity contained within the account.
         account activity
            A webpage showing your month-to-date AWS usage and costs. The account activity
               page is located at https://aws.amazon.com/account-activity/.
         AWS Account Management
            AWS Account Management is a tool that you can use to update the contact information for each of your AWS accounts.
            See also https://aws.amazon.com/organizations.
         ACLSee access control list (ACL).ACM
               AWS Certificate Manager is a web service for provisioning, managing, and deploying Secure 
                  Sockets Layer/Transport Layer Security
                  (SSL/TLS) certificates for use with AWS services.
               See also https://aws.amazon.com/certificate-manager/.
            action
            An API function. Also called operation or
                  call. The activity the principal has permission to perform. The action is B in the statement
               "A has permission to do B to C where D applies." For example, Jane sends a request to
               Amazon SQS with Action=ReceiveMessage.
            CloudWatch: The response initiated by the
               change in an alarm's state (for example, from OK to ALARM).
               The state change might be caused by a metric reaching the alarm threshold, or by a
                  SetAlarmState request. Each alarm can have one or more actions
               assigned to each state. Actions are performed once each time the alarm changes to a
               state that has an action assigned. Example actions include an Amazon SNS notification, running an Amazon EC2 Auto Scaling
               policy, and an 
                  Amazon EC2 instance stop/terminate action.
         active trusted key groups
            
            A list that shows each of the trusted key groups, and the IDs of the public keys in each key
               group, that are active for a distribution in Amazon CloudFront. CloudFront can use the public keys
               in these key groups to verify the signatures of CloudFront signed URLs
                  and signed cookies.
         active trusted signers
            
            See active trusted key groups.
         active-active
            A class of high availability strategies in which a workload exists simultaneously in multiple Regions, uses multiple primary resources, and serves traffic from all of the Regions to which it's deployed. Sometimes referred to as active/active. 
            See also read local/write global, read local/write local, 
               global consistency.
            
         active-passive
            A class of disaster recovery strategies that involve a primary Region and a standby Region in a back up and restore, hot standby, pilot light, or warm standby configuration. Sometimes referred to as active/passive. 
         additional authenticated
            data
            Information that's checked for integrity but not encrypted, such as headers or
               other contextual metadata.
         administrative suspension
            Amazon EC2 Auto Scaling might suspend processes
               for Auto Scaling group that
               repeatedly fail to launch instances. Auto Scaling groups that most commonly experience
               administrative suspension have zero running instances, have been trying to launch
               instances for more than 24 hours, and have not succeeded in that time. 
         alarm
            
            An item that watches a single metric over a specified time period and starts an
               Amazon SNS
               topic or an Amazon EC2 Auto Scaling
               policy. These actions are started if the
               value of the metric crosses a threshold value over a predetermined number of time
               periods.
         allow
            
            One of two possible outcomes (the other is deny) when an IAM
               access policy is evaluated. When a user
               makes a request to AWS, AWS evaluates the request based on all permissions that apply
               to the user and then returns either allow or deny.
         Amazon Machine Image
            (AMI)
            An Amazon Machine Image (AMI) is an encrypted machine image stored in Amazon EBS or
               Amazon S3. AMIs function similarly to a
               template of a computer's root drive. They contain the operating system and can also
               include software and layers of your application, such as database servers,
               middleware, and web servers. 
         Amazon Web Services
            (AWS)
            An infrastructure web services platform in the cloud for companies of all
               sizes.
            See also https://aws.amazon.com/what-is-cloud-computing/.
         AMISee Amazon Machine Image
            (AMI).Amplify
            AWS Amplify is a complete solution that frontend web and mobile developers can
               use to build and deploy secure, scalable full-stack applications powered by AWS.
               Amplify provides two services: Amplify Hosting and Amplify Studio.
            See also 
               https://aws.amazon.com/amplify/
            .
         Amplify Android
            Amplify Android is a collection of open-source client libraries that provides
               interfaces for specific use cases across many AWS services. Amplify Android is
               the recommended way to build native Android applications powered by AWS.
            See also 
               https://aws.amazon.com/amplify/
            .
         Amplify Hosting
            AWS Amplify Hosting is a fully managed continuous integration and continuous
               delivery (CI/CD) and hosting service for fast, secure, and reliable static and
               server-side rendered apps. Amplify Hosting provides a Git-based workflow for
               hosting full-stack serverless web apps with continuous deployment.
            See also 
               https://aws.amazon.com/amplify/hosting/
            .
         Amplify iOS
            Amplify iOS is a collection of open-source client libraries that provides
               interfaces for specific use cases across many AWS services. Amplify iOS is the
               recommended way to build native iOS applications powered by AWS.
            See also 
               https://aws.amazon.com/amplify/
            .
         Amplify Studio
            AWS Amplify Studio is a visual development environment that web and mobile
               developers can use to build the frontend UI components and the backend environment
               for a full-stack application.
            See also 
               https://aws.amazon.com/amplify/studio/
            .
         analysis rules
            AWS Clean Rooms: The query restrictions that authorize a specific type of query.
         analysis scheme
            
            CloudSearch: Language-specific text
               analysis options that are applied to a text field to control stemming and configure
               stopwords and synonyms. 
         API Gateway
            Amazon API Gateway is a fully managed service that developers can use to create, publish, maintain,
               monitor, and secure APIs at any scale.
            See also https://aws.amazon.com/api-gateway.
         AWS App2Container
            AWS App2Container is a transformation tool that modernizes .NET and Java applications by migrating them into containerized applications.
            See also https://aws.amazon.com/app2container.
         AWS AppConfig
            AWS AppConfig is a service used to update software at runtime without deploying new code. With AWS AppConfig, you can configure, validate, and deploy feature flags and application configurations.
            See also https://aws.amazon.com/systems-manager/features/appconfig.
         Amazon AppFlow
            Amazon AppFlow is a fully managed integration service that you can use to transfer data securely between software as a service (SaaS) applications and AWS services.
            See also https://aws.amazon.com/appflow.
         application
            
            Elastic Beanstalk: A logical collection of
               components, including environments, versions, and environment configurations. An
               application is conceptually similar to a folder.
            CodeDeploy: A name that
               uniquely identifies the application to be deployed. AWS CodeDeploy uses this name to
               ensure the correct combination of revision, deployment configuration, and deployment
               group are referenced during a deployment.
         Application Auto Scaling
            AWS Application Auto Scaling is a web service that you can use to configure automatic scaling for AWS resources
               beyond Amazon EC2, such as Amazon ECS services, Amazon EMR clusters, and DynamoDB tables.
            See also https://aws.amazon.com/autoscaling/.
         Application Billing
            
            The location where your customers manage the Amazon DevPay products they've purchased. The
               web address is http://www.amazon.com/dp-applications.
         Application Composer
            AWS Application Composer is a visual designer that you can use to build
               serverless applications from multiple AWS services. As you design an application,
               Application Composer automatically generates a YAML template with CloudFormation and AWS SAM template resources.
            See also 
               https://aws.amazon.com/application-composer/
            .
         Application Cost Profiler
            AWS Application Cost Profiler is a solution to track the consumption of shared AWS resources used by software applications and report granular cost breakdown across tenant base.
            See also https://aws.amazon.com/aws-cost-management/aws-application-cost-profiler/.
         Application Discovery Service
            AWS Application Discovery Service is a web service that helps you plan to migrate to AWS by identifying IT assets in
               a data center—including servers, virtual machines, applications, application
               dependencies, and network infrastructure. 
            See also https://aws.amazon.com/application-discovery/.
         application revision
            CodeDeploy: An archive file
               containing source content—such as source code, webpages, executable files, and
               deployment scripts—along with an application specification
            file. Revisions are stored in Amazon S3
               buckets or GitHub repositories. For Amazon S3, a revision is uniquely identified by
               its Amazon S3 object key and its ETag, version, or both. For GitHub, a revision is
               uniquely identified by its commit ID.
         application specification
            file
            CodeDeploy: A YAML-formatted
               file used to map the source files in an application revision to destinations on the
               instance. The file is also used to specify custom permissions for deployed files and
               specify scripts to be run on each instance at various stages of the deployment
               process.
         application version
            
            Elastic Beanstalk: A specific, labeled
               iteration of an application that represents a functionally consistent set of
               deployable application code. A version points to an Amazon S3 object (a JAVA WAR file) that contains the application code. 
         AppSpec fileSee application specification
            file.AppStream 2.0
            Amazon AppStream 2.0 is a fully managed, secure service for streaming desktop applications to users
               without rewriting those applications.
            See also https://aws.amazon.com/appstream/.
         AWS AppSync
            AWS AppSync is an enterprise-level, fully managed GraphQL service with real-time data
               synchronization and offline programming features.
            See also https://aws.amazon.com/appsync/.
         ARNSee Amazon Resource Name (ARN).artifact
            CodePipeline: A copy of the
               files or changes that are worked on by the pipeline. 
         asymmetric encryption
            
               Encryption that uses both a
               public key and a private key.
         asynchronous bounce
            
            A type of bounce that occurs when a receiver initially accepts an email message
               for delivery and then subsequently fails to deliver it.
         Athena
            Amazon Athena is an interactive query service that you can use to analyze data in Amazon S3 using ANSI
               SQL. Athena is serverless, so there's no infrastructure to manage. Athena scales
               automatically and is simple to use, so you can start analyzing your datasets within
               seconds.
            See also https://aws.amazon.com/athena/.
         atomic counter
            DynamoDB: A method of incrementing or decrementing the value of an existing attribute
               without interfering with other write requests.
         attribute
            A fundamental data element, something that doesn't need to be broken down any
               further. In DynamoDB, attributes are similar in many ways to fields or columns in other
               database systems.
             Amazon Machine Learning: A unique, named property within an observation in a dataset. In tabular
               data, such as spreadsheets or comma-separated values (.csv) files, the column
               headings represent the attributes, and the rows contain values for each
               attribute.
         AUC
            Area Under a Curve. An industry-standard metric to evaluate the quality of a
               binary classification machine learning model. AUC measures the ability of the model
               to predict a higher score for positive examples, those that are “correct,” than for
               negative examples, those that are “incorrect.” The AUC metric returns a decimal value
               from 0 to 1. AUC values near 1 indicate an ML model that's highly accurate.
         Aurora
               Amazon Aurora is a fully managed MySQL-compatible relational database engine that combines the
                  speed and availability of commercial databases with the simplicity and
                  cost-effectiveness of open-source databases.
               See also https://aws.amazon.com/rds/aurora/.
            authenticated encryption
            Encryption that provides
               confidentiality, data integrity, and authenticity assurances of the encrypted
               data.
         authentication
            The process of proving your identity to a system.
         AWS Auto Scaling
            AWS Auto Scaling is a fully managed service that you can use to quickly discover the scalable AWS
               resources that are part of your application and to configure dynamic scaling.
            See also https://aws.amazon.com/autoscaling/.
         Auto Scaling group
            A representation of multiple EC2 instances that 
               share similar characteristics, and that are treated as a logical grouping for the 
               purposes of instance scaling and management.
         Availability Zone
            
            A distinct location within a Region
               that's insulated from failures in other Availability Zones, and provides inexpensive,
               low-latency network connectivity to other Availability Zones in the same
               Region.
         AWSSee Amazon Web Services
            (AWS).B
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      back up and restore
            A disaster recovery strategy in which backups of data in the primary Region are copied to a standby Region and can be restored from the standby Region. You must provision the infrastructure and other resources, such as compute, as part of a failover process. 
            See also active-passive, hot standby, pilot light, warm standby.
         Backint Agent
            AWS Backint Agent for SAP HANA is an SAP-certified backup and restore solution for SAP HANA workloads running on Amazon EC2 instances in the cloud.
            See also https://aws.amazon.com/backint-agent.
         AWS Backup
            AWS Backup is a managed backup service that you can use to centralize and automate the backup of
               data across AWS services in the cloud and on premises.
            See also https://aws.amazon.com/backup/.
         basic monitoring
            
            Monitoring of AWS provided metrics derived at a 5-minute frequency.
         batchSee document batch.batch prediction
            Amazon Machine Learning: An operation that processes multiple input data observations at one time
               (asynchronously). Unlike real-time predictions, batch predictions aren't available
               until all predictions have been processed.
            See also real-time predictions.
         BGP ASN
            
            Border Gateway Protocol Autonomous System Number is a unique identifier for a
               network, for use in BGP routing. Amazon EC2
               supports all 2-byte ASN numbers in the range of 1 – 65335, with the exception
               of 7224, which is reserved.
         billingSee Billing and Cost Management.Billing and Cost Management
            AWS Billing and Cost Management is the AWS Cloud computing model where you pay for services on demand and use as
               much or as little as you need. While resources are active under your account, you pay for the cost of
               allocating those resources. You also pay for any incidental usage associated with
               those resources, such as data transfer or allocated storage.
            See also https://aws.amazon.com/billing/new-user-faqs/.
         binary attribute
            Amazon Machine Learning: An attribute for which one of two possible values is possible. Valid
               positive values are 1, y, yes, t, and true answers. Valid negative values are 0, n,
               no, f, and false. Amazon Machine Learning outputs 1 for positive values and 0 for negative
               values.
            See also attribute.
         binary classification model
            Amazon Machine Learning: A machine learning model that predicts the answer to questions where the
               answer can be expressed as a binary variable. For example, questions with answers of
               “1” or “0”, “yes” or “no”, “will click” or “will not click” are questions that have
               binary answers. The result for a binary classification model is always either a “1”
               (for a “true” or affirmative answers) or a “0” (for a “false” or negative
               answers).
         block
            
            A dataset. Amazon EMR breaks large amounts of data into
               subsets. Each subset is called a data block. Amazon EMR assigns an ID to each block and
               uses a hash table to keep track of block processing.
         block device
            
            A storage device that supports reading and (optionally) writing data in fixed-size
               blocks, sectors, or clusters.
         block device mapping
            
            A mapping structure for every AMI and instance that specifies the block devices attached to the
               instance.
         AWS Blockchain TemplatesSee Managed Blockchain.blue/green deployment
            CodeDeploy: A deployment method where the instances in a deployment group (the original
               environment) are replaced by a different set of instances (the replacement
               environment).
         bootstrap action
            
            A user-specified default or custom action that runs a script or an application on
               all nodes of a job flow before Hadoop
               starts.
         Border Gateway Protocol Autonomous System NumberSee BGP ASN.bounce
            
            A failed email delivery attempt.
         Braket
            Amazon Braket is a fully managed quantum computing service that helps you run quantum algorithms to accelerate your research and discovery.
            See also https://aws.amazon.com/braket.
         breach
            
            Amazon EC2 Auto Scaling: The condition where a
               user-set threshold (upper or lower boundary) is passed. If the duration of the breach
               is significant, as set by a breach duration parameter, it can possibly start a scaling activity. 
         bucket
            
            Amazon S3: A container for stored objects. Every
               object is contained in a bucket. For example, if the object named
                  photos/puppy.jpg is stored in the amzn-s3-demo-bucket
               bucket, then authorized users can access the object with the URL
                  https://amzn-s3-demo-bucket.s3.region-code.amazonaws.com/photos/puppy.jpg.
         bucket owner
            
            
            The person or organization that owns a bucket in Amazon S3. In the same way that Amazon is the only
               owner of the domain name Amazon.com, only one person or organization can own a
               bucket. 
         bundling
            
            A commonly used term for creating an Amazon Machine Image
            (AMI). It specifically refers to creating instance store-backed AMIs.
         C
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      cache cluster
            
            A logical cache distributed over multiple cache nodes. A cache cluster can be set up with a specific number of
               cache nodes.
         cache cluster identifier
            
            Customer-supplied identifier for the cache cluster that must be unique for that
               customer in an AWS Region.
         cache engine version
            
            The version of the Memcached service that's running on the cache node.
         cache node
            
            A fixed-size chunk of secure, network-attached RAM. Each cache node runs an
               instance of the Memcached service, and has its own DNS name and port. Multiple types
               of cache nodes are supported, each with varying amounts of associated memory.
         cache node type
            
            An EC2 instance type used to run the
               cache node.
         cache parameter group
            
            A container for cache engine parameter values that can be applied to one or more
               cache clusters.
         cache security group
            
            A group maintained by ElastiCache that combines inbound authorizations to cache nodes
               for hosts belonging to Amazon EC2
               security groups that are specified through the
               console or the API or command line tools.
         campaign
            Amazon Personalize: A deployed solution version (trained model) with provisioned dedicated transaction capacity for creating real-time recommendations for your application users. After you create a campaign, you use the getRecommendations or getPersonalizedRanking personalization operations to get recommendations.
            See also recommendations.
            See also solution version.
         canned access policy
            
            A standard access control policy that you can apply to a bucket or object. Options include: private,
               public-read, public-read-write, and authenticated-read.
         canonicalization
            The process of converting data into a standard format that a service such as Amazon S3
               can recognize.
         capacity
            
            The amount of available compute size at a given time. Each Auto Scaling group is defined with a
               minimum and maximum compute size. A scaling activity increases or decreases the capacity within the defined
               minimum and maximum values.
         Cartesian product
            A mathematical operation that returns a product from multiple sets.
         Cartesian product processor
            A processor that calculates a Cartesian product. Also known as a
                  Cartesian data processor.
         AWS CDK
            AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining your cloud
               infrastructure in code and provisioning it through AWS CloudFormation.
            See also https://aws.amazon.com/cdk/.
         CDNSee content delivery network (CDN).certificate
            A credential that some AWS products use to authenticate AWS accounts and users. Also known as an X.509 certificate. The certificate is paired with a private
               key.
         chargeable resources
            Features or services whose use incurs fees. Although some AWS products are free,
               others include charges. For example, in an CloudFormation
               stack, AWS resources that have been created incur charges. The amount charged
               depends on the usage load. Use the Amazon Web Services Simple Monthly Calculator
               
               to estimate your cost prior to creating instances, stacks, or other resources.
         Amazon Q Developer in chat applications
            Amazon Q Developer in chat applications is an interactive agent that makes it easier to monitor, troubleshoot, and operate AWS resources in your Slack channels and Amazon Chime chat rooms.
            See also https://aws.amazon.com/chatbot.
         Amazon Chime
            Amazon Chime is a secure, real-time, unified communications service that transforms meetings by
               making them more efficient and easier to conduct.
            See also https://aws.amazon.com/chime/.
         CIDR block
            Classless Inter-Domain Routing. An internet protocol address allocation and route
               aggregation methodology.
            See also Classless
               Inter-Domain Routing on Wikipedia.
         ciphertext
            Information that has been encrypted, as opposed to plaintext, which is information that has not.
         classification
            In machine learning, a type of problem that seeks to place (classify) a data
               sample into a single category or “class.” Often, classification problems are modeled
               to choose one category (class) out of two. These are binary classification problems.
               Problems with more than two available categories (classes) are called "multiclass
               classification" problems.
            See also binary classification model.
            See also multiclass classification
            model.
         AWS Clean Rooms
            AWS Clean Rooms is an AWS service that helps multiple parties to join their data together in a secure collaboration workspace.
            See also https://aws.amazon.com/clean-rooms/.
         Client VPN
            AWS Client VPN is a client-based, managed VPN service that remote clients can use to securely access your AWS resources using an Open VPN-based software client.
            See also https://aws.amazon.com/vpn/client-vpn.
         AWS Cloud Control API
            AWS Cloud Control API is a set of standardized application programming interfaces (APIs) that developers can use to create, read, update, delete, and list supported cloud infrastructure.
            See also https://aws.amazon.com/cloudcontrolapi.
         Cloud Directory
            Amazon Cloud Directory is a service that provides a highly scalable directory store for your application's
               multihierarchical data.
            See also https://aws.amazon.com/cloud-directory/.
         AWS Cloud Map
            AWS Cloud Map is a service that you use to create and maintain a map of the backend services and
               resources that your applications depend on. With AWS Cloud Map, you can name and
               discover your AWS Cloud resources.
            See also https://aws.amazon.com/cloud-map.
         cloud service provider
            (CSP)
            A cloud service provider is a company that provides subscribers with access to internet-hosted computing,
               storage, and software services.
         AWS Cloud WAN
            AWS Cloud WAN is a managed wide-area networking service used to build, manage, and monitor a unified global network.
            See also https://aws.amazon.com/cloud-wan.
         AWS Cloud9
            AWS Cloud9 is a cloud-based integrated development environment (IDE) that you use to write, run,
               and debug code.
            See also https://aws.amazon.com/cloud9/.
         CloudFormation
            AWS CloudFormation is a service for writing or changing templates that create and delete related AWS
               resources together as a unit.
            See also https://aws.amazon.com/cloudformation.
         CloudFront
            Amazon CloudFront is an AWS content delivery service that helps you improve the performance,
               reliability, and availability of your websites and applications.
            See also https://aws.amazon.com/cloudfront.
         CloudHSM
            AWS CloudHSM is a web service that helps you meet corporate, contractual, and regulatory
               compliance requirements for data security by using dedicated hardware security module
               (HSM) appliances within the AWS Cloud.
            See also https://aws.amazon.com/cloudhsm/.
         CloudSearch
            Amazon CloudSearch is a fully managed service in the AWS Cloud that you can use to set up, manage, and scale a search solution for your website or application.
            See also https://aws.amazon.com/cloudsearch/.
         CloudTrail
            AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files
               to you. The recorded information includes the identity of the API caller, the time of
               the API call, the source IP address of the API caller, the request parameters, and
               the response elements that the AWS service returns.
            See also https://aws.amazon.com/cloudtrail/.
         CloudWatch
            Amazon CloudWatch is a web service that you can use to monitor and manage various metrics, and
               configure alarm actions based on data from those metrics.
            See also https://aws.amazon.com/cloudwatch.
         CloudWatch Events
            Amazon CloudWatch Events is a web service that you can use to deliver a timely stream of system events that
               describe changes in AWS resources to Lambda functions, streams in Kinesis Data Streams, Amazon SNS topics, or built-in targets. 
            See also https://aws.amazon.com/cloudwatch.
         CloudWatch Logs
            Amazon CloudWatch Logs is a web service for monitoring and troubleshooting your systems and applications
               from your existing system, application, and custom log files. You can send your
               existing log files to CloudWatch Logs and monitor these logs in near-real time.
            See also https://aws.amazon.com/cloudwatch.
         cluster
            A logical grouping of container instances that you can place tasks on. 
            OpenSearch Service: A logical grouping of one or more data
               nodes, optional dedicated master nodes, and storage required to run Amazon OpenSearch Service (OpenSearch Service)
               and operate your OpenSearch Service domain.
            See also data node.
            See also dedicated master node.
            See also node.
         cluster compute instance
            
            A type of instance that provides a
               great amount of CPU power coupled with increased networking performance, making it
               well suited for High Performance Compute (HPC) applications and other demanding
               network-bound applications. 
         cluster placement group
            
            A logical cluster compute instance grouping
               to provide lower latency and high-bandwidth connectivity between the instances. 
         cluster status
            OpenSearch Service: An indicator of the health of a cluster. A
               status can be green, yellow, or red. At the shard level, green means that all shards
               are allocated to nodes in a cluster, yellow means that the primary shard is allocated
               but the replica shards aren't, and red means that the primary and replica shards of
               at least one index aren't allocated. The shard status determines the index status,
               and the index status determines the cluster status. 
         CNAME
            Canonical Name Record. A type of resource record in the Domain Name System (DNS) that specifies that the
               domain name is an alias of another, canonical domain name. Specifically, it's an
               entry in a DNS table that you can use to alias one fully qualified domain name to
               another. 
         Code Signing for AWS IoT
            A service for signing code that you create for any IoT device that's supported by
               Amazon Web Services (AWS).
         CodeBuild
            AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs
               tests, and produces software packages that are ready to deploy.
            See also https://aws.amazon.com/codebuild.
         CodeCommit
            AWS CodeCommit is a fully managed source control service that companies can use to host secure and
               highly scalable private Git repositories.
            See also https://aws.amazon.com/codecommit.
         CodeDeploy
            AWS CodeDeploy is a service that automates code deployments to any instance, including EC2 instances and instances running on-premises.
            See also https://aws.amazon.com/codedeploy.
         AWS CodeDeploy agent
            AWS CodeDeploy agent is a software package that, when installed and configured on an instance, enables
               that instance to be used in CodeDeploy deployments.
         CodeGuru
            Amazon CodeGuru is a collection of developer tools that automate code reviews and provide intelligent recommendations to optimize application performance.
            See also https://aws.amazon.com/codeguru.
         CodePipeline
            AWS CodePipeline is a continuous delivery service for fast and reliable application updates.
            See also https://aws.amazon.com/codepipeline.
         Amazon Cognito
            Amazon Cognito is a web service that you can use to save mobile user data in the AWS Cloud without
               writing any backend code or managing any infrastructure. Examples of mobile user data
               that you can save include app preferences and game states. Amazon Cognito offers mobile
               identity management and data synchronization across devices. 
            See also https://aws.amazon.com/cognito/.
         collaboration
            AWS Clean Rooms: A secure logical boundary in AWS Clean Rooms 
               in which members can perform SQL queries on configured tables.
         AWS CLI
            AWS Command Line Interface is a unified downloadable and configurable tool for managing AWS services. Control
               multiple AWS services from the command line and automate them through
               scripts.
            See also https://aws.amazon.com/cli/.
         complaint
            
            The event where a recipient who
               doesn't want to receive an email message chooses "Mark as Spam" within the email
               client, and the internet service provider
               (ISP) sends a notification to Amazon SES.
         compound query
            
            CloudSearch: A search request that
               specifies multiple search criteria using the Amazon CloudSearch structured search syntax.
         Amazon Comprehend
            Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to find insights and relationships in text.
            See also https://aws.amazon.com/comprehend/.
         Amazon Comprehend Medical
            Amazon Comprehend Medical is a HIPAA-eligible natural language processing (NLP) service that uses machine learning (ML), and has been pre-trained to understand and extract health data from medical text, such as prescriptions, procedures, or diagnoses.
            See also https://aws.amazon.com/comprehend/medical.
         condition
            
            IAM: Any restriction or detail
               about a permission. The condition is D in the statement "A has
               permission to do B to C where D applies."
            AWS WAF: A set of attributes that AWS WAF
               searches for in web requests to AWS resources such as Amazon CloudFront
               distributions. Conditions can include values such as the IP addresses that web
               requests originate from or values in request headers. Based on the specified
               conditions, you can configure AWS WAF to allow or block web requests to AWS
               resources.
         conditional parameterSee mapping.AWS Config
            AWS Config is a fully managed service that provides an AWS resource inventory, configuration history, and configuration change
               notifications for better security and governance. You can create rules that
               automatically check the configuration of AWS resources that AWS Config records.
            See also https://aws.amazon.com/config/.
         configuration API
            
            CloudSearch: The API call that you
               use to create, configure, and manage search domains.
         configuration template
            
            A series of key–value pairs that define parameters for various AWS products
               so that Elastic Beanstalk can provision them for
               an environment.
         Amazon Connect
            Amazon Connect is a service solution that offers self-service configuration and provides dynamic,
               personal, and natural customer engagement at any scale.
            See also https://aws.amazon.com/connect/.
         consistency model
            The method a service uses to achieve high availability. For example, it could
               involve replicating data across multiple servers in a data center.
            See also eventual consistency.
         consoleSee AWS Management Console.Console Mobile Application
            AWS Console Mobile Application lets AWS customers monitor and manage a select set of resources to stay informed and connected with their AWS resources while on the go.
            See also https://aws.amazon.com/console/mobile.
         consolidated billing
            A feature of the AWS Organizations service for consolidating payment for multiple AWS accounts. You create an organization that contains your AWS accounts, and you use the
               management account of your organization to pay for all member accounts. You can see a
               combined view of AWS costs that are incurred by all accounts in your organization,
               and you can get detailed cost reports for individual accounts. 
         container
            A container is a standard unit of software that contains application code and all
               relevant dependencies.
         container definition
            A container definition specifies the details that are associated with running a
                  container on Amazon ECS. More specifically,
               a container definition specifies details such as the container image to use and how
               much CPU and memory the container is allocated. The container definition is included
               as part of an Amazon ECS task definition.
         container instance
            A container instance is a self-managed EC2 instance or an on-premises server or virtual machine (VM) that's
               running the Amazon Elastic Container Service (Amazon ECS) container agent and has been registered into a cluster. A container instance serves as the
               infrastructure that your Amazon ECS workloads are run on.
         container registry 
            A container registry is a collection of repositories that store container images.
               One example is Amazon Elastic Container Registry (Amazon ECR).
         content delivery network (CDN)
            A web service that speeds up distribution of your static and dynamic web
               content—such as .html, .css, .js, media files, and image files—to your users by using
               a worldwide network of data centers. When a user requests your content, the request
               is routed to the data center that provides the lowest latency (time delay). If the
               content is already in the location with the lowest latency, the CDN delivers it
               immediately. If not, the CDN retrieves it from an origin that you specify (for
               example, a web server or an Amazon S3 bucket). With some CDNs, you can help secure
               your content by configuring an HTTPS connection between users and data centers, and
               between data centers and your origin. Amazon CloudFront is an example of a
               CDN.
         contextual metadata
            Amazon Personalize:
               Interactions data that you collect about a user's browsing context (such as device
               used or location) when an event (such as a click) occurs. Contextual metadata can
               improve recommendation relevance for new and existing users.
            See also Interactions dataset.
            See also event.
         continuous delivery
            A software development practice where code changes are automatically built,
               tested, and prepared for a release to production.
            See also https://aws.amazon.com/devops/continuous-delivery/.
         continuous integration
            A software development practice where developers regularly merge code changes into
               a central repository, after which automated builds and tests are run.
            See also https://aws.amazon.com/devops/continuous-integration/.
         AWS Control Tower
            AWS Control Tower is a service used to set up and govern a secure, multi-account AWS environment.
            See also https://aws.amazon.com/controltower.
         cooldown period
            
            Amount of time that Amazon EC2 Auto Scaling
               doesn't allow the desired size of the Auto Scaling group to be changed by any other notification from an CloudWatch
               alarm.
         core node
            
            An EC2 instance that runs Hadoop map and reduce tasks and stores data
               using the Hadoop Distributed File System (HDFS). Core nodes are managed by the master node, which assigns Hadoop tasks to
               nodes and monitors their status. The EC2 instances you assign as core nodes are
               capacity that must be allotted for the entire job flow run. Because core nodes store
               data, you can't remove them from a job flow. However, you can add more core nodes to
               a running job flow. 
            Core nodes run both the DataNodes and TaskTracker Hadoop daemons.
         corpus
            
            CloudSearch: A collection of data
               that you want to search.
         Corretto
            Amazon Corretto is a no-cost, multiplatform, production-ready distribution of the Open Java
               Development Kit (OpenJDK).
            See also https://aws.amazon.com/corretto/.
         coverage
            Amazon Personalize: An
               evaluation metric that tells you the proportion of unique items that Amazon Personalize might
               recommend using your model out of the total number of unique items in Interactions
               and Items datasets. To make sure Amazon Personalize recommends more of your items, use a model
               with a higher coverage score. Recipes that feature item exploration, such as
               user-personalization, have higher coverage than those that don’t, such as
               popularity-count.
            See also metrics.
            See also Items dataset.
            See also Interactions dataset.
            See also item exploration.
            See also user-personalization recipe.
            See also popularity-count recipe.
         credential helper
            CodeCommit: A program that
               stores credentials for repositories and supplies them to Git when making connections
               to those repositories. The AWS CLI
               includes a credential helper that you can use with Git when connecting to CodeCommit
               repositories.
         credentials
            Also called access credentials or security
                  credentials. In authentication and authorization, a system uses
               credentials to identify who is making a call and whether to allow the requested
               access. In AWS, these credentials are typically the access key ID and the secret access key.
         cross-account access
            The process of permitting limited, controlled use of resources in one AWS account by a user in another AWS account. For
               example, in CodeCommit and CodeDeploy you can configure
               cross-account access so that a user in AWS account A can access an CodeCommit repository
               created by account B. Or a pipeline in CodePipeline created by account A can use CodeDeploy resources created
               by account B. In IAM you use a role to delegate temporary access to a user in one account to resources in
               another.
         cross-Region replication
            A solution for replicating data across different AWS Regions, in near-real time.
         Cryptographic Computing for Clean Rooms (C3R)
            AWS Clean Rooms: A capability in AWS Clean Rooms that organizations can use
               to bring sensitive data together to derive new insights from data analytics while cryptographically limiting 
               what any party in the process can learn.
         customer gateway
            
            A router or software application on your side of a VPN tunnel that's managed by
                  Amazon VPC. The internal interfaces of the
               customer gateway are attached to one or more devices in your home network. The
               external interface is attached to the virtual private gateway (VGW) across the VPN tunnel. 
         customer managed policy
            An IAM
               managed policy that you create and
               manage in your AWS account.
         customer master key
            (CMK)
            We no longer use customer master key or CMK. These terms 
               are replaced by AWS KMS key (first mention) and KMS key 
               (subsequent mention). For more information, see KMS key.
         D
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      dashboardSee service health dashboard.data consistency
            A concept that describes when data is written or updated successfully and all
               copies of the data are updated in all AWS Regions. However, it takes time for the data to propagate to all
               storage locations. To support varied application requirements, DynamoDB supports both eventually consistent
               and strongly consistent reads.
            See also eventual consistency.
            See also eventually consistent read.
            See also strongly consistent read.
         AWS Data Exchange
            AWS Data Exchange is a service that helps you find, subscribe to, and use third-party data in the cloud.
            See also https://aws.amazon.com/data-exchange.
         Amazon Data Lifecycle Manager
            Amazon Data Lifecycle Manager is an Amazon service that automates and manages the lifecycle of Amazon EBS
               snapshots and Amazon EBS-backed AMIs.
         data node
            OpenSearch Service: An OpenSearch instance that holds data and
               responds to data upload requests.
            See also dedicated master node.
            See also node.
         Data Pipeline
            AWS Data Pipeline is a web service for processing and moving data between different AWS compute and
               storage services, as well as on-premises data sources, at specified intervals.
            See also https://aws.amazon.com/datapipeline.
         data schemaSee schema.data source
            The database, file, or repository that provides information required by an
               application or database. For example, in OpsWorks, valid data sources include an instance for a stack's MySQL layer or a stack's Amazon RDS service layer. In Amazon Redshift , valid data sources include text
               files in an Amazon S3
               bucket, in an Amazon EMR cluster, or on a remote host that a cluster can access through an
               SSH connection.
            See also datasource.
         database engine
            
            The database software and version running on the DB instance.
         database name
            
            The name of a database hosted in a DB instance. A DB instance can host multiple databases, but databases
               hosted by the same DB instance must each have a unique name within that instance.
            
         dataset
            Amazon Personalize: A container for the data used by Amazon Personalize. There are three types of Amazon Personalize datasets: Users, Items, and Interactions.
            See also Interactions dataset.
            See also Users dataset.
            See also Items dataset.
         dataset group
            Amazon Personalize: A container for Amazon Personalize components, including datasets, event trackers, solutions, filters, campaigns, and batch inference jobs. A dataset group organizes your resources into independent collections, so resources from one dataset group can’t influence resources in any other dataset group.
            See also dataset.
            See also event tracker.
            See also solution.
            See also campaign.
         datasource
            Amazon ML: An object
               that contains metadata about the input data. Amazon ML reads the input data, computes
               descriptive statistics on its attributes, and stores the statistics—along with
               a schema and other information—as part of the datasource object. Amazon ML uses
               datasources to train and evaluate a machine learning model and generate batch
               predictions.
            See also data source.
         DataSync
            AWS DataSync is an online data transfer service that simplifies, automates, and accelerates moving data between storage systems and services.
            See also https://aws.amazon.com/datasync.
         DB compute class
            
            The size of the database compute platform used to run the instance.
         DB instance
            
            An isolated database environment running in the cloud. A DB instance can contain
               multiple user-created databases.
         DB instance identifier
            
            User-supplied identifier for the DB instance. The identifier must be unique for
               that user in an AWS Region.
         DB parameter group
            
            A container for database engine parameter values that apply to one or more DB instances.
         DB security group
            
            A method that controls access to the DB instance. By default, network access is turned off to DB instances.
               After inbound traffic is configured for a security group, the same rules apply to all DB instances associated
               with that group.
         DB snapshot
            
            A user-initiated point backup of a DB instance.
         Dedicated Host
            
            A physical server with EC2 instance
               capacity fully dedicated to a user.
         Dedicated Instance
            
            An instance that's physically isolated
               at the host hardware level and launched within a Amazon VPC.
         dedicated master node
            OpenSearch Service: An OpenSearch instance that performs
               cluster management tasks, but doesn't hold data or respond to data upload requests.
               Amazon OpenSearch Service (OpenSearch Service) uses dedicated master nodes to increase cluster stability. 
            See also data node.
            See also node.
         Dedicated Reserved Instance
            
            An option that you purchase to guarantee that sufficient capacity will be
               available to launch Dedicated Instances into a Amazon VPC.
            
         AWS DeepComposer
            AWS DeepComposer is a web service designed specifically to educate developers through tutorials, sample code, and training data.
            See also https://aws.amazon.com/deepcomposer.
         AWS DeepLens
            AWS DeepLens is a tool that provides AWS customers with a centralized place to search, discover, and connect with trusted APN Technology and Consulting Partners, based on customers' business needs.
            See also https://aws.amazon.com/deeplens.
         AWS DeepRacer
            AWS DeepRacer is a cloud-based 3D racing simulator, global racing league, and fully autonomous 1/18th-scale race car driven by reinforcement learning.
            See also https://aws.amazon.com/deepracer.
         delegation
            Within a single AWS account: Giving
               AWS users access to resources your AWS account. 
            Between two AWS accounts: Setting up a trust between the account that owns the
               resource (the trusting account), and the account that contains the users that need to
               access the resource (the trusted account).
            See also trust policy.
         delete marker
            
            An object with a key and version ID, but without content. Amazon S3 inserts delete markers automatically into versioned buckets when an object is deleted.
         deliverability
            
            The likelihood that an email message arrives at its intended destination.
         deliveries
            
            The number of email messages, sent through Amazon SES, that were accepted by an internet service provider
               (ISP) for
               delivery to recipients over a period of
               time.
         deny
            The result of a policy statement that
               includes deny as the effect, so that a specific action or actions are expressly
               forbidden for a user, group, or role. Explicit deny take precedence over explicit
                  allow. 
         deployment configuration
            CodeDeploy: A set of deployment
               rules and success and failure conditions used by the service during a
               deployment.
         deployment group
            CodeDeploy: A set of
               individually tagged instances or EC2 instances in Auto Scaling groups, or both.
         Description property
            A property added to parameters, resources, resource properties, mappings, and outputs to help you to
               document CloudFormation template
               elements.
         detailed monitoring
            
            Monitoring of AWS provided metrics derived at a 1-minute frequency.
         Detective
            Amazon Detective is a service that collects log data from your AWS resources to analyze and identify
               the root cause of security findings or suspicious activities. The Detective behavior
               graph provides visualizations to help you to determine the nature and extent of
               possible security issues and conduct an efficient investigation.
            See also https://aws.amazon.com/detective/.
         Device Farm
            AWS Device Farm is an app testing service that you can use to test Android, iOS, and web
               apps on real, physical phones and tablets that are hosted by AWS.
            See also https://aws.amazon.com/device-farm/.
         Amazon DevOps Guru
            Amazon DevOps Guru is a fully managed operations service powered by machine learning (ML), designed to improve an application's operational performance and availability.
            See also https://aws.amazon.com/devops-guru/.
         dimension
            
            A name–value pair (for example, InstanceType=m1.small, or
               EngineName=mysql), that contains additional information to identify a metric.
         Direct Connect
            AWS Direct Connect is a web service that simplifies establishing a dedicated network connection from
               your premises to AWS. Using AWS Direct Connect, you can establish private connectivity
               between AWS and your data center, office, or colocation environment.
            See also 
               https://aws.amazon.com/directconnect.
         Directory Service
            AWS Directory Service is a managed service for connecting your AWS resources to an existing on-premises Microsoft Active Directory or to
               set up and operate a new, standalone directory in the AWS Cloud.
            See also 
               https://aws.amazon.com/directoryservice.
         discussion forums
            A place where AWS users can post technical questions and feedback to help
               accelerate their development efforts and to engage with the AWS community. For more
               information, see the Amazon Web Services Discussion Forums.
         distribution
            
            A link between an origin server (such as an Amazon S3
               bucket) and a domain name, which CloudFront automatically assigns.
               Through this link, CloudFront identifies the object you have stored in your origin server. 
         DKIM
            DomainKeys Identified Mail is a standard that email senders use to sign their
               messages. ISPs use those signatures to verify that messages are legitimate. For more
               information, see https://tools.ietf.org/html/rfc6376.
         AWS DMS
            AWS Database Migration Service is a web service that can help you migrate data to and from many widely used
               commercial and open-source databases.
            See also https://aws.amazon.com/dms.
         DNSSee Domain Name System.Docker image
             A layered file system template that's the basis of a Docker container. Docker images can comprise
               specific operating systems or applications. 
         document
            
            CloudSearch: An item that can be
               returned as a search result. Each document has a collection of fields that contain
               the data that can be searched or returned. The value of a field can be either a
               string or a number. Each document must have a unique ID and at least one field.
            
         document batch
            
            CloudSearch: A collection of add and
               delete document operations. You use the document service API to submit batches to
               update the data in your search domain. 
         document service API
            
            CloudSearch: The API call that you
               use to submit document batches to update the data in a search domain.
         document service endpoint
            
            CloudSearch: The URL that you
               connect to when sending document updates to an Amazon CloudSearch domain. Each search domain has a
               unique document service endpoint that remains the same for the life of the
               domain.
         Amazon DocumentDB
            Amazon DocumentDB (with MongoDB compatibility) is a managed database service that you can use to set up, operate, and scale
               MongoDB-compatible databases in the cloud.
            See also https://aws.amazon.com/documentdb/.
         domain
            OpenSearch Service: The hardware, software, and data exposed
               by Amazon OpenSearch Service (OpenSearch Service) endpoints. An OpenSearch Service domain is a service wrapper around an OpenSearch
               cluster. An OpenSearch Service domain encapsulates the engine instances that process OpenSearch Service requests,
               the indexed data that you want to search, snapshots of the domain, access policies,
               and metadata.
            See also cluster.
            See also Elasticsearch.
         Domain Name System
            Domain Name System is a service that routes internet traffic to websites by translating human-readable
               domain names (for example, www.example.com) into the numeric IP
               addresses, such as 192.0.2.1, which computers use to connect to each other.
         Donation button
            
            An HTML-coded button to provide a simple and secure way for US-based,
               IRS-certified 501(c)(3) nonprofit organizations to solicit donations.
         DynamoDB
            Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable
               performance with seamless scalability. 
            See also https://aws.amazon.com/dynamodb/.
         Amazon DynamoDB Encryption Client
            Amazon DynamoDB Encryption Client is a software library that helps you protect your table data before you send it to
               DynamoDB.
         Amazon DynamoDB Storage Backend for
            Titan
            Amazon DynamoDB Storage Backend for Titan is a graph database implemented on top of Amazon DynamoDB.
               Titan is a scalable graph database optimized for storing and querying graphs.
            See also https://aws.amazon.com/dynamodb/.
         DynamoDB Streams
            Amazon DynamoDB Streams is an AWS service that captures a time-ordered sequence of item-level modifications
               in any Amazon DynamoDB table. This service also stores this information in a log for up to
               24 hours. Applications can access this log and view the data items as they appeared
               before and after they were modified, in near-real time. 
            See also https://aws.amazon.com/dynamodb/.
         E
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Amazon EBS
            Amazon Elastic Block Store is a service that provides block level storage volumes or use with EC2 instances.
            See also https://aws.amazon.com/ebs.
         Amazon EBS-backed AMI
            An Amazon EBS-backed AMI is a type of Amazon Machine Image
            (AMI)
               whose instances use an Amazon EBS
               volume as their root device. Compare this
               with instances launched from instance store-backed
                  AMIs, which use the instance store as the root device.
         Amazon EC2
            Amazon Elastic Compute Cloud is a web service for launching and managing Linux/UNIX and Windows Server instances in Amazon data
               centers. 
            See also https://aws.amazon.com/ec2.
         Amazon EC2 Auto Scaling
            Amazon EC2 Auto Scaling is a web service that launches or terminates instances automatically based on user-defined policies, schedules, 
               and health checks.
            See also https://aws.amazon.com/ec2/autoscaling.
         EC2 instance
            A compute instance in the Amazon EC2 service. Other AWS services use the
               term EC2 instance to distinguish these instances from other
               types of instances they support.
         Amazon ECR
            Amazon Elastic Container Registry (Amazon ECR) is a fully managed Docker container registry that you can use to store, manage, and
               deploy Docker container images. Amazon ECR is integrated with Amazon ECS and IAM.
            See also https://aws.amazon.com/ecr.
         Amazon ECS
            Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container
               management service that you can use to run, stop, and manage Docker containers on a
               cluster of EC2 instances.
            See also https://aws.amazon.com/ecs.
         edge location
            
            edge location is a data center that an AWS service uses to perform service-specific operations.
               For example, CloudFront uses edge
               locations to cache copies of your content, so the content is closer to your users and
               can be delivered faster regardless of their location. Route 53 uses edge locations to speed up the response to
               public DNS queries.
         Amazon EFS
            Amazon Elastic File System is a file storage service for EC2
               instances. Amazon EFS provides an interface
               that you can use to create and configure file systems. Amazon EFS storage capacity grows
               and shrinks automatically as you add and remove files.
            See also https://aws.amazon.com/efs/.
         Amazon EKS
            Amazon Elastic Kubernetes Service is a managed service that you can use to run Kubernetes on AWS without needing to
               stand up or maintain your own Kubernetes control plane.
            See also https://aws.amazon.com/eks/.
         Elastic
            A company that provides open-source solutions—including OpenSearch, Logstash,
               Kibana, and Beats—that take data from any source and search, analyze, and visualize
               it in real time.
            Amazon OpenSearch Service (OpenSearch Service) is an AWS managed service for deploying, operating, and scaling
               OpenSearch in the AWS Cloud.
            See also OpenSearch Service.
            See also Elasticsearch.
         Elastic Beanstalk
            AWS Elastic Beanstalk is a web service for deploying and managing applications in the AWS Cloud without
               worrying about the infrastructure that runs those applications.
            See also https://aws.amazon.com/elasticbeanstalk.
         Elastic Block StoreSee Amazon EBS.Elastic Inference
            Amazon Elastic Inference is a resource that customers can use to attach low-cost GPU-powered acceleration to Amazon EC2 and SageMaker AI instances, or Amazon ECS tasks, to reduce the cost of running deep learning inference by up to 75%.
            See also https://aws.amazon.com/machine-learning/elastic-inference.
         Elastic IP address
            A fixed (static) IP address that you have allocated in Amazon EC2 or Amazon VPC and then attached to an instance. Elastic IP addresses are associated
               with your account, not a specific instance. They are elastic
               because you can easily allocate, attach, detach, and free them as your needs change.
               Unlike traditional static IP addresses, Elastic IP addresses allow you to mask
               instance or Availability Zone failures by rapidly remapping
               your public IP addresses to another instance.
         ELB
            Elastic Load Balancing is a web service that improves an application's availability by distributing incoming
               traffic between two or more EC2 instances.
            See also https://aws.amazon.com/elasticloadbalancing.
         elastic network interface
            An additional network interface that can be attached to an instance. Elastic network interfaces include
               a primary private IP address, one or more secondary private IP addresses, an Elastic
               IP Address (optional), a MAC address, membership in specified security groups, a description, and a
               source/destination check flag. You can create an elastic network interface, attach it
               to an instance, detach it from an instance, and attach it to another instance.
            
         Elastic Transcoder
            Amazon Elastic Transcoder is a cloud-based media transcoding service. Elastic Transcoder is a highly scalable tool for
               converting (or transcoding) media files from their source format
               into versions that play on devices such as smartphones, tablets, and PCs.
            See also https://aws.amazon.com/elastictranscoder/.
         ElastiCache
            Amazon ElastiCache is a web service that simplifies deploying, operating, and scaling an in-memory cache
               in the cloud. The service improves the performance of web applications by providing
               information retrieval from fast, managed, in-memory caches, instead of relying
               entirely on slower disk-based databases.
            See also https://aws.amazon.com/elasticache/.
         Elasticsearch
            An open-source, real-time distributed search and analytics engine used for
               full-text search, structured search, and analytics. OpenSearch was developed by the
               Elastic company.
            Amazon OpenSearch Service (OpenSearch Service) is an AWS managed service for deploying, operating, and scaling
               OpenSearch in the AWS Cloud.
            See also OpenSearch Service.
            See also Elastic.
         AWS Elemental MediaConnect
            AWS Elemental MediaConnect is a fully-managed live video distribution service that reliably and securely ingests video into the AWS Cloud and transports it to multiple destinations within the AWS network and the internet.
            See also https://aws.amazon.com/mediaconnect.
         AWS Elemental MediaConvert
            AWS Elemental MediaConvert is a file-based media conversion service that transforms content into formats for traditional broadcast and internet streaming.
            See also https://aws.amazon.com/mediaconvert.
         AWS Elemental MediaLive
            AWS Elemental MediaLive is a cloud-based live video encoding service that creates high-quality streams for delivery to broadcasts and internet-connected devices.
            See also https://aws.amazon.com/medialive.
         AWS Elemental MediaPackage
            AWS Elemental MediaPackage is a highly-scalable video origination and packaging service that delivers video securely and reliably.
            See also https://aws.amazon.com/mediapackage.
         AWS Elemental MediaStore
            AWS Elemental MediaStore is a storage service optimized for media that provides the performance, consistency,
               and low latency required to deliver live and on-demand video content at scale.
            See also https://aws.amazon.com/mediastore.
         AWS Elemental MediaTailor
            AWS Elemental MediaTailor is a channel assembly and personalized ad-insertion service for over-the-top (OTT) video and audio applications.
            See also https://aws.amazon.com/mediatailor.
         EMP
             The AWS End-of-Support Migration Program for Windows Server provides the technology and guidance to migrate your applications running on Windows Server 2003, Windows Server 2008, and Windows Server 2008 R2 to the latest, supported versions of Windows Server running on Amazon Web Services (AWS).
         Amazon EMR
            Amazon Elastic Map Reduce is a web service that you can use to process large amounts of data efficiently. Amazon EMR
               uses Hadoop processing combined with several
               AWS products to do such tasks as web indexing, data mining, log file analysis,
               machine learning, scientific simulation, and data warehousing. 
            See also https://aws.amazon.com/elasticmapreduce.
         encrypt
            To use a mathematical algorithm to make data unintelligible to unauthorized users. Encryption also gives authorized
               users a method (such as a key or password) to convert the altered data back to its
               original state.
         encryption context
            A set of key–value pairs that contains additional information associated
               with AWS KMS–encrypted
               information.
         AWS Encryption SDK
            AWS Encryption SDK is a client-side encryption library that you can use to encrypt and decrypt data
               using industry standards and best practices.
            See also https://aws.amazon.com/blogs/security/tag/aws-encryption-sdk/.
         endpoint
            A URL that identifies a host and port as the entry point for a web service. Every
               web service request contains an endpoint. Most AWS products provide endpoints for a
               Region to enable faster connectivity.
            ElastiCache: The DNS name of a cache node.
            Amazon RDS: The DNS name of a DB instance.
            CloudFormation: The DNS name or
               IP address of the server that receives an HTTP request.
         endpoint port
            ElastiCache: The port number used by
               a cache node.
            Amazon RDS: The port number used by a
                  DB instance.
         envelope encryption
            The use of a master key and a data key to algorithmically protect data. The master
               key is used to encrypt and decrypt the data key and the data key is used to encrypt
               and decrypt the data itself. 
         environment
            
            Elastic Beanstalk: A specific running instance
               of an application. The application has
               a CNAME and includes an application version and a customizable configuration (which
               is inherited from the default container type).
            CodeDeploy: Instances in a
               deployment group in a blue/green deployment. At the start of a blue/green deployment,
               the deployment group is made up of instances in the original environment. At the end
               of the deployment, the deployment group is made up of instances in the replacement
               environment.
         environment configuration
            
            A collection of parameters and settings that define how an environment and its
               associated resources behave.
         ephemeral storeSee instance store.epoch
            The date from which time is measured. For most Unix environments, the epoch is
               January 1, 1970.
         ETLSee extract, transform, and load (ETL).evaluation
            Amazon Machine Learning: The process of measuring the predictive performance of a machine
               learning (ML) model.
            Also a machine learning object that stores the details and result of an ML model
               evaluation.
         evaluation datasource
            The data that Amazon Machine Learning uses to evaluate the predictive accuracy of a machine
               learning model.
         event
            Amazon Personalize: A user activity—such as a click, a purchase, or a video viewing—that you record and upload to an Amazon Personalize Interactions dataset. You record events individually in real time or record and upload events in bulk.
            See also dataset.
            See also Interactions dataset.
         event tracker
            Amazon Personalize: Specifies a destination dataset group for event data that you record in real time. When you record events in real time, you provide the ID of the event tracker so that Amazon Personalize knows where to add the data.
            See also dataset group.
            See also event.
         EventBridge
            Amazon EventBridge is a serverless event bus service that you can use to connect your applications with
               data from a variety of sources and routes that data to targets such as AWS Lambda. You
               can set up routing rules to determine where to send your data to build application
               architectures that react in real time to all of your data sources.
            See also https://aws.amazon.com/eventbridge/.
         eventual consistency
            The method that AWS services use to achieve high availability. This involves
               replicating data across multiple servers in Amazon data centers. When data is written
               or updated and Success is returned, all copies of the data are updated.
               However, it takes time for the data to propagate to all storage locations. The data
               will eventually be consistent, but an immediate read might not show the change.
               Consistency is usually reached within seconds.
            See also data consistency.
            See also eventually consistent read.
            See also strongly consistent read.
         eventually consistent read
            A read process that returns data from only one Region and might not show the most
               recent write information. However, if you repeat your read request after a short
               time, the response should eventually return the latest data.
            See also data consistency.
            See also eventual consistency.
            See also strongly consistent read.
         eviction
            
            The deletion by CloudFront of
               an object from an edge location before its
               expiration time. If an object in an edge location isn't frequently requested, CloudFront
               might evict the object (remove the object before its expiration date) to make room
               for objects that are more popular. 
         exbibyte (EiB)
            A contraction of exa binary byte. An exbibyte (EiB) is 2^60 or
               1,152,921,504,606,846,976 bytes. An exabyte (EB) is 10^18 or
               1,000,000,000,000,000,000 bytes. 1,024 EiB is a zebibyte (ZiB).
         expiration
            
            For CloudFront caching, the
               time when CloudFront stops responding to user requests with an object. If you don't use
               headers or CloudFront distribution
               settings to specify how long you want objects to stay in an edge location, the objects expire after 24 hours.
               The next time a user requests an object that has expired, CloudFront forwards the request
               to the origin.
         explicit impressions
            Amazon Personalize: A list of items that you manually add to an Amazon Personalize Interactions dataset to influence future recommendations. Unlike implicit impressions, where Amazon Personalize automatically derives the impressions data, you choose what to include in explicit impressions.
            See also recommendations.
            See also Interactions dataset.
            See also impressions data.
            See also implicit impressions.
         explicit launch permission
            
            An Amazon Machine Image
            (AMI) launch
               permission granted to a specific AWS account.
         exponential backoff
            A strategy that incrementally increases the wait between retry attempts in order
               to reduce the load on the system and increase the likelihood that repeated requests
               will succeed. For example, client applications might wait up to 400 milliseconds
               before attempting the first retry, up to 1600 milliseconds before the second, and up to
               6400 milliseconds (6.4 seconds) before the third.
         expression
            
            CloudSearch: A numeric expression
               that you can use to control how search hits are sorted. You can construct Amazon CloudSearch
               expressions using numeric fields, other rank expressions, a document's default
               relevance score, and standard numeric operators and functions. When you use the
                  sort option to specify an expression in a search request, the
               expression is evaluated for each search hit and the hits are listed according to
               their expression values.
         extract, transform, and load (ETL)
            A process that's used to integrate data from multiple sources. Data is collected
               from sources (extract), converted to an appropriate format (transform), and written
               to a target data store (load) for purposes of analysis and querying.
            ETL tools combine these three functions to consolidate and move data from one
               environment to another. AWS Glue is a fully
               managed ETL service for discovering and organizing data, transforming it, and making
               it available for search and analytics.
         F
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      facet
            
            CloudSearch: An index field that
               represents a category that you want to use to refine and filter search
               results.
         facet enabled
            
            CloudSearch: An index field option
               that enables facet information to be calculated for the field.
         AWS Fargate
            AWS Fargate is a serverless, pay-as-you-go compute engine that you can use to
               build applications on AWS. You can use Amazon Elastic Container Service (Amazon ECS) or Amazon Elastic Kubernetes Service (Amazon EKS) to maintain
               container applications using AWS Fargate. 
            See also https://aws.amazon.com/fargate/.
         Fault Injection Simulator (AWS FIS)AWS Fault Injection Service is a managed service that you can use to perform fault injection experiments on your AWS workloads.
         See also https://aws.amazon.com/fis.
      FBLSee feedback loop (FBL).feature transformation
            Amazon Machine Learning: The machine learning process of constructing more predictive input
               representations or “features” from the raw input variables to optimize a machine
               learning model’s ability to learn and generalize. Also known as data
                  transformation or feature engineering.
         federated identity management
            (FIM)
            Allows individuals to sign in to different networks or services, using the same
               group or personal credentials to access data across all networks. With identity
               federation in AWS, external identities (federated users) are granted secure access
               to resources in an AWS account without having to create IAM users. These external identities can come
               from a corporate identity store (such as LDAP or Windows Active Directory) or from a
               third party (such as Login with Amazon, Facebook, or Google). AWS federation also
               supports SAML 2.0.
         federated userSee federated identity management
            (FIM).federationSee federated identity management
            (FIM).feedback loop (FBL)
            
            The mechanism by which a mailbox provider (for example, an internet service provider
               (ISP))
               forwards a recipient's complaint back to the sender.
         field weight
            The relative importance of a text field in a search index. Field weights control
               how much matches in particular text fields affect a document's relevance
               score.
         filter
            A criterion that you specify to limit the results when you list or describe your
                  Amazon EC2
               resources.
         filter query
            
            A way to filter search results without affecting how the results are scored and
               sorted. Specified with the CloudSearch
               fq parameter. 
         FIMSee federated identity management
            (FIM).FinSpace
            Amazon FinSpace is a data management and analytics service purpose-built for the financial services industry (FSI).
            See also https://aws.amazon.com/finspace.
         FirehoseSee Firehose.Firewall Manager
            AWS Firewall Manager is a service that you use with AWS WAF to simplify your AWS WAF administration
               and maintenance tasks across multiple accounts and resources. With AWS Firewall Manager, you set
               up your firewall rules only once. The service automatically applies your rules across
               your accounts and resources, even as you add new resources.
            See also https://aws.amazon.com/firewall-manager.
         Forecast
            Amazon Forecast is a fully managed service that uses statistical and machine learning algorithms to produce highly accurate time-series forecasts.
            See also https://aws.amazon.com/forecast/.
         format versionSee template format version.forumsSee discussion forums.functionSee intrinsic function.fuzzy search
            
            A simple search query that uses approximate string matching (fuzzy matching) to
               correct for typographical errors and misspellings.
         G
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      GameKit
            AWS GameKit is an open-source SDK and game engine plugin that empowers game
               developers to build and deploy cloud-based features with AWS from their game
               engine.
            See also https://aws.amazon.com/gamekit/.
         Amazon GameLift Servers
            Amazon GameLift Servers is a managed service for deploying, operating, and scaling session-based multiplayer
               games.
            See also https://aws.amazon.com/gamelift/.
         GameSparks
            Amazon GameSparks is a fully managed AWS service that provides a multi-service backend
               for game developers.
            See also https://aws.amazon.com/gamesparks/.
         geospatial search
            
            A search query that uses locations specified as a latitude and longitude to
               determine matches and sort the results. 
         gibibyte (GiB)
            A contraction of giga binary byte, a gibibyte is 2^30 or 1,073,741,824 bytes. A
               gigabyte (GB) is 10^9 or 1,000,000,000 bytes. 1,024 GiB is a tebibyte (TiB).
         GitHub
            A web-based repository that uses Git for version control.
         Global Accelerator
            AWS Global Accelerator is a network layer service that you use to create accelerators that direct traffic to
               optimal endpoints over the AWS global network. This improves the availability and
               performance of your internet applications that are used by a global audience.
            See also https://aws.amazon.com/global-accelerator.
         global consistency
            An active-active strategy in which all reads and writes for a workload are handled in the Region where the request originates and are replicated synchronously to all other Regions in the architecture. 
            See also read local/write global, read local/write local.
            
         global secondary index
            An index with a partition key and a sort key that can be different from those on
               the table. A global secondary index is considered global because queries on the index
               can span all of the data in a table, across all partitions.
            See also local secondary index.
         AWS Glue
            AWS Glue is a fully managed extract, transform, and load (ETL) service that you can use to catalog data and load
               it for analytics. With AWS Glue, you can discover your data, develop scripts to
               transform sources into targets, and schedule and run ETL jobs in a serverless
               environment.
            See also https://aws.amazon.com/glue.
         AWS GovCloud (US)
            AWS GovCloud (US) is an isolated AWS Region that hosts sensitive workloads in the cloud, ensuring
               that this work meets the US government's regulatory and compliance requirements. The
               AWS GovCloud (US) Region adheres to United States International Traffic in Arms
               Regulations (ITAR), Federal Risk and Authorization Management Program (FedRAMP)
               requirements, Department of Defense (DOD) Cloud Security Requirements Guide (SRG)
               Levels 2 and 4, and Criminal Justice Information Services (CJIS) Security Policy
               requirements.
            See also https://aws.amazon.com/govcloud-us/.
         grant
            AWS KMS: A mechanism for giving AWS
                  principals long-term permissions to
               use KMS keys. 
         grant token
            A type of identifier that allows the permissions in a grant to take effect
               immediately.
         ground truth
            The observations used in the machine learning (ML) model training process that
               include the correct value for the target attribute. To train an ML model to predict
               house sales prices, the input observations would typically include prices of previous
               house sales in the area. The sale prices of these houses constitute the ground
               truth.
         group
            A collection of IAM
               users. You can use IAM groups to
               simplify specifying and managing permissions for multiple users.
         GuardDuty
            Amazon GuardDuty is a continuous security monitoring service. Amazon GuardDuty can help to identify
               unexpected and potentially unauthorized or malicious activity in your AWS
               environment.
            See also https://aws.amazon.com/guardduty/.
         H
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Hadoop
            Software that enables distributed processing for big data by using clusters and
               simple programming models. For more information, see http://hadoop.apache.org.
            
         hard bounce
            
            A persistent email delivery failure such as "mailbox does not exist."
         hardware VPN
            A hardware-based IPsec VPN connection over the internet.
         AWS Health
            AWS Health is a service that provides ongoing visibility into AWS customers' accounts and the availability of their AWS services and resources.
            See also https://aws.amazon.com/premiumsupport/technology/aws-health-dashboard.
         health check
            
            A system call to check on the health status of each instance in an Amazon EC2 Auto Scaling group.
         HealthLake
            AWS HealthLake is a HIPAA-eligible service that helps customers store, query, and generate artificial intelligence (AI) and machine learning (ML) insights from healthcare data and enables healthcare data interoperability.
            See also https://aws.amazon.com/healthlake.
         highlight enabled
            
            CloudSearch: An index field option
               that enables matches within the field to be highlighted.
         highlights
            
            CloudSearch: Excerpts returned with
               search results that show where the search terms appear within the text of the
               matching documents.
         high-quality email
            
            Email that recipients find valuable and want to receive. Value means different
               things to different recipients and can come in such forms as offers, order
               confirmations, receipts, or newsletters.
         hit
            
            A document that matches the criteria specified in a search request. Also referred
               to as a search result.
         HMAC
            Hash-based Message Authentication Code is a specific construction for calculating a
               message authentication code (MAC) involving a cryptographic hash function in
               combination with a secret key. You can use it to verify both the data integrity and
               the authenticity of a message at the same time. AWS calculates the HMAC using a
               standard, cryptographic hash algorithm, such as SHA-256. 
         hosted zone
            
            A collection of resource record
               sets that Route 53 hosts. Similar to a
               traditional DNS zone file, a hosted zone represents a collection of records that are
               managed together under a single domain name.
         hot standby
            An active-passive disaster recovery strategy in which a workload is fully scaled up in both the primary and standby Regions, but serves traffic from only the primary Region. 
            See also back up and restore, pilot light, warm standby.
            
         HRNN
            Amazon Personalize: A hierarchical recurrent neural network machine learning algorithm that models changes in user behavior and predicts the items that a user might interact with in personal recommendation applications.
         HTTP-QuerySee Query.HVM virtualization
            Hardware Virtual Machine virtualization. Allows the guest VM to run as though it's
               on a native hardware platform, except that it still uses paravirtual (PV) network and
               storage drivers for improved performance.
            See also PV virtualization.
         I
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      IAM
            AWS Identity and Access Management is a web service that Amazon Web Services
            (AWS) customers can use to manage users and user
               permissions within AWS.
            See also https://aws.amazon.com/iam.
         IAM Access Analyzer
            Access Management Access Analyzer is a feature of IAM that you can use to
               identify the resources in your organization and accounts that are shared with an
               external entity. Example resources include Amazon S3 buckets or IAM roles.
            See also https://aws.amazon.com/about-aws/whats-new/2019/12/introducing-aws-identity-and-access-management-access-analyzer/.
         IAM groupSee group.IAM Identity Center
            AWS IAM Identity Center is a cloud-based service that brings together administration of users and their access to AWS accounts and
               cloud applications. You can control single sign-on access and user permissions across all
               your AWS accounts in AWS Organizations.
            See also https://aws.amazon.com/single-sign-on/.
         IAM policy simulatorSee policy simulator.IAM roleSee role.IAM userSee user.Identity and Access ManagementSee IAM.identity provider (IdP) 
            An IAM entity that holds metadata
               about external identity providers.
         IdPSee identity provider (IdP) .imageSee Amazon Machine Image
            (AMI).Image Builder
            EC2 Image Builder is a service that facilitates building, maintaining, and distributing customized server images that launch EC2 instances, or that run in Docker containers.
            See also https://aws.amazon.com/image-builder.
         implicit impressions
            Amazon Personalize: The recommendations that your application shows a user. Unlike explicit impressions, where you manually record each impression, Amazon Personalize automatically derives implicit impressions from your recommendation data.
            See also recommendations.
            See also impressions data.
            See also explicit impressions.
         import log
            
            A report that contains details about how Import/Export processed your data.
         Import/Export
            AWS Import/Export is a service for transferring large amounts of data between AWS and portable storage
               devices. 
            See also https://aws.amazon.com/importexport.
         import/export station
            
            A machine that uploads or downloads your data to or from Amazon S3.
         impressions data
            Amazon Personalize: The list of
               items that you presented to a user when they interacted with a particular item such as by
               clicking it, watching it, or purchasing it. Amazon Personalize uses impressions data to calculate
               the relevance of new items for a user based on how frequently users have selected or
               ignored the same item.
            See also explicit impressions.
            See also implicit impressions.
         indexSee search index.index field
            
            A name–value pair that's included in an CloudSearch domain's index. An index field can contain text or numeric
               data, dates, or a location. 
         indexing options
            
            Configuration settings that define an CloudSearch domain's index fields, how document data is mapped to
               those index fields, and how the index fields can be used. 
         inline policy
            An IAM
               policy that's embedded in a single IAM
               user, group, or role.
         in-place deployment
            CodeDeploy: A deployment method where the application on each instance in the
               deployment group is stopped, the latest application revision is installed, and the
               new version of the application is started and validated. You can choose to use a load
               balancer so each instance is deregistered during its deployment and then restored to
               service after the deployment is complete.
         input data
            Amazon Machine Learning: The observations that you provide to Amazon Machine Learning to train and evaluate a
               machine learning model and generate predictions.
         Amazon Inspector
            Amazon Inspector is an automated security assessment service that helps improve the security and
               compliance of applications deployed on AWS. Amazon Inspector automatically assesses
               applications for vulnerabilities or deviations from best practices. After performing
               an assessment, Amazon Inspector produces a detailed report with prioritized steps for
               remediation.
            See also https://aws.amazon.com/inspector.
         instance
            A copy of an Amazon Machine Image
            (AMI) running as a virtual server in the AWS Cloud.
         instance family
            
            A general instance type grouping
               using either storage or CPU capacity. 
         instance group
            
            A Hadoop cluster contains one master
               instance group that contains one master node, a core instance group that contains one or more core node and an optional task node instance group, which can contain
               any number of task nodes. 
         instance profile
            A container that passes IAM
               role information to an EC2 instance at launch.
         instance store
            
            Disk storage that's physically attached to the host computer for an EC2 instance, and therefore has the same
               lifespan as the instance. When the instance is terminated, you lose any data in the
               instance store. 
         instance store-backed AMI
            A type of Amazon Machine Image
            (AMI)
               whose instances use an instance store
               volume as the root device. Compare this with
               instances launched from Amazon EBS-backed AMIs, which use
               an Amazon EBS volume as the root device.
         instance type
            
            A specification that defines the memory, CPU, storage capacity, and usage cost for
               an instance. Some instance types are for
               standard applications, whereas others are for CPU-intensive, memory-intensive
               applications. 
         Interactions dataset
            Amazon Personalize: A container for historical and real-time data collected from interactions between users and items (called events). Interactions data can include impressions data and contextual metadata.
            See also dataset.
            See also event.
            See also impressions data.
            See also contextual metadata.
         internet gateway
            Connects a network to the internet. You can route traffic for IP addresses outside
               your Amazon VPC to the internet gateway. 
         internet service provider
               (ISP)
            A company that provides subscribers with access to the internet. Many ISPs are
               also mailbox providers. Mailbox
               providers are sometimes referred to as ISPs, even if they only provide mailbox
               services.
         intrinsic function
            
            A special action in a CloudFormation template that assigns values to properties not
               available until runtime. These functions follow the format
                  Fn::Attribute, such as Fn::GetAtt. Arguments for
               intrinsic functions can be parameters, pseudo parameters, or the output of other
               intrinsic functions.
         AWS IoT 1-Click
            AWS IoT 1-Click is a service that simple devices can use to launch AWS Lambda functions.
            See also https://aws.amazon.com/iot-1-click.
         AWS IoT Analytics
            AWS IoT Analytics is a fully managed service used to run sophisticated analytics on massive volumes of
               IoT data.
            See also https://aws.amazon.com/iot-analytics.
         AWS IoT Core
            AWS IoT Core is a managed cloud platform that lets connected devices easily and securely interact
               with cloud applications and other devices.
            See also https://aws.amazon.com/iot.
         AWS IoT Device Defender
            AWS IoT Device Defender is an AWS IoT security service that you can use to audit the configuration of your
               devices, monitor your connected devices to detect abnormal behavior, and to mitigate
               security risks.
            See also https://aws.amazon.com/iot-device-defender.
         AWS IoT Device Management
            AWS IoT Device Management is a service used to securely onboard, organize, monitor, and remotely manage IoT
               devices at scale.
            See also https://aws.amazon.com/iot-device-management.
         AWS IoT Events
            AWS IoT Events is a fully managed AWS IoT service that you can use to detect and respond to events
               from IoT sensors and applications.
            See also https://aws.amazon.com/iot-events.
         AWS IoT FleetWise
            AWS IoT FleetWise is a service that you can use to collect, transform, and transfer vehicle data to the cloud at scale.
            See also https://aws.amazon.com/iot-fleetwise.
         AWS IoT Greengrass
            AWS IoT Greengrass is a software that you can use to run local compute, messaging, data caching, sync, and
               ML inference capabilities for connected devices in a secure way.
            See also https://aws.amazon.com/greengrass.
         AWS IoT RoboRunner
            AWS IoT RoboRunner is a solution that provides infrastructure for integrating robots with work management systems and building robotics fleet management applications.
            See also https://aws.amazon.com/roborunner.
         AWS IoT SiteWise
            AWS IoT SiteWise is a managed service that you can use to collect, organize, and analyze data from
               industrial equipment at scale.
            See also https://aws.amazon.com/iot-sitewise.
         AWS IoT Things Graph
            AWS IoT Things Graph is a service that you can use to visually connect different devices and web services
               to build IoT applications.
            See also https://aws.amazon.com/iot-things-graph.
         IP address
            
            A numerical address (for example, 192.0.2.44) that networked devices use to
               communicate with one another using the Internet Protocol (IP). Each EC2 instance is assigned two IP addresses
               at launch, which are directly mapped to each other through network address
               translation (NAT): a private IP address
               (following RFC 1918) and a public IP address. Instances launched in a VPC are assigned only a private IP address. Instances launched in your
               default VPC are assigned both a private IP address and a public IP address.
         IP match condition
            AWS WAF: An attribute that specifies the
               IP addresses or IP address ranges that web requests originate from. Based on the
               specified IP addresses, you can configure AWS WAF to allow or block web requests to AWS
                  resources such as Amazon CloudFront distributions.
         AWS IQ
            AWS IQ is a cloud service that AWS customers can use to find, engage, and pay AWS Certified third-party experts for on-demand project work.
            See also https://iq.aws.amazon.com.
         ISPSee internet service provider
               (ISP).issuer
            The person who writes a policy to grant
               permissions to a resource. The issuer (by
               definition) is always the resource owner. AWS doesn't permit Amazon SQS users to create policies for resources they don't own. If John is
               the resource owner, AWS authenticates John's identity when he submits the policy
               he's written to grant permissions for that resource.
         item
            A group of attributes that's uniquely identifiable among all of the other items.
               Items in DynamoDB are similar in many ways
               to rows, records, or tuples in other database systems.
         item exploration
            Amazon Personalize: The process
               that Amazon Personalize uses to test different item recommendations, including recommendations of
               new items with no or little interaction data, and learn how users respond. You
               configure item exploration at the campaign level for solution versions created with
               the user-personalization recipe.
            See also recommendations.
            See also campaign.
            See also solution version.
            See also user-personalization recipe.
         Items dataset
            Amazon Personalize: A container
               for metadata about items, such as price, genre, or availability.
            See also dataset.
         item-to-item similarities (SIMS) recipe
            Amazon Personalize: A RELATED_ITEMS recipe that uses the data from an Interactions dataset to make recommendations for items that are similar to a specified item. The SIMS recipe calculates similarity based on the way users interact with items instead of matching item metadata, such as price or age.
            See also recipe.
            See also RELATED_ITEMS recipes.
            See also Interactions dataset.
         J
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      job flow
            
            Amazon EMR: One or more steps that
               specify all of the functions to be performed on the data.
         job ID
            
            A five-character, alphanumeric string that uniquely identifies an Import/Export storage device in your
               shipment. AWS issues the job ID in response to a CREATE JOB email
               command. 
         job prefix
            
            An optional string that you can add to the beginning of an Import/Export log file name to
               prevent collisions with objects of the same name.
            See also key prefix.
         JSON
            JavaScript Object Notation. A lightweight data interchange format. For information
               about JSON, see http://www.json.org/.
         junk folder
            
            The location where email messages that various filters determine to be of lesser
               value are collected so that they don't arrive in the recipient's inbox but are still accessible to the recipient. This is
               also referred to as a spam or bulk
               folder.
         K
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Amazon Kendra
            Amazon Kendra is a search service powered by machine learning (ML) that developers can use to add search capabilities to their applications so their end users can discover information stored within the vast amount of content spread across their company.
            See also https://aws.amazon.com/kendra/.
         key
            A credential that identifies an AWS account or user to AWS
               (such as the AWS secret access key).
         
            Amazon S3, Amazon EMR: The
               unique identifier for an object in a bucket.
               Every object in a bucket has exactly one key. Because a bucket and key together
               uniquely identify each object, you can think of Amazon S3 as a basic data map between the
                  bucket + key, and the object itself. You can uniquely address
               every object in Amazon S3 through the combination of the web service endpoint, bucket
               name, and key, as in this example:
                  http://doc.s3.amazonaws.com/2006-03-01/AmazonS3.wsdl, where
                  doc is the name of the bucket, and
                  2006-03-01/AmazonS3.wsdl is the key.
         
            Import/Export: The name of an
               object in Amazon S3. It's a sequence of Unicode characters whose UTF-8 encoding can't
               exceed 1024 bytes. If a key (for example, logPrefix + import-log-JOBID) is longer
               than 1024 bytes, Elastic Beanstalk returns an
                  InvalidManifestField error. 
         
            IAM: In a policy, a specific characteristic that's the
               basis for restricting access (such as the current time or the IP address of the
               requester).
         
            Tagging resources: A general tag label that
               acts like a category for more specific tag values. For example, you might have EC2 instance with the tag key of
                  Owner and the tag value of Jan. You can
               tag an AWS resource with up to 10
               key–value pairs. Not all AWS resources can be tagged.
         key pair
            A set of security credentials that you use to prove your identity electronically.
               A key pair consists of a private key and a public key.
         key prefix
            
            A string of characters that is a subset of an object key name, starting with 
               the first character. The prefix can be any length, up to the maximum length of 
               the object key name (1,024 bytes).
         Amazon Keyspaces
            Amazon Keyspaces (for Apache Cassandra) is a scalable, highly available, and managed Apache Cassandra-compatible database service.
            See also https://aws.amazon.com/keyspaces/.
         kibibyte (KiB)
            A contraction of kilo binary byte, a kibibyte is 2^10 or 1,024 bytes. A kilobyte
               (KB) is 10^3 or 1,000 bytes. 1,024 KiB is a mebibyte (MiB).
         Kinesis
            Amazon Kinesis is a platform for streaming data on AWS. Kinesis offers services that simplify the
               loading and analysis of streaming data. 
            See also https://aws.amazon.com/kinesis/.
         Firehose
            Amazon Data Firehose is a fully managed service for loading streaming data into AWS. Firehose can capture and
               automatically load streaming data into Amazon S3 and Amazon Redshift , enabling
               near real-time analytics with existing business intelligence tools and dashboards.
               Firehose automatically scales to match the throughput of your data and requires no
               ongoing administration. It can also batch, compress, and encrypt the data before
               loading it. 
            See also https://aws.amazon.com/kinesis/firehose/.
         Kinesis Data Streams
            Amazon Kinesis Data Streams is a web service for building custom applications that process or analyze streaming
               data for specialized needs. Amazon Kinesis Data Streams can continuously capture and store terabytes of
               data per hour from hundreds of thousands of sources. 
            See also https://aws.amazon.com/kinesis/streams/.
         AWS KMS
            AWS Key Management Service is a managed service that simplifies the creation and control of encryption keys that are used to encrypt data.
            See also https://aws.amazon.com/kms.
         KMS key
            The primary resource in AWS Key Management Service. In general, 
               KMS keys are created, used, and deleted entirely within KMS. KMS supports symmetric and asymmetric KMS keys for encryption and signing. KMS keys can be either customer managed, AWS managed, or AWS owned. For more information, see AWS KMS keys in the AWS Key Management Service Developer Guide.
         L
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      labeled data
            In machine learning, data for which you already know the target or “correct”
               answer.
         Lake Formation
            AWS Lake Formation is a managed service that makes it easy to set up, secure, and manage your data lakes. Lake Formation helps you discover your data sources and then catalog, cleanse, and transform the data.
            See also https://aws.amazon.com/lake-formation.
         Lambda
            AWS Lambda is a web service that you can use to run code without provisioning or managing
               servers. You can run code for virtually any type of application or backend service
               with zero administration. You can set up your code to automatically start from other
               AWS services or call it directly from any web or mobile app.
            See also https://aws.amazon.com/lambda/.
         launch configuration
            
            A set of descriptive parameters used to create new EC2 instances in an Amazon EC2 Auto Scaling activity. 
            A template that an Auto Scaling group uses to launch new EC2 instances. The launch
               configuration contains information such as the Amazon Machine Image
            (AMI) ID, the instance
               type, key pairs, security groups, and
               block device mappings, among other configuration settings.
         launch permission
            
            An Amazon Machine Image
            (AMI)
               attribute that allows users to launch an AMI. 
         Launch Wizard
            AWS Launch Wizard is a cloud solution that offers a guided way of sizing, configuring, and deploying AWS resources for third-party applications, such as Microsoft SQL Server Always On and HANA based SAP systems, without the need to manually identify and provision individual AWS resources.
            See also https://aws.amazon.com/launchwizard.
         Amazon Lex
            Amazon Lex is a fully managed artificial intelligence (AI) service with advanced natural language models to design, build, test, and deploy conversational interfaces in applications.
            See also https://aws.amazon.com/lex/.
         lifecycle
            
            The lifecycle state of the EC2 instance contained in an Auto Scaling group. EC2 instances progress through several states over their lifespan; these include
                  Pending, InService,
                  Terminating and Terminated. 
         lifecycle action
            An action that can be paused by Auto Scaling, such as launching or terminating an EC2
               instance.
         lifecycle hook
            A feature for pausing Auto Scaling after it launches or terminates an EC2 instance so that
               you can perform a custom action while the instance isn't in service.
         Lightsail
            Amazon Lightsail is a service used to launch and manage a virtual private server with AWS.
               Lightsail offers bundled plans that include everything you need to deploy a virtual
               private server, for a low monthly rate.
            See also https://aws.amazon.com/lightsail/.
         load balancer
            
            A DNS name combined with a set of ports, which together provide a destination for
               all requests intended for your application. A load balancer can distribute traffic to
               multiple application instances across every Availability Zone
               within a Region. Load balancers can span
               multiple Availability Zones within an AWS Region into which an Amazon EC2 instance was launched. But load
               balancers can't span multiple Regions. 
         local secondary index
            An index that has the same partition key as the table, but a different sort key. A
               local secondary index is local in the sense that every partition of a local secondary
               index is scoped to a table partition that has the same partition key value.
            See also local secondary index.
         Amazon Location
            Amazon Location Service is a fully managed service that makes it easy for a developer to add location functionality, such as maps, points of interest, geocoding, routing, tracking, and geofencing, to their applications, without sacrificing data security, user privacy, data quality, or cost.
            See also https://aws.amazon.com/location/.
         logical name
            A case-sensitive unique string within an CloudFormation template that identifies a resource, mapping, parameter, or output. In an AWS CloudFormation template, each parameter,
                  resource, property, mapping, and output
               must be declared with a unique logical name. You use the logical name when
               dereferencing these items using the Ref function.
         Lookout for Equipment
            Amazon Lookout for Equipment is a machine learning service that uses data from sensors mounted on factory
               equipment to detect abnormal behavior so you can take action before machine failures
               occur.
            See also https://aws.amazon.com/lookout-for-equipment/.
         Lookout for Metrics
            Amazon Lookout for Metrics is a machine learning (ML) service that automatically detects and diagnoses anomalies in business and operational data, such as a sudden dip in sales revenue or customer acquisition rates.
            See also https://aws.amazon.com/lookout-for-metrics.
         Lookout for Vision
            Amazon Lookout for Vision is a machine learning service that uses computer vision (CV) to find defects in industrial products. Amazon Lookout for Vision can identify missing components in an industrial product, damage to vehicles or structures, irregularities in production lines, and even minuscule defects in silicon wafers—or any other physical item where quality is important.
            See also https://aws.amazon.com/lookout-for-vision/.
         LumberyardSee O3DE.M
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Macie
            Amazon Macie is a security service that uses machine learning to automatically discover, classify,
               and protect sensitive data in AWS.
            See also http://aws.amazon.com/macie/.
         Mail Transfer Agent (MTA)
            
            Software that transports email messages from one computer to another by using a
               client-server architecture.
         mailbox provider
            
            An organization that provides email mailbox hosting services. Mailbox providers
               are sometimes referred to as internet service providers (ISPs), even if they only provide mailbox
               services.
         mailbox simulator
            
            A set of email addresses that you can use to test an Amazon SES-based email-sending application without sending
               messages to actual recipients. Each email address represents a specific scenario
               (such as a bounce or complaint) and generates a typical response that's specific to
               the scenario.
         main route table
            The default route table that any new
                  Amazon VPC
               subnet uses for routing. You can associate a
               subnet with a different route table of your choice. You can also change which route
               table is the main route table.
         AWS Mainframe Modernization
            AWS Mainframe Modernization service is a cloud native platform for migration, modernization, execution, and operation of mainframe applications.
            See also https://aws.amazon.com/mainframe-modernization.
         Managed Blockchain
            Amazon Managed Blockchain is a fully managed service for creating and managing scalable blockchain networks
               using popular open source frameworks.
            See also http://aws.amazon.com/managed-blockchain/.
         Amazon Managed Grafana
            Amazon Managed Grafana is a fully managed and secure data visualization service that you can use to instantly query, correlate, and visualize operational metrics, logs, and traces from multiple data sources.
            See also https://aws.amazon.com/grafana/.
         AWS managed key
            One type of KMS key in AWS KMS.
         managed policy
            A standalone IAM
               policy that you can attach to multiple users, groups, and roless in your IAM
                  account. Managed policies can either be
               AWS managed policies (which are created and managed by AWS) or customer managed
               policies (which you create and manage in your AWS account).
         AWS managed policy
            An IAM
               managed policy that's created and
               managed by AWS.
         Amazon Managed Service for Prometheus
            Amazon Managed Service for Prometheus is a service that provides highly available, secure, and managed monitoring for your
               containers.
            See also https://aws.amazon.com/prometheus/.
         AWS Management Console
            AWS Management Console is a graphical interface to manage compute, storage, and other cloud resources.
            See also https://aws.amazon.com/console.
         management portal
            AWS Management Portal for vCenter is a web service for managing your AWS resources using VMware vCenter. You install the portal as a vCenter
               plugin within your existing vCenter environment. After it's installed, you can migrate
               VMware VMs to Amazon EC2 and manage AWS
               resources from within vCenter.
            See also https://aws.amazon.com/ec2/vcenter-portal/.
         manifest
            
            When sending a create job request for an import or export
               operation, you describe your job in a text file called a manifest. The manifest file
               is a YAML-formatted file that specifies how to transfer data between your storage
               device and the AWS Cloud.
         manifest file
            Amazon Machine Learning: The file used for describing batch predictions. The manifest file
               relates each input data file with its associated batch prediction results. It's
               stored in the Amazon S3 output location.
         mapping
            
            A way to add conditional parameter values to an CloudFormation template. You specify
               mappings in the template's optional Mappings section and retrieve the desired value
               using the FN::FindInMap function.
         markerSee pagination token.AWS Marketplace
            AWS Marketplace is a web portal where qualified partners market and sell their software to AWS
               customers. AWS Marketplace is an online software store that helps customers find,
               buy, and immediately start using the software and services that run on AWS.
            See also https://aws.amazon.com/partners/aws-marketplace/.
         master node
            
            A process running on an Amazon Machine Image
            (AMI) that keeps track of the work its core and task
               nodes complete. 
         maximum price
            
             The maximum price you pay to launch one or more Spot Instances. If your maximum price
               exceeds the current Spot price and your
               restrictions are met, Amazon EC2 launches
               instances on your behalf. 
         maximum send rate
            
            The maximum number of email messages that you can send per second using Amazon SES.
         mean reciprocal rank at 25
            Amazon Personalize: An evaluation metric that assesses the relevance of a model’s highest ranked recommendation. Amazon Personalize calculates this metric using the average accuracy of the model when ranking the most relevant recommendation out of the top 25 recommendations over all requests for recommendations.
            See also metrics.
            See also recommendations.
         mebibyte (MiB)
            A contraction of mega binary byte. A mebibyte (MiB) is 2^20 or 1,048,576 bytes. A
               megabyte (MB) is 10^6 or 1,000,000 bytes. 1,024 MiB is a gibibyte (GiB).
         member resourcesSee resource.MemoryDB
            Amazon MemoryDB is a Redis-compatible, durable, in-memory database service that's purpose-built for modern applications with microservices architectures.
            See also https://aws.amazon.com/memorydb.
         message ID
            Amazon SES: A unique identifier that's assigned to
               every email message that's sent.
            Amazon SQS: The identifier returned when you send a message to a queue.
         metadata
            Information about other data or objects. In Amazon S3
               and Amazon EMR
               metadata takes the form of name–value pairs that describe the object. These
               include default metadata such as the date last modified and standard HTTP metadata
               (for example, Content-Type). Users can also specify custom metadata at the time they
               store an object. In Amazon EC2 metadata includes data
               about an EC2 instance that the instance
               can retrieve to determine things about itself, such as the instance type or the IP
               address.
         metric
            
            An element of time-series data defined by a unique combination of exactly one
                  namespace, exactly one metric name,
               and between zero and ten dimensions. Metrics and the statistics derived from them are
               the basis of CloudWatch.
         metric name
            
            The primary identifier of a metric, used with a namespace and optional dimensions.
         metrics
            Amazon Personalize: Evaluation data that Amazon Personalize generates when you train a model. You use metrics to evaluate the performance of the model, view the effects of modifying a solution’s configuration, and compare results between solutions that use the same training data but were created with different recipes.
               See also solution.
               See also recipe.
         MFASee multi-factor authentication
               (MFA).micro instance
            
             A type of EC2 instance that's more
               economical to use if you have occasional bursts of high CPU activity.
         AWS Microservice Extractor for .NET
            AWS Microservice Extractor for .NET is an assistive modernization tool that helps to reduce the time and effort required to break down large, monolithic applications running on the AWS Cloud or on premises into smaller, independent services. These services can be operated and managed independently.
         Migration Hub
            AWS Migration Hub is a service that provides a single location to track migration tasks across multiple
               AWS tools and partner solutions.
            See also https://aws.amazon.com/migration-hub/.
         MIMESee Multipurpose Internet Mail
            Extensions (MIME).Amazon ML
            Amazon Machine Learning is a cloud-based service that creates machine learning (ML) models by finding
               patterns in your data, and uses these models to process new data and generate
               predictions.
            See also http://aws.amazon.com/machine-learning/.
         ML model
            In machine learning (ML), a mathematical model that generates predictions by
               finding patterns in data. Amazon Machine Learning supports three types of ML models: binary
               classification, multiclass classification, and regression. Also known as a
               predictive model.
            See also binary classification model.
            See also multiclass classification
            model.
            See also regression model.
         Mobile Analytics
            Amazon Mobile Analytics is a service for collecting, visualizing, understanding, and extracting mobile app
               usage data at scale.
            See also https://aws.amazon.com/mobileanalytics.
         Mobile HubSee Amplify.AWS Mobile SDKSee Amplify.Mobile SDK for AndroidSee Amplify Android.Mobile SDK for iOSSee Amplify iOS.Mobile SDK for Unity
            The AWS Mobile SDK for Unity is included in the AWS SDK for .NET.
         Mobile SDK for Xamarin
            The AWS Mobile SDK for Xamarin is included in the AWS SDK for .NET.
         Amazon Monitron
            Amazon Monitron is an end-to-end system that uses machine learning (ML) to detect abnormal behavior in industrial machinery. Use Amazon Monitron to implement predictive maintenance and reduce unplanned downtime.
            See also https://aws.amazon.com/monitron/.
         Amazon MQ
            Amazon MQ is a managed message broker service for Apache ActiveMQ that you can use to set up
               and operate message brokers in the cloud.
            See also https://aws.amazon.com/amazon-mq/.
         MTASee Mail Transfer Agent (MTA).Multi-AZ deployment
            
            A primary DB instance that has a
               synchronous standby replica in a different Availability Zone.
               The primary DB instance is synchronously replicated across Availability Zones to the
               standby replica.
         multiclass classification
            model
            A machine learning model that predicts values that belong to a limited,
               pre-defined set of permissible values. For example, "Is this product a book, movie,
               or clothing?"
         multi-factor authentication
               (MFA)
            An optional AWS account security feature. After
               you enable AWS MFA, you must provide a six-digit, single-use code in addition to
               your sign-in credentials whenever you access secure AWS webpages or the AWS Management Console. You get
               this single-use code from an authentication device that you keep in your physical possession.
            See also https://aws.amazon.com/mfa/.
         multipart upload
            
            A feature that you can use to upload a single object as a set of parts.
         Multipurpose Internet Mail
            Extensions (MIME)
            
            An internet standard that extends the email protocol to include non-ASCII text and
               nontext elements, such as attachments.
         Multitool
            
            A cascading application that provides a simple command-line interface for managing
               large datasets. 
         multi-valued attribute
            An attribute with more than one value.
         Amazon MWAA
            Amazon Managed Workflows for Apache Airflow is a managed orchestration service for Apache Airflow to assist in setting up and operating end-to-end data pipelines in the cloud at scale.
            See also https://aws.amazon.com/managed-workflows-for-apache-airflow.
         N
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      namespace
            An abstract container that provides context for the items (names, or technical
               terms, or words) it holds, and allows disambiguation of homonym items residing in
               different namespaces.
         NAT
            Network address translation. A strategy of mapping one or more IP addresses to
               another while data packets are in transit across a traffic routing device. This is
               commonly used to restrict internet communication to private instances while allowing
               outgoing traffic. 
            See also Network Address Translation and Protocol
            Translation.
            See also NAT gateway.
            See also NAT instance.
         NAT gateway
            A NAT device, managed by AWS, that performs
               network address translation in a private subnet, to secure inbound internet traffic. A NAT gateway uses both
               NAT and port address translation.
            See also NAT instance.
         NAT instance
            A NAT device, configured by a user, that
               performs network address translation in a Amazon VPC
               public subnet to secure inbound internet
               traffic. 
            See also NAT gateway.
         Neptune
            Amazon Neptune is a managed graph database service that you can use to build and run applications
               that work with highly connected datasets. Neptune supports the popular graph query
               languages Apache TinkerPop Gremlin and W3C's SPARQL, enabling you to build queries
               that efficiently navigate highly connected datasets.
            See also https://aws.amazon.com/neptune/.
         network ACL
            An optional layer of security that acts as a firewall for controlling traffic in
               and out of a subnet. You can associate
               multiple subnets with a single network ACL, but a subnet can be associated with only one network ACL at a
               time.
         Network Address Translation and Protocol
            Translation
            (NAT-PT) An internet protocol standard
               defined in RFC 2766.
            See also NAT instance.
            See also NAT gateway.
         Network Firewall
            AWS Network Firewall is a managed service that deploys essential network protections for all
               Amazon Virtual Private Clouds (Amazon VPCs).
            See also https://aws.amazon.com/network-firewall.
         n-gram processor
            A processor that performs n-gram transformations.
            See also n-gram transformation.
         n-gram transformation
            Amazon Machine Learning: A transformation that aids in text string analysis. An n-gram
               transformation takes a text variable as input and outputs strings by sliding a window
               of size n words, where n is specified by
               the user, over the text, and outputting every string of words of size
                  n and all smaller sizes. For example, specifying the n-gram
               transformation with window size =2 returns all the two-word combinations and all of
               the single words.
         NICE Desktop Cloud Visualization
            A remote visualization technology for securely connecting users to
               graphic-intensive 3D applications hosted on a remote, high-performance server. 
            
         Nimble Studio
            Amazon Nimble Studio is a managed AWS cloud service for creative studios to produce visual effects, animation, and interactive content—from storyboard to final deliverable.
            See also https://aws.amazon.com/nimble-studio/.
         node
            OpenSearch Service: An OpenSearch instance. A node can be
               either a data instance or a dedicated master instance.
            See also dedicated master node.
         NoEcho
            A property of CloudFormation
               parameters that prevent the otherwise default reporting of names and values of a
               template parameter. Declaring the NoEcho property causes the parameter
               value to be masked with asterisks in the report by the
                  cfn-describe-stacks command.
         normalized discounted cumulative gain (NCDG) at K (5/10/25)
            Amazon Personalize: An evaluation metric that tells you about the relevance of your model’s highly ranked recommendations, where K is a sample size of 5, 10, or 25 recommendations. Amazon Personalize calculates this by assigning weight to recommendations based on their position in a ranked list, where each recommendation is discounted (given a lower weight) by a factor dependent on its position. The normalized discounted cumulative gain at K assumes that recommendations that are lower on a list are less relevant than recommendations higher on the list.
            See also metrics.
            See also recommendations.
         NoSQL
            Nonrelational database systems that are highly available, scalable, and optimized
               for high performance. Instead of the relational model, NoSQL databases (for example,
                  DynamoDB) use alternate models for data
               management, such as key–value pairs or document storage. 
         null object
            
            A null object is one whose version ID is null. Amazon S3
               adds a null object to a bucket when versioning for that bucket is
               suspended. It's possible to have only one null object for each key in a
               bucket.
         number of passes
            The number of times that you allow Amazon Machine Learning to use the same data records to train
               a machine learning model.
         O
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      O3DE
            Open 3D Engine (successor to Amazon Lumberyard) is an open-source 3D development engine
               for creating games and simulations. O3DE is licensed under Apache 2.0 and maintained
               by a community of contributors, including Amazon.
            See also https://www.o3de.org/.
            See also https://aws.amazon.com/lumberyard/.
            See also https://docs.aws.amazon.com/lumberyard/.
         object
            
            Amazon S3: The fundamental entity type stored in
               Amazon S3. Objects consist of object data and metadata. The data portion is opaque to
               Amazon S3.
            
            CloudFront: Any entity that can be served
               either over HTTP or a version of RTMP.
         observation
            Amazon Machine Learning: A single instance of data that Amazon Machine Learning (Amazon ML) uses to either train a
               machine learning model how to predict or to generate a prediction. Each row in an
               Amazon ML input data file is an observation.
         On-Demand Instance
            
            An Amazon EC2 pricing option that
               charges you for compute capacity by the hour or second (minimum of 60 seconds) with no long-term commitment.
         Open 3D EngineSee O3DE.OpenSearch Service
            Amazon OpenSearch Service is an AWS managed service for deploying, operating, and scaling OpenSearch, an
               open-source search and analytics engine, in the AWS Cloud. Amazon OpenSearch Service (OpenSearch Service) also
               offers security options, high availability, data durability, and direct access to the
               OpenSearch API.
            See also https://aws.amazon.com/elasticsearch-service.
         operation
            An API function. Also called an action.
         OpsWorks
            AWS OpsWorks is a configuration management service that helps you use Chef to configure and
               operate groups of instances and applications. You can define the application's
               architecture and the specification of each component including package installation,
               software configuration, and resources such
               as storage. You can automate tasks based on time, load, or lifecycle events.
            See also https://aws.amazon.com/opsworks/.
         optimistic locking
            A strategy to ensure that an item that you want to update has not been modified by
               others before you perform the update. For DynamoDB, optimistic locking support is provided by the AWS
               SDKs.
         opt-in Region
            An AWS Region that is disabled by default. To use an opt-in Region, you must
               enable it. Regions introduced after March 20, 2019 are opt-in Regions. For a list of
               opt-in Regions, see Considerations before enabling and disabling Regions in the AWS Account Management Guide. 
            See also Region that is enabled by default.
            
         organization
            Organizations: An entity
               that you create to consolidate and manage your AWS accounts. An organization has
               one management account along with zero or more member accounts.
         organizational unit
            Organizations: A container
               for accounts within a root of an organization.
               An organizational unit (OU) can contain other OUs.
         Organizations
            AWS Organizations is an account management service that you can use to consolidate multiple
               AWS accounts into an organization that you create and centrally manage. 
            See also https://aws.amazon.com/organizations/.
         origin access identity
            
            Also called OAI. When using Amazon CloudFront to serve content with an Amazon S3
               
               bucket as the origin, a virtual identity
               that you use to require users to access your content through CloudFront URLs instead of
               Amazon S3 URLs. Usually used with CloudFront private content. 
         origin server
            
            The Amazon S3
               bucket or custom origin containing the
               definitive original version of the content you deliver through CloudFront.
         original environment
            The instances in a deployment group at the start of an CodeDeploy blue/green
               deployment.
         OSB transformation
            Orthogonal sparse bigram transformation. In machine learning, a transformation
               that aids in text string analysis and that's an alternative to the n-gram
               transformation. OSB transformations are generated by sliding the window of size
                  n words over the text, and outputting every pair of words
               that includes the first word in the window.
            See also n-gram transformation.
         OUSee organizational unit.Outposts
            AWS Outposts is a fully managed service by AWS that extends AWS infrastructure, services, APIs, and tools to on-premises data centers and edge locations. Use AWS Outposts for workloads and devices requiring low latency access to on-premises systems, local data processing, data residency, and application migration with local system interdependencies.
            See also https://aws.amazon.com/outposts.
         output location
            Amazon Machine Learning: An Amazon S3 location where the results of a batch prediction are
               stored.
         P
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      pagination
            The process of responding to an API request by returning a large list of records
               in small separate parts. Pagination can occur in the following situations:
            
                
                
            
                  The client sets the maximum number of returned records to a value below the
                     total number of records.
               
                  The service has a default maximum number of returned records that's lower
                     than the total number of records.
               
            When an API response is paginated, the service sends a subset of the large list of
               records and a pagination token that indicates that more records are available. The
               client includes this pagination token in a subsequent API request, and the service
               responds with the next subset of records. This continues until the service responds
               with a subset of records and no pagination token, indicating that all records have
               been sent. 
         pagination token
            A marker that indicates that an API response contains a subset of a larger list of
               records. The client can return this marker in a subsequent API request to retrieve
               the next subset of records until the service responds with a subset of records and no
               pagination token, indicating that all records have been sent. 
            See also pagination.
         paid AMI
            An Amazon Machine Image
            (AMI) that
               you sell to other Amazon EC2 users on AWS Marketplace.
         AWS Panorama
            AWS Panorama is a machine learning (ML) Appliance and Software Development Kit (SDK) that organizations can use to bring computer vision (CV) to on-premises cameras to make predictions locally.
            See also https://aws.amazon.com/panorama.
         AWS ParallelCluster
            AWS ParallelCluster is an AWS supported open source cluster management tool that helps you to deploy and
               manage high performance computing (HPC) clusters in the AWS Cloud.
         paravirtual virtualizationSee PV virtualization.part
            
            A contiguous portion of the object's data in a multipart upload request.
         partition
            A group of AWS Regions.
               Each Region is in only one partition, and each partition contains one or more
               Regions. Partitions have independent instances of the AWS Identity and Access Management (IAM)
               infrastructure. In other words, a partition is comprised of Regions that share the
               same authentication, account, and resource stack. Each AWS account is scoped to one
               partition. You can't use IAM credentials from one partition to interact with
               resources in a different partition. 
            Some AWS services are designed to provide cross-Region functionality. Such
               cross-Region functionality is supported only between Regions in the same partition.
               AWS commercial Regions are in the AWS partition, China Regions are
               in the AWS-cn partition, and AWS GovCloud (US) Regions are in the
                  AWS-us-gov partition. 
            
         partition key
            A simple primary key, composed of one attribute (also known as a hash
                  attribute).
            See also primary key.
            See also sort key.
         PAT
            Port address translation. 
         pebibyte (PiB)
            A contraction of peta binary byte, a pebibyte is 2^50 or 1,125,899,906,842,624
               bytes. A petabyte (PB) is 10^15 or 1,000,000,000,000,000 bytes. 1,024 PiB is an exbibyte (EiB).
         periodSee sampling period.permission
            
            A statement within a policy that allows
               or denies access to a particular resource.
               You can state any permission in the following way: "A has permission to do B to
               C." For example, Jane (A) has permission to read messages (B) from John's Amazon SQS queue (C). Whenever Jane sends a request to Amazon SQS to use John's
               queue, the service checks to see if she has permission. It further checks to see if
               the request satisfies the conditions John set forth in the permission.
         persistent storage
            A data storage solution where the data remains intact until it's deleted. Options
               within AWS include: Amazon S3, Amazon RDS, DynamoDB, and other
               services.
         Amazon Personalize
            Amazon Personalize is an artificial intelligence service for creating individualized product and content recommendations.
            See also https://aws.amazon.com/personalize/.
         PERSONALIZED_RANKING recipes
            Amazon Personalize: Recipes that provide item recommendations in ranked order based on the predicted interest for a user.
            See also recipe.
            See also recommendations.
            See also personalized-ranking recipe.
            See also popularity-count recipe.
         personalized-ranking recipe
            Amazon Personalize: A PERSONALIZED_RANKING recipe that ranks a collection of items that you provide based on the predicted interest level for a specific user. Use the personalized-ranking recipe to create curated lists of items or ordered search results that are personalized for a specific user.
            See also recipe.
            See also PERSONALIZED_RANKING recipes.
         physical name
            A unique label that CloudFormation assigns to each resource when creating
               a stack. Some AWS CloudFormation commands accept the
               physical name as a value with the --physical-name parameter.
         pilot light
            An active-passive disaster recovery strategy in which you replicate data from the primary Region as standby, then provision a replica that contains only the core workload infrastructure. To make this infrastructure functional and serve requests, you must provision the remaining resources, such as compute. 
            See also back up and restore, hot standby, warm standby.
         Amazon Pinpoint
            Amazon Pinpoint is a multichannel communications service that helps organizations send timely, targeted content through SMS, email, mobile push notifications, voice messages, and in-application channels.
            See also https://aws.amazon.com/pinpoint.
         pipeline
            CodePipeline: A workflow
               construct that defines the way software changes go through a release process.
         plaintext
            Information that has not been encrypted, as opposed to ciphertext.
         policy
            IAM: A document defining
               permissions that apply to a user, group, or role; the permissions in turn determine
               what users can do in AWS. A policy typically allows access to specific actions, and can optionally grant that the
               actions are allowed for specific resources, such as EC2 instances or Amazon S3
               
               buckets. Policies can also explicitly deny access.
            
            Amazon EC2 Auto Scaling: An object that stores
               the information that's needed to launch or terminate instances for an Auto Scaling group.
               Running the policy causes instances to be launched or terminated. You can configure
               an alarm to invoke an Auto Scaling policy.
         policy generator
            A tool in the IAM
               AWS Management Console that
               helps you build a policy by selecting
               elements from lists of available options. 
         policy simulator
            A tool in the IAM
               AWS Management Console that
               helps you test and troubleshoot policies so you can see their effects in real-world scenarios. 
         policy validator
            A tool in the IAM
               AWS Management Console that
               examines your existing IAM access control policies to ensure that they comply with the IAM policy
               grammar.
         Amazon Polly
            Amazon Polly is a text-to-speech (TTS) service that turns text into natural-sounding human speech.
               Amazon Polly provides dozens of lifelike voices across a broad set of languages so that
               you can build speech-enabled applications that work in many different
               countries.
            See also https://aws.amazon.com/polly/.
         popularity-count recipe
            Amazon Personalize: A USER_PERSONALIZATION recipe that recommends the items that have had the most interactions with unique users.
            See also recipe.
            See also USER_PERSONALIZATION recipes.
         Porting Assistant for .NET
            Porting Assistant for .NET is a compatibility analyzer that reduces the manual effort required to port Microsoft .NET Framework applications to open source .NET Core.
         precision at K (5/10/25)
            Amazon Personalize: An evaluation metric that tells you how relevant your model’s recommendations are based on a sample size of K (5, 10, or 25) recommendations. Amazon Personalize calculates this metric based on the number of relevant recommendations out of the top K recommendations, divided by K, where K is 5, 10, or 25.
            See also metrics.
            See also recommendations.
         prefixSee job prefix.Premium Support
            A one-on-one, fast-response support channel that AWS customers can subscribe to
               for support for AWS infrastructure services. 
            See also https://aws.amazon.com/premiumsupport/.
         presigned URL
            A web address that uses query string authentication. 
         primary key
            One or two attributes that uniquely identify each item in a DynamoDB table, so that no two items can have
               the same key.
            See also partition key.
            See also sort key.
         primary shardSee shard.principal
            The user, service, or account that receives permissions that are
               defined in a policy. The principal is A in
               the statement "A has permission to do B to C."
         AWS Private CA
            AWS Private Certificate Authority is a hosted private certificate authority service for issuing and revoking private
               digital certificates.
            See also https://aws.amazon.com/certificate-manager/private-certificate-authority/.
         private content
            When using Amazon CloudFront to
               serve content with an Amazon S3
               bucket as the origin, a method of
               controlling access to your content by requiring users to use signed URLs. Signed URLs
               can restrict user access based on the current date and time, the IP addresses that
               the requests originate from, or both.
         private IP address
            
            A private numerical address (for example, 192.0.2.44) that networked devices use
               to communicate with one another using the Internet Protocol (IP). Each EC2 instance is assigned two IP addresses
               at launch, which are directly mapped to each other through network address
               translation (NAT): a private address (following
               RFC 1918) and a public address. Exception: Instances launched in
                  Amazon VPC are assigned only a private IP
               address.
         private subnet
            A Amazon VPC
               subnet whose instances can't be reached from
               the internet.
         product code
            An identifier provided by AWS when you submit a product to AWS Marketplace.
         propertiesSee resource property.property rule
            A JSON-compliant markup standard for
               declaring properties, mappings, and output values in an CloudFormation template. 
         Provisioned IOPS
            A storage option that delivers fast, predictable, and consistent I/O performance.
               When you specify an IOPS rate while creating a DB instance, Amazon RDS provisions that IOPS rate
               for the lifetime of the DB instance.
         pseudo parameter
            
            A predefined setting (for example, AWS:StackName) that can be used in
                  CloudFormation templates without
               having to declare them. You can use pseudo parameters anywhere you can use a regular
               parameter.
         public AMI
            
            An Amazon Machine Image
            (AMI) that
               all AWS accounts have permission to
               launch.
         public dataset
            A large collection of public information that can be seamlessly integrated into
               applications that are based in the AWS Cloud. Amazon stores public datasets at no
               charge to the community and, similar to other AWS services, users pay only for the
               compute and storage they use for their own applications. These datasets currently
               include data from the Human Genome Project, the US Census, Wikipedia, and other
               sources. 
            See also https://aws.amazon.com/publicdatasets.
         public IP address
            
            A public numerical address (for example, 192.0.2.44) that networked devices use to
               communicate with one another using the Internet Protocol (IP). Each EC2 instance is assigned two IP addresses
               at launch, which are directly mapped to each other through Network Address
               Translation (NAT): a private address (following
               RFC 1918) and a public address. Exception: Instances launched in
                  Amazon VPC are assigned only a private IP
               address.
         public subnet
            A subnet whose instances can be reached
               from the internet.
         PV virtualization
            Paravirtual virtualization allows guest VMs to run on host systems that don't
               have special support extensions for full hardware and CPU virtualization. Because PV
               guests run a modified operating system that doesn't use hardware emulation, they
               can't provide hardware-related features, such as enhanced networking or GPU
               support.
            See also HVM virtualization.
         Q
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Amazon QLDB
            Amazon Quantum Ledger Database (Amazon QLDB) is a fully managed ledger database that provides a transparent, immutable, and cryptographically verifiable transaction log owned by a central trusted authority.
            See also https://aws.amazon.com/qldb.
         quartile binning
            transformation
            Amazon Machine Learning: A process that takes two inputs, a numerical variable and a parameter
               called a bin number, and outputs a categorical variable. Quartile binning
               transformations discover non-linearity in a variable's distribution by enabling the
               machine learning model to learn separate importance values for parts of the numeric
               variable’s distribution.
         Query
            A type of web service that generally uses only the GET or POST HTTP method and a
               query string with parameters in the URL.
            See also REST.
         query string authentication
            An AWS feature that you can use to place the authentication information in the
               HTTP request query string instead of in the Authorization header, which
               provides URL-based access to objects in a bucket.
         queue
            A sequence of messages or jobs that are held in temporary storage awaiting
               transmission or processing. 
         queue URL
            
            A web address that uniquely identifies a queue.
         QuickSight
            Amazon QuickSight is a fast, cloud-powered business analytics service that you can use to build
               visualizations, perform analysis, and quickly get business insights from your data. 
            See also https://aws.amazon.com/quicksight/.
         quota
            The maximum value for your resources, actions, and items in your AWS account
         R
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      AWS RAM
            AWS Resource Access Manager is a web service that AWS customers can use to securely share AWS resources with any AWS account or within your organization.
            See also https://aws.amazon.com/ram.
         range GET
            A request that specifies a byte range of data to get for a download. If an object
               is large, you can break up a download into smaller units by sending multiple range
               GET requests that each specify a different byte range to GET. 
         raw email
            
            A type of sendmail request with which you can specify the
               email headers and MIME types. 
         Amazon RDS
            Amazon Relational Database Service is a web service that makes it easier to set up, operate, and scale a relational
               database in the cloud. It provides cost-efficient, resizable capacity for an
               industry-standard relational database and manages common database administration
               tasks.
            See also https://aws.amazon.com/rds.
         read local/write global
            An active-active strategy in which all writes for a workload are sent to one
               primary Region and all read traffic is served from the Region where the request
               originates. Typically architected with an asynchronous data store. Sometimes referred
               to as read local-write global. 
            See also read local/write local, global consistency.
         read local/write local
            An active-active strategy in which all writes for a workload are sent to one primary Region and all read traffic is served from the Region where the request originates. Typically architected with an asynchronous data store. Sometimes referred to as read local-write global. 
            See also read local/write global, global consistency.
         read replica
            
            Amazon RDS: An active copy of another
               DB instance. Any updates to the data on the source DB instance are replicated to the
               read replica DB instance using the built-in replication feature of MySQL 5.1.
         real-time predictions
            Amazon Machine Learning: Synchronously generated predictions for individual data
               observations.
            See also batch prediction.
         receipt handle
            
            Amazon SQS: An identifier that you get when you receive a message from the
               queue. This identifier is required to delete a message from the queue or when
               changing a message's visibility timeout.
         receiver
            
            The entity that consists of the network systems, software, and policies that
               manage email delivery for a recipient.
            
         recipe
            Amazon Personalize: An Amazon Personalize
               algorithm that's preconfigured to predict the items that a user interacts with (for
               USER_PERSONALIZATION recipes), or calculate items that are similar to specific items
               that a user has shown interest in (for RELATED_ITEMS recipes), or rank a collection
               of items that you provide based on the predicted interest for a specific user (for
               PERSONALIZED_RANKING recipes).
            See also USER_PERSONALIZATION recipes.
            See also RELATED_ITEMS recipes.
            See also PERSONALIZED_RANKING recipes.
         recipient
            Amazon SES: The person or entity receiving an email
               message. For example, a person named in the "To" field of a message.
         recommendations
            Amazon Personalize: A list of
               items that Amazon Personalize predicts that a user interacts with. Depending on the Amazon Personalize recipe
               used, recommendations can be either a list of items (with USER_PERSONALIZATION
               recipes and RELATED_ITEMS recipes), or a ranking of a collection of items you
               provided (with PERSONALIZED_RANKING recipes).
            See also recipe.
            See also campaign.
            See also solution version.
            See also USER_PERSONALIZATION recipes.
            See also RELATED_ITEMS recipes.
            See also PERSONALIZED_RANKING recipes.
         Redis
            A fast, open-source, in-memory key-value data structure store. Redis comes with a
               set of versatile in-memory data structures with which you can easily create a variety
               of custom applications.
         Amazon Redshift 
            Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. With Amazon Redshift,
               you can analyze your data using your existing business intelligence tools.
            See also https://aws.amazon.com/redshift/.
         reference
            
            A means of inserting a property from one AWS resource into another. For example, you could insert an Amazon EC2
               security group property into an Amazon RDS resource.
         Region
            A named set of AWS resources that's in the same geographical area. A Region is comprised of
               at least three Availability Zones.
               AWS Regions are divided into partitions. AWS commercial Regions are in the AWS
               partition, China Regions are in the AWS-cn partition, and
               AWS GovCloud (US) Regions are in the AWS-us-gov partition.
            
         Region that is enabled by default
            An AWS Region that is enabled by default. Regions that were introduced before
               March 20, 2019 are enabled by default and can’t be disabled. For a list of Regions
               that aren’t enabled by default (opt-in Region), see Considerations before enabling and disabling Regions in the AWS Account Management Guide.
         regression model
            Amazon Machine Learning: Preformatted instructions for common data transformations that fine-tune
               machine learning model performance.
         regression model
            A type of machine learning model that predicts a numeric value, such as the exact
               purchase price of a house.
         regularization
            A machine learning (ML) parameter that you can tune to obtain higher-quality ML
               models. Regularization helps prevent ML models from memorizing training data examples
               instead of learning how to generalize the patterns it sees (called overfitting). When
               training data is overfitted, the ML model performs well on the training data, but
               doesn't perform well on the evaluation data or on new data.
         Amazon Rekognition
            Amazon Rekognition is a machine learning service that identifies objects, people, text, scenes, and activities, including inappropriate content, in either image or video files. With Amazon Rekognition Custom Labels, you can create a customized ML model that detects objects and scenes specific to your business in images.
            See also https://aws.amazon.com/rekognition/.
         RELATED_ITEMS recipes
            Amazon PersonalizeRecipes that recommend items that are
               similar to a specified item, such as the item-to-item (SIMS) recipe.
            See also recipe.
            See also item-to-item similarities (SIMS) recipe.
         replacement environment
            The instances in a deployment group after the CodeDeploy blue/green deployment.
         replica shardSee shard.reply path
            
            The email address that an email reply is sent to. This is different from the return path.
         representational state transferSee REST.reputation
            
            1. An Amazon SES metric, based on
               factors that might include bounces, complaints, and other metrics, regarding
               whether a customer is sending high-quality email.
            2. A measure of confidence, as judged by an internet service provider
               (ISP) or
               other entity that an IP address that they are receiving email from isn't the source
               of spam.
         requester
            The person (or application) that sends a request to AWS to perform a specific
               action. When AWS receives a request, it first evaluates the requester's permissions
               to determine whether the requester is allowed to perform the request action (if
               applicable, for the requested resource).
         Requester Pays
            
            An Amazon S3
               feature that allows a bucket owner to specify that anyone who
               requests access to objects in a particular bucket must pay the data transfer and request costs.
         reservation
            
            A collection of EC2 instances started
               as part of the same launch request. This is not to be confused with a Reserved Instance.
         Reserved Instance
            
            A pricing option for EC2 instances
               that discounts the on-demand usage charge for instances that meet the specified parameters.
               Customers pay for the entire term of the instance, regardless of how they use
               it.
         Reserved Instance Marketplace
            An online exchange that matches sellers who have reserved capacity that they no
               longer need with buyers who are looking to purchase additional capacity. reserved instances that you purchase
               from third-party sellers have less than a full standard term remaining and can be
               sold at different upfront prices. The usage or reoccurring fees remain the same as
               the fees set when the Reserved Instances were originally purchased. Full standard
               terms for Reserved Instances available from AWS run for one year or three
               years.
         Resilience Hub
            AWS Resilience Hub gives you a central place to define, validate, and track the resiliency of your AWS application. It helps you to protect your applications from disruptions, and reduce recovery costs to optimize business continuity to help meet compliance and regulatory requirements.
            
            See also https://aws.amazon.com/resilience-hub.
         resource
            An entity that users can work with in AWS, such as an EC2 instance, an DynamoDB table, an Amazon S3
               bucket, an IAM user, or an OpsWorks
               stack.
         Resource Groups
            AWS Resource Groups is a web service that AWS customers can use to manage and automate tasks on large numbers of resources at one time.
            See also AWS Resource Groups.
         Amazon Resource Name (ARN)
            Amazon Resource Name is a standardized way to refer to an AWS resource (for example,
                  arn:aws:iam::123456789012:user/division_abc/subdivision_xyz/Bob).
         resource property
            
            A value required when including an AWS resource in an CloudFormation
               stack. Each resource can have one or more
               properties associated with it. For example, an AWS::EC2::Instance
               resource might have a UserData property. In an AWS CloudFormation template, resources
               must declare a properties section, even if the resource has no properties.
         resource record
            Also called resource record set. The fundamental information
               elements in the Domain Name System (DNS).
            See also Domain Name
                  System on Wikipedia.
         REST
            Representational state transfer. A simple stateless architecture that generally
               runs over HTTPS/TLS. REST emphasizes that resources have unique and hierarchical
               identifiers (URIs), are represented by common media types (such as HTML, XML, or
                  JSON), and that operations on the resources
               are either predefined or discoverable within the media type. In practice, this
               generally results in a limited number of operations.
            See also Query.
            See also WSDL.
            See also SOAP.
         RESTful web service
            Also known as RESTful API. A web service that follows REST architectural constraints. The API operations must use HTTP
               methods explicitly, expose hierarchical URIs, and transfer either XML, JSON, or both. 
         return enabled
            
            CloudSearch: An index field option
               that enables the field's values to be returned in the search results.
         return path
            
            The email address that bounced email is returned to. The return path is specified
               in the header of the original email. This is different from the reply path.
         revision
            CodePipeline: A change that's
               made to a source that's configured in a source action, such as a pushed commit to a
                  GitHub repository or an update to a file
               in a versioned Amazon S3
               bucket. 
         AWS RoboMaker
            AWS RoboMaker is a cloud-based simulation service that robotics developers use to run, scale, and automate simulation without managing any infrastructure.
            See also https://aws.amazon.com/robomaker.
         role
            A tool for giving temporary access to AWS resources in your AWS account.
         rollback
            A return to a previous state that follows the failure to create an object, such as
                  CloudFormation
               stack. All resources that are associated with the failure are deleted during the rollback.
               For AWS CloudFormation, you can override this behavior using the --disable-rollback
               option on the command line.
         root
            Organizations: A parent
               container for the accounts in your organization. If you apply a service control policy to the
               root, it applies to every organizational unit and account in the organization.
         root credentials
            Authentication information associated with the AWS account owner. 
         root device volume
            
            A volume that contains the image used to
               boot the instance (also known as a
                  root device). If you launched the instance from an AMI backed
               by instance store, this is an instance
               store volume created from a template stored
               in Amazon S3. If you launched the instance
               from an AMI backed by Amazon EBS, this is
               an Amazon EBS volume created from an Amazon EBS snapshot.
         route table
            A set of routing rules that controls the traffic leaving any subnet that's associated with the route table.
               You can associate multiple subnets with a single route table, but a subnet can be
               associated with only one route table at a time.
         Route 53
            Amazon Route 53 is a web service that you can use to create a new DNS service or to migrate your
               existing DNS service to the cloud.
            See also https://aws.amazon.com/route53.
         row identifier
            Amazon Machine Learning: An attribute in the input data that you can include in the evaluation or
               prediction output to make it easier to associate a prediction with an
               observation.
         rule
            AWS WAF: A set of conditions that AWS WAF
               searches for in web requests to AWS resources such as Amazon CloudFront
               distributions. You add rules to a web
                  ACL, and then specify whether you want to allow or block web requests based
               on each rule.
         S
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      Amazon S3
            Amazon S3 is storage for the internet. You can use it to store and retrieve any amount of data
               at any time, from anywhere on the web.
            See also https://aws.amazon.com/s3.
         Amazon S3 Glacier
            Amazon S3 Glacier is a secure, durable, and low-cost storage service for data archiving and long-term
               backup. You can reliably store large or small amounts of data for significantly less
               than on-premises solutions. S3 Glacier is optimized for infrequently accessed data, where a
               retrieval time of several hours is suitable.
            See also https://aws.amazon.com/glacier/.
         Amazon S3-Backed AMISee instance store-backed AMI.SageMaker AI
            Amazon SageMaker AI is a fully managed cloud service that builds, trains, and deploys machine learning (ML) models by using AWS infrastructure, tools, and workflows.
            See also https://aws.amazon.com/sagemaker.
         AWS SAM
            AWS Serverless Application Model is an open-source framework for building and running serverless
               applications. AWS SAM provides a command line interface tool and a shorthand syntax
               template specification that you can use to quickly iterate through your serverless
               application lifecycle.
            See also https://aws.amazon.com/serverless/sam/.
         sampling period
            
            A defined duration of time, such as one minute, which CloudWatch computes a statistic over. 
         sandbox
            A testing location where you can test the functionality of your application
               without affecting production, incurring charges, or purchasing products.
            Amazon SES: An environment that
               developers can use to test and evaluate the service. In the sandbox, you have full
               access to the Amazon SES API, but you can only send messages to verified email addresses
               and the mailbox simulator. To get out of the sandbox, you must apply for production
               access. Accounts in the sandbox also have lower sending limits than production accounts.
         scale in
            To remove EC2 instances from an Auto Scaling group.
         scale out
            To add EC2 instances to an Auto Scaling group.
         scaling activity
            A process that changes the size, configuration, or makeup of an Auto Scaling group by launching or
               terminating instances.
         scaling policy
            A description of how Auto Scaling automatically scales an Auto Scaling group in response to
               changing demand.
            See also scale in.
            See also scale out.
         scheduler
             The method used for placing tasks on container instances. 
         schema
            Amazon Machine Learning: The information that's needed to interpret the input data for a machine
               learning model, including attribute names and their assigned data types, and the
               names of special attributes.
         score cut-off value
            Amazon Machine Learning: A binary classification model outputs a score that ranges from 0 to 1.
               To decide whether an observation is classified as 1 or 0, you pick a classification
               threshold, or cut-off, and Amazon ML compares the score against it. Observations with
               scores higher than the cut-off are predicted as target equals 1, and scores lower
               than the cut-off are predicted as target equals 0.
         SCPSee service control policy.AWS SCT
            AWS Schema Conversion Tool is a desktop application that automates heterogeneous database migrations. You can use AWS SCT to convert database schemas and code objects, SQL code in your applications, and ETL scripts to a format compatible with the target database. Then, you can use AWS SCT data extraction agents to migrate data to your target database.
            See also https://aws.amazon.com/dms/schema-conversion-tool.
         AWS SDK for .NET
            AWS SDK for .NET is a software development kit that provides .NET API operations for AWS services
               including Amazon S3, Amazon EC2, IAM,
               and more. You can download the SDK as multiple service-specific packages on
               NuGet.
            See also https://aws.amazon.com/sdk-for-net/.
         SDK for C++
            AWS SDK for C++ is a software development kit that provides C++ APIs for many AWS services
               including Amazon S3, Amazon EC2, DynamoDB,
               and more. The single, downloadable package includes the AWS C++ library, code
               examples, and documentation.
            See also https://aws.amazon.com/sdk-for-cpp/.
         SDK for Go
            AWS SDK for Go is a software development kit for integrating your Go application with the full suite
               of AWS services.
            See also https://aws.amazon.com/sdk-for-go/.
         SDK for Java
            AWS SDK for Java is a software development kit that provides Java API operations for many AWS services including Amazon S3, Amazon EC2, DynamoDB,
               and more. The single, downloadable package includes the AWS Java library, code
               examples, and documentation. 
            See also https://aws.amazon.com/sdk-for-java/.
         SDK for JavaScript in Node.js
            AWS SDK for JavaScript in Node.js is a software development kit for accessing AWS services from JavaScript in
               Node.js. The SDK provides JavaScript objects for AWS services, including Amazon S3, Amazon EC2, DynamoDB, and Amazon SWF. The single, downloadable package includes the AWS JavaScript
               library and documentation.
            See also https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/.
         SDK for JavaScript in the Browser
            AWS SDK for JavaScript in the Browser is a software development kit for accessing AWS services from JavaScript code
               running in the browser. Authenticate users through Facebook, Google, or Login with
               Amazon using web identity federation. Store application data in DynamoDB, and save user files to Amazon S3.
            See also https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/.
         SDK for PHP
            AWS SDK for PHP is a software development kit and open-source PHP library for integrating your PHP
               application with AWS services such as Amazon S3, Amazon S3 Glacier, and DynamoDB.
            See also https://aws.amazon.com/sdk-for-php/.
         SDK for Python (Boto3)
            AWS SDK for Python (Boto3) is a software development kit for using Python to access AWS services such as Amazon EC2, Amazon EMR, Amazon EC2 Auto Scaling,
               Kinesis, or Lambda.
            See also http://boto.readthedocs.org/en/latest/.
         SDK for Ruby
            AWS SDK for Ruby is a software development kit for accessing AWS services from Ruby. The SDK
               provides Ruby classes for many AWS services including Amazon S3, Amazon EC2, DynamoDB and more. The single, downloadable
               package includes the AWS Ruby Library and documentation.
            See also https://aws.amazon.com/sdk-for-ruby/.
         SDK for Rust
            AWS SDK for Rust is a software development kit that provides APIs and utilities for developers. It enables Rust applications to integrate with AWS services such as Amazon S3 and Amazon EC2.
         SDK for Swift
            AWS SDK for Swift is a software development kit that provides support for accessing AWS infrastructure and services using the Swift language.
         search API
            
            CloudSearch: The API that you use to
               submit search requests to a search domain. 
         search domain
            
            CloudSearch: Encapsulates your
               searchable data and the search instances that handle your search requests. You
               typically set up a separate Amazon CloudSearch domain for each different collection of data that
               you want to search.
         search domain configuration
            
            CloudSearch: A domain's indexing
               options, analysis schemes, expressions, suggesters, access policies, and scaling and
               availability options. 
         search enabled
            
            CloudSearch: An index field option
               that enables the field data to be searched. 
         search endpoint
            
            CloudSearch: The URL that you
               connect to when sending search requests to a search domain. Each Amazon CloudSearch domain has a
               unique search endpoint that remains the same for the life of the domain.
         search index
            
            CloudSearch: A representation of
               your searchable data that facilitates fast and accurate data retrieval.
         search instance
            
            CloudSearch: A compute resource that indexes your data and processes
               search requests. An Amazon CloudSearch domain has one or more search instances, each with a finite
               amount of RAM and CPU resources. As your data volume grows, more search instances or
               larger search instances are deployed to contain your indexed data. When necessary,
               your index is automatically partitioned across multiple search instances. As your
               request volume or complexity increases, each search partition is automatically
               replicated to provide additional processing capacity. 
         search request
            
            CloudSearch: A request that's sent
               to an Amazon CloudSearch domain's search endpoint to retrieve documents from the index that match
               particular search criteria. 
         search result
            
            CloudSearch: A document that matches
               a search request. Also referred to as a search hit. 
         secret access key
            A key that's used with the access key ID to cryptographically sign programmatic AWS requests. Signing a request
               identifies the sender and prevents the request from being altered. You can generate
               secret access keys for your AWS account, individual
               IAM users and temporary
               sessions.
         Secrets Manager
            AWS Secrets Manager is a service for securely encrypting, storing, and rotating credentials for databases
               and other services.
            See also https://aws.amazon.com/secrets-manager/.
         security group
            A named set of allowed inbound network connections for an instance. (Security
               groups in Amazon VPC also include support for outbound
               connections.) Each security group consists of a list of protocols, ports, and IP
               address ranges. A security group can apply to multiple instances, and multiple groups
               can regulate a single instance. 
         Security Hub
            AWS Security Hub is a service that provides a comprehensive view of the security state of your AWS
               resources. Security Hub collects security data from AWS accounts and services and helps
               you analyze your security trends to identify and prioritize the security issues
               across your AWS environment.
            See also https://aws.amazon.com/security-hub/.
         sender
            The person or entity sending an email message.
         Sender ID
            A Microsoft controlled version of SPF. An
               email authentication and anti-spoofing system. For more information about Sender ID,
               see Sender ID in
               Wikipedia.
         sending limits
            
            The sending quota and maximum send rate that are associated
               with every Amazon SES account.
         sending quota
            
            The maximum number of email messages that you can send using Amazon SES in a 24-hour period.
         AWS Serverless Application Repository
            AWS Serverless Application Repository is a managed repository that teams, organizations, and individual
               developers can use to store and share reusable applications, and assemble and deploy
               serverless architectures in powerful new ways.
            See also https://aws.amazon.com/serverless/serverlessrepo/.
         server-side encryption (SSE)
            The encrypting of data at
               the server level. Amazon S3
               supports three modes of
               server-side encryption: SSE-S3, where Amazon S3 manages the keys; SSE-C, where the
               customer manages the keys; and SSE-KMS, where AWS KMS manages keys.
         Service Catalog
            AWS Service Catalog is a web service that helps organizations create and manage catalogs of IT services
               that are approved for use on AWS. These IT services can include everything from
               virtual machine images, servers, software, and databases to complete multitier
               application architectures.
            See also https://aws.amazon.com/servicecatalog/.
         service control policy
            Organizations: A
               policy-based control that specifies the services and actions that users and roles can
               use in the accounts that the service control policy (SCP) affects.
         service endpointSee endpoint.service health dashboard
            A webpage showing up-to-the-minute information about AWS service availability.
               The dashboard is located at http://status.aws.amazon.com/.
         AWS Service Management Connector
            AWS Service Management Connector enables customers to provision, manage, and operate AWS resources and capabilities in familiar IT Service Management (ITSM) tooling.
            See also https://aws.amazon.com/service-management-connector.
         Service Quotas
            A service for viewing and managing your quotas easily and at scale as your AWS
               workloads grow. Quotas, also referred to as limits, are the maximum number of
               resources that you can create in an AWS account.
         service role
            An IAM
               role that grants permissions to an AWS service
               so it can access AWS resources. The
               policies that you attach to the service role determine which AWS resources the
               service can access and what it can do with those resources.
         Amazon SES
            Amazon Simple Email Service is a simple and cost-effective email solution for applications. 
            See also https://aws.amazon.com/ses.
         session
            The period when the temporary security credentials that are provided by 
               AWS STS allow access to your AWS account.
         SHA
            Secure Hash Algorithm. SHA1 is an earlier version of the algorithm, which AWS
               has replaced with SHA256. 
         shard
            OpenSearch Service: A partition of data in an index. You can
               split an index into multiple shards, which can include primary shards (original
               shards) and replica shards (copies of the primary shards). Replica shards provide
               failover. This means that, if a cluster node that contains a primary shard fails, a
               replica shard is promoted to a primary shard. Replica shards also can handle
               requests.
         shared AMI
            
            An Amazon Machine Image
            (AMI) that a
               developer builds and makes available for others to use. 
         Shield
            AWS Shield is a service that helps to protect your resources—such as Amazon EC2 instances,
               Elastic Load Balancing load balancers, Amazon CloudFront distributions, and Route 53 hosted
               zones—against DDoS attacks. AWS Shield is automatically included at no extra
               cost beyond what you already pay for AWS WAF and your other AWS services. For
               added protection against DDoS attacks, AWS offers AWS Shield Advanced. 
            See also https://aws.amazon.com/shield.
         shutdown action
            
            Amazon EMR: A predefined bootstrap action that launches a script that runs a
               series of commands in parallel before terminating the job flow. 
         signature
            Refers to a digital signature, which is a mathematical way to
               confirm the authenticity of a digital message. AWS uses signatures to authenticate
               the requests you send to our web services. For more information, to https://aws.amazon.com/security. 
         SIGNATURE file
            
            Import/Export: A file that you
               copy to the root directory of your storage device. The file contains a job ID,
               manifest file, and a signature.
         Signature Version 4
            Protocol for authenticating inbound API requests to AWS services in all AWS Regions.
         Signer
            AWS Signer is a fully managed code-signing service used to ensure the authenticity and integrity of an AWS customer's code.
         Silk
            Amazon Silk is a next-generation web browser that's available only on Fire OS tablets and phones.
               Built on a split architecture that divides processing between the client and the
               AWS Cloud, Amazon Silk creates a faster, more responsive mobile browsing
               experience.
         Simple Mail Transfer ProtocolSee SMTP.Simple Object Access ProtocolSee SOAP.SimSpace Weaver
            AWS SimSpace Weaver is a managed service that you can use to build and run large-scale
               spatial simulations in the AWS Cloud.
            See also https://aws.amazon.com/simspaceweaver/.
         SIMS recipeSee item-to-item similarities (SIMS) recipe.single sign-on
            An authentication scheme that allows users to sign in one time to access multiple applications and websites. The service name AWS Single Sign-On is now AWS IAM Identity Center.
            See also IAM Identity Center.
         Single-AZ DB instance
            
            A standard (non-Multi-AZ) DB instance
               that's deployed in one Availability Zone, without a standby
               replica in another Availability Zone. 
            See also Multi-AZ deployment.
         Site-to-Site VPN
            AWS Site-to-Site VPN is a fully managed service that you can use to establish Internet Protocol security (IPsec) VPN connections between your AWS networks and your on-premises networks.
            See also https://aws.amazon.com/vpn/site-to-site-vpn.
         sloppy phrase search
            
            A search for a phrase that specifies how close the terms must be to one another to
               be considered a match. 
         AWS SMS
            AWS Server Migration Service is a service that combines data collection tools with automated server replication to speed the migration of on-premises servers to AWS.
            See also https://aws.amazon.com/server-migration-service.
         SMTP
            
            Simple Mail Transfer Protocol. The standard that's used to exchange email messages
               between internet hosts for the purpose of routing and delivery.
         snapshot
            
            Amazon EBS: A backup of your volumes that's stored in Amazon S3. You can use these snapshots as the starting point for new Amazon EBS
               volumes or to protect your data for long-term durability.
            See also DB snapshot.
         Snowball
            AWS Snowball is a petabyte-scale data transport solution that uses devices that are secure to
               transfer large amounts of data into and out of the AWS Cloud.
            See also https://aws.amazon.com/snowball.
         Amazon SNS
            Amazon Simple Notification Service is a web service that applications, users, and devices can use to instantly send and
               receive notifications from the cloud.
            See also https://aws.amazon.com/sns.
         SOAP
            Simple Object Access Protocol. An XML-based protocol that you can use to exchange
               information over a particular protocol (for example, HTTP or SMTP) between
               applications.
            See also REST.
            See also WSDL.
         soft bounce
            
            A temporary email delivery failure such as one resulting from a full
               mailbox.
         software VPN
            A software appliance-based VPN connection over the internet. 
         solution
            Amazon Personalize: The recipe, customized parameters, and trained models (solution versions) that can be used to generate recommendations.
            See also recipe.
            See also solution version.
            See also recommendations.
         solution version
            Amazon Personalize: A trained model that you create as part of a solution in Amazon Personalize. You deploy a solution version in a campaign to generate recommendations.
            See also solution.
            See also campaign.
            See also recommendations.
         sort enabled
            
            CloudSearch: An index field option
               that enables a field to be used to sort the search results.
         sort key
            An attribute used to sort the order of partition keys in a composite primary key
               (also known as a range attribute). 
            See also partition key.
            See also primary key.
         source/destination checking
            A security measure to verify that an EC2 instance is the origin of all traffic that it sends and the
               ultimate destination of all traffic that it receives. In other words, this measure
               verifies that the instance isn't relaying traffic. By default, source/destination
               checking is turned on. For instances that function as gateways, such as Amazon VPC
               NAT instances, source/destination checking must
               be disabled.
         spam
            
            Unsolicited bulk emails.
         spamtrap
            
            An email address that's set up by an anti-spam entity. This email address isn't for correspondence but rather
               for monitoring unsolicited emails. This is also called a
                  honeypot.
         SPF
            Sender Policy Framework. A standard for authenticating email. 
         SPICE
            A robust in-memory engine that is part of Amazon QuickSight. Engineered for the cloud, SPICE (Super-fast,
               Parallel, In-memory Calculation Engine) uses a combination of storage and in-memory
               technologies. It uses these to get faster results from interactive queries and
               advanced calculations on large datasets. SPICE automatically replicates data for high
               availability. SPICE makes it possible for Amazon QuickSight to support hundreds of thousands
               of simultaneous analyses across a variety of data sources.
         Spot Instance
            
             A type of EC2 instance that you can
               bid on to use unused Amazon EC2
               capacity.
         Spot price
            
            The price for a Spot Instance at any
               given time. If your maximum price exceeds the current price and your restrictions are
               met, Amazon EC2 launches instances on your
               behalf. 
         SQL injection match condition
            
            AWS WAF: An attribute that specifies the
               part of web requests (such as a header or a query string) that AWS WAF inspects for
               malicious SQL code. Based on the specified conditions, you can configure AWS WAF to
               allow or block web requests to an AWS resource, such as an Amazon CloudFront distribution.
         Amazon SQS
            Amazon Simple Queue Service is a reliable and scalable hosted queues for storing messages as they travel between
               computers. 
            See also https://aws.amazon.com/sqs.
         Amazon SWF
            Amazon Simple Workflow Service is a fully managed service that helps developers build, run, and scale background
               jobs that have parallel or sequential steps. Amazon SWF functions similar to a state
               tracker and task coordinator in the AWS Cloud.
            See also https://aws.amazon.com/swf/.
         SSESee server-side encryption (SSE).SSL
            Secure Sockets Layer
            See also Transport Layer Security
               (TLS).
         stack
            
            CloudFormation: A collection of
               AWS resources that you create and delete
               as a single unit.
            OpsWorks: A set of instances that you
               manage collectively, typically because they have a common purpose such as serving PHP
               applications. A stack serves as a container and handles tasks that apply to the group
               of instances as a whole, such as managing applications and cookbooks.
         station
            CodePipeline: A portion of a
               pipeline workflow where one or more actions are performed.
         station
            
            A place at an AWS facility where your AWS Import/Export data is transferred on to, or off of,
               your storage device.
         statistic
            
            One of five functions of the values submitted for a given sampling period. These functions are
                  Maximum, Minimum, Sum,
               Average, and SampleCount.
         stem
            
            The common root or substring shared by a set of related words. 
         stemming
            
            The process of mapping related words to a common stem. This enables matching on
               variants of a word. For example, a search for "horse" could return matches for
               horses, horseback, and horsing, as well as horse. CloudSearch supports both dictionary based and algorithmic
               stemming.
         step
            
            Amazon EMR: A single function applied to the data in a job flow. The sum of all steps comprises a job
               flow.
         Step Functions
            AWS Step Functions is a web service that coordinates the components of distributed applications as a
               series of steps in a visual workflow.
            See also https://aws.amazon.com/step-functions/.
         step type
            
            Amazon EMR: The type of work done in a step. There are a limited number of step
               types, such as moving data from Amazon S3
               to Amazon EC2 or from Amazon EC2 to Amazon S3. 
         sticky session
            
            A feature of the ELB load balancer that
               binds a user's session to a specific application instance. This is so that all
               requests that are coming from the user during the session are sent to the same
               application instance. By contrast, a load balancer defaults to route each request
               independently to the application instance with the smallest load. 
         stopping
            
            The process of filtering stop words from an index or search request.
         stopword
            
            A word that isn't indexed and is automatically filtered out of search requests
               because it's either insignificant or so common that including it results in too many
               matches to be useful. Stopwords are language specific. 
         Storage Gateway
            AWS Storage Gateway is a hybrid cloud storage service that provides on-premises access to
               virtually unlimited cloud storage.
            See also AWS Storage Gateway.
         streaming
            Amazon EMR: A
               utility that comes with Hadoop that you can
               use to develop MapReduce executables in languages other than Java. 
            CloudFront: The ability to use a media
               file in real time—as it's transmitted in a steady stream from a server.
         streaming distribution
            
            A special kind of distribution that
               serves streamed media files using a Real Time Messaging Protocol (RTMP)
               connection.
         StreamsSee Kinesis Data Streams.string match condition
            AWS WAF: An attribute that specifies the
               strings that AWS WAF searches for in a web request, such as a value in a header or a
               query string. Based on the specified strings, you can configure AWS WAF to allow or
               block web requests to an AWS resource, such
               as a CloudFront
               distribution.
         string-to-sign
            Before you calculate an HMAC signature, you
               first assemble the required components in a canonical order. The preencrypted string
               is the string-to-sign.
         strongly consistent read
            A read process that returns a response with the most up-to-date data. This data
               reflects the updates from all previous write operations that were
               successful—regardless of the Region.
            See also data consistency.
            See also eventual consistency.
            See also eventually consistent read.
         structured query
            
            Search criteria that are specified using the CloudSearch structured query language. You use the structured query
               language to construct compound queries that use advanced search options and combine
               multiple search criteria using Boolean operators. 
         AWS STS
            AWS Security Token Service is a web service for requesting temporary, limited-privilege credentials for IAM users or for users that you authenticate
               (federated
                  users).
            See also https://aws.amazon.com/iam/.
         subnet
            
            A segment of the IP address range of a Amazon VPC
               that an EC2 instance can be attached to.
               You can create subnets to group instances according to security and operational
               needs. 
         Subscription button
            
            An HTML-coded button that provides a simple way to charge customers a recurring
               fee.
         suggester
            
            CloudSearch: Specifies an index
               field for getting autocomplete suggestions and options that can enable fuzzy matches
               and control how suggestions are sorted.
         suggestions
            
            Documents that contain a match for the partial search string in the field that's
               designated by the suggester. CloudSearch suggestions include the
               document IDs and field values for each matching document. To be a match, the string
               must match the contents of the field starting from the beginning of the field. 
         Sumerian
            Amazon Sumerian is a set of tools for creating and running high-quality 3D, augmented reality (AR),
               and virtual reality (VR) applications on the web.
            See also https://aws.amazon.com/sumerian/.
         supported AMI
            
            An Amazon Machine Image
            (AMI) similar
               to a paid AMI, except that the owner charges
               for additional software or a service that customers use with their own AMIs.
         SWFSee Amazon SWF.symmetric encryption
            Encryption that uses a
               private key only.
            See also asymmetric encryption.
         synchronous bounce
            
            A type of bounce that occurs while the
               email servers of the sender and receiver are actively communicating.
         synonym
            
            A word that's the same or nearly the same as an indexed word and that likely
               produces the same results when specified in a search request. For example, a search
               for "Rocky Four" or "Rocky 4" likely returns the fourth Rocky
               movie. You can do this by designating that four and 4 are
               synonyms for IV. Synonyms are language specific. 
         Systems Manager
            AWS Systems Manager is the operations hub for AWS and hybrid cloud environments that can help achieve secure operations at scale. It provides a unified user interface for users to view operations data from multiple AWS services and automate tasks across their AWS resources.
            See also https://aws.amazon.com/systems-manager.
         T
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      table
            A collection of data. Similar to other database systems, DynamoDB stores data in
               tables. 
         tag
            
            Metadata that you can define and assign to AWS resources, such as an EC2 instance. Not all AWS resources can be tagged.
         tagging
            Tagging resources: Applying a tag to an AWS
                  resource.
            
            Amazon SES: Also called
                  labeling. A way to format return path email addresses so that you can specify a different return
               path for each recipient of a message. You can use tagging to support VERP. For example, if Andrew manages a mailing
               list, he can use the return paths andrew+recipient1@example.net and
               andrew+recipient2@example.net so that he can determine which email bounced.
         target attribute
            Amazon Machine Learning (Amazon ML): The attribute in the input data that contains the “correct”
               answers. Amazon ML uses the target attribute to learn how to make predictions on new data.
               For example, if you were building a model for predicting the sale price of a house,
               the target attribute would be “target sale price in USD.”
         target revision
            CodeDeploy: The most recent
               version of the application revision that has been uploaded to the repository and will
               be deployed to the instances in a deployment group. In other words, the application
               revision currently targeted for deployment. This is also the revision that will be
               pulled for automatic deployments.
         task
             An instantiation of a task definition that's running on a container instance. 
         task definition
            The blueprint for your task. Specifies the name of the task, revisions, container definitions, and volume information. 
         task node
            An EC2 instance that runs Hadoop map and reduce tasks, but doesn't store
               data. Task nodes are managed by the master node, which assigns Hadoop tasks to nodes and monitors their
               status. While a job flow is running, you can increase and decrease the number of task
               nodes. Because they don't store data and can be added and removed from a job flow,
               you can use task nodes to manage the EC2 instance capacity your job flow uses,
               increasing capacity to handle peak loads and decreasing it later.
            Task nodes only run a TaskTracker Hadoop daemon.
         tebibyte (TiB)
            A contraction of tera binary byte. A tebibyte (TiB) is 2^40 or 1,099,511,627,776
               bytes. A terabyte (TB) is 10^12 or 1,000,000,000,000 bytes. 1,024 TiB is a pebibyte (PiB).
         template format version
            The version of an CloudFormation
               template design that determines the available features. If you omit the
                  AWSTemplateFormatVersion section from your template, AWS CloudFormation assumes
               the most recent format version.
         template validation
            The process of confirming the use of JSON
               code in an CloudFormation template.
               You can validate any AWS CloudFormation template using the cfn-validate-template
               command.
         temporary security credentials
            Authentication information that's provided by AWS STS when you call an STS API action. Includes an access key ID, a secret access key, a session token, and an expiration time.
         Amazon Textract
            Amazon Textract is a service that automatically extracts text and data from scanned documents.
               Amazon Textract goes beyond simple optical character recognition (OCR) to also identify
               the contents of fields in forms and information stored in tables.
            See also https://aws.amazon.com/textract/.
         throttling
            
            The automatic restricting or slowing down of a process based on one or more
               limits. For example, Kinesis Data Streams throttles operations if an application (or group
               of applications operating on the same stream) attempts to get data from a shard at a
               rate faster than the shard limit. API Gateway uses throttling to limit the steady-state request rates for
               a single account. Amazon SES uses
               throttling to reject attempts to send email that exceeds the sending limits.
         time-series data
            
            Data that's provided as part of a metric. The time value is assumed to be when the
               value occurred. A metric is the fundamental concept for CloudWatch and represents a time-ordered set of
               data points. You publish metric data points into CloudWatch and later retrieve statistics
               about those data points as a time-series ordered dataset.
         timestamp
            A date/time string in the ISO 8601 format (more specifically, in the
                  YYYY-MM-DD format).
         Timestream
            Amazon Timestream is a scalable and serverless time series database service for real-time analytics, DevOps, and IoT applications that you can use to store and analyze trillions of events per day.
            See also https://aws.amazon.com/timestream.
         TLSSee Transport Layer Security
               (TLS).tokenization
            
            The process of splitting a stream of text into separate tokens on detectable
               boundaries such as white space and hyphens.
         AWS Toolkit for Eclipse
            AWS Toolkit for Eclipse is an open-source plugin for the Eclipse Java integrated development environment
               (IDE) that makes it easier to develop, debug, and deploy Java applications using
               Amazon Web Services.
            See also https://aws.amazon.com/eclipse/.
         AWS Toolkit for JetBrains
            AWS Toolkit for JetBrains is an open-source plugin for the integrated development environments (IDEs) from
               JetBrains that makes it easier to develop, debug, and deploy serverless applications
               using Amazon Web Services.
            See also https://aws.amazon.com/intellij/,
               https://aws.amazon.com/pycharm/.
         AWS Toolkit for Microsoft Azure DevOps
            AWS Toolkit for Microsoft Azure DevOps provides tasks you can use in build and release definitions in VSTS to interact
               with AWS services.
            See also https://aws.amazon.com/vsts/.
         AWS Toolkit for Visual Studio
            AWS Toolkit for Visual Studio is an extension for Visual Studio that helps in developing, debugging, and deploying
               .NET applications using Amazon Web Services. 
            See also https://aws.amazon.com/visualstudio/.
         AWS Toolkit for Visual Studio Code
            AWS Toolkit for Visual Studio Code is an open-source plugin for the Visual Studio Code (VS Code) editor that makes it
               easier to develop, debug, and deploy applications using Amazon Web Services.
            See also https://aws.amazon.com/visualstudiocode/.
         AWS Tools for PowerShell
            AWS Tools for PowerShell is a set of PowerShell cmdlets to help developers and administrators manage their
               AWS services from the PowerShell scripting environment.
            See also https://aws.amazon.com/powershell/.
         topic
            
            A communication channel to send messages and subscribe to notifications. It
               provides an access point for publishers and subscribers to communicate with each
               other.
         Traffic Mirroring
            An Amazon VPC feature that you can use to copy network traffic from an elastic network
               interface of Amazon EC2 instances. You can then send this network traffic to out-of-band
               security and monitoring appliances for content inspection, threat monitoring, and
               troubleshooting.
            See also https://aws.amazon.com/vpc/.
         training datasource
            A datasource that contains the data that Amazon Machine Learning uses to train the machine
               learning model to make predictions.
         Amazon Transcribe
            Amazon Transcribe is a machine learning service that uses automatic speech recognition (ASR) to quickly and accurately convert speech to text.
            See also https://aws.amazon.com/transcribe/.
         Amazon Transcribe Medical
            Amazon Transcribe Medical is an automatic speech recognition (ASR) service for adding medical speech-to-text capabilities to voice-enabled clinical documentation applications.
            See also https://aws.amazon.com/transcribe/medical/.
         Transfer Family
            AWS Transfer Family offers fully managed support for transferring files over SFTP, FTPS, and FTP into and out of Amazon S3 or Amazon EFS, as well as support for the Applicability Statement 2 (AS2) protocol for business-to-business (B2B) transfers.
            See also https://aws.amazon.com/aws-transfer-family.
         transition
            CodePipeline: The act of a
               revision in a pipeline continuing from one stage to the next in a workflow.
         Amazon Translate
            Amazon Translate is a neural machine translation service that delivers fast, high-quality, and affordable language translation.
            See also https://aws.amazon.com/translate/.
         Transport Layer Security
               (TLS)
            
            A cryptographic protocol that provides security for communication over the
               internet. Its predecessor is Secure Sockets Layer (SSL).
         trust policy
            An IAM
               policy that's an inherent part of an IAM
                  role. The trust policy specifies which
                  principals are allowed to use the role.
         Trusted Advisor
            AWS Trusted Advisor is a web service that inspects your AWS environment and makes recommendations for
               saving money, improving system availability and performance, and helping to close
               security gaps.
            See also https://aws.amazon.com/premiumsupport/trustedadvisor/.
         trusted key groups
            
            Amazon CloudFront key groups whose public keys CloudFront can use to verify the signatures of
                  CloudFront signed URLs
                  and signed cookies.
         trusted signers
            
            See trusted key groups.
         tuning
            
            Selecting the number and type of AMIs to
               run a Hadoop job flow most
               efficiently.
         tunnel
            A route for transmission of private network traffic that uses the internet to
               connect nodes in the private network. The tunnel uses encryption and secure protocols
               such as PPTP to prevent the traffic from being intercepted as it passes through
               public routing nodes. 
         U
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      unbounded
            The number of potential occurrences isn't limited by a set number. This value is
               often used when defining a data type that's a list (for example,
                  maxOccurs="unbounded"), in WSDL.
         unit
            
            Standard measurement for the values submitted to CloudWatch as metric data. Units include seconds, percent, bytes, bits,
               count, bytes/second, bits/second, count/second, and none.
         usage report
            An AWS record that details your usage of a particular AWS service. You can
               generate and download usage reports from https://aws.amazon.com/usage-reports/.
         user
            
            A person or application under an account
               that makes API calls to AWS products. Each user has a unique name within the
               AWS account, and a set of security credentials that aren't shared with other users.
               These credentials are separate from the security credentials for the AWS account.
               Each user is associated with one and only one AWS account.
         USER_PERSONALIZATION recipes
            Amazon Personalize: Recipes
               that are used to build a recommendation system that predicts the items that a user
               interacts with based on data provided in Interactions, Items, and Users
               datasets.
            See also recipe.
            See also user-personalization recipe.
            See also popularity-count recipe.
            See also HRNN.
         user-personalization recipe
            Amazon Personalize: An
               HRNN-based USER_PERSONALIZATION recipe that predicts the items that a user interacts
               with. The user-personalization recipe can use item exploration and impressions data
               to generate recommendations for new items.
            See also HRNN.
            See also recipe.
            See also USER_PERSONALIZATION recipes.
            See also item exploration.
            See also impressions data.
            See also recommendations.
         Users dataset
            Amazon Personalize: A container for metadata about your users, such as age, gender, or loyalty membership.
            See also dataset.
         V
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      validationSee template validation.value
            Instances of attributes for an item, such as
               cells in a spreadsheet. An attribute might have multiple values.
         
            Tagging resources: A specific tag label that
               acts as a descriptor within a tag category (key). For example, you might have EC2 instance with the tag key of
                  Owner and the tag value of Jan. You can
               tag an AWS resource with up to 10
               key–value pairs. Not all AWS resources can be tagged.
         Variable Envelope Return PathSee VERP.verification
            
            The process of confirming that you own an email address or a domain so that you
               can send email from or to it.
         VERP
            
            Variable Envelope Return Path. A way that email-sending applications can match
                  bounced email with the undeliverable
               address that caused the bounce by using a different return path for each recipient. VERP is typically used for mailing
               lists. With VERP, the recipient's email address is embedded in the address of the
               return path, which is where bounced email is returned. This makes it possible to
               automate the processing of bounced email without having to open the bounce messages,
               which might vary in content.
         versioning
            
            Every object in Amazon S3
               has a key and a version ID.
               Objects with the same key, but different version IDs can be stored in the same bucket. Versioning is enabled at the bucket
               layer using PUT Bucket versioning. 
         VGWSee virtual private gateway (VGW).virtual private gateway (VGW)
            The Amazon side of a VPN connection
               that maintains connectivity. The internal interfaces of the virtual private gateway
               connect to your Amazon VPC through the VPN attachment.
               The external interfaces connect to the VPN connection, which leads to the customer gateway.
         virtualization
            Allows multiple guest virtual machines (VM) to run on a host operating system.
               Guest VMs can run on one or more levels above the host hardware, depending on the
               type of virtualization. 
            See also PV virtualization.
            See also HVM virtualization.
         visibility timeout
            
            The period of time that a message is invisible to the rest of your application
               after an application component gets it from the queue. During the visibility timeout,
               the component that received the message usually processes it, and then deletes it
               from the queue. This prevents multiple components from processing the same
               message.
         VM Import/Export
            VM Import/Export is a service for importing virtual machine (VM) images from your existing
               virtualization environment to Amazon EC2 and then exporting them back.
            See also https://aws.amazon.com/ec2/vm-import.
         volume
            A fixed amount of storage on an instance. You can share volume data between more than one container and persist the data on the container instance when the
               containers are no longer running. 
         Amazon VPC
            Amazon Virtual Private Cloud is a web service for provisioning a logically isolated section of the AWS Cloud
               virtual network that you define. You control your virtual networking environment by selecting your own IP address range, creating subnets and configuring route tables and network gateways.
            See also https://aws.amazon.com/vpc.
         VPC endpoint
            
            A feature that you can use to create a private connection between your Amazon VPC and another AWS service without requiring
               access over the internet, through a NAT
               instance, a VPN connection, or Direct Connect. 
         VPGSee virtual private gateway (VGW).AWS VPN
            AWS Virtual Private Network provides functionality that establishes encrypted connections between
               your network or device, and AWS. AWS VPN is comprised of two services: AWS Client VPN and AWS Site-to-Site VPN.
            See also https://aws.amazon.com/vpn.
         AWS VPN CloudHub
            AWS VPN CloudHub is a feature that enables secure communication between branch offices using a simple hub-and-spoke model, with or without a VPN.
         VPN connection
            Amazon Web Services
            (AWS): The IPsec
               connection that's between a Amazon VPC and some other
               network, such as a corporate data center, home network, or colocation
               facility.
         W
         Numbers and symbols | A | B | C
         | D | E | F | G |
            H | I | J | K |
            L | M | N | O |
            P | Q | R | S |
            T | U | V | W |
            X, Y, Z
      AWS WAF
            AWS WAF is a web application firewall service that controls access to content by allowing or
               blocking web requests based on criteria that you specify. For example, you can filter
               access based on the header values or the IP addresses that the requests originate
               from. AWS WAF helps protect web applications from common web exploits that could affect
               application availability, compromise security, or consume excessive resources.
            See also https://aws.amazon.com/waf/.
         Amazon WAM
            Amazon WorkSpaces Application Manager (Amazon WAM) is a web service for deploying and managing applications for WorkSpaces. Amazon WAM accelerates
               software deployment, upgrades, patching, and retirement by packaging Windows desktop
               applications into virtualized application containers. 
            See also https://aws.amazon.com/workspaces/applicationmanager.
         warm standby
            An active-passive disaster recovery strategy in which a workload is scaled down in the passive standby Region, but is otherwise fully functional. This is not an Amazon EC2 Auto Scaling term, but an industry-standard resilience term. 
            See also back up and restore, hot standby, pilot light.AWS Wavelength
            AWS Wavelength is a service by AWS that embeds AWS compute and storage services within 5G networks to provide mobile edge computing infrastructure. Use AWS Wavelength to develop, deploy, and scale ultra-low-latency applications to mobile devices and end users.
            See also https://aws.amazon.com/wavelength.
         web access control list (web ACL)
            AWS WAF: A set of rules that defines the
               conditions that AWS WAF searches for in web requests to an AWS resource, such as a Amazon CloudFront distribution. A web
               access control list (web ACL) specifies if to allow, block, or count the
               requests.
         Web Services Description LanguageSee WSDL.WorkDocs
            Amazon WorkDocs is a managed, secure enterprise document storage and sharing service with
               administrative controls and feedback capabilities.
            See also https://aws.amazon.com/workdocs/.
         Amazon WorkLink
            Amazon WorkLink is a cloud-based service that provides secure access to internal websites and web
               apps from mobile devices.
            See also https://aws.amazon.com/worklink/.
         WorkMail
            Amazon WorkMail is a managed, secure business email and calendar service with support for existing
               desktop and mobile email clients. 
            See also https://aws.amazon.com/workmail/.
         WorkSpaces
            Amazon WorkSpaces is a managed, secure desktop computing service for provisioning cloud-based desktops
               and providing users access to documents, applications, and resources from supported devices.
            See also https://aws.amazon.com/workspaces/.
         WSDL
            Web Services Description Language. A language that's used to describe the actions
               that a web service can perform, along with the syntax of action requests and
               responses. 
            See also REST.
            See also SOAP.
         X, Y, ZX.509 certificate
            A digital document that uses the X.509 public key infrastructure (PKI) standard to
               verify that a public key belongs to the entity that's described in the certificate.
         X-Ray
            AWS X-Ray is a web service that collects data about requests that your application serves.
               X-Ray provides tools that you can use to view, filter, and gain insights into that
               data to identify issues and opportunities for optimization.
            See also https://aws.amazon.com/xray/.
         yobibyte (YiB)
            A contraction of yotta binary byte. A yobibyte (YiB) is 2^80 or
               1,208,925,819,614,629,174,706,176 bytes. A yottabyte (YB) is 10^24 or
               1,000,000,000,000,000,000,000,000 bytes.
         zebibyte (ZiB)
            A contraction of zetta binary byte. A zebibyte (ZiB) is 2^70 or
               1,180,591,620,717,411,303,424 bytes. A zettabyte (ZB) is 10^21 or
               1,000,000,000,000,000,000,000 bytes. 1,024 ZiB is a yobibyte (YiB).
         zone awareness
            OpenSearch Service: A configuration that distributes nodes in
               a cluster across two Availability Zones
               in the same Region. Zone awareness helps to prevent data loss and minimizes downtime
               if a node and data center fails. If you enable zone awareness, you must have an even
               number of data instances in the instance count, and you also must use the Amazon OpenSearch Service
               Configuration API to replicate your data for your OpenSearch cluster.
         Document ConventionsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationReference guideAWS security credentialsAWS IP address rangesAWS APIsAWS services endpoints and quotasAWS GlossaryAWS General ReferenceThe AWS General Reference provides AWS service endpoint and quota information for Amazon Web Services. Additionally, you can find links to other common topics.ContentsAWS security credentialsAWS IP address rangesAWS APIsAWS services endpoints and quotasAWS Glossary
    AWS security credentials
    
    When you interact with AWS, you specify your AWS security
      credentials to verify who you are and whether you have permission to access the
      resources that you are requesting. AWS uses the security credentials to authenticate and
      authorize your requests.
 
    For more information, see the following resources:
        
    
       
       
      
    
      
      AWS security credentials in the
        IAM User GuideAWS
        security audit guidelines in the
        IAM User Guide
    
   
    AWS IP address ranges
    
    AWS publishes its current IP address ranges in JSON format. You can download
      a .json file to view current ranges. 
    The IP address ranges that you bring to AWS through bring your own IP addresses (BYOIP)
      are not included in the .json file.
    For more information, see the following resources:
    
    
       
       
    AWS IP address ranges in the
        Amazon VPC User GuideAWS services that support IPv6 in the
        Amazon VPC User Guide
   
    AWS APIs
    
    The following pages provide information that is useful when using an AWS API:
    
    
       
       
    Retry behavior in the
        AWS SDKs and Tools Reference GuideSigning AWS API requests in the
        IAM User Guide
    
   
    AWS services endpoints and quotas
    
    You can learn about the endpoints and service quotas in the following pages:
    
    
       
       
       
       
    AWS service endpointsAWS service quotasService endpoints and quotasSpecifying which AWS Regions your account can use in the AWS Account Management Guide
    
    
    
    
    
    
    
   
    AWS Glossary
    
    For the latest AWS terminology, see the AWS Glossary.  
  Document ConventionsAWS service endpointsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideImport and use constructsConstruct levelsDefining constructsWorking with constructsWorking with third-party constructsLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK ConstructsConstructs are the basic building blocks of AWS Cloud Development Kit (AWS CDK) applications. A construct is a component within your
    application that represents one or more AWS CloudFormation resources and their configuration. You build your application, piece by
    piece, by importing and configuring constructs.
    Import and use constructs

    Constructs are classes that you import into your CDK applications from the AWS Construct Library. You can also create and distribute your own constructs, or use
      constructs created by third-party developers.

    Constructs are part of the Construct Programming Model (CPM). They are available to use with other tools such as
      CDK for Terraform (CDKtf), CDK for Kubernetes (CDK8s), and
        Projen.

    Numerous third parties have also published constructs compatible with the AWS CDK. Visit Construct Hub to explore the
      AWS CDK construct partner ecosystem.

   
    Construct levels

    Constructs from the AWS Construct Library are categorized into three levels. Each level offers an increasing level of
      abstraction. The higher the abstraction, the easier to configure, requiring less expertise. The lower the abstraction,
      the more customization available, requiring more expertise.

    
       

      
       

      
       
    

        
        Level 1 (L1) constructs
        
          L1 constructs, also known as CFN resources, are the lowest-level construct and offer no
            abstraction. Each L1 construct maps directly to a single AWS CloudFormation resource. With L1 constructs, you import a
            construct that represents a specific AWS CloudFormation resource. You then define the resource’s properties within your
            construct instance.
          L1 constructs are great to use when you are familiar with AWS CloudFormation and need complete control over defining your
            AWS resource properties.
          In the AWS Construct Library, L1 constructs are named starting with Cfn, followed by an identifier for
            the AWS CloudFormation resource that it represents. For example, the CfnBucket construct is an L1 construct
            that represents an AWS::S3::Bucket AWS CloudFormation
            resource.
          L1 constructs are generated from the AWS CloudFormation resource specification.
            If a resource exists in AWS CloudFormation, it'll be available in the AWS CDK as an L1 construct. New resources or properties
            may take up to a week to become available in the AWS Construct Library. For more information, see AWS
              resource and property types reference in the AWS CloudFormation User Guide.
        
      
        Level 2 (L2) constructs
        
          L2 constructs, also known as curated constructs, are thoughtfully developed by the
            CDK team and are usually the most widely used construct type. L2 constructs map directly to single AWS CloudFormation
            resources, similar to L1 constructs. Compared to L1 constructs, L2 constructs provide a higher-level abstraction
            through an intuitive intent-based API. L2 constructs include sensible default property configurations, best
            practice security policies, and generate a lot of the boilerplate code and glue logic for you.
          L2 constructs also provide helper methods for most resources that make it simpler and quicker to define
            properties, permissions, event-based interactions between resources, and more.
          The s3.Bucket class is an example of an L2 construct for an Amazon Simple Storage Service (Amazon S3) bucket resource.
          The AWS Construct Library contains L2 constructs that are designated stable and ready for production use. For L2
            constructs under development, they are designated as experimental and offered in a separate module.
        
      
        Level 3 (L3) constructs
        
          L3 constructs, also known as patterns, are the highest-level of abstraction. Each L3
            construct can contain a collection of resources that are configured to work together to accomplish a specific
            task or service within your application. L3 constructs are used to create entire AWS architectures for
            particular use cases in your application.
          To provide complete system designs, or substantial parts of a larger system, L3 constructs offer opinionated
            default property configurations. They are built around a particular approach toward solving a problem and
            providing a solution. With L3 constructs, you can create and configure multiple resources quickly, with the
            fewest amount of input and code.
          The ecsPatterns.ApplicationLoadBalancedFargateService class is an example of an L3 construct that
            represents an AWS Fargate service running on an Amazon Elastic Container Service (Amazon ECS) cluster and fronted by an application load
            balancer.
          Similar to L2 constructs, L3 constructs that are ready for production use are included in the AWS Construct Library.
            Those under development are offered in separate modules.
        
      
   
    Defining constructs

    
     
      Composition
      Composition is the key pattern for defining higher-level abstractions through constructs. A
        high-level construct can be composed from any number of lower-level constructs. From a bottom-up perspective, you use
        constructs to organize the individual AWS resources that you want to deploy. You use whatever abstractions are
        convenient for your purpose, with as many levels as you need.
      With composition, you define reusable components and share them like any other code. For example, a team can
        define a construct that implements the company’s best practice for an Amazon DynamoDB table, including backup, global
        replication, automatic scaling, and monitoring. The team can share the construct internally with other teams, or
        publicly.
      Teams can use constructs like any other library package. When the library is updated, developers get access to
        the new version’s improvements and bug fixes, similar to any other code library.
     

    
     
      Initialization
      Constructs are implemented in classes that extend the Construct base class. You define a construct
        by instantiating the class. All constructs take three parameters when they are initialized:
      
         
         
         
      
          scope – The construct's parent or owner. This can either be a stack
            or another construct. Scope determines the construct's place in the construct
              tree. You should usually pass this (self in Python), which
            represents the current object, for the scope.
        
          id – An identifier that must be
            unique within the scope. The identifier serves as a namespace for everything that’s defined within the construct.
            It’s used to generate unique identifiers, such as resource names
            and AWS CloudFormation logical IDs.
          Identifiers need only be unique within a scope. This lets you instantiate and reuse constructs without
            concern for the constructs and identifiers they might contain, and enables composing constructs into higher-level
            abstractions. In addition, scopes make it possible to refer to groups of constructs all at once. Examples include
            for tagging, or specifying where
            the constructs will be deployed.
        
          props – A set of properties or keyword arguments, depending on the
            language, that define the construct’s initial configuration. Higher-level constructs provide more defaults, and
            if all prop elements are optional, you can omit the props parameter completely.
        
     

    
     
      Configuration
      Most constructs accept props as their third argument (or in Python, keyword arguments), a name/value
        collection that defines the construct's configuration. The following example defines a bucket with AWS Key Management Service (AWS KMS)
        encryption and static website hosting enabled. Since it does not explicitly specify an encryption key, the
          Bucket construct defines a new kms.Key and associates it with the bucket.

      

        TypeScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});

          

        JavaScript
            new s3.Bucket(this, 'MyEncryptedBucket', {
  encryption: s3.BucketEncryption.KMS,
  websiteIndexDocument: 'index.html'
});
          

        Python
            s3.Bucket(self, "MyEncryptedBucket", encryption=s3.BucketEncryption.KMS,
    website_index_document="index.html")
          

        Java
            Bucket.Builder.create(this, "MyEncryptedBucket")
        .encryption(BucketEncryption.KMS_MANAGED)
        .websiteIndexDocument("index.html").build();
          

        C#
            new Bucket(this, "MyEncryptedBucket", new BucketProps
{
    Encryption = BucketEncryption.KMS_MANAGED,
    WebsiteIndexDocument = "index.html"
});
          

        Go
            	awss3.NewBucket(stack, jsii.String("MyEncryptedBucket"), &awss3.BucketProps{
		Encryption: awss3.BucketEncryption_KMS,
		WebsiteIndexDocument: jsii.String("index.html"),
	})
          

      

     

    
     
      Interacting with constructs
      Constructs are classes that extend the base Construct class. After you instantiate a construct,
        the construct object exposes a set of methods and properties that let you interact with the construct and pass it
        around as a reference to other parts of the system.
      The AWS CDK framework doesn't put any restrictions on the APIs of constructs. Authors can define any API they want.
        However, the AWS constructs that are included with the AWS Construct Library, such as s3.Bucket,
        follow guidelines and common patterns. This provides a consistent experience across all AWS resources.

      Most AWS constructs have a set of grant methods that you can use to
        grant AWS Identity and Access Management (IAM) permissions on that construct to a principal. The following example grants the IAM group
          data-science permission to read from the Amazon S3 bucket raw-data.

      

        TypeScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        JavaScript
            const rawData = new s3.Bucket(this, 'raw-data');
const dataScience = new iam.Group(this, 'data-science');
rawData.grantRead(dataScience);
          

        Python
            raw_data = s3.Bucket(self, 'raw-data')
data_science = iam.Group(self, 'data-science')
raw_data.grant_read(data_science)
          

        Java
            Bucket rawData = new Bucket(this, "raw-data");
Group dataScience = new Group(this, "data-science");
rawData.grantRead(dataScience);
          

        C#
            var rawData = new Bucket(this, "raw-data");
var dataScience = new Group(this, "data-science");
rawData.GrantRead(dataScience);
          

        Go
            	rawData := awss3.NewBucket(stack, jsii.String("raw-data"), nil)
	dataScience := awsiam.NewGroup(stack, jsii.String("data-science"), nil)
	rawData.GrantRead(dataScience, nil)
          

      

      Another common pattern is for AWS constructs to set one of the resource's attributes from data supplied
        elsewhere. Attributes can include Amazon Resource Names (ARNs), names, or URLs.
      The following code defines an AWS Lambda function and associates it with an Amazon Simple Queue Service (Amazon SQS) queue through the
        queue's URL in an environment variable.

      

        TypeScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        JavaScript
            const jobsQueue = new sqs.Queue(this, 'jobs');
const createJobLambda = new lambda.Function(this, 'create-job', {
  runtime: lambda.Runtime.NODEJS_18_X,
  handler: 'index.handler',
  code: lambda.Code.fromAsset('./create-job-lambda-code'),
  environment: {
    QUEUE_URL: jobsQueue.queueUrl
  }
});
          

        Python
            jobs_queue = sqs.Queue(self, "jobs")
create_job_lambda = lambda_.Function(self, "create-job",
    runtime=lambda_.Runtime.NODEJS_18_X,
    handler="index.handler",
    code=lambda_.Code.from_asset("./create-job-lambda-code"),
    environment=dict(
        QUEUE_URL=jobs_queue.queue_url
    )
)
          

        Java
            final Queue jobsQueue = new Queue(this, "jobs");
Function createJobLambda = Function.Builder.create(this, "create-job")
                .handler("index.handler")
                .code(Code.fromAsset("./create-job-lambda-code"))
                .environment(java.util.Map.of(   // Map.of is Java 9 or later
                    "QUEUE_URL", jobsQueue.getQueueUrl())
                .build();
          

        C#
            var jobsQueue = new Queue(this, "jobs");
var createJobLambda = new Function(this, "create-job", new FunctionProps
{
    Runtime = Runtime.NODEJS_18_X,
    Handler = "index.handler",
    Code = Code.FromAsset(@".\create-job-lambda-code"),
    Environment = new Dictionary<string, string>
    {
        ["QUEUE_URL"] = jobsQueue.QueueUrl
    }
});
          

        Go
            	createJobLambda := awslambda.NewFunction(stack, jsii.String("create-job"), &awslambda.FunctionProps{
		Runtime: awslambda.Runtime_NODEJS_18_X(),
		Handler: jsii.String("index.handler"),
		Code:    awslambda.Code_FromAsset(jsii.String(".\\create-job-lambda-code"), nil),
		Environment: &map[string]*string{
			"QUEUE_URL": jsii.String(*jobsQueue.QueueUrl()),
		},
	})
          

      

      For information about the most common API patterns in the AWS Construct Library, see Resources and the AWS CDK.

     

    
     
      The app and stack construct
      The App and
            Stack classes from
        the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
        own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS
        resources must be defined, directly or indirectly, within the scope of a Stack construct.
          Stack constructs are defined within the scope of an App construct.
      To learn more about CDK apps, see AWS CDK apps. To learn more about
        CDK stacks, see Introduction to AWS CDK stacks.
      The following example defines an app with a single stack. Within the stack, an L2 construct is used to configure
        an Amazon S3 bucket resource.
      

        TypeScript
            import { App, Stack, StackProps } from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

class HelloCdkStack extends Stack {
  constructor(scope: App, id: string, props?: StackProps) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        JavaScript
            const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class HelloCdkStack extends Stack {
  constructor(scope, id, props) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true
    });
  }
}

const app = new App();
new HelloCdkStack(app, "HelloCdkStack");
          

        Python
            from aws_cdk import App, Stack
import aws_cdk.aws_s3 as s3
from constructs import Construct

class HelloCdkStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        s3.Bucket(self, "MyFirstBucket", versioned=True)

app = App()
HelloCdkStack(app, "HelloCdkStack")
          

        Java
            Stack defined in HelloCdkStack.java file:
            import software.constructs.Construct;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
            .versioned(true).build();
    }
}
            App defined in HelloCdkApp.java file:
            import software.amazon.awscdk.App;
import software.amazon.awscdk.StackProps;

public class HelloCdkApp {
    public static void main(final String[] args) {
        App app = new App();

        new HelloCdkStack(app, "HelloCdkStack", StackProps.builder()
                .build());

        app.synth();
    }
}
          

        C#
            using Amazon.CDK;
using Amazon.CDK.AWS.S3;

namespace HelloCdkApp
{
    internal static class Program
    {
        public static void Main(string[] args)
        {
            var app = new App();
            new HelloCdkStack(app, "HelloCdkStack");
            app.Synth();
        }
    }
    
    public class HelloCdkStack : Stack
    {
        public HelloCdkStack(Construct scope, string id, IStackProps props=null) : base(scope, id, props)
        {
            new Bucket(this, "MyFirstBucket", new BucketProps { Versioned = true });
        }
    }
}
          


        Go
            func NewHelloCdkStack(scope constructs.Construct, id string, props *HelloCdkStackProps) awscdk.Stack {
	var sprops awscdk.StackProps
	if props != nil {
		sprops = props.StackProps
	}
	stack := awscdk.NewStack(scope, &id, &sprops)

	awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})

	return stack
}
          

      

     

   
    Working with constructs

    
     
      Working with L1 constructs
      L1 constructs map directly to individual AWS CloudFormation resources. You must provide the resource's required
        configuration.
      In this example, we create a bucket object using the CfnBucket L1 construct:
      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket"
});
          

        Python
            bucket = s3.CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket")
          

        Java
            CfnBucket bucket = new CfnBucket.Builder().bucketName("amzn-s3-demo-bucket").build();
          

        C#
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName= "amzn-s3-demo-bucket"
});
          

        Go
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
	})
          


      

      Construct properties that aren't simple Booleans, strings, numbers, or containers are handled differently in the
        supported languages.

      

        TypeScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        JavaScript
            const bucket = new s3.CfnBucket(this, "amzn-s3-demo-bucket", {
  bucketName: "amzn-s3-demo-bucket",
  corsConfiguration: {
    corsRules: [{
          allowedOrigins: ["*"],
          allowedMethods: ["GET"]
    }]
  }
});
          

        Python
            In Python, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property cors_configuration of a CfnBucket requires a wrapper
              of type CfnBucket.CorsConfigurationProperty. Here we are defining cors_configuration
              on a CfnBucket instance.
            bucket = CfnBucket(self, "amzn-s3-demo-bucket", bucket_name="amzn-s3-demo-bucket",
    cors_configuration=CfnBucket.CorsConfigurationProperty(
        cors_rules=[CfnBucket.CorsRuleProperty(
            allowed_origins=["*"],
            allowed_methods=["GET"]
        )]
    )
)
          

        Java
            In Java, these properties are represented by types defined as inner classes of the L1 construct. For
              example, the optional property corsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket.CorsConfigurationProperty. Here we are defining corsConfiguration on a
                CfnBucket instance.
            CfnBucket bucket = CfnBucket.Builder.create(this, "amzn-s3-demo-bucket")
                        .bucketName("amzn-s3-demo-bucket")
                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()
                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()
                                .allowedOrigins(Arrays.asList("*"))
                                .allowedMethods(Arrays.asList("GET"))
                                .build()))
                            .build())
                        .build();
          

        C#
            In C#, these properties are represented by types defined as inner classes of the L1 construct. For example,
              the optional property CorsConfiguration of a CfnBucket requires a wrapper of type
                CfnBucket.CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            var bucket = new CfnBucket(this, "amzn-s3-demo-bucket", new CfnBucketProps
{
    BucketName = "amzn-s3-demo-bucket",
    CorsConfiguration = new CfnBucket.CorsConfigurationProperty
    {
        CorsRules = new object[] {
            new CfnBucket.CorsRuleProperty
            {
                AllowedOrigins = new string[] { "*" },
                AllowedMethods = new string[] { "GET" },
            }
        }
    }
});
          

        Go
            In Go, these types are named using the name of the L1 construct, an underscore, and the property name. For
              example, the optional property CorsConfiguration of a CfnBucket requires a wrapper of
              type CfnBucket_CorsConfigurationProperty. Here we are defining CorsConfiguration on a
                CfnBucket instance.
            	awss3.NewCfnBucket(stack, jsii.String("amzn-s3-demo-bucket"), &awss3.CfnBucketProps{
		BucketName: jsii.String("amzn-s3-demo-bucket"),
		CorsConfiguration: &awss3.CfnBucket_CorsConfigurationProperty{
			CorsRules: []awss3.CorsRule{
				awss3.CorsRule{
					AllowedOrigins: jsii.Strings("*"),
					AllowedMethods: &[]awss3.HttpMethods{"GET"},
				},
			},
		},
	})

          

      

      ImportantYou can't use L2 property types with L1 constructs, or vice versa. When working with L1 constructs, always use
          the types defined for the L1 construct you're using. Do not use types from other L1 constructs (some may have the
          same name, but they are not the same type).Some of our language-specific API references currently have errors in the paths to L1 property types, or don't
          document these classes at all. We hope to fix this soon. In the meantime, remember that such types are always inner
          classes of the L1 construct they are used with.

     

    
     

      Working with L2 constructs
      In the following example, we define an Amazon S3 bucket by creating an object from the Bucket L2 construct:

      
        TypeScript
            import * as s3 from 'aws-cdk-lib/aws-s3';

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        JavaScript
            const s3 = require('aws-cdk-lib/aws-s3');

// "this" is HelloCdkStack
new s3.Bucket(this, 'MyFirstBucket', {
  versioned: true
});
          

        Python
            import aws_cdk.aws_s3 as s3

# "self" is HelloCdkStack
s3.Bucket(self, "MyFirstBucket", versioned=True)
          

        Java
            import software.amazon.awscdk.services.s3.*;

public class HelloCdkStack extends Stack {
    public HelloCdkStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "MyFirstBucket")
                .versioned(true).build();
    }
}
          

        C#
            using Amazon.CDK.AWS.S3;

// "this" is HelloCdkStack
new Bucket(this, "MyFirstBucket", new BucketProps
{
    Versioned = true
});
          

        Go
            import (
	"github.com/aws/aws-cdk-go/awscdk/v2/awss3"
	"github.com/aws/jsii-runtime-go"
)

// stack is HelloCdkStack
awss3.NewBucket(stack, jsii.String("MyFirstBucket"), &awss3.BucketProps{
		Versioned: jsii.Bool(true),
	})>
          

      

      MyFirstBucket is not the name of the bucket that AWS CloudFormation creates. It is a logical identifier given to
        the new construct within the context of your CDK app. The physicalName value will be used to name
        the AWS CloudFormation resource.

     

   
    Working with third-party constructs
    Construct Hub is a resource to help you discover additional constructs from AWS, third parties, and the
      open-source CDK community.

    
     
      Writing your own constructs
      In addition to using existing constructs, you can also write your own constructs and let anyone use them in their
        apps. All constructs are equal in the AWS CDK. Constructs from the AWS Construct Library are treated the same as a construct
        from a third-party library published via NPM, Maven, or PyPI. Constructs
        published to your company's internal package repository are also treated in the same way.

      To declare a new construct, create a class that extends the Construct base class, in the
          constructs package, then follow the pattern for initializer arguments.

      The following example shows how to declare a construct that represents an Amazon S3 bucket. The S3 bucket sends an
        Amazon Simple Notification Service (Amazon SNS) notification every time someone uploads a file into it.

      

        TypeScript

            export interface NotifyingBucketProps {
  prefix?: string;
}

export class NotifyingBucket extends Construct {
  constructor(scope: Construct, id: string, props: NotifyingBucketProps = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

          

        JavaScript

            class NotifyingBucket extends Construct {
  constructor(scope, id, props = {}) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    const topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic),
      { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket }
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        Topic topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucketProps : BucketProps
{
    public string Prefix { get; set; }
}

public class NotifyingBucket : Construct
{
    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        var topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          

        Go
            type NotifyingBucketProps struct {
	awss3.BucketProps
	Prefix *string
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) awss3.Bucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	return bucket
}
          


      

      NoteOur NotifyingBucket construct inherits not from Bucket but rather from
            Construct. We are using composition, not inheritance, to bundle an Amazon S3 bucket and an Amazon SNS topic
          together. In general, composition is preferred over inheritance when developing AWS CDK constructs.

      The NotifyingBucket constructor has a typical construct signature: scope,
          id, and props. The last argument, props, is optional (gets the default value
          {}) because all props are optional. (The base Construct class does not take a
          props argument.) You could define an instance of this construct in your app without
        props, for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket');
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket");
          


        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), nil)

          

      

      Or you could use props (in Java, an additional parameter) to specify the path prefix to filter on,
        for example:

      

        TypeScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        JavaScript
            new NotifyingBucket(this, 'MyNotifyingBucket', { prefix: 'images/' });
          

        Python
            NotifyingBucket(self, "MyNotifyingBucket", prefix="images/")
          

        Java
            new NotifyingBucket(this, "MyNotifyingBucket", "/images");
          

        C#
            new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
          

        Go
            NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
	Prefix: jsii.String("images/"),
})
          

      

      Typically, you would also want to expose some properties or methods on your constructs. It's not very useful to
        have a topic hidden behind your construct, because users of your construct aren't able to subscribe to it. Adding a
          topic property lets consumers access the inner topic, as shown in the following example:

      

        TypeScript
            export class NotifyingBucket extends Construct {
  public readonly topic: sns.Topic;

  constructor(scope: Construct, id: string, props: NotifyingBucketProps) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}
          

        JavaScript
            class NotifyingBucket extends Construct {

  constructor(scope, id, props) {
    super(scope, id);
    const bucket = new s3.Bucket(this, 'bucket');
    this.topic = new sns.Topic(this, 'topic');
    bucket.addObjectCreatedNotification(new s3notify.SnsDestination(this.topic), { prefix: props.prefix });
  }
}

module.exports = { NotifyingBucket };
          

        Python
            class NotifyingBucket(Construct):

    def __init__(self, scope: Construct, id: str, *, prefix=None, **kwargs):
        super().__init__(scope, id)
        bucket = s3.Bucket(self, "bucket")
        self.topic = sns.Topic(self, "topic")
        bucket.add_object_created_notification(s3notify.SnsDestination(self.topic),
            s3.NotificationKeyFilter(prefix=prefix))
          

        Java
            public class NotifyingBucket extends Construct {

    public Topic topic = null;
    
    public NotifyingBucket(final Construct scope, final String id) {
        this(scope, id, null, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final BucketProps props) {
        this(scope, id, props, null);
    }
    
    public NotifyingBucket(final Construct scope, final String id, final String prefix) {
        this(scope, id, null, prefix);
    }

    public NotifyingBucket(final Construct scope, final String id, final BucketProps props, final String prefix) {
        super(scope, id);

        Bucket bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        if (prefix != null)
            bucket.addObjectCreatedNotification(new SnsDestination(topic),
                NotificationKeyFilter.builder().prefix(prefix).build());
     }
}
          

        C#
            public class NotifyingBucket : Construct
{
    public readonly Topic topic;

    public NotifyingBucket(Construct scope, string id, NotifyingBucketProps props = null) : base(scope, id)
    {
        var bucket = new Bucket(this, "bucket");
        topic = new Topic(this, "topic");
        bucket.AddObjectCreatedNotification(new SnsDestination(topic), new NotificationKeyFilter
        {
            Prefix = props?.Prefix
        });
    }
}
          
        Go
            To do this in Go, we'll need a little extra plumbing. Our original NewNotifyingBucket function
              returned an awss3.Bucket. We'll need to extend Bucket to include a topic
              member by creating a NotifyingBucket struct. Our function will then return this type.
            type NotifyingBucket struct {
	awss3.Bucket
	topic awssns.Topic
}

func NewNotifyingBucket(scope constructs.Construct, id *string, props *NotifyingBucketProps) NotifyingBucket {
	var bucket awss3.Bucket
	if props == nil {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), nil)
	} else {
		bucket = awss3.NewBucket(scope, jsii.String(*id+"Bucket"), &props.BucketProps)
	}
	topic := awssns.NewTopic(scope, jsii.String(*id+"Topic"), nil)
	if props == nil {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic))
	} else {
		bucket.AddObjectCreatedNotification(awss3notifications.NewSnsDestination(topic), &awss3.NotificationKeyFilter{
			Prefix: props.Prefix,
		})
	}
	var nbucket NotifyingBucket
	nbucket.Bucket = bucket
	nbucket.topic = topic
	return nbucket
}
          

      

      Now, consumers can subscribe to the topic, for example:

      

        TypeScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        JavaScript
            const queue = new sqs.Queue(this, 'NewImagesQueue');
const images = new NotifyingBucket(this, '/images');
images.topic.addSubscription(new sns_sub.SqsSubscription(queue));
          

        Python
            queue = sqs.Queue(self, "NewImagesQueue")
images = NotifyingBucket(self, prefix="Images")
images.topic.add_subscription(sns_sub.SqsSubscription(queue))
          

        Java
            NotifyingBucket images = new NotifyingBucket(this, "MyNotifyingBucket", "/images");
images.topic.addSubscription(new SqsSubscription(queue));
          

        C#
            var queue = new Queue(this, "NewImagesQueue");
var images = new NotifyingBucket(this, "MyNotifyingBucket", new NotifyingBucketProps
{
    Prefix = "/images"
});
images.topic.AddSubscription(new SqsSubscription(queue));
          
        Go
            	queue := awssqs.NewQueue(stack, jsii.String("NewImagesQueue"), nil)
	images := NewNotifyingBucket(stack, jsii.String("MyNotifyingBucket"), &NotifyingBucketProps{
		Prefix: jsii.String("/images"),
	})
	images.topic.AddSubscription(awssnssubscriptions.NewSqsSubscription(queue, nil))
          

      

     

   
    Learn more
    The following video provides a comprehensive overview of CDK constructs, and explains how you can use them
      in your CDK apps.

    
       
        
       
    
    
  Document ConventionsCDK stagesEnvironmentsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideThe AWS CDK LibraryThe AWS Construct LibraryThe Constructs libraryThe AWS CDK API referenceLearn moreThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.The AWS CDK librariesLearn about the core libraries that you will use with the AWS Cloud Development Kit (AWS CDK).
		The AWS CDK Library

		The AWS CDK Library, also referred to as aws-cdk-lib, is the main library that you will use to develop
			applications with the AWS CDK. It is developed and maintained by AWS. This library contains base classes, such as
					App and Stack. It also contains the
			libraries you will use to define your infrastructure through constructs.

	 
		The AWS Construct Library

		The AWS Construct Library is a part of the AWS CDK Library. It contains a collection of constructs that are developed and maintained by AWS. It is organized into various modules for each
			AWS service. Each module includes constructs that you can use to define your AWS resources and properties.

	 
		The Constructs library

		The Constructs library, commonly referred to as constructs, is a library for defining and composing
			cloud infrastructure components. It contains the core Construct class, which represents the construct
			building block. This class is the foundational base class of all constructs from the AWS Construct Library. The Constructs
			library is a separate general-purpose library that is used by other construct-based tools such as CDK
				for Terraform and CDK for Kubernetes.

	 
		The AWS CDK API reference

		The AWS CDK API reference
			contains official reference documentation for the AWS CDK Library, including the AWS Construct Library and Constructs library. A
			version of the API reference is provided for each supported programming language.

		
			 
			 
			 
		
				For AWS CDK Library (aws-cdk-lib) documentation, see aws-cdk-lib module.
			
				Documentation for constructs in the AWS Construct Library are organized by AWS service in the following format:
							aws-cdk-lib.<service>. For example, construct documentation for
					Amazon Simple Storage Service (Amazon S3), can be found at aws-cdk-lib.aws_s3 module.
			
				For Constructs library (constructs) documentation, see constructs module.
			

		
		 
			Contribute to the AWS CDK API reference

			The AWS CDK is open-source and we welcome you to contribute. Community contributions positively impact and improve
				the AWS CDK. For instructions on contributing specifically to AWS CDK API reference documentation, see Documentation in the
					aws-cdk GitHub repository.

		 

	 
		Learn more

		For instructions on importing and using the CDK Library, see Work with the CDK library.
		
	Document ConventionsProgramming languagesProjectsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nclass CfnBucket (construct)


LanguageType name


 .NETAmazon.CDK.AWS.S3.CfnBucket
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awss3#CfnBucket
 Javasoftware.amazon.awscdk.services.s3.CfnBucket
 Pythonaws_cdk.aws_s3.CfnBucket
 TypeScript aws-cdk-lib » aws_s3 » CfnBucket


Implements
IConstruct, IDependable, IInspectable, ITaggable
The AWS::S3::Bucket resource creates an Amazon S3 bucket in the same AWS Region where you create the AWS CloudFormation stack.
To control how AWS CloudFormation handles the bucket when the stack is deleted, you can set a deletion policy for your bucket. You can choose to retain the bucket or to delete the bucket. For more information, see DeletionPolicy Attribute .

You can only delete empty buckets. Deletion fails for buckets that have contents.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html
Example
declare const cfnTemplate: cfn_inc.CfnInclude;
const cfnBucket = cfnTemplate.getResource('Bucket') as s3.CfnBucket;

const role = new iam.Role(this, 'Role', {
  assumedBy: new iam.AnyPrincipal(),
});
role.addToPolicy(new iam.PolicyStatement({
  actions: ['s3:*'],
  resources: [cfnBucket.attrArn],
}));

Initializer
new CfnBucket(scope: Construct, id: string, props?: CfnBucketProps)

Parameters

scope Construct  — Scope in which this resource is defined.
id string  — Construct identifier for this resource (unique in its scope).
props CfnBucketProps  — Resource properties.

Construct Props


NameTypeDescription


accelerateConfiguration?IResolvable | AccelerateConfigurationPropertyConfigures the transfer acceleration state for an Amazon S3 bucket.
accessControl?string> This is a legacy property, and it is not recommended for most use cases.
analyticsConfigurations?IResolvable | IResolvable | AnalyticsConfigurationProperty[]Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
bucketEncryption?IResolvable | BucketEncryptionPropertySpecifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
bucketName?stringA name for the bucket.
corsConfiguration?IResolvable | CorsConfigurationPropertyDescribes the cross-origin access configuration for objects in an Amazon S3 bucket.
intelligentTieringConfigurations?IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]Defines how Amazon S3 handles Intelligent-Tiering storage.
inventoryConfigurations?IResolvable | IResolvable | InventoryConfigurationProperty[]Specifies the inventory configuration for an Amazon S3 bucket.
lifecycleConfiguration?IResolvable | LifecycleConfigurationPropertySpecifies the lifecycle configuration for objects in an Amazon S3 bucket.
loggingConfiguration?IResolvable | LoggingConfigurationPropertySettings that define where logs are stored.
metadataTableConfiguration?IResolvable | MetadataTableConfigurationPropertyThe metadata table configuration of an Amazon S3 general purpose bucket.
metricsConfigurations?IResolvable | IResolvable | MetricsConfigurationProperty[]Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
notificationConfiguration?IResolvable | NotificationConfigurationPropertyConfiguration that defines how Amazon S3 handles bucket notifications.
objectLockConfiguration?IResolvable | ObjectLockConfigurationProperty> This operation is not supported for directory buckets.
objectLockEnabled?boolean | IResolvableIndicates whether this bucket has an Object Lock configuration enabled.
ownershipControls?IResolvable | OwnershipControlsPropertyConfiguration that defines how Amazon S3 handles Object Ownership rules.
publicAccessBlockConfiguration?IResolvable | PublicAccessBlockConfigurationPropertyConfiguration that defines how Amazon S3 handles public access.
replicationConfiguration?IResolvable | ReplicationConfigurationPropertyConfiguration for replicating objects in an S3 bucket.
tags?CfnTag[]An arbitrary set of tags (key-value pairs) for this S3 bucket.
versioningConfiguration?IResolvable | VersioningConfigurationPropertyEnables multiple versions of all objects in this bucket.
websiteConfiguration?IResolvable | WebsiteConfigurationPropertyInformation used to configure the bucket as a static website.



accelerateConfiguration?
Type:
IResolvable | AccelerateConfigurationProperty
(optional)
Configures the transfer acceleration state for an Amazon S3 bucket.
For more information, see Amazon S3 Transfer Acceleration in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-accelerateconfiguration

accessControl?
Type:
string
(optional)

This is a legacy property, and it is not recommended for most use cases.

A majority of modern use cases in Amazon S3 no longer require the use of ACLs, and we recommend that you keep ACLs disabled. For more information, see Controlling object ownership in the Amazon S3 User Guide .
A canned access control list (ACL) that grants predefined permissions to the bucket. For more information about canned ACLs, see Canned ACL in the Amazon S3 User Guide .
S3 buckets are created with ACLs disabled by default. Therefore, unless you explicitly set the AWS::S3::OwnershipControls property to enable ACLs, your resource will fail to deploy with any value other than Private. Use cases requiring ACLs are uncommon.
The majority of access control configurations can be successfully and more easily achieved with bucket policies. For more information, see AWS::S3::BucketPolicy . For examples of common policy configurations, including S3 Server Access Logs buckets and more, see Bucket policy examples in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-accesscontrol

analyticsConfigurations?
Type:
IResolvable | IResolvable | AnalyticsConfigurationProperty[]
(optional)
Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-analyticsconfigurations

bucketEncryption?
Type:
IResolvable | BucketEncryptionProperty
(optional)
Specifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
For information about the Amazon S3 default encryption feature, see Amazon S3 Default Encryption for S3 Buckets in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-bucketencryption

bucketName?
Type:
string
(optional)
A name for the bucket.
If you don't specify a name, AWS CloudFormation generates a unique ID and uses that ID for the bucket name. The bucket name must contain only lowercase letters, numbers, periods (.), and dashes (-) and must follow Amazon S3 bucket restrictions and limitations . For more information, see Rules for naming Amazon S3 buckets in the Amazon S3 User Guide .

If you specify a name, you can't perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you need to replace the resource, specify a new name.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-bucketname

corsConfiguration?
Type:
IResolvable | CorsConfigurationProperty
(optional)
Describes the cross-origin access configuration for objects in an Amazon S3 bucket.
For more information, see Enabling Cross-Origin Resource Sharing in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-corsconfiguration

intelligentTieringConfigurations?
Type:
IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]
(optional)
Defines how Amazon S3 handles Intelligent-Tiering storage.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-intelligenttieringconfigurations

inventoryConfigurations?
Type:
IResolvable | IResolvable | InventoryConfigurationProperty[]
(optional)
Specifies the inventory configuration for an Amazon S3 bucket.
For more information, see GET Bucket inventory in the Amazon S3 API Reference .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-inventoryconfigurations

lifecycleConfiguration?
Type:
IResolvable | LifecycleConfigurationProperty
(optional)
Specifies the lifecycle configuration for objects in an Amazon S3 bucket.
For more information, see Object Lifecycle Management in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-lifecycleconfiguration

loggingConfiguration?
Type:
IResolvable | LoggingConfigurationProperty
(optional)
Settings that define where logs are stored.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-loggingconfiguration

metadataTableConfiguration?
Type:
IResolvable | MetadataTableConfigurationProperty
(optional)
The metadata table configuration of an Amazon S3 general purpose bucket.
For more information, see Accelerating data discovery with S3 Metadata and Setting up permissions for configuring metadata tables .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-metadatatableconfiguration

metricsConfigurations?
Type:
IResolvable | IResolvable | MetricsConfigurationProperty[]
(optional)
Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
If you're updating an existing metrics configuration, note that this is a full replacement of the existing metrics configuration. If you don't include the elements you want to keep, they are erased. For more information, see PutBucketMetricsConfiguration .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-metricsconfigurations

notificationConfiguration?
Type:
IResolvable | NotificationConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles bucket notifications.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-notificationconfiguration

objectLockConfiguration?
Type:
IResolvable | ObjectLockConfigurationProperty
(optional)

This operation is not supported for directory buckets.

Places an Object Lock configuration on the specified bucket. The rule specified in the Object Lock configuration will be applied by default to every new object placed in the specified bucket. For more information, see Locking Objects .


The DefaultRetention settings require both a mode and a period.
The DefaultRetention period can be either Days or Years but you must select one. You cannot specify Days and Years at the same time.
You can enable Object Lock for new or existing buckets. For more information, see Configuring Object Lock .


See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-objectlockconfiguration

objectLockEnabled?
Type:
boolean | IResolvable
(optional)
Indicates whether this bucket has an Object Lock configuration enabled.
Enable ObjectLockEnabled when you apply ObjectLockConfiguration to a bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-objectlockenabled

ownershipControls?
Type:
IResolvable | OwnershipControlsProperty
(optional)
Configuration that defines how Amazon S3 handles Object Ownership rules.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-ownershipcontrols

publicAccessBlockConfiguration?
Type:
IResolvable | PublicAccessBlockConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles public access.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-publicaccessblockconfiguration

replicationConfiguration?
Type:
IResolvable | ReplicationConfigurationProperty
(optional)
Configuration for replicating objects in an S3 bucket.
To enable replication, you must also enable versioning by using the VersioningConfiguration property.
Amazon S3 can store replicated objects in a single destination bucket or multiple destination buckets. The destination bucket or buckets must already exist.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-replicationconfiguration

tags?
Type:
CfnTag[]
(optional)
An arbitrary set of tags (key-value pairs) for this S3 bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-tags

versioningConfiguration?
Type:
IResolvable | VersioningConfigurationProperty
(optional)
Enables multiple versions of all objects in this bucket.
You might enable versioning to prevent objects from being deleted or overwritten by mistake or to archive objects so that you can retrieve previous versions of them.

When you enable versioning on a bucket for the first time, it might take a short amount of time for the change to be fully propagated. We recommend that you wait for 15 minutes after enabling versioning before issuing write operations ( PUT or DELETE ) on objects in the bucket.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-versioningconfiguration

websiteConfiguration?
Type:
IResolvable | WebsiteConfigurationProperty
(optional)
Information used to configure the bucket as a static website.
For more information, see Hosting Websites on Amazon S3 .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-websiteconfiguration
Properties


NameTypeDescription


attrArnstringReturns the Amazon Resource Name (ARN) of the specified bucket.
attrDomainNamestringReturns the IPv4 DNS name of the specified bucket.
attrDualStackDomainNamestringReturns the IPv6 DNS name of the specified bucket.
attrMetadataTableConfigurationS3TablesDestinationTableArnstringThe Amazon Resource Name (ARN) for the metadata table in the metadata table configuration.
attrMetadataTableConfigurationS3TablesDestinationTableNamespacestringThe table bucket namespace for the metadata table in your metadata table configuration.
attrRegionalDomainNamestringReturns the regional domain name of the specified bucket.
attrWebsiteUrlstringReturns the Amazon S3 website endpoint for the specified bucket.
cfnOptionsICfnResourceOptionsOptions for this resource, such as condition, update policy etc.
cfnProperties{ [string]: any }
cfnResourceTypestringAWS resource type.
creationStackstring[]
logicalIdstringThe logical ID for this CloudFormation stack element.
nodeNodeThe tree node.
refstringReturn a string that will be resolved to a CloudFormation { Ref } for this element.
stackStackThe stack in which this element is defined.
tagsTagManagerTag Manager which manages the tags for this resource.
accelerateConfiguration?IResolvable | AccelerateConfigurationPropertyConfigures the transfer acceleration state for an Amazon S3 bucket.
accessControl?string> This is a legacy property, and it is not recommended for most use cases.
analyticsConfigurations?IResolvable | IResolvable | AnalyticsConfigurationProperty[]Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
bucketEncryption?IResolvable | BucketEncryptionPropertySpecifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
bucketName?stringA name for the bucket.
corsConfiguration?IResolvable | CorsConfigurationPropertyDescribes the cross-origin access configuration for objects in an Amazon S3 bucket.
intelligentTieringConfigurations?IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]Defines how Amazon S3 handles Intelligent-Tiering storage.
inventoryConfigurations?IResolvable | IResolvable | InventoryConfigurationProperty[]Specifies the inventory configuration for an Amazon S3 bucket.
lifecycleConfiguration?IResolvable | LifecycleConfigurationPropertySpecifies the lifecycle configuration for objects in an Amazon S3 bucket.
loggingConfiguration?IResolvable | LoggingConfigurationPropertySettings that define where logs are stored.
metadataTableConfiguration?IResolvable | MetadataTableConfigurationPropertyThe metadata table configuration of an Amazon S3 general purpose bucket.
metricsConfigurations?IResolvable | IResolvable | MetricsConfigurationProperty[]Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
notificationConfiguration?IResolvable | NotificationConfigurationPropertyConfiguration that defines how Amazon S3 handles bucket notifications.
objectLockConfiguration?IResolvable | ObjectLockConfigurationProperty> This operation is not supported for directory buckets.
objectLockEnabled?boolean | IResolvableIndicates whether this bucket has an Object Lock configuration enabled.
ownershipControls?IResolvable | OwnershipControlsPropertyConfiguration that defines how Amazon S3 handles Object Ownership rules.
publicAccessBlockConfiguration?IResolvable | PublicAccessBlockConfigurationPropertyConfiguration that defines how Amazon S3 handles public access.
replicationConfiguration?IResolvable | ReplicationConfigurationPropertyConfiguration for replicating objects in an S3 bucket.
tagsRaw?CfnTag[]An arbitrary set of tags (key-value pairs) for this S3 bucket.
versioningConfiguration?IResolvable | VersioningConfigurationPropertyEnables multiple versions of all objects in this bucket.
websiteConfiguration?IResolvable | WebsiteConfigurationPropertyInformation used to configure the bucket as a static website.
static CFN_RESOURCE_TYPE_NAMEstringThe CloudFormation resource type name for this resource class.



attrArn
Type:
string
Returns the Amazon Resource Name (ARN) of the specified bucket.
Example: arn:aws:s3:::DOC-EXAMPLE-BUCKET

attrDomainName
Type:
string
Returns the IPv4 DNS name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.amazonaws.com

attrDualStackDomainName
Type:
string
Returns the IPv6 DNS name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com
For more information about dual-stack endpoints, see Using Amazon S3 Dual-Stack Endpoints .

attrMetadataTableConfigurationS3TablesDestinationTableArn
Type:
string
The Amazon Resource Name (ARN) for the metadata table in the metadata table configuration.
The specified metadata table name must be unique within the aws_s3_metadata namespace in the destination table bucket.

attrMetadataTableConfigurationS3TablesDestinationTableNamespace
Type:
string
The table bucket namespace for the metadata table in your metadata table configuration.
This value is always aws_s3_metadata .

attrRegionalDomainName
Type:
string
Returns the regional domain name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.us-east-2.amazonaws.com

attrWebsiteUrl
Type:
string
Returns the Amazon S3 website endpoint for the specified bucket.
Example (IPv4): http://DOC-EXAMPLE-BUCKET.s3-website.us-east-2.amazonaws.com
Example (IPv6): http://DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com

cfnOptions
Type:
ICfnResourceOptions
Options for this resource, such as condition, update policy etc.

cfnProperties
Type:
{ [string]: any }

cfnResourceType
Type:
string
AWS resource type.

creationStack
Type:
string[]

logicalId
Type:
string
The logical ID for this CloudFormation stack element.
The logical ID of the element
is calculated from the path of the resource node in the construct tree.
To override this value, use overrideLogicalId(newLogicalId).

node
Type:
Node
The tree node.

ref
Type:
string
Return a string that will be resolved to a CloudFormation { Ref } for this element.
If, by any chance, the intrinsic reference of a resource is not a string, you could
coerce it to an IResolvable through Lazy.any({ produce: resource.ref }).

stack
Type:
Stack
The stack in which this element is defined.
CfnElements must be defined within a stack scope (directly or indirectly).

tags
Type:
TagManager
Tag Manager which manages the tags for this resource.

accelerateConfiguration?
Type:
IResolvable | AccelerateConfigurationProperty
(optional)
Configures the transfer acceleration state for an Amazon S3 bucket.

accessControl?
Type:
string
(optional)

This is a legacy property, and it is not recommended for most use cases.


analyticsConfigurations?
Type:
IResolvable | IResolvable | AnalyticsConfigurationProperty[]
(optional)
Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.

bucketEncryption?
Type:
IResolvable | BucketEncryptionProperty
(optional)
Specifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).

bucketName?
Type:
string
(optional)
A name for the bucket.

corsConfiguration?
Type:
IResolvable | CorsConfigurationProperty
(optional)
Describes the cross-origin access configuration for objects in an Amazon S3 bucket.

intelligentTieringConfigurations?
Type:
IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]
(optional)
Defines how Amazon S3 handles Intelligent-Tiering storage.

inventoryConfigurations?
Type:
IResolvable | IResolvable | InventoryConfigurationProperty[]
(optional)
Specifies the inventory configuration for an Amazon S3 bucket.

lifecycleConfiguration?
Type:
IResolvable | LifecycleConfigurationProperty
(optional)
Specifies the lifecycle configuration for objects in an Amazon S3 bucket.

loggingConfiguration?
Type:
IResolvable | LoggingConfigurationProperty
(optional)
Settings that define where logs are stored.

metadataTableConfiguration?
Type:
IResolvable | MetadataTableConfigurationProperty
(optional)
The metadata table configuration of an Amazon S3 general purpose bucket.

metricsConfigurations?
Type:
IResolvable | IResolvable | MetricsConfigurationProperty[]
(optional)
Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.

notificationConfiguration?
Type:
IResolvable | NotificationConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles bucket notifications.

objectLockConfiguration?
Type:
IResolvable | ObjectLockConfigurationProperty
(optional)

This operation is not supported for directory buckets.


objectLockEnabled?
Type:
boolean | IResolvable
(optional)
Indicates whether this bucket has an Object Lock configuration enabled.

ownershipControls?
Type:
IResolvable | OwnershipControlsProperty
(optional)
Configuration that defines how Amazon S3 handles Object Ownership rules.

publicAccessBlockConfiguration?
Type:
IResolvable | PublicAccessBlockConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles public access.

replicationConfiguration?
Type:
IResolvable | ReplicationConfigurationProperty
(optional)
Configuration for replicating objects in an S3 bucket.

tagsRaw?
Type:
CfnTag[]
(optional)
An arbitrary set of tags (key-value pairs) for this S3 bucket.

versioningConfiguration?
Type:
IResolvable | VersioningConfigurationProperty
(optional)
Enables multiple versions of all objects in this bucket.

websiteConfiguration?
Type:
IResolvable | WebsiteConfigurationProperty
(optional)
Information used to configure the bucket as a static website.

static CFN_RESOURCE_TYPE_NAME
Type:
string
The CloudFormation resource type name for this resource class.
Methods


NameDescription


addDeletionOverride(path)Syntactic sugar for addOverride(path, undefined).
addDependency(target)Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
addDependsOn(target)⚠️Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
addMetadata(key, value)Add a value to the CloudFormation Resource Metadata.
addOverride(path, value)Adds an override to the synthesized CloudFormation resource.
addPropertyDeletionOverride(propertyPath)Adds an override that deletes the value of a property from the resource definition.
addPropertyOverride(propertyPath, value)Adds an override to a resource property.
applyRemovalPolicy(policy?, options?)Sets the deletion policy of the resource based on the removal policy specified.
getAtt(attributeName, typeHint?)Returns a token for an runtime attribute of this resource.
getMetadata(key)Retrieve a value value from the CloudFormation Resource Metadata.
inspect(inspector)Examines the CloudFormation resource and discloses attributes.
obtainDependencies()Retrieves an array of resources this resource depends on.
obtainResourceDependencies()Get a shallow copy of dependencies between this resource and other resources in the same stack.
overrideLogicalId(newLogicalId)Overrides the auto-generated logical ID with a specific ID.
removeDependency(target)Indicates that this resource no longer depends on another resource.
replaceDependency(target, newTarget)Replaces one dependency with another.
toString()Returns a string representation of this construct.
protected renderProperties(props)



addDeletionOverride(path)
public addDeletionOverride(path: string): void

Parameters

path string  — The path of the value to delete.

Syntactic sugar for addOverride(path, undefined).

addDependency(target)
public addDependency(target: CfnResource): void

Parameters

target CfnResource

Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
This can be used for resources across stacks (or nested stack) boundaries
and the dependency will automatically be transferred to the relevant scope.

addDependsOn(target)⚠️
public addDependsOn(target: CfnResource): void

⚠️ Deprecated: use addDependency
Parameters

target CfnResource

Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.

addMetadata(key, value)
public addMetadata(key: string, value: any): void

Parameters

key string
value any

Add a value to the CloudFormation Resource Metadata.
See also: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.)

addOverride(path, value)
public addOverride(path: string, value: any): void

Parameters

path string  — - The path of the property, you can use dot notation to override values in complex types.
value any  — - The value.

Adds an override to the synthesized CloudFormation resource.
To add a
property override, either use addPropertyOverride or prefix path with
"Properties." (i.e. Properties.TopicName).
If the override is nested, separate each nested level using a dot (.) in the path parameter.
If there is an array as part of the nesting, specify the index in the path.
To include a literal . in the property name, prefix with a \. In most
programming languages you will need to write this as "\\." because the
\ itself will need to be escaped.
For example,
cfnResource.addOverride('Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes', ['myattribute']);
cfnResource.addOverride('Properties.GlobalSecondaryIndexes.1.ProjectionType', 'INCLUDE');

would add the overrides
"Properties": {
  "GlobalSecondaryIndexes": [
    {
      "Projection": {
        "NonKeyAttributes": [ "myattribute" ]
        ...
      }
      ...
    },
    {
      "ProjectionType": "INCLUDE"
      ...
    },
  ]
  ...
}

The value argument to addOverride will not be processed or translated
in any way. Pass raw JSON values in here with the correct capitalization
for CloudFormation. If you pass CDK classes or structs, they will be
rendered with lowercased key names, and CloudFormation will reject the
template.

addPropertyDeletionOverride(propertyPath)
public addPropertyDeletionOverride(propertyPath: string): void

Parameters

propertyPath string  — The path to the property.

Adds an override that deletes the value of a property from the resource definition.

addPropertyOverride(propertyPath, value)
public addPropertyOverride(propertyPath: string, value: any): void

Parameters

propertyPath string  — The path of the property.
value any  — The value.

Adds an override to a resource property.
Syntactic sugar for addOverride("Properties.<...>", value).

applyRemovalPolicy(policy?, options?)
public applyRemovalPolicy(policy?: RemovalPolicy, options?: RemovalPolicyOptions): void

Parameters

policy RemovalPolicy
options RemovalPolicyOptions

Sets the deletion policy of the resource based on the removal policy specified.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN). In some
cases, a snapshot can be taken of the resource prior to deletion
(RemovalPolicy.SNAPSHOT). A list of resources that support this policy
can be found in the following link:
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options

getAtt(attributeName, typeHint?)
public getAtt(attributeName: string, typeHint?: ResolutionTypeHint): Reference

Parameters

attributeName string  — The name of the attribute.
typeHint ResolutionTypeHint

Returns

Reference

Returns a token for an runtime attribute of this resource.
Ideally, use generated attribute accessors (e.g. resource.arn), but this can be used for future compatibility
in case there is no generated attribute.

getMetadata(key)
public getMetadata(key: string): any

Parameters

key string

Returns

any

Retrieve a value value from the CloudFormation Resource Metadata.
See also: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.)

inspect(inspector)
public inspect(inspector: TreeInspector): void

Parameters

inspector TreeInspector  — tree inspector to collect and process attributes.

Examines the CloudFormation resource and discloses attributes.

obtainDependencies()
public obtainDependencies(): Stack &#124; CfnResource[]

Returns

Stack | CfnResource[]

Retrieves an array of resources this resource depends on.
This assembles dependencies on resources across stacks (including nested stacks)
automatically.

obtainResourceDependencies()
public obtainResourceDependencies(): CfnResource[]

Returns

CfnResource[]

Get a shallow copy of dependencies between this resource and other resources in the same stack.

overrideLogicalId(newLogicalId)
public overrideLogicalId(newLogicalId: string): void

Parameters

newLogicalId string  — The new logical ID to use for this stack element.

Overrides the auto-generated logical ID with a specific ID.

removeDependency(target)
public removeDependency(target: CfnResource): void

Parameters

target CfnResource

Indicates that this resource no longer depends on another resource.
This can be used for resources across stacks (including nested stacks)
and the dependency will automatically be removed from the relevant scope.

replaceDependency(target, newTarget)
public replaceDependency(target: CfnResource, newTarget: CfnResource): void

Parameters

target CfnResource  — The dependency to replace.
newTarget CfnResource  — The new dependency to add.

Replaces one dependency with another.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

protected renderProperties(props)
protected renderProperties(props: { [string]: any }): { [string]: any }

Parameters

props { [string]: any }

Returns

{ [string]: any }\n\nclass CfnBucket (construct)


LanguageType name


 .NETAmazon.CDK.AWS.S3.CfnBucket
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awss3#CfnBucket
 Javasoftware.amazon.awscdk.services.s3.CfnBucket
 Pythonaws_cdk.aws_s3.CfnBucket
 TypeScript aws-cdk-lib » aws_s3 » CfnBucket


Implements
IConstruct, IDependable, IInspectable, ITaggable
The AWS::S3::Bucket resource creates an Amazon S3 bucket in the same AWS Region where you create the AWS CloudFormation stack.
To control how AWS CloudFormation handles the bucket when the stack is deleted, you can set a deletion policy for your bucket. You can choose to retain the bucket or to delete the bucket. For more information, see DeletionPolicy Attribute .

You can only delete empty buckets. Deletion fails for buckets that have contents.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html
Example
declare const cfnTemplate: cfn_inc.CfnInclude;
const cfnBucket = cfnTemplate.getResource('Bucket') as s3.CfnBucket;

const role = new iam.Role(this, 'Role', {
  assumedBy: new iam.AnyPrincipal(),
});
role.addToPolicy(new iam.PolicyStatement({
  actions: ['s3:*'],
  resources: [cfnBucket.attrArn],
}));

Initializer
new CfnBucket(scope: Construct, id: string, props?: CfnBucketProps)

Parameters

scope Construct  — Scope in which this resource is defined.
id string  — Construct identifier for this resource (unique in its scope).
props CfnBucketProps  — Resource properties.

Construct Props


NameTypeDescription


accelerateConfiguration?IResolvable | AccelerateConfigurationPropertyConfigures the transfer acceleration state for an Amazon S3 bucket.
accessControl?string> This is a legacy property, and it is not recommended for most use cases.
analyticsConfigurations?IResolvable | IResolvable | AnalyticsConfigurationProperty[]Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
bucketEncryption?IResolvable | BucketEncryptionPropertySpecifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
bucketName?stringA name for the bucket.
corsConfiguration?IResolvable | CorsConfigurationPropertyDescribes the cross-origin access configuration for objects in an Amazon S3 bucket.
intelligentTieringConfigurations?IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]Defines how Amazon S3 handles Intelligent-Tiering storage.
inventoryConfigurations?IResolvable | IResolvable | InventoryConfigurationProperty[]Specifies the inventory configuration for an Amazon S3 bucket.
lifecycleConfiguration?IResolvable | LifecycleConfigurationPropertySpecifies the lifecycle configuration for objects in an Amazon S3 bucket.
loggingConfiguration?IResolvable | LoggingConfigurationPropertySettings that define where logs are stored.
metadataTableConfiguration?IResolvable | MetadataTableConfigurationPropertyThe metadata table configuration of an Amazon S3 general purpose bucket.
metricsConfigurations?IResolvable | IResolvable | MetricsConfigurationProperty[]Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
notificationConfiguration?IResolvable | NotificationConfigurationPropertyConfiguration that defines how Amazon S3 handles bucket notifications.
objectLockConfiguration?IResolvable | ObjectLockConfigurationProperty> This operation is not supported for directory buckets.
objectLockEnabled?boolean | IResolvableIndicates whether this bucket has an Object Lock configuration enabled.
ownershipControls?IResolvable | OwnershipControlsPropertyConfiguration that defines how Amazon S3 handles Object Ownership rules.
publicAccessBlockConfiguration?IResolvable | PublicAccessBlockConfigurationPropertyConfiguration that defines how Amazon S3 handles public access.
replicationConfiguration?IResolvable | ReplicationConfigurationPropertyConfiguration for replicating objects in an S3 bucket.
tags?CfnTag[]An arbitrary set of tags (key-value pairs) for this S3 bucket.
versioningConfiguration?IResolvable | VersioningConfigurationPropertyEnables multiple versions of all objects in this bucket.
websiteConfiguration?IResolvable | WebsiteConfigurationPropertyInformation used to configure the bucket as a static website.



accelerateConfiguration?
Type:
IResolvable | AccelerateConfigurationProperty
(optional)
Configures the transfer acceleration state for an Amazon S3 bucket.
For more information, see Amazon S3 Transfer Acceleration in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-accelerateconfiguration

accessControl?
Type:
string
(optional)

This is a legacy property, and it is not recommended for most use cases.

A majority of modern use cases in Amazon S3 no longer require the use of ACLs, and we recommend that you keep ACLs disabled. For more information, see Controlling object ownership in the Amazon S3 User Guide .
A canned access control list (ACL) that grants predefined permissions to the bucket. For more information about canned ACLs, see Canned ACL in the Amazon S3 User Guide .
S3 buckets are created with ACLs disabled by default. Therefore, unless you explicitly set the AWS::S3::OwnershipControls property to enable ACLs, your resource will fail to deploy with any value other than Private. Use cases requiring ACLs are uncommon.
The majority of access control configurations can be successfully and more easily achieved with bucket policies. For more information, see AWS::S3::BucketPolicy . For examples of common policy configurations, including S3 Server Access Logs buckets and more, see Bucket policy examples in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-accesscontrol

analyticsConfigurations?
Type:
IResolvable | IResolvable | AnalyticsConfigurationProperty[]
(optional)
Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-analyticsconfigurations

bucketEncryption?
Type:
IResolvable | BucketEncryptionProperty
(optional)
Specifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
For information about the Amazon S3 default encryption feature, see Amazon S3 Default Encryption for S3 Buckets in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-bucketencryption

bucketName?
Type:
string
(optional)
A name for the bucket.
If you don't specify a name, AWS CloudFormation generates a unique ID and uses that ID for the bucket name. The bucket name must contain only lowercase letters, numbers, periods (.), and dashes (-) and must follow Amazon S3 bucket restrictions and limitations . For more information, see Rules for naming Amazon S3 buckets in the Amazon S3 User Guide .

If you specify a name, you can't perform updates that require replacement of this resource. You can perform updates that require no or some interruption. If you need to replace the resource, specify a new name.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-bucketname

corsConfiguration?
Type:
IResolvable | CorsConfigurationProperty
(optional)
Describes the cross-origin access configuration for objects in an Amazon S3 bucket.
For more information, see Enabling Cross-Origin Resource Sharing in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-corsconfiguration

intelligentTieringConfigurations?
Type:
IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]
(optional)
Defines how Amazon S3 handles Intelligent-Tiering storage.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-intelligenttieringconfigurations

inventoryConfigurations?
Type:
IResolvable | IResolvable | InventoryConfigurationProperty[]
(optional)
Specifies the inventory configuration for an Amazon S3 bucket.
For more information, see GET Bucket inventory in the Amazon S3 API Reference .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-inventoryconfigurations

lifecycleConfiguration?
Type:
IResolvable | LifecycleConfigurationProperty
(optional)
Specifies the lifecycle configuration for objects in an Amazon S3 bucket.
For more information, see Object Lifecycle Management in the Amazon S3 User Guide .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-lifecycleconfiguration

loggingConfiguration?
Type:
IResolvable | LoggingConfigurationProperty
(optional)
Settings that define where logs are stored.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-loggingconfiguration

metadataTableConfiguration?
Type:
IResolvable | MetadataTableConfigurationProperty
(optional)
The metadata table configuration of an Amazon S3 general purpose bucket.
For more information, see Accelerating data discovery with S3 Metadata and Setting up permissions for configuring metadata tables .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-metadatatableconfiguration

metricsConfigurations?
Type:
IResolvable | IResolvable | MetricsConfigurationProperty[]
(optional)
Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
If you're updating an existing metrics configuration, note that this is a full replacement of the existing metrics configuration. If you don't include the elements you want to keep, they are erased. For more information, see PutBucketMetricsConfiguration .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-metricsconfigurations

notificationConfiguration?
Type:
IResolvable | NotificationConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles bucket notifications.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-notificationconfiguration

objectLockConfiguration?
Type:
IResolvable | ObjectLockConfigurationProperty
(optional)

This operation is not supported for directory buckets.

Places an Object Lock configuration on the specified bucket. The rule specified in the Object Lock configuration will be applied by default to every new object placed in the specified bucket. For more information, see Locking Objects .


The DefaultRetention settings require both a mode and a period.
The DefaultRetention period can be either Days or Years but you must select one. You cannot specify Days and Years at the same time.
You can enable Object Lock for new or existing buckets. For more information, see Configuring Object Lock .


See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-objectlockconfiguration

objectLockEnabled?
Type:
boolean | IResolvable
(optional)
Indicates whether this bucket has an Object Lock configuration enabled.
Enable ObjectLockEnabled when you apply ObjectLockConfiguration to a bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-objectlockenabled

ownershipControls?
Type:
IResolvable | OwnershipControlsProperty
(optional)
Configuration that defines how Amazon S3 handles Object Ownership rules.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-ownershipcontrols

publicAccessBlockConfiguration?
Type:
IResolvable | PublicAccessBlockConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles public access.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-publicaccessblockconfiguration

replicationConfiguration?
Type:
IResolvable | ReplicationConfigurationProperty
(optional)
Configuration for replicating objects in an S3 bucket.
To enable replication, you must also enable versioning by using the VersioningConfiguration property.
Amazon S3 can store replicated objects in a single destination bucket or multiple destination buckets. The destination bucket or buckets must already exist.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-replicationconfiguration

tags?
Type:
CfnTag[]
(optional)
An arbitrary set of tags (key-value pairs) for this S3 bucket.
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-tags

versioningConfiguration?
Type:
IResolvable | VersioningConfigurationProperty
(optional)
Enables multiple versions of all objects in this bucket.
You might enable versioning to prevent objects from being deleted or overwritten by mistake or to archive objects so that you can retrieve previous versions of them.

When you enable versioning on a bucket for the first time, it might take a short amount of time for the change to be fully propagated. We recommend that you wait for 15 minutes after enabling versioning before issuing write operations ( PUT or DELETE ) on objects in the bucket.

See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-versioningconfiguration

websiteConfiguration?
Type:
IResolvable | WebsiteConfigurationProperty
(optional)
Information used to configure the bucket as a static website.
For more information, see Hosting Websites on Amazon S3 .
See also: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-s3-bucket.html#cfn-s3-bucket-websiteconfiguration
Properties


NameTypeDescription


attrArnstringReturns the Amazon Resource Name (ARN) of the specified bucket.
attrDomainNamestringReturns the IPv4 DNS name of the specified bucket.
attrDualStackDomainNamestringReturns the IPv6 DNS name of the specified bucket.
attrMetadataTableConfigurationS3TablesDestinationTableArnstringThe Amazon Resource Name (ARN) for the metadata table in the metadata table configuration.
attrMetadataTableConfigurationS3TablesDestinationTableNamespacestringThe table bucket namespace for the metadata table in your metadata table configuration.
attrRegionalDomainNamestringReturns the regional domain name of the specified bucket.
attrWebsiteUrlstringReturns the Amazon S3 website endpoint for the specified bucket.
cfnOptionsICfnResourceOptionsOptions for this resource, such as condition, update policy etc.
cfnProperties{ [string]: any }
cfnResourceTypestringAWS resource type.
creationStackstring[]
logicalIdstringThe logical ID for this CloudFormation stack element.
nodeNodeThe tree node.
refstringReturn a string that will be resolved to a CloudFormation { Ref } for this element.
stackStackThe stack in which this element is defined.
tagsTagManagerTag Manager which manages the tags for this resource.
accelerateConfiguration?IResolvable | AccelerateConfigurationPropertyConfigures the transfer acceleration state for an Amazon S3 bucket.
accessControl?string> This is a legacy property, and it is not recommended for most use cases.
analyticsConfigurations?IResolvable | IResolvable | AnalyticsConfigurationProperty[]Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.
bucketEncryption?IResolvable | BucketEncryptionPropertySpecifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).
bucketName?stringA name for the bucket.
corsConfiguration?IResolvable | CorsConfigurationPropertyDescribes the cross-origin access configuration for objects in an Amazon S3 bucket.
intelligentTieringConfigurations?IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]Defines how Amazon S3 handles Intelligent-Tiering storage.
inventoryConfigurations?IResolvable | IResolvable | InventoryConfigurationProperty[]Specifies the inventory configuration for an Amazon S3 bucket.
lifecycleConfiguration?IResolvable | LifecycleConfigurationPropertySpecifies the lifecycle configuration for objects in an Amazon S3 bucket.
loggingConfiguration?IResolvable | LoggingConfigurationPropertySettings that define where logs are stored.
metadataTableConfiguration?IResolvable | MetadataTableConfigurationPropertyThe metadata table configuration of an Amazon S3 general purpose bucket.
metricsConfigurations?IResolvable | IResolvable | MetricsConfigurationProperty[]Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.
notificationConfiguration?IResolvable | NotificationConfigurationPropertyConfiguration that defines how Amazon S3 handles bucket notifications.
objectLockConfiguration?IResolvable | ObjectLockConfigurationProperty> This operation is not supported for directory buckets.
objectLockEnabled?boolean | IResolvableIndicates whether this bucket has an Object Lock configuration enabled.
ownershipControls?IResolvable | OwnershipControlsPropertyConfiguration that defines how Amazon S3 handles Object Ownership rules.
publicAccessBlockConfiguration?IResolvable | PublicAccessBlockConfigurationPropertyConfiguration that defines how Amazon S3 handles public access.
replicationConfiguration?IResolvable | ReplicationConfigurationPropertyConfiguration for replicating objects in an S3 bucket.
tagsRaw?CfnTag[]An arbitrary set of tags (key-value pairs) for this S3 bucket.
versioningConfiguration?IResolvable | VersioningConfigurationPropertyEnables multiple versions of all objects in this bucket.
websiteConfiguration?IResolvable | WebsiteConfigurationPropertyInformation used to configure the bucket as a static website.
static CFN_RESOURCE_TYPE_NAMEstringThe CloudFormation resource type name for this resource class.



attrArn
Type:
string
Returns the Amazon Resource Name (ARN) of the specified bucket.
Example: arn:aws:s3:::DOC-EXAMPLE-BUCKET

attrDomainName
Type:
string
Returns the IPv4 DNS name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.amazonaws.com

attrDualStackDomainName
Type:
string
Returns the IPv6 DNS name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com
For more information about dual-stack endpoints, see Using Amazon S3 Dual-Stack Endpoints .

attrMetadataTableConfigurationS3TablesDestinationTableArn
Type:
string
The Amazon Resource Name (ARN) for the metadata table in the metadata table configuration.
The specified metadata table name must be unique within the aws_s3_metadata namespace in the destination table bucket.

attrMetadataTableConfigurationS3TablesDestinationTableNamespace
Type:
string
The table bucket namespace for the metadata table in your metadata table configuration.
This value is always aws_s3_metadata .

attrRegionalDomainName
Type:
string
Returns the regional domain name of the specified bucket.
Example: DOC-EXAMPLE-BUCKET.s3.us-east-2.amazonaws.com

attrWebsiteUrl
Type:
string
Returns the Amazon S3 website endpoint for the specified bucket.
Example (IPv4): http://DOC-EXAMPLE-BUCKET.s3-website.us-east-2.amazonaws.com
Example (IPv6): http://DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com

cfnOptions
Type:
ICfnResourceOptions
Options for this resource, such as condition, update policy etc.

cfnProperties
Type:
{ [string]: any }

cfnResourceType
Type:
string
AWS resource type.

creationStack
Type:
string[]

logicalId
Type:
string
The logical ID for this CloudFormation stack element.
The logical ID of the element
is calculated from the path of the resource node in the construct tree.
To override this value, use overrideLogicalId(newLogicalId).

node
Type:
Node
The tree node.

ref
Type:
string
Return a string that will be resolved to a CloudFormation { Ref } for this element.
If, by any chance, the intrinsic reference of a resource is not a string, you could
coerce it to an IResolvable through Lazy.any({ produce: resource.ref }).

stack
Type:
Stack
The stack in which this element is defined.
CfnElements must be defined within a stack scope (directly or indirectly).

tags
Type:
TagManager
Tag Manager which manages the tags for this resource.

accelerateConfiguration?
Type:
IResolvable | AccelerateConfigurationProperty
(optional)
Configures the transfer acceleration state for an Amazon S3 bucket.

accessControl?
Type:
string
(optional)

This is a legacy property, and it is not recommended for most use cases.


analyticsConfigurations?
Type:
IResolvable | IResolvable | AnalyticsConfigurationProperty[]
(optional)
Specifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.

bucketEncryption?
Type:
IResolvable | BucketEncryptionProperty
(optional)
Specifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS).

bucketName?
Type:
string
(optional)
A name for the bucket.

corsConfiguration?
Type:
IResolvable | CorsConfigurationProperty
(optional)
Describes the cross-origin access configuration for objects in an Amazon S3 bucket.

intelligentTieringConfigurations?
Type:
IResolvable | IResolvable | IntelligentTieringConfigurationProperty[]
(optional)
Defines how Amazon S3 handles Intelligent-Tiering storage.

inventoryConfigurations?
Type:
IResolvable | IResolvable | InventoryConfigurationProperty[]
(optional)
Specifies the inventory configuration for an Amazon S3 bucket.

lifecycleConfiguration?
Type:
IResolvable | LifecycleConfigurationProperty
(optional)
Specifies the lifecycle configuration for objects in an Amazon S3 bucket.

loggingConfiguration?
Type:
IResolvable | LoggingConfigurationProperty
(optional)
Settings that define where logs are stored.

metadataTableConfiguration?
Type:
IResolvable | MetadataTableConfigurationProperty
(optional)
The metadata table configuration of an Amazon S3 general purpose bucket.

metricsConfigurations?
Type:
IResolvable | IResolvable | MetricsConfigurationProperty[]
(optional)
Specifies a metrics configuration for the CloudWatch request metrics (specified by the metrics configuration ID) from an Amazon S3 bucket.

notificationConfiguration?
Type:
IResolvable | NotificationConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles bucket notifications.

objectLockConfiguration?
Type:
IResolvable | ObjectLockConfigurationProperty
(optional)

This operation is not supported for directory buckets.


objectLockEnabled?
Type:
boolean | IResolvable
(optional)
Indicates whether this bucket has an Object Lock configuration enabled.

ownershipControls?
Type:
IResolvable | OwnershipControlsProperty
(optional)
Configuration that defines how Amazon S3 handles Object Ownership rules.

publicAccessBlockConfiguration?
Type:
IResolvable | PublicAccessBlockConfigurationProperty
(optional)
Configuration that defines how Amazon S3 handles public access.

replicationConfiguration?
Type:
IResolvable | ReplicationConfigurationProperty
(optional)
Configuration for replicating objects in an S3 bucket.

tagsRaw?
Type:
CfnTag[]
(optional)
An arbitrary set of tags (key-value pairs) for this S3 bucket.

versioningConfiguration?
Type:
IResolvable | VersioningConfigurationProperty
(optional)
Enables multiple versions of all objects in this bucket.

websiteConfiguration?
Type:
IResolvable | WebsiteConfigurationProperty
(optional)
Information used to configure the bucket as a static website.

static CFN_RESOURCE_TYPE_NAME
Type:
string
The CloudFormation resource type name for this resource class.
Methods


NameDescription


addDeletionOverride(path)Syntactic sugar for addOverride(path, undefined).
addDependency(target)Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
addDependsOn(target)⚠️Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
addMetadata(key, value)Add a value to the CloudFormation Resource Metadata.
addOverride(path, value)Adds an override to the synthesized CloudFormation resource.
addPropertyDeletionOverride(propertyPath)Adds an override that deletes the value of a property from the resource definition.
addPropertyOverride(propertyPath, value)Adds an override to a resource property.
applyRemovalPolicy(policy?, options?)Sets the deletion policy of the resource based on the removal policy specified.
getAtt(attributeName, typeHint?)Returns a token for an runtime attribute of this resource.
getMetadata(key)Retrieve a value value from the CloudFormation Resource Metadata.
inspect(inspector)Examines the CloudFormation resource and discloses attributes.
obtainDependencies()Retrieves an array of resources this resource depends on.
obtainResourceDependencies()Get a shallow copy of dependencies between this resource and other resources in the same stack.
overrideLogicalId(newLogicalId)Overrides the auto-generated logical ID with a specific ID.
removeDependency(target)Indicates that this resource no longer depends on another resource.
replaceDependency(target, newTarget)Replaces one dependency with another.
toString()Returns a string representation of this construct.
protected renderProperties(props)



addDeletionOverride(path)
public addDeletionOverride(path: string): void

Parameters

path string  — The path of the value to delete.

Syntactic sugar for addOverride(path, undefined).

addDependency(target)
public addDependency(target: CfnResource): void

Parameters

target CfnResource

Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.
This can be used for resources across stacks (or nested stack) boundaries
and the dependency will automatically be transferred to the relevant scope.

addDependsOn(target)⚠️
public addDependsOn(target: CfnResource): void

⚠️ Deprecated: use addDependency
Parameters

target CfnResource

Indicates that this resource depends on another resource and cannot be provisioned unless the other resource has been successfully provisioned.

addMetadata(key, value)
public addMetadata(key: string, value: any): void

Parameters

key string
value any

Add a value to the CloudFormation Resource Metadata.
See also: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.)

addOverride(path, value)
public addOverride(path: string, value: any): void

Parameters

path string  — - The path of the property, you can use dot notation to override values in complex types.
value any  — - The value.

Adds an override to the synthesized CloudFormation resource.
To add a
property override, either use addPropertyOverride or prefix path with
"Properties." (i.e. Properties.TopicName).
If the override is nested, separate each nested level using a dot (.) in the path parameter.
If there is an array as part of the nesting, specify the index in the path.
To include a literal . in the property name, prefix with a \. In most
programming languages you will need to write this as "\\." because the
\ itself will need to be escaped.
For example,
cfnResource.addOverride('Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes', ['myattribute']);
cfnResource.addOverride('Properties.GlobalSecondaryIndexes.1.ProjectionType', 'INCLUDE');

would add the overrides
"Properties": {
  "GlobalSecondaryIndexes": [
    {
      "Projection": {
        "NonKeyAttributes": [ "myattribute" ]
        ...
      }
      ...
    },
    {
      "ProjectionType": "INCLUDE"
      ...
    },
  ]
  ...
}

The value argument to addOverride will not be processed or translated
in any way. Pass raw JSON values in here with the correct capitalization
for CloudFormation. If you pass CDK classes or structs, they will be
rendered with lowercased key names, and CloudFormation will reject the
template.

addPropertyDeletionOverride(propertyPath)
public addPropertyDeletionOverride(propertyPath: string): void

Parameters

propertyPath string  — The path to the property.

Adds an override that deletes the value of a property from the resource definition.

addPropertyOverride(propertyPath, value)
public addPropertyOverride(propertyPath: string, value: any): void

Parameters

propertyPath string  — The path of the property.
value any  — The value.

Adds an override to a resource property.
Syntactic sugar for addOverride("Properties.<...>", value).

applyRemovalPolicy(policy?, options?)
public applyRemovalPolicy(policy?: RemovalPolicy, options?: RemovalPolicyOptions): void

Parameters

policy RemovalPolicy
options RemovalPolicyOptions

Sets the deletion policy of the resource based on the removal policy specified.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN). In some
cases, a snapshot can be taken of the resource prior to deletion
(RemovalPolicy.SNAPSHOT). A list of resources that support this policy
can be found in the following link:
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options

getAtt(attributeName, typeHint?)
public getAtt(attributeName: string, typeHint?: ResolutionTypeHint): Reference

Parameters

attributeName string  — The name of the attribute.
typeHint ResolutionTypeHint

Returns

Reference

Returns a token for an runtime attribute of this resource.
Ideally, use generated attribute accessors (e.g. resource.arn), but this can be used for future compatibility
in case there is no generated attribute.

getMetadata(key)
public getMetadata(key: string): any

Parameters

key string

Returns

any

Retrieve a value value from the CloudFormation Resource Metadata.
See also: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html
Note that this is a different set of metadata from CDK node metadata; this
metadata ends up in the stack template under the resource, whereas CDK
node metadata ends up in the Cloud Assembly.)

inspect(inspector)
public inspect(inspector: TreeInspector): void

Parameters

inspector TreeInspector  — tree inspector to collect and process attributes.

Examines the CloudFormation resource and discloses attributes.

obtainDependencies()
public obtainDependencies(): Stack &#124; CfnResource[]

Returns

Stack | CfnResource[]

Retrieves an array of resources this resource depends on.
This assembles dependencies on resources across stacks (including nested stacks)
automatically.

obtainResourceDependencies()
public obtainResourceDependencies(): CfnResource[]

Returns

CfnResource[]

Get a shallow copy of dependencies between this resource and other resources in the same stack.

overrideLogicalId(newLogicalId)
public overrideLogicalId(newLogicalId: string): void

Parameters

newLogicalId string  — The new logical ID to use for this stack element.

Overrides the auto-generated logical ID with a specific ID.

removeDependency(target)
public removeDependency(target: CfnResource): void

Parameters

target CfnResource

Indicates that this resource no longer depends on another resource.
This can be used for resources across stacks (including nested stacks)
and the dependency will automatically be removed from the relevant scope.

replaceDependency(target, newTarget)
public replaceDependency(target: CfnResource, newTarget: CfnResource): void

Parameters

target CfnResource  — The dependency to replace.
newTarget CfnResource  — The new dependency to add.

Replaces one dependency with another.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

protected renderProperties(props)
protected renderProperties(props: { [string]: any }): { [string]: any }

Parameters

props { [string]: any }

Returns

{ [string]: any }\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideSyntaxPropertiesReturn valuesExamplesSee alsoAWS::S3::BucketThe AWS::S3::Bucket resource creates an Amazon S3 bucket in the same AWS Region where you create the AWS CloudFormation stack.To control how AWS CloudFormation handles the bucket when the stack is
      deleted, you can set a deletion policy for your bucket. You can choose to
        retain the bucket or to delete the bucket. For
      more information, see DeletionPolicy
        Attribute.ImportantYou can only delete empty buckets. Deletion fails for buckets that have contents.SyntaxTo declare this entity in your AWS CloudFormation template, use the following syntax:JSON{
  "Type" : "AWS::S3::Bucket",
  "Properties" : {
      "AccelerateConfiguration" : AccelerateConfiguration,
      "AccessControl" : String,
      "AnalyticsConfigurations" : [ AnalyticsConfiguration, ... ],
      "BucketEncryption" : BucketEncryption,
      "BucketName" : String,
      "CorsConfiguration" : CorsConfiguration,
      "IntelligentTieringConfigurations" : [ IntelligentTieringConfiguration, ... ],
      "InventoryConfigurations" : [ InventoryConfiguration, ... ],
      "LifecycleConfiguration" : LifecycleConfiguration,
      "LoggingConfiguration" : LoggingConfiguration,
      "MetadataTableConfiguration" : MetadataTableConfiguration,
      "MetricsConfigurations" : [ MetricsConfiguration, ... ],
      "NotificationConfiguration" : NotificationConfiguration,
      "ObjectLockConfiguration" : ObjectLockConfiguration,
      "ObjectLockEnabled" : Boolean,
      "OwnershipControls" : OwnershipControls,
      "PublicAccessBlockConfiguration" : PublicAccessBlockConfiguration,
      "ReplicationConfiguration" : ReplicationConfiguration,
      "Tags" : [ Tag, ... ],
      "VersioningConfiguration" : VersioningConfiguration,
      "WebsiteConfiguration" : WebsiteConfiguration
    }
}
YAMLType: AWS::S3::Bucket
Properties:
  AccelerateConfiguration: 
    AccelerateConfiguration
  AccessControl: String
  AnalyticsConfigurations: 
    - AnalyticsConfiguration
  BucketEncryption: 
    BucketEncryption
  BucketName: String
  CorsConfiguration: 
    CorsConfiguration
  IntelligentTieringConfigurations: 
    - IntelligentTieringConfiguration
  InventoryConfigurations: 
    - InventoryConfiguration
  LifecycleConfiguration: 
    LifecycleConfiguration
  LoggingConfiguration: 
    LoggingConfiguration
  MetadataTableConfiguration: 
    MetadataTableConfiguration
  MetricsConfigurations: 
    - MetricsConfiguration
  NotificationConfiguration: 
    NotificationConfiguration
  ObjectLockConfiguration: 
    ObjectLockConfiguration
  ObjectLockEnabled: Boolean
  OwnershipControls: 
    OwnershipControls
  PublicAccessBlockConfiguration: 
    PublicAccessBlockConfiguration
  ReplicationConfiguration: 
    ReplicationConfiguration
  Tags: 
    - Tag
  VersioningConfiguration: 
    VersioningConfiguration
  WebsiteConfiguration: 
    WebsiteConfiguration
PropertiesAccelerateConfiguration
                    Configures the transfer acceleration state for an Amazon S3 bucket. For more information, see
            Amazon S3
            Transfer Acceleration in the Amazon S3 User Guide.
                Required: NoType: AccelerateConfigurationUpdate requires: No interruptionAccessControl
                    Important This is a legacy property, and it is not recommended for most use cases. A majority of
        modern use cases in Amazon S3 no longer require the use of ACLs, and we recommend that you
        keep ACLs disabled. For more information, see Controlling object
          ownership in the Amazon S3 User Guide.
                    A canned access control list (ACL) that grants predefined permissions to the bucket. For
      more information about canned ACLs, see Canned ACL in the
        Amazon S3 User Guide.
                     S3 buckets are created with ACLs disabled by default. Therefore, unless you explicitly set the AWS::S3::OwnershipControls property to enable ACLs, your resource will fail to deploy
    with any value other than Private. Use cases requiring ACLs are uncommon.
                     The majority of access control configurations can be successfully and more easily
      achieved with bucket policies. For more information, see AWS::S3::BucketPolicy. For examples of common policy configurations, including S3
      Server Access Logs buckets and more, see Bucket policy examples in the
      Amazon S3 User Guide.
                Required: NoType: StringAllowed values: AuthenticatedRead | AwsExecRead | BucketOwnerFullControl | BucketOwnerRead | LogDeliveryWrite | Private | PublicRead | PublicReadWriteUpdate requires: No interruptionAnalyticsConfigurations
                    Specifies the configuration and any analyses for the analytics filter of an Amazon S3
         bucket.
                Required: NoType: Array of AnalyticsConfigurationUpdate requires: No interruptionBucketEncryption
                    Specifies default encryption for a bucket using server-side encryption with Amazon
      S3-managed keys (SSE-S3), AWS KMS-managed keys (SSE-KMS), or dual-layer server-side encryption with KMS-managed keys (DSSE-KMS). For
      information about the Amazon S3 default encryption feature, see Amazon S3 Default Encryption for S3
        Buckets in the Amazon S3 User Guide.
                Required: NoType: BucketEncryptionUpdate requires: No interruptionBucketName
                    A name for the bucket. If you don't specify a name, AWS CloudFormation
      generates a unique ID and uses that ID for the bucket name. The bucket name must contain only
      lowercase letters, numbers, periods (.), and dashes (-) and must follow Amazon S3 bucket
        restrictions and limitations. For more information, see Rules for naming Amazon
        S3 buckets in the Amazon S3 User Guide. 
                    ImportantIf you specify a name, you can't perform updates that require replacement of this
        resource. You can perform updates that require no or some interruption. If you need to
        replace the resource, specify a new name.
                Required: NoType: StringUpdate requires: ReplacementCorsConfiguration
                    Describes the cross-origin access configuration for objects in an Amazon S3 bucket. For more
         information, see Enabling
            Cross-Origin Resource Sharing in the
         Amazon S3 User Guide.
                Required: NoType: CorsConfigurationUpdate requires: No interruptionIntelligentTieringConfigurations
                    Defines how Amazon S3 handles Intelligent-Tiering storage.
                Required: NoType: Array of IntelligentTieringConfigurationUpdate requires: No interruptionInventoryConfigurations
                    Specifies the inventory configuration for an Amazon S3 bucket. For more information, see
            GET Bucket inventory in the Amazon S3 API Reference. 
                Required: NoType: Array of InventoryConfigurationUpdate requires: No interruptionLifecycleConfiguration
                    Specifies the lifecycle configuration for objects in an Amazon S3 bucket. For more
         information, see Object Lifecycle Management
         in the Amazon S3 User Guide.
                Required: NoType: LifecycleConfigurationUpdate requires: No interruptionLoggingConfiguration
                    Settings that define where logs are stored.
                Required: NoType: LoggingConfigurationUpdate requires: No interruptionMetadataTableConfiguration
                    
         The metadata table configuration of an Amazon S3 general purpose bucket.
      
                Required: NoType: MetadataTableConfigurationUpdate requires: No interruptionMetricsConfigurations
                    Specifies a metrics configuration for the CloudWatch request metrics (specified by the
         metrics configuration ID) from an Amazon S3 bucket. If you're updating an existing metrics
         configuration, note that this is a full replacement of the existing metrics configuration.
         If you don't include the elements you want to keep, they are erased. For more information,
         see PutBucketMetricsConfiguration.
                Required: NoType: Array of MetricsConfigurationUpdate requires: No interruptionNotificationConfiguration
                    Configuration that defines how Amazon S3 handles bucket notifications.
                Required: NoType: NotificationConfigurationUpdate requires: No interruptionObjectLockConfiguration
                    NoteThis operation is not supported for directory buckets.
                    Places an Object Lock configuration on the specified bucket. The rule specified in the
         Object Lock configuration will be applied by default to every new object placed in the
         specified bucket. For more information, see Locking Objects. 
                    Note
                             
                             
                             
                        
                                The DefaultRetention settings require both a mode and a
                  period.
                            
                                The DefaultRetention period can be either Days or
                     Years but you must select one. You cannot specify
                     Days and Years at the same time.
                            
                                You can enable Object Lock for new or existing buckets. For more information,
                  see Configuring Object
                     Lock.
                            
                Required: NoType: ObjectLockConfigurationUpdate requires: No interruptionObjectLockEnabled
                    Indicates whether this bucket has an Object Lock configuration enabled. Enable
        ObjectLockEnabled when you apply ObjectLockConfiguration to a
      bucket. 
                Required: NoType: BooleanUpdate requires: No interruptionOwnershipControls
                    Configuration that defines how Amazon S3 handles Object Ownership rules.
                Required: NoType: OwnershipControlsUpdate requires: No interruptionPublicAccessBlockConfiguration
                    Configuration that defines how Amazon S3 handles public access.
                Required: NoType: PublicAccessBlockConfigurationUpdate requires: No interruptionReplicationConfiguration
                    Configuration for replicating objects in an S3 bucket. To enable replication, you must
      also enable versioning by using the VersioningConfiguration property.
                    Amazon S3 can store replicated objects in a single destination bucket or multiple
      destination buckets. The destination bucket or buckets must already exist.
                Required: NoType: ReplicationConfigurationUpdate requires: No interruptionTags
                    An arbitrary set of tags (key-value pairs) for this S3 bucket.
                Required: NoType: Array of TagUpdate requires: No interruptionVersioningConfiguration
                    Enables multiple versions of all objects in this bucket. You might enable versioning to
      prevent objects from being deleted or overwritten by mistake or to archive objects so that you
      can retrieve previous versions of them.
                    NoteWhen you enable versioning on a bucket for the first time, it might take a short
            amount of time for the change to be fully propagated. We recommend that you wait for 15
            minutes after enabling versioning before issuing write operations
            (PUT
            or
            DELETE)
            on objects in the bucket. 
                Required: NoType: VersioningConfigurationUpdate requires: Some interruptionsWebsiteConfiguration
                    Information used to configure the bucket as a static website. For more information, see
        Hosting Websites
        on Amazon S3.
                Required: NoType: WebsiteConfigurationUpdate requires: No interruptionReturn valuesRefWhen you pass the logical ID of this resource to the intrinsic Ref function, Ref returns the bucket name.Example: 
                            amzn-s3-demo-bucket
                        For more information about using the Ref function, see Ref.Fn::GetAttThe Fn::GetAtt intrinsic function returns a value for a specified attribute of this type. The following are the available attributes and sample return values.
For more information about using the Fn::GetAtt intrinsic function, see Fn::GetAtt.Arn
                            Returns the Amazon Resource Name (ARN) of the specified bucket.
                            Example: arn:aws:s3:::DOC-EXAMPLE-BUCKET
                        DomainName
                            Returns the IPv4 DNS name of the specified bucket.
                            Example: DOC-EXAMPLE-BUCKET.s3.amazonaws.com
                        DualStackDomainName
                            Returns the IPv6 DNS name of the specified bucket.
                            Example:  DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com
                            For more information about dual-stack endpoints, see Using Amazon S3 Dual-Stack
        Endpoints.
                        MetadataTableConfiguration.S3TablesDestination.TableArn
                            The Amazon Resource Name (ARN) for the metadata table in the metadata table configuration. The specified metadata table name must be unique within the aws_s3_metadata namespace in the destination table bucket.
                            Example: arn:aws:s3tables:region:account-id:bucket/amzn-s3-demo-bucket/table/1234567890abcdef0
                        MetadataTableConfiguration.S3TablesDestination.TableNamespace
                            The table bucket namespace for the metadata table in the specified bucket's metadata table configuration. This value is always aws_s3_metadata.
                        RegionalDomainName
                            Returns the regional domain name of the specified bucket.
                            Example: DOC-EXAMPLE-BUCKET.s3.us-east-2.amazonaws.com
                        WebsiteURL
                            Returns the Amazon S3 website endpoint for the specified bucket.
                            Example (IPv4): http://DOC-EXAMPLE-BUCKET.s3-website.us-east-2.amazonaws.com
                            Example (IPv6):
        http://DOC-EXAMPLE-BUCKET.s3.dualstack.us-east-2.amazonaws.com
                        Examples Create an S3 bucketAssociate a replication configuration IAM role with an S3 bucketGranting public access to S3 bucketsEnabling ACLsConfigure a static website with a routing ruleEnable cross-origin resource sharingManage the lifecycle for S3 objectsLog access requests for a specific S3 bucketReceive S3 bucket notifications to an SNS topicEnable versioning and replicate objectsSpecify analytics and inventory configurations for an S3 bucket
            
            Create an S3 bucketThe following example creates an S3 bucket with a Retain deletion
          policy.JSON{
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "DeletionPolicy": "Retain",
            "Properties": {
                "BucketName": "DOC-EXAMPLE-BUCKET"
            }
        }
    }
}YAMLResources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    Properties:
      BucketName: DOC-EXAMPLE-BUCKET
            Associate a replication configuration IAM role with an S3 bucketThe following example creates an S3 bucket and grants it permission to write to a
          replication bucket by using an AWS Identity and Access Management (IAM)
          role. To avoid a circular dependency, the role's policy is declared as a separate
          resource. The bucket depends on the WorkItemBucketBackupRole role. If the
          policy is included in the role, the role also depends on the bucket.JSON{
    "Resources": {
        "RecordServiceS3Bucket": {
            "Type": "AWS::S3::Bucket",
            "DeletionPolicy": "Retain",
            "Properties": {
                "ReplicationConfiguration": {
                    "Role": {
                        "Fn::GetAtt": [
                            "WorkItemBucketBackupRole",
                            "Arn"
                        ]
                    },
                    "Rules": [
                        {
                            "Destination": {
                                "Bucket": {
                                    "Fn::Join": [
                                        "",
                                        [
                                            "arn:aws:s3:::",
                                            {
                                                "Fn::Join": [
                                                    "-",
                                                    [
                                                        {
                                                            "Ref": "AWS::Region"
                                                        },
                                                        {
                                                            "Ref": "AWS::StackName"
                                                        },
                                                        "replicationbucket"
                                                    ]
                                                ]
                                            }
                                        ]
                                    ]
                                },
                                "StorageClass": "STANDARD"
                            },
                            "Id": "Backup",
                            "Prefix": "",
                            "Status": "Enabled"
                        }
                    ]
                },
                "VersioningConfiguration": {
                    "Status": "Enabled"
                }
            }
        },
        "WorkItemBucketBackupRole": {
            "Type": "AWS::IAM::Role",
            "Properties": {
                "AssumeRolePolicyDocument": {
                    "Statement": [
                        {
                            "Action": [
                                "sts:AssumeRole"
                            ],
                            "Effect": "Allow",
                            "Principal": {
                                "Service": [
                                    "s3.amazonaws.com"
                                ]
                            }
                        }
                    ]
                }
            }
        },
        "BucketBackupPolicy": {
            "Type": "AWS::IAM::Policy",
            "Properties": {
                "PolicyDocument": {
                    "Statement": [
                        {
                            "Action": [
                                "s3:GetReplicationConfiguration",
                                "s3:ListBucket"
                            ],
                            "Effect": "Allow",
                            "Resource": [
                                {
                                    "Fn::Join": [
                                        "",
                                        [
                                            "arn:aws:s3:::",
                                            {
                                                "Ref": "RecordServiceS3Bucket"
                                            }
                                        ]
                                    ]
                                }
                            ]
                        },
                        {
                            "Action": [
                                "s3:GetObjectVersion",
                                "s3:GetObjectVersionAcl"
                            ],
                            "Effect": "Allow",
                            "Resource": [
                                {
                                    "Fn::Join": [
                                        "",
                                        [
                                            "arn:aws:s3:::",
                                            {
                                                "Ref": "RecordServiceS3Bucket"
                                            },
                                            "/*"
                                        ]
                                    ]
                                }
                            ]
                        },
                        {
                            "Action": [
                                "s3:ReplicateObject",
                                "s3:ReplicateDelete"
                            ],
                            "Effect": "Allow",
                            "Resource": [
                                {
                                    "Fn::Join": [
                                        "",
                                        [
                                            "arn:aws:s3:::",
                                            {
                                                "Fn::Join": [
                                                    "-",
                                                    [
                                                        {
                                                            "Ref": "AWS::Region"
                                                        },
                                                        {
                                                            "Ref": "AWS::StackName"
                                                        },
                                                        "replicationbucket"
                                                    ]
                                                ]
                                            },
                                            "/*"
                                        ]
                                    ]
                                }
                            ]
                        }
                    ]
                },
                "PolicyName": "BucketBackupPolicy",
                "Roles": [
                    {
                        "Ref": "WorkItemBucketBackupRole"
                    }
                ]
            }
        }
    }
}YAMLResources:
  RecordServiceS3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    Properties:
      ReplicationConfiguration:
        Role: !GetAtt
          - WorkItemBucketBackupRole
          - Arn
        Rules:
          - Destination:
              Bucket: !Join
                - ''
                - - 'arn:aws:s3:::'
                  - !Join
                    - '-'
                    - - !Ref 'AWS::Region'
                      - !Ref 'AWS::StackName'
                      - replicationbucket
              StorageClass: STANDARD
            Id: Backup
            Prefix: ''
            Status: Enabled
      VersioningConfiguration:
        Status: Enabled
  WorkItemBucketBackupRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: Allow
            Principal:
              Service:
                - s3.amazonaws.com
  BucketBackupPolicy:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyDocument:
        Statement:
          - Action:
              - 's3:GetReplicationConfiguration'
              - 's3:ListBucket'
            Effect: Allow
            Resource:
              - !Join
                - ''
                - - 'arn:aws:s3:::'
                  - !Ref RecordServiceS3Bucket
          - Action:
              - 's3:GetObjectVersion'
              - 's3:GetObjectVersionAcl'
            Effect: Allow
            Resource:
              - !Join
                - ''
                - - 'arn:aws:s3:::'
                  - !Ref RecordServiceS3Bucket
                  - /*
          - Action:
              - 's3:ReplicateObject'
              - 's3:ReplicateDelete'
            Effect: Allow
            Resource:
              - !Join
                - ''
                - - 'arn:aws:s3:::'
                  - !Join
                    - '-'
                    - - !Ref 'AWS::Region'
                      - !Ref 'AWS::StackName'
                      - replicationbucket
                  - /*
      PolicyName: BucketBackupPolicy
      Roles:
        - !Ref WorkItemBucketBackupRole
            Granting public access to S3 bucketsWhen you create a new bucket, all Block Public Access settings are automatically
          enabled. We recommend that you keep all Block Public Access settings enabled. If you require some level of public access to your buckets, you can disable Block Public Access settings. The following example shows creating a bucket called my-bucket and
          then disabling Block Public Access. A public bucket policy is then added to the bucket. NoteThe following example assumes the  BlockPublicPolicy and
              RestrictPublicBuckets Block Public Access settings have been disabled at
            the account level. JSON
        {
          "Resources": {
            "MyBucket": {
              "Type": "AWS::S3::Bucket",
              "Properties": {
                "BucketName": "my-bucket",
                "PublicAccessBlockConfiguration": {
                  "BlockPublicAcls": false,
                  "BlockPublicPolicy": false,
                  "IgnorePublicAcls": false,
                  "RestrictPublicBuckets": false
                  
                }
              }
            },
            "MyBucketPolicy": {
              "Type": "AWS::S3::BucketPolicy",
              "Properties": {
                "Bucket": {
                  "Ref": "MyBucket"
                },
                "PolicyDocument": {
                  "Version": "2012-10-17",
                  "Statement": [
                    {
                       "Effect": "Allow",
                       "Principal": "*",
                       "Action": "s3:GetObject",
                       "Resource": {
                         "Fn::Join": [
                           "",
                           [
                             "arn:aws:s3:::",
                             {
                               "Ref": "MyBucket"
                             },
                             "/*"
                           ]
                         ]
                       }
                     }
                   ]
                 }
               }
             }
           }
         } YAML
        Resources:
          MyBucket:
            Type: 'AWS::S3::Bucket'
            Properties:
              BucketName: my-bucket
              PublicAccessBlockConfiguration:
                BlockPublicAcls: false
                BlockPublicPolicy: false
                IgnorePublicAcls: false
                RestrictPublicBuckets: false
          MyBucketPolicy:
            Type: 'AWS::S3::BucketPolicy'
            Properties:
              Bucket:
                Ref: 'MyBucket'
              PolicyDocument:
                Version: '2012-10-17'
                Statement:
                  - Effect: Allow
                    Principal: '*'
                    Action: 's3:GetObject'
                    Resource:
                      Fn::Join:
                        - ''
                        - - 'arn:aws:s3:::'
                          - Ref: 'MyBucket'
                          - '/*'
            Enabling ACLs By default, S3 Object Ownership is set to BucketOwnerEnforced and ACLs are disabled. A majority of modern use cases in S3 no longer require the use of ACLs, and we recommend that you keep ACLs disabled. With ACLs disabled, you can control access to all objects in your bucket, regardless of who uploaded the objects to your bucket. 
          If your specific use case requires enabling ACLs, you can set S3 Object Ownership to BucketOwnerPreferred or ObjectWriter. For more information, see Controlling
            ownership of objects and disabling ACLs in the Amazon S3 User
              Guide. The following example shows Object Ownership set to BucketOwnerPreferred. JSON
        {
          "Resources": {
            "MyBucket": {
              "Type": "AWS::S3::Bucket",
              "Properties": {
                "BucketName": "my-bucket",
                "OwnershipControls": {
                       "Rules": [
                           {
                               "ObjectOwnership": "BucketOwnerPreferred"
                           }
                       ]
                   },
                "AccessControl": "AwsExecRead"
              }
           }
         }
       } YAML
        Resources:
          MyBucket:
            Type: 'AWS::S3::Bucket'
            Properties:
              BucketName: my-bucket
              OwnershipControls:
                Rules:
                - ObjectOwnership: BucketOwnerPreferred
              AccessControl: AwsExecRead              
      
            Configure a static website with a routing ruleIn this example, AWS::S3::Bucket's Fn::GetAtt values are used to provide
          outputs. If an HTTP 404 error occurs, the routing rule redirects requests to an EC2
          instance and inserts the object key prefix report-404/ in the redirect. For
          example, if you request a page called ExamplePage.html and it results in an
          HTTP 404 error, the request is routed to a page called
            report-404/ExamplePage.html on the specified instance. For all other HTTP
          error codes, error.html is returned. This example also specifies a metrics configuration called EntireBucket
          that enables CloudWatch request metrics at the bucket level.JSON{
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "AccessControl": "PublicRead",
                "BucketName": "public-bucket",
                "MetricsConfigurations": [
                    {
                        "Id": "EntireBucket"
                    }
                ],
                "WebsiteConfiguration": {
                    "IndexDocument": "index.html",
                    "ErrorDocument": "error.html",
                    "RoutingRules": [
                        {
                            "RoutingRuleCondition": {
                                "HttpErrorCodeReturnedEquals": "404",
                                "KeyPrefixEquals": "out1/"
                            },
                            "RedirectRule": {
                                "HostName": "ec2-11-22-333-44.compute-1.amazonaws.com",
                                "ReplaceKeyPrefixWith": "report-404/"
                            }
                        }
                    ]
                }
            },
            "DeletionPolicy": "Retain"
        }
    },
    "Outputs": {
        "WebsiteURL": {
            "Value": {
                "Fn::GetAtt": [
                    "S3Bucket",
                    "WebsiteURL"
                ]
            },
            "Description": "URL for website hosted on S3"
        },
        "S3BucketSecureURL": {
            "Value": {
                "Fn::Join": [
                    "",
                    [
                        "https://",
                        {
                            "Fn::GetAtt": [
                                "S3Bucket",
                                "DomainName"
                            ]
                        }
                    ]
                ]
            },
            "Description": "Name of S3 bucket to hold website content"
        }
    }
}YAMLResources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      AccessControl: PublicRead
      BucketName: public-bucket
      MetricsConfigurations:
        - Id: EntireBucket
      WebsiteConfiguration:
        IndexDocument: index.html
        ErrorDocument: error.html
        RoutingRules:
          - RoutingRuleCondition:
              HttpErrorCodeReturnedEquals: '404'
              KeyPrefixEquals: out1/
            RedirectRule:
              HostName: ec2-11-22-333-44.compute-1.amazonaws.com
              ReplaceKeyPrefixWith: report-404/
    DeletionPolicy: Retain
Outputs:
  WebsiteURL:
    Value: !GetAtt
      - S3Bucket
      - WebsiteURL
    Description: URL for website hosted on S3
  S3BucketSecureURL:
    Value: !Join
      - ''
      - - 'https://'
        - !GetAtt
          - S3Bucket
          - DomainName
    Description: Name of S3 bucket to hold website content
            Enable cross-origin resource sharingThe following example template shows a public S3 bucket with two cross-origin resource
          sharing rules.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "AccessControl": "PublicRead",
                "CorsConfiguration": {
                    "CorsRules": [
                        {
                            "AllowedHeaders": [
                                "*"
                            ],
                            "AllowedMethods": [
                                "GET"
                            ],
                            "AllowedOrigins": [
                                "*"
                            ],
                            "ExposedHeaders": [
                                "Date"
                            ],
                            "Id": "myCORSRuleId1",
                            "MaxAge": 3600
                        },
                        {
                            "AllowedHeaders": [
                                "x-amz-*"
                            ],
                            "AllowedMethods": [
                                "DELETE"
                            ],
                            "AllowedOrigins": [
                                "http://www.example.com",
                                "http://www.example.net"
                            ],
                            "ExposedHeaders": [
                                "Connection",
                                "Server",
                                "Date"
                            ],
                            "Id": "myCORSRuleId2",
                            "MaxAge": 1800
                        }
                    ]
                }
            }
        }
    },
    "Outputs": {
        "BucketName": {
            "Value": {
                "Ref": "S3Bucket"
            },
            "Description": "Name of the sample Amazon S3 bucket with CORS enabled."
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      AccessControl: PublicRead
      CorsConfiguration:
        CorsRules:
          - AllowedHeaders:
              - '*'
            AllowedMethods:
              - GET
            AllowedOrigins:
              - '*'
            ExposedHeaders:
              - Date
            Id: myCORSRuleId1
            MaxAge: 3600
          - AllowedHeaders:
              - x-amz-*
            AllowedMethods:
              - DELETE
            AllowedOrigins:
              - 'http://www.example.com'
              - 'http://www.example.net'
            ExposedHeaders:
              - Connection
              - Server
              - Date
            Id: myCORSRuleId2
            MaxAge: 1800
Outputs:
  BucketName:
    Value: !Ref S3Bucket
    Description: Name of the sample Amazon S3 bucket with CORS enabled.
            Manage the lifecycle for S3 objectsThe following example template shows an S3 bucket with a lifecycle configuration rule.
          The rule applies to all objects with the glacier key prefix. The objects are
          transitioned to Glacier after one day, and deleted after one year.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "AccessControl": "Private",
                "LifecycleConfiguration": {
                    "Rules": [
                        {
                            "Id": "GlacierRule",
                            "Prefix": "glacier",
                            "Status": "Enabled",
                            "ExpirationInDays": 365,
                            "Transitions": [
                                {
                                    "TransitionInDays": 1,
                                    "StorageClass": "GLACIER"
                                }
                            ]
                        }
                    ]
                }
            }
        }
    },
    "Outputs": {
        "BucketName": {
            "Value": {
                "Ref": "S3Bucket"
            },
            "Description": "Name of the sample Amazon S3 bucket with a lifecycle configuration."
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      AccessControl: Private
      LifecycleConfiguration:
        Rules:
          - Id: GlacierRule
            Prefix: glacier
            Status: Enabled
            ExpirationInDays: 365
            Transitions:
              - TransitionInDays: 1
                StorageClass: GLACIER
Outputs:
  BucketName:
    Value: !Ref S3Bucket
    Description: Name of the sample Amazon S3 bucket with a lifecycle configuration.
            Log access requests for a specific S3 bucketThe following example template creates two S3 buckets. The LoggingBucket
          bucket store the logs from the S3Bucket bucket. To receive logs from the
            S3Bucket bucket, the logging bucket requires log delivery write
          permissions.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "LoggingConfiguration": {
                    "DestinationBucketName": {
                        "Ref": "LoggingBucket"
                    },
                    "LogFilePrefix": "testing-logs"
                }
            }
        },
        "LoggingBucket": {
            "Type": "AWS::S3::Bucket"
        },
        "S3BucketPolicy": {
            "Type": "AWS::S3::BucketPolicy",
            "Properties": {
                "Bucket": {
                    "Ref": "LoggingBucket"
                },
                "PolicyDocument": {
                    "Version": "2012-10-17",
                    "Statement": [
                        {
                            "Action": [
                                "s3:PutObject"
                            ],
                            "Effect": "Allow",
                            "Principal": {
                                "Service": "logging.s3.amazonaws.com"
                            },
                            "Resource": {
                                "Fn::Join": [
                                    "",
                                    [
                                        "arn:aws:s3:::",
                                        {
                                            "Ref": "LoggingBucket"
                                        },
                                        "/*"
                                    ]
                                ]
                            },
                            "Condition": {
                                "ArnLike": {
                                    "aws:SourceArn": {
                                        "Fn::GetAtt": [
                                            "S3Bucket",
                                            "Arn"
                                        ]
                                    }
                                },
                                "StringEquals": {
                                    "aws:SourceAccount": {
                                        "Fn::Sub": "${AWS::AccountId}"
                                    }
                                }
                            }
                        }
                    ]
                }
            }
        }
    },
    "Outputs": {
        "BucketName": {
            "Value": {
                "Ref": "S3Bucket"
            },
            "Description": "Name of the sample Amazon S3 bucket with a logging configuration."
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      LoggingConfiguration:
        DestinationBucketName: !Ref LoggingBucket
        LogFilePrefix: testing-logs
  LoggingBucket:
    Type: 'AWS::S3::Bucket'
  S3BucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      Bucket: !Ref LoggingBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - 's3:PutObject'
            Effect: Allow
            Principal:
              Service: logging.s3.amazonaws.com
            Resource: !Join 
              - ''
              - - 'arn:aws:s3:::'
                - !Ref LoggingBucket
                - /*
            Condition:
              ArnLike:
                'aws:SourceArn': !GetAtt 
                  - S3Bucket
                  - Arn
              StringEquals:
                'aws:SourceAccount': !Sub '${AWS::AccountId}'
Outputs:
  BucketName:
    Value: !Ref S3Bucket
    Description: Name of the sample Amazon S3 bucket with a logging configuration.


            Receive S3 bucket notifications to an SNS topicThe following example template shows an Amazon S3 bucket with a notification
          configuration that sends an event to the specified SNS topic when S3 has lost all replicas
          of an object.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "AccessControl": "Private",
                "NotificationConfiguration": {
                    "TopicConfigurations": [
                        {
                            "Topic": "arn:aws:sns:us-east-1:123456789012:TestTopic",
                            "Event": "s3:ReducedRedundancyLostObject"
                        }
                    ]
                }
            }
        }
    },
    "Outputs": {
        "BucketName": {
            "Value": {
                "Ref": "S3Bucket"
            },
            "Description": "Name of the sample Amazon S3 bucket with a notification configuration."
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      AccessControl: Private
      NotificationConfiguration:
        TopicConfigurations:
          - Topic: 'arn:aws:sns:us-east-1:123456789012:TestTopic'
            Event: 's3:ReducedRedundancyLostObject'
Outputs:
  BucketName:
    Value: !Ref S3Bucket
    Description: Name of the sample Amazon S3 bucket with a notification configuration.
            Enable versioning and replicate objectsThe following example enables versioning and two replication rules. The rules copy
          objects prefixed with either MyPrefix and MyOtherPrefix and
          stores the copied objects in a bucket named my-replication-bucket.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Resources": {
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "VersioningConfiguration": {
                    "Status": "Enabled"
                },
                "ReplicationConfiguration": {
                    "Role": "arn:aws:iam::123456789012:role/replication_role",
                    "Rules": [
                        {
                            "Id": "MyRule1",
                            "Status": "Enabled",
                            "Prefix": "MyPrefix",
                            "Destination": {
                                "Bucket": "arn:aws:s3:::my-replication-bucket",
                                "StorageClass": "STANDARD"
                            }
                        },
                        {
                            "Status": "Enabled",
                            "Prefix": "MyOtherPrefix",
                            "Destination": {
                                "Bucket": "arn:aws:s3:::my-replication-bucket"
                            }
                        }
                    ]
                }
            }
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      VersioningConfiguration:
        Status: Enabled
      ReplicationConfiguration:
        Role: 'arn:aws:iam::123456789012:role/replication_role'
        Rules:
          - Id: MyRule1
            Status: Enabled
            Prefix: MyPrefix
            Destination:
              Bucket: 'arn:aws:s3:::my-replication-bucket'
              StorageClass: STANDARD
          - Status: Enabled
            Prefix: MyOtherPrefix
            Destination:
              Bucket: 'arn:aws:s3:::my-replication-bucket'
            Specify analytics and inventory configurations for an S3 bucketThe following example specifies analytics and inventory results to be generated for an
          S3 bucket, including the format of the results and the destination bucket. The inventory
          list generates reports weekly and includes the current version of each object.JSON{
    "AWSTemplateFormatVersion": "2010-09-09",
    "Description": "S3 Bucket with Inventory and Analytics Configurations",
    "Resources": {
        "Helper": {
            "Type": "AWS::S3::Bucket"
        },
        "S3Bucket": {
            "Type": "AWS::S3::Bucket",
            "Properties": {
                "AnalyticsConfigurations": [
                    {
                        "Id": "AnalyticsConfigurationId",
                        "StorageClassAnalysis": {
                            "DataExport": {
                                "Destination": {
                                    "BucketArn": {
                                        "Fn::GetAtt": [
                                            "Helper",
                                            "Arn"
                                        ]
                                    },
                                    "Format": "CSV",
                                    "Prefix": "AnalyticsDestinationPrefix"
                                },
                                "OutputSchemaVersion": "V_1"
                            }
                        },
                        "Prefix": "AnalyticsConfigurationPrefix",
                        "TagFilters": [
                            {
                                "Key": "AnalyticsTagKey",
                                "Value": "AnalyticsTagValue"
                            }
                        ]
                    }
                ],
                "InventoryConfigurations": [
                    {
                        "Id": "InventoryConfigurationId",
                        "Destination": {
                            "BucketArn": {
                                "Fn::GetAtt": [
                                    "Helper",
                                    "Arn"
                                ]
                            },
                            "Format": "CSV",
                            "Prefix": "InventoryDestinationPrefix"
                        },
                        "Enabled": true,
                        "IncludedObjectVersions": "Current",
                        "Prefix": "InventoryConfigurationPrefix",
                        "ScheduleFrequency": "Weekly"
                    }
                ]
            }
        }
    }
}YAMLAWSTemplateFormatVersion: 2010-09-09
Description: S3 Bucket with Inventory and Analytics Configurations
Resources:
  Helper:
    Type: 'AWS::S3::Bucket'
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      AnalyticsConfigurations:
        - Id: AnalyticsConfigurationId
          StorageClassAnalysis:
            DataExport:
              Destination:
                BucketArn: !GetAtt
                  - Helper
                  - Arn
                Format: CSV
                Prefix: AnalyticsDestinationPrefix
              OutputSchemaVersion: V_1
          Prefix: AnalyticsConfigurationPrefix
          TagFilters:
            - Key: AnalyticsTagKey
              Value: AnalyticsTagValue
      InventoryConfigurations:
        - Id: InventoryConfigurationId
          Destination:
            BucketArn: !GetAtt
              - Helper
              - Arn
            Format: CSV
            Prefix: InventoryDestinationPrefix
          Enabled: true
          IncludedObjectVersions: Current
          Prefix: InventoryConfigurationPrefix
          ScheduleFrequency: Weekly
        See also
                 
            
                    
                        Amazon S3 Template Snippets
                    
                Document ConventionsVpcConfigurationAbortIncompleteMultipartUploadDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideCloudFormation resource specificationThe AWS CloudFormation resource specification is a JSON-formatted text file that defines the resources
    and properties that CloudFormation supports. The document is a machine-readable, strongly typed
    specification that you can use to build tools for creating CloudFormation templates. For example, you can
    use the specification to build auto completion and validation functionality for CloudFormation templates
    in your IDE (integrated development environment).The resource specification is organized as both a single file and as a series of files,
    where each file contains the definition of one resource type. The single and separated files
    contain identical information. Depending on the tool and your implementation, use the file or
    files that work for you.To download the resource specification, see the following table.Resource availability may vary by region. To check the availability of a resource in a given
    region, refer to the resource specification for that region.
        
          
            Region name
          
          
            Region
          
          
            Single file
          
          
            All files
          
        
      
        
        
        
          
            US East (Ohio)
          
          
            us-east-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            US East (N. Virginia)
          
          
            us-east-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            US West (N. California)
          
          
            us-west-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            US West (Oregon)
          
          
            us-west-2
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Africa (Cape Town)
          
          
            af-south-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Asia Pacific (Hong Kong)
          
          
            ap-east-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Hyderabad)
          
          
            ap-south-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Jakarta)
          
          
            ap-southeast-3
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Melbourne)
          
          
            ap-southeast-4
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Malaysia)
          
          
            ap-southeast-5
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Thailand)
          
          
            ap-southeast-7
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Mumbai)
          
          
            ap-south-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Osaka)
          
          
            ap-northeast-3
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Seoul)
          
          
            ap-northeast-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Singapore)
          
          
            ap-southeast-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Sydney)
          
          
            ap-southeast-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Asia Pacific (Tokyo)
          
          
            ap-northeast-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Canada (Central)
          
          
            ca-central-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Canada West (Calgary)
          
          
            ca-west-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            China (Beijing)
          
          
            cn-north-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            China (Ningxia)
          
          
            cn-northwest-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Europe (Frankfurt)
          
          
            eu-central-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Ireland)
          
          
            eu-west-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (London)
          
          
            eu-west-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Milan)
          
          
            eu-south-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Paris)
          
          
            eu-west-3
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Spain)
          
          
            eu-south-2
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Stockholm)
          
          
            eu-north-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Europe (Zurich)
          
          
            eu-central-2
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Israel (Tel Aviv)
          
          
            il-central-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Middle East (Bahrain)
          
          
            me-south-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            Middle East (UAE)
          
          
            me-central-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            Mexico (Central)
          
          
            mx-central-1
          
          
            .json
          
          
            .zip
          
        
        
        
        
          
            South America (São Paulo)
          
          
            sa-east-1
          
          
            .json
          
          
            .zip
          
        
        
        
          
            AWS GovCloud (US-East)
          
          
            us-gov-east-1
          
          
            .json
          
          
            .zip
          
        
        
          
            AWS GovCloud (US-West)
          
          
            us-gov-west-1
          
          
            .json
          
          
            .zip
          
        
      The following example shows the specification for an AWS Key Management Service key resource
      (AWS::KMS::Key). It shows the properties for the AWS::KMS::Key
    resource, which properties are required, the type of allowed value for each property, and their
    update behavior. For details about the specification, see Specification format.    "AWS::KMS::Key": {
      "Attributes": {
        "Arn": {
          "PrimitiveType": "String"
        }
      },
      "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html",
      "Properties": {
        "Description": {
          "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html#cfn-kms-key-description",
          "PrimitiveType": "String",
          "Required": false,
          "UpdateType": "Mutable"
        },
        "EnableKeyRotation": {
          "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html#cfn-kms-key-enablekeyrotation",
          "PrimitiveType": "Boolean",
          "Required": false,
          "UpdateType": "Mutable"
        },
        "Enabled": {
          "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html#cfn-kms-key-enabled",
          "PrimitiveType": "Boolean",
          "Required": false,
          "UpdateType": "Mutable"
        },
        "KeyPolicy": {
          "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html#cfn-kms-key-keypolicy",
          "PrimitiveType": "Json",
          "Required": true,
          "UpdateType": "Mutable"
        },
        "KeyUsage": {
          "Documentation": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kms-key.html#cfn-kms-key-keyusage",
          "PrimitiveType": "String",
          "Required": false,
          "UpdateType": "Immutable"
        }
      }
    }Document Conventionscfn-hupSpecification formatDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS CloudFormationUser GuideAWS resource and property types referenceThis section contains reference information for all AWS resource and property types that are supported by
  AWS CloudFormation.Resource type identifiers always take the following form:service-provider::service-name::data-type-nameService resource typeAWS Amplify ConsoleAWS Amplify UI BuilderAmazon API GatewayAmazon API Gateway V2AWS AppConfigAmazon AppFlowAmazon AppIntegrationsApplication Auto ScalingAWS App MeshAWS App RunnerAmazon AppStream 2.0AWS AppSyncAWS ARC - Zonal ShiftAlexa Skills KitAmazon AthenaAWS Audit ManagerAWS Auto ScalingAWS B2B Data InterchangeAWS BackupAWS Backup gatewayAWS BatchAmazon BedrockAWS Billing ConductorAWS BudgetsAWS Certificate ManagerAmazon Q Developer in chat applicationsAWS Clean RoomsCleanRoomsMLAWS Cloud9AWS CloudFormationAmazon CloudFrontAWS Cloud MapAWS CloudTrailAmazon CloudWatchAmazon CloudWatch Application InsightsCloudWatch Application SignalsAmazon CloudWatch EvidentlyAmazon CloudWatch Internet MonitorAmazon CloudWatch LogsAmazon CloudWatch SyntheticsAWS CodeArtifactAWS CodeBuildAWS CodeCommitAWS CodeConnectionsAWS CodeDeployAmazon CodeGuru ProfilerAmazon CodeGuru ReviewerAWS CodePipelineAWS CodeStarAWS CodeStar ConnectionsAWS CodeStar NotificationsAmazon CognitoAmazon ComprehendAWS ConfigAmazon ConnectAmazon Connect Outbound Campaigns Amazon Connect Outbound Campaigns V2 AWS Control TowerAmazon Connect Customer ProfilesAWS Cost ExplorerAWS Cost and Usage ReportAWS Data ExportsAmazon Data Lifecycle ManagerAWS Data PipelineAWS DataSyncAmazon DataZoneAWS Deadline CloudDynamoDB AcceleratorAmazon DetectiveAWS Device FarmAmazon DevOps GuruAWS Directory ServiceAWS Database Migration ServiceAmazon DocumentDB (with MongoDB compatibility)Amazon DocumentDB (with MongoDB compatibility) elasticAmazon DynamoDBAmazon EC2Amazon EC2 Auto ScalingAmazon ECRAmazon ECSAmazon Elastic File SystemAmazon Elastic Kubernetes ServiceAWS Elastic BeanstalkElastic Load BalancingElastic Load Balancing V2Amazon EMRAmazon EMR ServerlessAmazon EMR on EKSAmazon ElastiCacheAWS Entity ResolutionAmazon EventBridgeAmazon EventBridge PipesAmazon EventBridge SchedulerAmazon EventBridge SchemasAmazon FinSpace schemasAWS Fault Injection ServiceAWS Firewall ManagerAmazon ForecastAmazon Fraud DetectorAmazon FSxAmazon GameLift ServersAmazon GameLift StreamsAWS Global AcceleratorAWS GlueAWS Glue DataBrewAmazon Managed GrafanaAWS Ground StationAmazon GuardDutyAWS HealthImagingAWS HealthLakeAWS Identity and Access ManagementAWS IAM Identity CenterIdentity StoreAWS Identity and Access Management Access AnalyzerEC2 Image BuilderAWS Systems Manager Incident ManagerAWS Systems Manager Incident Manager ContactsAmazon Inspector classicAmazon InspectorAWS InvoicingAWS IoTAWS IoT AnalyticsAWS IoT Core Device AdvisorAWS IoT EventsFleet Hub for AWS IoT Device ManagementAWS IoT FleetWiseAWS IoT GreengrassAWS IoT Greengrass Version 2AWS IoT SiteWiseAWS IoT TwinMakerAWS IoT WirelessAmazon IVSAmazon IVS ChatAmazon KendraAmazon Kendra Intelligent RankingAmazon Keyspaces (for Apache Cassandra)Amazon KinesisAmazon Managed Service for Apache FlinkAmazon Managed Service for Apache Flink V2Amazon Data FirehoseAmazon Kinesis Video StreamsAWS Key Management ServiceAWS Lake FormationAWS LambdaAWS Launch WizardAmazon LexAWS License ManagerAmazon LightsailAmazon Location ServiceAmazon Lookout for EquipmentAmazon Lookout for MetricsAmazon Lookout for VisionAWS Mainframe ModernizationAWS Mainframe Modernization Application TestingAmazon MacieAmazon Managed BlockchainAWS Elemental MediaConnectAWS Elemental MediaConvertAWS Elemental MediaLiveAWS Elemental MediaPackageAWS Elemental MediaPackage V2AWS Elemental MediaTailorAWS Elemental MediaStoreAmazon MQAmazon MemoryDBAmazon Managed Streaming for Apache KafkaAmazon Managed Streaming for Apache Kafka ConnectAmazon Managed Workflows for Apache AirflowAmazon NeptuneAmazon Neptune AnalyticsAWS Network FirewallAWS Network ManagerNotificationsNotificationsContactsObservability Access Manager (OAM)AWS HealthOmicsAmazon OpenSearch IngestionAmazon OpenSearch ServiceAmazon OpenSearch Service (legacy Elasticsearch resource)Amazon OpenSearch ServerlessAWS OpsWorksAWS OpsWorks CMAWS OrganizationsAWS PCSAWS PanoramaAWS Payment CryptographyAmazon PersonalizeAmazon PinpointAmazon Pinpoint EmailAWS Private Certificate AuthorityAWS Private Certificate Authority for Active DirectoryAWS Private Certificate Authority Connector for SCEPAWS ProtonAmazon Managed Service for PrometheusAmazon Q BusinessAmazon QLDBAmazon QuickSightAWS Resource Access ManagerRecycle BinAmazon Relational Database ServiceAmazon RedshiftAmazon Redshift ServerlessAWS Migration Hub Refactor SpacesAmazon RekognitionAWS Resilience HubAWS Resource ExplorerAWS Resource GroupsAWS RoboMakerIAM Roles AnywhereAmazon Route 53Amazon Route 53 Recovery ControlAmazon Route 53 Recovery ReadinessAmazon Route 53 ResolverAmazon Route 53 ProfilesAmazon CloudWatch RUMAmazon S3Amazon S3 ExpressAmazon S3 Object LambdaAmazon S3 on OutpostsAmazon S3 TablesAmazon SageMaker AIAWS Secrets ManagerAmazon Security LakeAWS Service CatalogAWS Service Catalog AppRegistryAWS Security HubAmazon Simple Email ServiceAmazon SimpleDBAWS ShieldAWS SignerAWS SimSpace WeaverAmazon Simple Notification ServiceAmazon Simple Queue ServiceAWS Step FunctionsAWS Systems ManagerAWS Systems Manager Quick SetupAWS Support AppAWS Systems Manager for SAPAmazon TimestreamAWS Transfer FamilyAmazon Verified PermissionsAmazon Connect Voice ID Amazon VPC LatticeAWS WAFAWS WAF RegionalAWS WAF V2Amazon Connect WisdomAmazon WorkSpacesAmazon WorkSpaces Thin ClientAmazon WorkSpaces Secure BrowserAWS X-RayShared property typesDocument ConventionsTemplate referenceAWS Amplify ConsoleDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nclass Bucket (construct)


LanguageType name


 .NETAmazon.CDK.AWS.S3.Bucket
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awss3#Bucket
 Javasoftware.amazon.awscdk.services.s3.Bucket
 Pythonaws_cdk.aws_s3.Bucket
 TypeScript (source)aws-cdk-lib » aws_s3 » Bucket


Implements
IConstruct, IDependable, IResource, IBucket
An S3 bucket with associated policy objects.
This bucket does not yet have all features that exposed by the underlying
BucketResource.
Example
import { RemovalPolicy } from 'aws-cdk-lib';

new s3.Bucket(scope, 'Bucket', {
  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,
  encryption: s3.BucketEncryption.S3_MANAGED,
  enforceSSL: true,
  versioned: true,
  removalPolicy: RemovalPolicy.RETAIN,
});

Initializer
new Bucket(scope: Construct, id: string, props?: BucketProps)

Parameters

scope Construct
id string
props BucketProps

Construct Props


NameTypeDescription


accessControl?BucketAccessControlSpecifies a canned ACL that grants predefined permissions to the bucket.
autoDeleteObjects?booleanWhether all objects should be automatically deleted when the bucket is removed from the stack or when the stack is deleted.
blockPublicAccess?BlockPublicAccessThe block public access configuration of this bucket.
bucketKeyEnabled?booleanWhether Amazon S3 should use its own intermediary key to generate data keys.
bucketName?stringPhysical name of this bucket.
cors?CorsRule[]The CORS configuration of this bucket.
encryption?BucketEncryptionThe kind of server-side encryption to apply to this bucket.
encryptionKey?IKeyExternal KMS key to use for bucket encryption.
enforceSSL?booleanEnforces SSL for requests.
eventBridgeEnabled?booleanWhether this bucket should send notifications to Amazon EventBridge or not.
intelligentTieringConfigurations?IntelligentTieringConfiguration[]Intelligent Tiering Configurations.
inventories?Inventory[]The inventory configuration of the bucket.
lifecycleRules?LifecycleRule[]Rules that define how Amazon S3 manages objects during their lifetime.
metrics?BucketMetrics[]The metrics configuration of this bucket.
minimumTLSVersion?numberEnforces minimum TLS version for requests.
notificationsHandlerRole?IRoleThe role to be used by the notifications handler.
notificationsSkipDestinationValidation?booleanSkips notification validation of Amazon SQS, Amazon SNS, and Lambda destinations.
objectLockDefaultRetention?ObjectLockRetentionThe default retention mode and rules for S3 Object Lock.
objectLockEnabled?booleanEnable object lock on the bucket.
objectOwnership?ObjectOwnershipThe objectOwnership of the bucket.
publicReadAccess?booleanGrants public read access to all objects in the bucket.
removalPolicy?RemovalPolicyPolicy to apply when the bucket is removed from this stack.
replicationRole?IRoleThe role to be used by the replication.
replicationRules?ReplicationRule[]A container for one or more replication rules.
serverAccessLogsBucket?IBucketDestination bucket for the server access logs.
serverAccessLogsPrefix?stringOptional log file prefix to use for the bucket's access logs.
targetObjectKeyFormat?TargetObjectKeyFormatOptional key format for log objects.
transferAcceleration?booleanWhether this bucket should have transfer acceleration turned on or not.
transitionDefaultMinimumObjectSize?TransitionDefaultMinimumObjectSizeIndicates which default minimum object size behavior is applied to the lifecycle configuration.
versioned?booleanWhether this bucket should have versioning turned on or not.
websiteErrorDocument?stringThe name of the error document (e.g. "404.html") for the website. websiteIndexDocument must also be set if this is set.
websiteIndexDocument?stringThe name of the index document (e.g. "index.html") for the website. Enables static website hosting for this bucket.
websiteRedirect?RedirectTargetSpecifies the redirect behavior of all requests to a website endpoint of a bucket.
websiteRoutingRules?RoutingRule[]Rules that define when a redirect is applied and the redirect behavior.



accessControl?
Type:
BucketAccessControl
(optional, default: BucketAccessControl.PRIVATE)
Specifies a canned ACL that grants predefined permissions to the bucket.

autoDeleteObjects?
Type:
boolean
(optional, default: false)
Whether all objects should be automatically deleted when the bucket is removed from the stack or when the stack is deleted.
Requires the removalPolicy to be set to RemovalPolicy.DESTROY.
Warning if you have deployed a bucket with autoDeleteObjects: true,
switching this to false in a CDK version before 1.126.0 will lead to
all objects in the bucket being deleted. Be sure to update your bucket resources
by deploying with CDK version 1.126.0 or later before switching this value to false.
Setting autoDeleteObjects to true on a bucket will add s3:PutBucketPolicy to the
bucket policy. This is because during bucket deletion, the custom resource provider
needs to update the bucket policy by adding a deny policy for s3:PutObject to
prevent race conditions with external bucket writers.

blockPublicAccess?
Type:
BlockPublicAccess
(optional, default: CloudFormation defaults will apply. New buckets and objects don't allow public access, but users can modify bucket policies or object permissions to allow public access)
The block public access configuration of this bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html

bucketKeyEnabled?
Type:
boolean
(optional, default: false)
Whether Amazon S3 should use its own intermediary key to generate data keys.
Only relevant when using KMS for encryption.

If not enabled, every object GET and PUT will cause an API call to KMS (with the
attendant cost implications of that).
If enabled, S3 will use its own time-limited key instead.

Only relevant, when Encryption is not set to BucketEncryption.UNENCRYPTED.

bucketName?
Type:
string
(optional, default: Assigned by CloudFormation (recommended).)
Physical name of this bucket.

cors?
Type:
CorsRule[]
(optional, default: No CORS configuration.)
The CORS configuration of this bucket.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-cors.html

encryption?
Type:
BucketEncryption
(optional, default: KMS if encryptionKey is specified, or S3_MANAGED otherwise.)
The kind of server-side encryption to apply to this bucket.
If you choose KMS, you can specify a KMS key via encryptionKey. If
encryption key is not specified, a key will automatically be created.

encryptionKey?
Type:
IKey
(optional, default: If encryption is set to KMS and this property is undefined,
a new KMS key will be created and associated with this bucket.)
External KMS key to use for bucket encryption.
The encryption property must be either not specified or set to KMS or DSSE.
An error will be emitted if encryption is set to UNENCRYPTED or S3_MANAGED.

enforceSSL?
Type:
boolean
(optional, default: false)
Enforces SSL for requests.
S3.5 of the AWS Foundational Security Best Practices Regarding S3.
See also: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-ssl-requests-only.html

eventBridgeEnabled?
Type:
boolean
(optional, default: false)
Whether this bucket should send notifications to Amazon EventBridge or not.

intelligentTieringConfigurations?
Type:
IntelligentTieringConfiguration[]
(optional, default: No Intelligent Tiiering Configurations.)
Intelligent Tiering Configurations.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering.html

inventories?
Type:
Inventory[]
(optional, default: No inventory configuration)
The inventory configuration of the bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html

lifecycleRules?
Type:
LifecycleRule[]
(optional, default: No lifecycle rules.)
Rules that define how Amazon S3 manages objects during their lifetime.

metrics?
Type:
BucketMetrics[]
(optional, default: No metrics configuration.)
The metrics configuration of this bucket.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-metricsconfiguration.html

minimumTLSVersion?
Type:
number
(optional, default: No minimum TLS version is enforced.)
Enforces minimum TLS version for requests.
Requires enforceSSL to be enabled.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/amazon-s3-policy-keys.html#example-object-tls-version

notificationsHandlerRole?
Type:
IRole
(optional, default: a new role will be created.)
The role to be used by the notifications handler.

notificationsSkipDestinationValidation?
Type:
boolean
(optional, default: false)
Skips notification validation of Amazon SQS, Amazon SNS, and Lambda destinations.

objectLockDefaultRetention?
Type:
ObjectLockRetention
(optional, default: no default retention period)
The default retention mode and rules for S3 Object Lock.
Default retention can be configured after a bucket is created if the bucket already
has object lock enabled. Enabling object lock for existing buckets is not supported.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html#object-lock-bucket-config-enable

objectLockEnabled?
Type:
boolean
(optional, default: false, unless objectLockDefaultRetention is set (then, true))
Enable object lock on the bucket.
Enabling object lock for existing buckets is not supported. Object lock must be
enabled when the bucket is created.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html#object-lock-bucket-config-enable

objectOwnership?
Type:
ObjectOwnership
(optional, default: No ObjectOwnership configuration. By default, Amazon S3 sets Object Ownership to Bucket owner enforced.
This means ACLs are disabled and the bucket owner will own every object.)
The objectOwnership of the bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/about-object-ownership.html

publicReadAccess?
Type:
boolean
(optional, default: false)
Grants public read access to all objects in the bucket.
Similar to calling bucket.grantPublicAccess()

removalPolicy?
Type:
RemovalPolicy
(optional, default: The bucket will be orphaned.)
Policy to apply when the bucket is removed from this stack.

replicationRole?
Type:
IRole
(optional, default: a new role will be created.)
The role to be used by the replication.
When setting this property, you must also set replicationRules.

replicationRules?
Type:
ReplicationRule[]
(optional, default: No replication)
A container for one or more replication rules.

serverAccessLogsBucket?
Type:
IBucket
(optional, default: If "serverAccessLogsPrefix" undefined - access logs disabled, otherwise - log to current bucket.)
Destination bucket for the server access logs.

serverAccessLogsPrefix?
Type:
string
(optional, default: No log file prefix)
Optional log file prefix to use for the bucket's access logs.
If defined without "serverAccessLogsBucket", enables access logs to current bucket with this prefix.

targetObjectKeyFormat?
Type:
TargetObjectKeyFormat
(optional, default: the default key format is: [DestinationPrefix][YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString])
Optional key format for log objects.

transferAcceleration?
Type:
boolean
(optional, default: false)
Whether this bucket should have transfer acceleration turned on or not.

transitionDefaultMinimumObjectSize?
Type:
TransitionDefaultMinimumObjectSize
(optional, default: TransitionDefaultMinimumObjectSize.VARIES_BY_STORAGE_CLASS before September 2024,
otherwise TransitionDefaultMinimumObjectSize.ALL_STORAGE_CLASSES_128_K.)
Indicates which default minimum object size behavior is applied to the lifecycle configuration.
To customize the minimum object size for any transition you can add a filter that specifies a custom
objectSizeGreaterThan or objectSizeLessThan for lifecycleRules property. Custom filters always
take precedence over the default transition behavior.

versioned?
Type:
boolean
(optional, default: false (unless object lock is enabled, then true))
Whether this bucket should have versioning turned on or not.

websiteErrorDocument?
Type:
string
(optional, default: No error document.)
The name of the error document (e.g. "404.html") for the website. websiteIndexDocument must also be set if this is set.

websiteIndexDocument?
Type:
string
(optional, default: No index document.)
The name of the index document (e.g. "index.html") for the website. Enables static website hosting for this bucket.

websiteRedirect?
Type:
RedirectTarget
(optional, default: No redirection.)
Specifies the redirect behavior of all requests to a website endpoint of a bucket.
If you specify this property, you can't specify "websiteIndexDocument", "websiteErrorDocument" nor , "websiteRoutingRules".

websiteRoutingRules?
Type:
RoutingRule[]
(optional, default: No redirection rules.)
Rules that define when a redirect is applied and the redirect behavior.
Properties


NameTypeDescription


autoCreatePolicybooleanIndicates if a bucket resource policy should automatically created upon the first call to addToResourcePolicy.
bucketArnstringThe ARN of the bucket.
bucketDomainNamestringThe IPv4 DNS name of the specified bucket.
bucketDualStackDomainNamestringThe IPv6 DNS name of the specified bucket.
bucketNamestringThe name of the bucket.
bucketRegionalDomainNamestringThe regional domain name of the specified bucket.
bucketWebsiteDomainNamestringThe Domain name of the static website.
bucketWebsiteUrlstringThe URL of the static website.
envResourceEnvironmentThe environment this resource belongs to.
nodeNodeThe tree node.
stackStackThe stack in which this resource is defined.
disallowPublicAccess?booleanWhether to disallow public access.
encryptionKey?IKeyOptional KMS encryption key associated with this bucket.
isWebsite?booleanIf this bucket has been configured for static website hosting.
policy?BucketPolicyThe resource policy associated with this bucket.
replicationRoleArn?stringRole used to set up permissions on this bucket for replication.



autoCreatePolicy
Type:
boolean
Indicates if a bucket resource policy should automatically created upon the first call to addToResourcePolicy.

bucketArn
Type:
string
The ARN of the bucket.

bucketDomainName
Type:
string
The IPv4 DNS name of the specified bucket.

bucketDualStackDomainName
Type:
string
The IPv6 DNS name of the specified bucket.

bucketName
Type:
string
The name of the bucket.

bucketRegionalDomainName
Type:
string
The regional domain name of the specified bucket.

bucketWebsiteDomainName
Type:
string
The Domain name of the static website.

bucketWebsiteUrl
Type:
string
The URL of the static website.

env
Type:
ResourceEnvironment
The environment this resource belongs to.
For resources that are created and managed by the CDK
(generally, those created by creating new class instances like Role, Bucket, etc.),
this is always the same as the environment of the stack they belong to;
however, for imported resources
(those obtained from static methods like fromRoleArn, fromBucketName, etc.),
that might be different than the stack they were imported into.

node
Type:
Node
The tree node.

stack
Type:
Stack
The stack in which this resource is defined.

disallowPublicAccess?
Type:
boolean
(optional)
Whether to disallow public access.

encryptionKey?
Type:
IKey
(optional)
Optional KMS encryption key associated with this bucket.

isWebsite?
Type:
boolean
(optional)
If this bucket has been configured for static website hosting.

policy?
Type:
BucketPolicy
(optional)
The resource policy associated with this bucket.
If autoCreatePolicy is true, a BucketPolicy will be created upon the
first call to addToResourcePolicy(s).

replicationRoleArn?
Type:
string
(optional)
Role used to set up permissions on this bucket for replication.
Methods


NameDescription


addCorsRule(rule)Adds a cross-origin access configuration for objects in an Amazon S3 bucket.
addEventNotification(event, dest, ...filters)Adds a bucket notification event destination.
addInventory(inventory)Add an inventory configuration.
addLifecycleRule(rule)Add a lifecycle rule to the bucket.
addMetric(metric)Adds a metrics configuration for the CloudWatch request metrics from the bucket.
addObjectCreatedNotification(dest, ...filters)Subscribes a destination to receive notifications when an object is created in the bucket.
addObjectRemovedNotification(dest, ...filters)Subscribes a destination to receive notifications when an object is removed from the bucket.
addReplicationPolicy(roleArn, accessControlTransition?, account?)Function to add required permissions to the destination bucket for cross account replication.
addToResourcePolicy(permission)Adds a statement to the resource policy for a principal (i.e. account/role/service) to perform actions on this bucket and/or its contents. Use bucketArn and arnForObjects(keys) to obtain ARNs for this bucket or objects.
applyRemovalPolicy(policy)Apply the given removal policy to this resource.
arnForObjects(keyPattern)Returns an ARN that represents all objects within the bucket that match the key pattern specified.
enableEventBridgeNotification()Enables event bridge notification, causing all events below to be sent to EventBridge:.
grantDelete(identity, objectsKeyPattern?)Grants s3:DeleteObject* permission to an IAM principal for objects in this bucket.
grantPublicAccess(keyPrefix?, ...allowedActions)Allows unrestricted access to objects from this bucket.
grantPut(identity, objectsKeyPattern?)Grants s3:PutObject* and s3:Abort* permissions for this bucket to an IAM principal.
grantPutAcl(identity, objectsKeyPattern?)Grant the given IAM identity permissions to modify the ACLs of objects in the given Bucket.
grantRead(identity, objectsKeyPattern?)Grant read permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
grantReadWrite(identity, objectsKeyPattern?)Grants read/write permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
grantWrite(identity, objectsKeyPattern?, allowedActionPatterns?)Grant write permissions to this bucket to an IAM principal.
onCloudTrailEvent(id, options?)Define a CloudWatch event that triggers when something happens to this repository.
onCloudTrailPutObject(id, options?)Defines an AWS CloudWatch event that triggers when an object is uploaded to the specified paths (keys) in this bucket using the PutObject API call.
onCloudTrailWriteObject(id, options?)Defines an AWS CloudWatch event that triggers when an object at the specified paths (keys) in this bucket are written to.
s3UrlForObject(key?)The S3 URL of an S3 object. For example:.
toString()Returns a string representation of this construct.
transferAccelerationUrlForObject(key?, options?)The https Transfer Acceleration URL of an S3 object.
urlForObject(key?)The https URL of an S3 object. Specify regional: false at the options for non-regional URLs. For example:.
virtualHostedUrlForObject(key?, options?)The virtual hosted-style URL of an S3 object. Specify regional: false at the options for non-regional URL. For example:.
static fromBucketArn(scope, id, bucketArn)
static fromBucketAttributes(scope, id, attrs)Creates a Bucket construct that represents an external bucket.
static fromBucketName(scope, id, bucketName)
static fromCfnBucket(cfnBucket)Create a mutable IBucket based on a low-level CfnBucket.
static validateBucketName(physicalName, allowLegacyBucketNaming?)Thrown an exception if the given bucket name is not valid.



addCorsRule(rule)
public addCorsRule(rule: CorsRule): void

Parameters

rule CorsRule  — The CORS configuration rule to add.

Adds a cross-origin access configuration for objects in an Amazon S3 bucket.

addEventNotification(event, dest, ...filters)
public addEventNotification(event: EventType, dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

event EventType  — The event to trigger the notification.
dest IBucketNotificationDestination  — The notification destination (Lambda, SNS Topic or SQS Queue).
filters NotificationKeyFilter  — S3 object key filter rules to determine which objects trigger this event.

Adds a bucket notification event destination.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html
Example
   declare const myLambda: lambda.Function;
   const bucket = new s3.Bucket(this, 'MyBucket');
   bucket.addEventNotification(s3.EventType.OBJECT_CREATED, new s3n.LambdaDestination(myLambda), {prefix: 'home/myusername/*'});


addInventory(inventory)
public addInventory(inventory: Inventory): void

Parameters

inventory Inventory  — configuration to add.

Add an inventory configuration.

addLifecycleRule(rule)
public addLifecycleRule(rule: LifecycleRule): void

Parameters

rule LifecycleRule  — The rule to add.

Add a lifecycle rule to the bucket.

addMetric(metric)
public addMetric(metric: BucketMetrics): void

Parameters

metric BucketMetrics  — The metric configuration to add.

Adds a metrics configuration for the CloudWatch request metrics from the bucket.

addObjectCreatedNotification(dest, ...filters)
public addObjectCreatedNotification(dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

dest IBucketNotificationDestination  — The notification destination (see onEvent).
filters NotificationKeyFilter  — Filters (see onEvent).

Subscribes a destination to receive notifications when an object is created in the bucket.
This is identical to calling
onEvent(EventType.OBJECT_CREATED).

addObjectRemovedNotification(dest, ...filters)
public addObjectRemovedNotification(dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

dest IBucketNotificationDestination  — The notification destination (see onEvent).
filters NotificationKeyFilter  — Filters (see onEvent).

Subscribes a destination to receive notifications when an object is removed from the bucket.
This is identical to calling
onEvent(EventType.OBJECT_REMOVED).

addReplicationPolicy(roleArn, accessControlTransition?, account?)
public addReplicationPolicy(roleArn: string, accessControlTransition?: boolean, account?: string): void

Parameters

roleArn string
accessControlTransition boolean
account string

Function to add required permissions to the destination bucket for cross account replication.
These permissions will be added as a resource based policy on the bucket
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-accesscontroltranslation.html

addToResourcePolicy(permission)
public addToResourcePolicy(permission: PolicyStatement): AddToResourcePolicyResult

Parameters

permission PolicyStatement  — the policy statement to be added to the bucket's policy.

Returns

AddToResourcePolicyResult

Adds a statement to the resource policy for a principal (i.e. account/role/service) to perform actions on this bucket and/or its contents. Use bucketArn and arnForObjects(keys) to obtain ARNs for this bucket or objects.
Note that the policy statement may or may not be added to the policy.
For example, when an IBucket is created from an existing bucket,
it's not possible to tell whether the bucket already has a policy
attached, let alone to re-use that policy to add more statements to it.
So it's safest to do nothing in these cases.

applyRemovalPolicy(policy)
public applyRemovalPolicy(policy: RemovalPolicy): void

Parameters

policy RemovalPolicy

Apply the given removal policy to this resource.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN).

arnForObjects(keyPattern)
public arnForObjects(keyPattern: string): string

Parameters

keyPattern string

Returns

string

Returns an ARN that represents all objects within the bucket that match the key pattern specified.
To represent all keys, specify "*".
If you need to specify a keyPattern with multiple components, concatenate them into a single string, e.g.:
arnForObjects(home/${team}/${user}/*)

enableEventBridgeNotification()
public enableEventBridgeNotification(): void

Enables event bridge notification, causing all events below to be sent to EventBridge:.

Object Deleted (DeleteObject)
Object Deleted (Lifecycle expiration)
Object Restore Initiated
Object Restore Completed
Object Restore Expired
Object Storage Class Changed
Object Access Tier Changed
Object ACL Updated
Object Tags Added
Object Tags Deleted


grantDelete(identity, objectsKeyPattern?)
public grantDelete(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grants s3:DeleteObject* permission to an IAM principal for objects in this bucket.

grantPublicAccess(keyPrefix?, ...allowedActions)
public grantPublicAccess(keyPrefix?: string, ...allowedActions: string[]): Grant

Parameters

keyPrefix string  — the prefix of S3 object keys (e.g. home/*). Default is "*".
allowedActions string  — the set of S3 actions to allow.

Returns

Grant

Allows unrestricted access to objects from this bucket.
IMPORTANT: This permission allows anyone to perform actions on S3 objects
in this bucket, which is useful for when you configure your bucket as a
website and want everyone to be able to read objects in the bucket without
needing to authenticate.
Without arguments, this method will grant read ("s3:GetObject") access to
all objects ("*") in the bucket.
The method returns the iam.Grant object, which can then be modified
as needed. For example, you can add a condition that will restrict access only
to an IPv4 range like this:
const grant = bucket.grantPublicAccess();
grant.resourceStatement!.addCondition(‘IpAddress’, { “aws:SourceIp”: “54.240.143.0/24” });

Note that if this IBucket refers to an existing bucket, possibly not
managed by CloudFormation, this method will have no effect, since it's
impossible to modify the policy of an existing bucket.

grantPut(identity, objectsKeyPattern?)
public grantPut(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grants s3:PutObject* and s3:Abort* permissions for this bucket to an IAM principal.
If encryption is used, permission to use the key to encrypt the contents
of written files will also be granted to the same principal.

grantPutAcl(identity, objectsKeyPattern?)
public grantPutAcl(identity: IGrantable, objectsKeyPattern?: string): Grant

Parameters

identity IGrantable
objectsKeyPattern string

Returns

Grant

Grant the given IAM identity permissions to modify the ACLs of objects in the given Bucket.
If your application has the '@aws-cdk/aws-s3:grantWriteWithoutAcl' feature flag set,
calling grantWrite or grantReadWrite no longer grants permissions to modify the ACLs of the objects;
in this case, if you need to modify object ACLs, call this method explicitly.

grantRead(identity, objectsKeyPattern?)
public grantRead(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grant read permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
If encryption is used, permission to use the key to decrypt the contents
of the bucket will also be granted to the same principal.

grantReadWrite(identity, objectsKeyPattern?)
public grantReadWrite(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable
objectsKeyPattern any

Returns

Grant

Grants read/write permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
If an encryption key is used, permission to use the key for
encrypt/decrypt will also be granted.
Before CDK version 1.85.0, this method granted the s3:PutObject* permission that included s3:PutObjectAcl,
which could be used to grant read/write object access to IAM principals in other accounts.
If you want to get rid of that behavior, update your CDK version to 1.85.0 or later,
and make sure the @aws-cdk/aws-s3:grantWriteWithoutAcl feature flag is set to true
in the context key of your cdk.json file.
If you've already updated, but still need the principal to have permissions to modify the ACLs,
use the grantPutAcl method.

grantWrite(identity, objectsKeyPattern?, allowedActionPatterns?)
public grantWrite(identity: IGrantable, objectsKeyPattern?: any, allowedActionPatterns?: string[]): Grant

Parameters

identity IGrantable
objectsKeyPattern any
allowedActionPatterns string[]

Returns

Grant

Grant write permissions to this bucket to an IAM principal.
If encryption is used, permission to use the key to encrypt the contents
of written files will also be granted to the same principal.
Before CDK version 1.85.0, this method granted the s3:PutObject* permission that included s3:PutObjectAcl,
which could be used to grant read/write object access to IAM principals in other accounts.
If you want to get rid of that behavior, update your CDK version to 1.85.0 or later,
and make sure the @aws-cdk/aws-s3:grantWriteWithoutAcl feature flag is set to true
in the context key of your cdk.json file.
If you've already updated, but still need the principal to have permissions to modify the ACLs,
use the grantPutAcl method.

onCloudTrailEvent(id, options?)
public onCloudTrailEvent(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Define a CloudWatch event that triggers when something happens to this repository.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

onCloudTrailPutObject(id, options?)
public onCloudTrailPutObject(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Defines an AWS CloudWatch event that triggers when an object is uploaded to the specified paths (keys) in this bucket using the PutObject API call.
Note that some tools like aws s3 cp will automatically use either
PutObject or the multipart upload API depending on the file size,
so using onCloudTrailWriteObject may be preferable.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

onCloudTrailWriteObject(id, options?)
public onCloudTrailWriteObject(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Defines an AWS CloudWatch event that triggers when an object at the specified paths (keys) in this bucket are written to.
This includes
the events PutObject, CopyObject, and CompleteMultipartUpload.
Note that some tools like aws s3 cp will automatically use either
PutObject or the multipart upload API depending on the file size,
so using this method may be preferable to onCloudTrailPutObject.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

s3UrlForObject(key?)
public s3UrlForObject(key?: string): string

Parameters

key string  — The S3 key of the object.

Returns

string

The S3 URL of an S3 object. For example:.

s3://onlybucket
s3://bucket/key


toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

transferAccelerationUrlForObject(key?, options?)
public transferAccelerationUrlForObject(key?: string, options?: TransferAccelerationUrlOptions): string

Parameters

key string  — The S3 key of the object.
options TransferAccelerationUrlOptions  — Options for generating URL.

Returns

string

The https Transfer Acceleration URL of an S3 object.
Specify dualStack: true at the options
for dual-stack endpoint (connect to the bucket over IPv6). For example:

https://bucket.s3-accelerate.amazonaws.com
https://bucket.s3-accelerate.amazonaws.com/key


urlForObject(key?)
public urlForObject(key?: string): string

Parameters

key string  — The S3 key of the object.

Returns

string

The https URL of an S3 object. Specify regional: false at the options for non-regional URLs. For example:.

https://s3.us-west-1.amazonaws.com/onlybucket
https://s3.us-west-1.amazonaws.com/bucket/key
https://s3.cn-north-1.amazonaws.com.cn/china-bucket/mykey


virtualHostedUrlForObject(key?, options?)
public virtualHostedUrlForObject(key?: string, options?: VirtualHostedStyleUrlOptions): string

Parameters

key string  — The S3 key of the object.
options VirtualHostedStyleUrlOptions  — Options for generating URL.

Returns

string

The virtual hosted-style URL of an S3 object. Specify regional: false at the options for non-regional URL. For example:.

https://only-bucket.s3.us-west-1.amazonaws.com
https://bucket.s3.us-west-1.amazonaws.com/key
https://bucket.s3.amazonaws.com/key
https://china-bucket.s3.cn-north-1.amazonaws.com.cn/mykey


static fromBucketArn(scope, id, bucketArn)
public static fromBucketArn(scope: Construct, id: string, bucketArn: string): IBucket

Parameters

scope Construct
id string
bucketArn string

Returns

IBucket


static fromBucketAttributes(scope, id, attrs)
public static fromBucketAttributes(scope: Construct, id: string, attrs: BucketAttributes): IBucket

Parameters

scope Construct  — The parent creating construct (usually this).
id string  — The construct's name.
attrs BucketAttributes  — A BucketAttributes object.

Returns

IBucket

Creates a Bucket construct that represents an external bucket.

static fromBucketName(scope, id, bucketName)
public static fromBucketName(scope: Construct, id: string, bucketName: string): IBucket

Parameters

scope Construct
id string
bucketName string

Returns

IBucket


static fromCfnBucket(cfnBucket)
public static fromCfnBucket(cfnBucket: CfnBucket): IBucket

Parameters

cfnBucket CfnBucket

Returns

IBucket

Create a mutable IBucket based on a low-level CfnBucket.

static validateBucketName(physicalName, allowLegacyBucketNaming?)
public static validateBucketName(physicalName: string, allowLegacyBucketNaming?: boolean): void

Parameters

physicalName string  — name of the bucket.
allowLegacyBucketNaming boolean  — allow legacy bucket naming style, default is false.

Thrown an exception if the given bucket name is not valid.\n\nclass Bucket (construct)


LanguageType name


 .NETAmazon.CDK.AWS.S3.Bucket
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awss3#Bucket
 Javasoftware.amazon.awscdk.services.s3.Bucket
 Pythonaws_cdk.aws_s3.Bucket
 TypeScript (source)aws-cdk-lib » aws_s3 » Bucket


Implements
IConstruct, IDependable, IResource, IBucket
An S3 bucket with associated policy objects.
This bucket does not yet have all features that exposed by the underlying
BucketResource.
Example
import { RemovalPolicy } from 'aws-cdk-lib';

new s3.Bucket(scope, 'Bucket', {
  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,
  encryption: s3.BucketEncryption.S3_MANAGED,
  enforceSSL: true,
  versioned: true,
  removalPolicy: RemovalPolicy.RETAIN,
});

Initializer
new Bucket(scope: Construct, id: string, props?: BucketProps)

Parameters

scope Construct
id string
props BucketProps

Construct Props


NameTypeDescription


accessControl?BucketAccessControlSpecifies a canned ACL that grants predefined permissions to the bucket.
autoDeleteObjects?booleanWhether all objects should be automatically deleted when the bucket is removed from the stack or when the stack is deleted.
blockPublicAccess?BlockPublicAccessThe block public access configuration of this bucket.
bucketKeyEnabled?booleanWhether Amazon S3 should use its own intermediary key to generate data keys.
bucketName?stringPhysical name of this bucket.
cors?CorsRule[]The CORS configuration of this bucket.
encryption?BucketEncryptionThe kind of server-side encryption to apply to this bucket.
encryptionKey?IKeyExternal KMS key to use for bucket encryption.
enforceSSL?booleanEnforces SSL for requests.
eventBridgeEnabled?booleanWhether this bucket should send notifications to Amazon EventBridge or not.
intelligentTieringConfigurations?IntelligentTieringConfiguration[]Intelligent Tiering Configurations.
inventories?Inventory[]The inventory configuration of the bucket.
lifecycleRules?LifecycleRule[]Rules that define how Amazon S3 manages objects during their lifetime.
metrics?BucketMetrics[]The metrics configuration of this bucket.
minimumTLSVersion?numberEnforces minimum TLS version for requests.
notificationsHandlerRole?IRoleThe role to be used by the notifications handler.
notificationsSkipDestinationValidation?booleanSkips notification validation of Amazon SQS, Amazon SNS, and Lambda destinations.
objectLockDefaultRetention?ObjectLockRetentionThe default retention mode and rules for S3 Object Lock.
objectLockEnabled?booleanEnable object lock on the bucket.
objectOwnership?ObjectOwnershipThe objectOwnership of the bucket.
publicReadAccess?booleanGrants public read access to all objects in the bucket.
removalPolicy?RemovalPolicyPolicy to apply when the bucket is removed from this stack.
replicationRole?IRoleThe role to be used by the replication.
replicationRules?ReplicationRule[]A container for one or more replication rules.
serverAccessLogsBucket?IBucketDestination bucket for the server access logs.
serverAccessLogsPrefix?stringOptional log file prefix to use for the bucket's access logs.
targetObjectKeyFormat?TargetObjectKeyFormatOptional key format for log objects.
transferAcceleration?booleanWhether this bucket should have transfer acceleration turned on or not.
transitionDefaultMinimumObjectSize?TransitionDefaultMinimumObjectSizeIndicates which default minimum object size behavior is applied to the lifecycle configuration.
versioned?booleanWhether this bucket should have versioning turned on or not.
websiteErrorDocument?stringThe name of the error document (e.g. "404.html") for the website. websiteIndexDocument must also be set if this is set.
websiteIndexDocument?stringThe name of the index document (e.g. "index.html") for the website. Enables static website hosting for this bucket.
websiteRedirect?RedirectTargetSpecifies the redirect behavior of all requests to a website endpoint of a bucket.
websiteRoutingRules?RoutingRule[]Rules that define when a redirect is applied and the redirect behavior.



accessControl?
Type:
BucketAccessControl
(optional, default: BucketAccessControl.PRIVATE)
Specifies a canned ACL that grants predefined permissions to the bucket.

autoDeleteObjects?
Type:
boolean
(optional, default: false)
Whether all objects should be automatically deleted when the bucket is removed from the stack or when the stack is deleted.
Requires the removalPolicy to be set to RemovalPolicy.DESTROY.
Warning if you have deployed a bucket with autoDeleteObjects: true,
switching this to false in a CDK version before 1.126.0 will lead to
all objects in the bucket being deleted. Be sure to update your bucket resources
by deploying with CDK version 1.126.0 or later before switching this value to false.
Setting autoDeleteObjects to true on a bucket will add s3:PutBucketPolicy to the
bucket policy. This is because during bucket deletion, the custom resource provider
needs to update the bucket policy by adding a deny policy for s3:PutObject to
prevent race conditions with external bucket writers.

blockPublicAccess?
Type:
BlockPublicAccess
(optional, default: CloudFormation defaults will apply. New buckets and objects don't allow public access, but users can modify bucket policies or object permissions to allow public access)
The block public access configuration of this bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html

bucketKeyEnabled?
Type:
boolean
(optional, default: false)
Whether Amazon S3 should use its own intermediary key to generate data keys.
Only relevant when using KMS for encryption.

If not enabled, every object GET and PUT will cause an API call to KMS (with the
attendant cost implications of that).
If enabled, S3 will use its own time-limited key instead.

Only relevant, when Encryption is not set to BucketEncryption.UNENCRYPTED.

bucketName?
Type:
string
(optional, default: Assigned by CloudFormation (recommended).)
Physical name of this bucket.

cors?
Type:
CorsRule[]
(optional, default: No CORS configuration.)
The CORS configuration of this bucket.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-cors.html

encryption?
Type:
BucketEncryption
(optional, default: KMS if encryptionKey is specified, or S3_MANAGED otherwise.)
The kind of server-side encryption to apply to this bucket.
If you choose KMS, you can specify a KMS key via encryptionKey. If
encryption key is not specified, a key will automatically be created.

encryptionKey?
Type:
IKey
(optional, default: If encryption is set to KMS and this property is undefined,
a new KMS key will be created and associated with this bucket.)
External KMS key to use for bucket encryption.
The encryption property must be either not specified or set to KMS or DSSE.
An error will be emitted if encryption is set to UNENCRYPTED or S3_MANAGED.

enforceSSL?
Type:
boolean
(optional, default: false)
Enforces SSL for requests.
S3.5 of the AWS Foundational Security Best Practices Regarding S3.
See also: https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-ssl-requests-only.html

eventBridgeEnabled?
Type:
boolean
(optional, default: false)
Whether this bucket should send notifications to Amazon EventBridge or not.

intelligentTieringConfigurations?
Type:
IntelligentTieringConfiguration[]
(optional, default: No Intelligent Tiiering Configurations.)
Intelligent Tiering Configurations.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering.html

inventories?
Type:
Inventory[]
(optional, default: No inventory configuration)
The inventory configuration of the bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html

lifecycleRules?
Type:
LifecycleRule[]
(optional, default: No lifecycle rules.)
Rules that define how Amazon S3 manages objects during their lifetime.

metrics?
Type:
BucketMetrics[]
(optional, default: No metrics configuration.)
The metrics configuration of this bucket.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-metricsconfiguration.html

minimumTLSVersion?
Type:
number
(optional, default: No minimum TLS version is enforced.)
Enforces minimum TLS version for requests.
Requires enforceSSL to be enabled.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/amazon-s3-policy-keys.html#example-object-tls-version

notificationsHandlerRole?
Type:
IRole
(optional, default: a new role will be created.)
The role to be used by the notifications handler.

notificationsSkipDestinationValidation?
Type:
boolean
(optional, default: false)
Skips notification validation of Amazon SQS, Amazon SNS, and Lambda destinations.

objectLockDefaultRetention?
Type:
ObjectLockRetention
(optional, default: no default retention period)
The default retention mode and rules for S3 Object Lock.
Default retention can be configured after a bucket is created if the bucket already
has object lock enabled. Enabling object lock for existing buckets is not supported.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html#object-lock-bucket-config-enable

objectLockEnabled?
Type:
boolean
(optional, default: false, unless objectLockDefaultRetention is set (then, true))
Enable object lock on the bucket.
Enabling object lock for existing buckets is not supported. Object lock must be
enabled when the bucket is created.
See also: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html#object-lock-bucket-config-enable

objectOwnership?
Type:
ObjectOwnership
(optional, default: No ObjectOwnership configuration. By default, Amazon S3 sets Object Ownership to Bucket owner enforced.
This means ACLs are disabled and the bucket owner will own every object.)
The objectOwnership of the bucket.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/about-object-ownership.html

publicReadAccess?
Type:
boolean
(optional, default: false)
Grants public read access to all objects in the bucket.
Similar to calling bucket.grantPublicAccess()

removalPolicy?
Type:
RemovalPolicy
(optional, default: The bucket will be orphaned.)
Policy to apply when the bucket is removed from this stack.

replicationRole?
Type:
IRole
(optional, default: a new role will be created.)
The role to be used by the replication.
When setting this property, you must also set replicationRules.

replicationRules?
Type:
ReplicationRule[]
(optional, default: No replication)
A container for one or more replication rules.

serverAccessLogsBucket?
Type:
IBucket
(optional, default: If "serverAccessLogsPrefix" undefined - access logs disabled, otherwise - log to current bucket.)
Destination bucket for the server access logs.

serverAccessLogsPrefix?
Type:
string
(optional, default: No log file prefix)
Optional log file prefix to use for the bucket's access logs.
If defined without "serverAccessLogsBucket", enables access logs to current bucket with this prefix.

targetObjectKeyFormat?
Type:
TargetObjectKeyFormat
(optional, default: the default key format is: [DestinationPrefix][YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString])
Optional key format for log objects.

transferAcceleration?
Type:
boolean
(optional, default: false)
Whether this bucket should have transfer acceleration turned on or not.

transitionDefaultMinimumObjectSize?
Type:
TransitionDefaultMinimumObjectSize
(optional, default: TransitionDefaultMinimumObjectSize.VARIES_BY_STORAGE_CLASS before September 2024,
otherwise TransitionDefaultMinimumObjectSize.ALL_STORAGE_CLASSES_128_K.)
Indicates which default minimum object size behavior is applied to the lifecycle configuration.
To customize the minimum object size for any transition you can add a filter that specifies a custom
objectSizeGreaterThan or objectSizeLessThan for lifecycleRules property. Custom filters always
take precedence over the default transition behavior.

versioned?
Type:
boolean
(optional, default: false (unless object lock is enabled, then true))
Whether this bucket should have versioning turned on or not.

websiteErrorDocument?
Type:
string
(optional, default: No error document.)
The name of the error document (e.g. "404.html") for the website. websiteIndexDocument must also be set if this is set.

websiteIndexDocument?
Type:
string
(optional, default: No index document.)
The name of the index document (e.g. "index.html") for the website. Enables static website hosting for this bucket.

websiteRedirect?
Type:
RedirectTarget
(optional, default: No redirection.)
Specifies the redirect behavior of all requests to a website endpoint of a bucket.
If you specify this property, you can't specify "websiteIndexDocument", "websiteErrorDocument" nor , "websiteRoutingRules".

websiteRoutingRules?
Type:
RoutingRule[]
(optional, default: No redirection rules.)
Rules that define when a redirect is applied and the redirect behavior.
Properties


NameTypeDescription


autoCreatePolicybooleanIndicates if a bucket resource policy should automatically created upon the first call to addToResourcePolicy.
bucketArnstringThe ARN of the bucket.
bucketDomainNamestringThe IPv4 DNS name of the specified bucket.
bucketDualStackDomainNamestringThe IPv6 DNS name of the specified bucket.
bucketNamestringThe name of the bucket.
bucketRegionalDomainNamestringThe regional domain name of the specified bucket.
bucketWebsiteDomainNamestringThe Domain name of the static website.
bucketWebsiteUrlstringThe URL of the static website.
envResourceEnvironmentThe environment this resource belongs to.
nodeNodeThe tree node.
stackStackThe stack in which this resource is defined.
disallowPublicAccess?booleanWhether to disallow public access.
encryptionKey?IKeyOptional KMS encryption key associated with this bucket.
isWebsite?booleanIf this bucket has been configured for static website hosting.
policy?BucketPolicyThe resource policy associated with this bucket.
replicationRoleArn?stringRole used to set up permissions on this bucket for replication.



autoCreatePolicy
Type:
boolean
Indicates if a bucket resource policy should automatically created upon the first call to addToResourcePolicy.

bucketArn
Type:
string
The ARN of the bucket.

bucketDomainName
Type:
string
The IPv4 DNS name of the specified bucket.

bucketDualStackDomainName
Type:
string
The IPv6 DNS name of the specified bucket.

bucketName
Type:
string
The name of the bucket.

bucketRegionalDomainName
Type:
string
The regional domain name of the specified bucket.

bucketWebsiteDomainName
Type:
string
The Domain name of the static website.

bucketWebsiteUrl
Type:
string
The URL of the static website.

env
Type:
ResourceEnvironment
The environment this resource belongs to.
For resources that are created and managed by the CDK
(generally, those created by creating new class instances like Role, Bucket, etc.),
this is always the same as the environment of the stack they belong to;
however, for imported resources
(those obtained from static methods like fromRoleArn, fromBucketName, etc.),
that might be different than the stack they were imported into.

node
Type:
Node
The tree node.

stack
Type:
Stack
The stack in which this resource is defined.

disallowPublicAccess?
Type:
boolean
(optional)
Whether to disallow public access.

encryptionKey?
Type:
IKey
(optional)
Optional KMS encryption key associated with this bucket.

isWebsite?
Type:
boolean
(optional)
If this bucket has been configured for static website hosting.

policy?
Type:
BucketPolicy
(optional)
The resource policy associated with this bucket.
If autoCreatePolicy is true, a BucketPolicy will be created upon the
first call to addToResourcePolicy(s).

replicationRoleArn?
Type:
string
(optional)
Role used to set up permissions on this bucket for replication.
Methods


NameDescription


addCorsRule(rule)Adds a cross-origin access configuration for objects in an Amazon S3 bucket.
addEventNotification(event, dest, ...filters)Adds a bucket notification event destination.
addInventory(inventory)Add an inventory configuration.
addLifecycleRule(rule)Add a lifecycle rule to the bucket.
addMetric(metric)Adds a metrics configuration for the CloudWatch request metrics from the bucket.
addObjectCreatedNotification(dest, ...filters)Subscribes a destination to receive notifications when an object is created in the bucket.
addObjectRemovedNotification(dest, ...filters)Subscribes a destination to receive notifications when an object is removed from the bucket.
addReplicationPolicy(roleArn, accessControlTransition?, account?)Function to add required permissions to the destination bucket for cross account replication.
addToResourcePolicy(permission)Adds a statement to the resource policy for a principal (i.e. account/role/service) to perform actions on this bucket and/or its contents. Use bucketArn and arnForObjects(keys) to obtain ARNs for this bucket or objects.
applyRemovalPolicy(policy)Apply the given removal policy to this resource.
arnForObjects(keyPattern)Returns an ARN that represents all objects within the bucket that match the key pattern specified.
enableEventBridgeNotification()Enables event bridge notification, causing all events below to be sent to EventBridge:.
grantDelete(identity, objectsKeyPattern?)Grants s3:DeleteObject* permission to an IAM principal for objects in this bucket.
grantPublicAccess(keyPrefix?, ...allowedActions)Allows unrestricted access to objects from this bucket.
grantPut(identity, objectsKeyPattern?)Grants s3:PutObject* and s3:Abort* permissions for this bucket to an IAM principal.
grantPutAcl(identity, objectsKeyPattern?)Grant the given IAM identity permissions to modify the ACLs of objects in the given Bucket.
grantRead(identity, objectsKeyPattern?)Grant read permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
grantReadWrite(identity, objectsKeyPattern?)Grants read/write permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
grantWrite(identity, objectsKeyPattern?, allowedActionPatterns?)Grant write permissions to this bucket to an IAM principal.
onCloudTrailEvent(id, options?)Define a CloudWatch event that triggers when something happens to this repository.
onCloudTrailPutObject(id, options?)Defines an AWS CloudWatch event that triggers when an object is uploaded to the specified paths (keys) in this bucket using the PutObject API call.
onCloudTrailWriteObject(id, options?)Defines an AWS CloudWatch event that triggers when an object at the specified paths (keys) in this bucket are written to.
s3UrlForObject(key?)The S3 URL of an S3 object. For example:.
toString()Returns a string representation of this construct.
transferAccelerationUrlForObject(key?, options?)The https Transfer Acceleration URL of an S3 object.
urlForObject(key?)The https URL of an S3 object. Specify regional: false at the options for non-regional URLs. For example:.
virtualHostedUrlForObject(key?, options?)The virtual hosted-style URL of an S3 object. Specify regional: false at the options for non-regional URL. For example:.
static fromBucketArn(scope, id, bucketArn)
static fromBucketAttributes(scope, id, attrs)Creates a Bucket construct that represents an external bucket.
static fromBucketName(scope, id, bucketName)
static fromCfnBucket(cfnBucket)Create a mutable IBucket based on a low-level CfnBucket.
static validateBucketName(physicalName, allowLegacyBucketNaming?)Thrown an exception if the given bucket name is not valid.



addCorsRule(rule)
public addCorsRule(rule: CorsRule): void

Parameters

rule CorsRule  — The CORS configuration rule to add.

Adds a cross-origin access configuration for objects in an Amazon S3 bucket.

addEventNotification(event, dest, ...filters)
public addEventNotification(event: EventType, dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

event EventType  — The event to trigger the notification.
dest IBucketNotificationDestination  — The notification destination (Lambda, SNS Topic or SQS Queue).
filters NotificationKeyFilter  — S3 object key filter rules to determine which objects trigger this event.

Adds a bucket notification event destination.
See also: https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html
Example
   declare const myLambda: lambda.Function;
   const bucket = new s3.Bucket(this, 'MyBucket');
   bucket.addEventNotification(s3.EventType.OBJECT_CREATED, new s3n.LambdaDestination(myLambda), {prefix: 'home/myusername/*'});


addInventory(inventory)
public addInventory(inventory: Inventory): void

Parameters

inventory Inventory  — configuration to add.

Add an inventory configuration.

addLifecycleRule(rule)
public addLifecycleRule(rule: LifecycleRule): void

Parameters

rule LifecycleRule  — The rule to add.

Add a lifecycle rule to the bucket.

addMetric(metric)
public addMetric(metric: BucketMetrics): void

Parameters

metric BucketMetrics  — The metric configuration to add.

Adds a metrics configuration for the CloudWatch request metrics from the bucket.

addObjectCreatedNotification(dest, ...filters)
public addObjectCreatedNotification(dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

dest IBucketNotificationDestination  — The notification destination (see onEvent).
filters NotificationKeyFilter  — Filters (see onEvent).

Subscribes a destination to receive notifications when an object is created in the bucket.
This is identical to calling
onEvent(EventType.OBJECT_CREATED).

addObjectRemovedNotification(dest, ...filters)
public addObjectRemovedNotification(dest: IBucketNotificationDestination, ...filters: NotificationKeyFilter[]): void

Parameters

dest IBucketNotificationDestination  — The notification destination (see onEvent).
filters NotificationKeyFilter  — Filters (see onEvent).

Subscribes a destination to receive notifications when an object is removed from the bucket.
This is identical to calling
onEvent(EventType.OBJECT_REMOVED).

addReplicationPolicy(roleArn, accessControlTransition?, account?)
public addReplicationPolicy(roleArn: string, accessControlTransition?: boolean, account?: string): void

Parameters

roleArn string
accessControlTransition boolean
account string

Function to add required permissions to the destination bucket for cross account replication.
These permissions will be added as a resource based policy on the bucket
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket-accesscontroltranslation.html

addToResourcePolicy(permission)
public addToResourcePolicy(permission: PolicyStatement): AddToResourcePolicyResult

Parameters

permission PolicyStatement  — the policy statement to be added to the bucket's policy.

Returns

AddToResourcePolicyResult

Adds a statement to the resource policy for a principal (i.e. account/role/service) to perform actions on this bucket and/or its contents. Use bucketArn and arnForObjects(keys) to obtain ARNs for this bucket or objects.
Note that the policy statement may or may not be added to the policy.
For example, when an IBucket is created from an existing bucket,
it's not possible to tell whether the bucket already has a policy
attached, let alone to re-use that policy to add more statements to it.
So it's safest to do nothing in these cases.

applyRemovalPolicy(policy)
public applyRemovalPolicy(policy: RemovalPolicy): void

Parameters

policy RemovalPolicy

Apply the given removal policy to this resource.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN).

arnForObjects(keyPattern)
public arnForObjects(keyPattern: string): string

Parameters

keyPattern string

Returns

string

Returns an ARN that represents all objects within the bucket that match the key pattern specified.
To represent all keys, specify "*".
If you need to specify a keyPattern with multiple components, concatenate them into a single string, e.g.:
arnForObjects(home/${team}/${user}/*)

enableEventBridgeNotification()
public enableEventBridgeNotification(): void

Enables event bridge notification, causing all events below to be sent to EventBridge:.

Object Deleted (DeleteObject)
Object Deleted (Lifecycle expiration)
Object Restore Initiated
Object Restore Completed
Object Restore Expired
Object Storage Class Changed
Object Access Tier Changed
Object ACL Updated
Object Tags Added
Object Tags Deleted


grantDelete(identity, objectsKeyPattern?)
public grantDelete(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grants s3:DeleteObject* permission to an IAM principal for objects in this bucket.

grantPublicAccess(keyPrefix?, ...allowedActions)
public grantPublicAccess(keyPrefix?: string, ...allowedActions: string[]): Grant

Parameters

keyPrefix string  — the prefix of S3 object keys (e.g. home/*). Default is "*".
allowedActions string  — the set of S3 actions to allow.

Returns

Grant

Allows unrestricted access to objects from this bucket.
IMPORTANT: This permission allows anyone to perform actions on S3 objects
in this bucket, which is useful for when you configure your bucket as a
website and want everyone to be able to read objects in the bucket without
needing to authenticate.
Without arguments, this method will grant read ("s3:GetObject") access to
all objects ("*") in the bucket.
The method returns the iam.Grant object, which can then be modified
as needed. For example, you can add a condition that will restrict access only
to an IPv4 range like this:
const grant = bucket.grantPublicAccess();
grant.resourceStatement!.addCondition(‘IpAddress’, { “aws:SourceIp”: “54.240.143.0/24” });

Note that if this IBucket refers to an existing bucket, possibly not
managed by CloudFormation, this method will have no effect, since it's
impossible to modify the policy of an existing bucket.

grantPut(identity, objectsKeyPattern?)
public grantPut(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grants s3:PutObject* and s3:Abort* permissions for this bucket to an IAM principal.
If encryption is used, permission to use the key to encrypt the contents
of written files will also be granted to the same principal.

grantPutAcl(identity, objectsKeyPattern?)
public grantPutAcl(identity: IGrantable, objectsKeyPattern?: string): Grant

Parameters

identity IGrantable
objectsKeyPattern string

Returns

Grant

Grant the given IAM identity permissions to modify the ACLs of objects in the given Bucket.
If your application has the '@aws-cdk/aws-s3:grantWriteWithoutAcl' feature flag set,
calling grantWrite or grantReadWrite no longer grants permissions to modify the ACLs of the objects;
in this case, if you need to modify object ACLs, call this method explicitly.

grantRead(identity, objectsKeyPattern?)
public grantRead(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable  — The principal.
objectsKeyPattern any  — Restrict the permission to a certain key pattern (default '*').

Returns

Grant

Grant read permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
If encryption is used, permission to use the key to decrypt the contents
of the bucket will also be granted to the same principal.

grantReadWrite(identity, objectsKeyPattern?)
public grantReadWrite(identity: IGrantable, objectsKeyPattern?: any): Grant

Parameters

identity IGrantable
objectsKeyPattern any

Returns

Grant

Grants read/write permissions for this bucket and it's contents to an IAM principal (Role/Group/User).
If an encryption key is used, permission to use the key for
encrypt/decrypt will also be granted.
Before CDK version 1.85.0, this method granted the s3:PutObject* permission that included s3:PutObjectAcl,
which could be used to grant read/write object access to IAM principals in other accounts.
If you want to get rid of that behavior, update your CDK version to 1.85.0 or later,
and make sure the @aws-cdk/aws-s3:grantWriteWithoutAcl feature flag is set to true
in the context key of your cdk.json file.
If you've already updated, but still need the principal to have permissions to modify the ACLs,
use the grantPutAcl method.

grantWrite(identity, objectsKeyPattern?, allowedActionPatterns?)
public grantWrite(identity: IGrantable, objectsKeyPattern?: any, allowedActionPatterns?: string[]): Grant

Parameters

identity IGrantable
objectsKeyPattern any
allowedActionPatterns string[]

Returns

Grant

Grant write permissions to this bucket to an IAM principal.
If encryption is used, permission to use the key to encrypt the contents
of written files will also be granted to the same principal.
Before CDK version 1.85.0, this method granted the s3:PutObject* permission that included s3:PutObjectAcl,
which could be used to grant read/write object access to IAM principals in other accounts.
If you want to get rid of that behavior, update your CDK version to 1.85.0 or later,
and make sure the @aws-cdk/aws-s3:grantWriteWithoutAcl feature flag is set to true
in the context key of your cdk.json file.
If you've already updated, but still need the principal to have permissions to modify the ACLs,
use the grantPutAcl method.

onCloudTrailEvent(id, options?)
public onCloudTrailEvent(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Define a CloudWatch event that triggers when something happens to this repository.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

onCloudTrailPutObject(id, options?)
public onCloudTrailPutObject(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Defines an AWS CloudWatch event that triggers when an object is uploaded to the specified paths (keys) in this bucket using the PutObject API call.
Note that some tools like aws s3 cp will automatically use either
PutObject or the multipart upload API depending on the file size,
so using onCloudTrailWriteObject may be preferable.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

onCloudTrailWriteObject(id, options?)
public onCloudTrailWriteObject(id: string, options?: OnCloudTrailBucketEventOptions): Rule

Parameters

id string  — The id of the rule.
options OnCloudTrailBucketEventOptions  — Options for adding the rule.

Returns

Rule

Defines an AWS CloudWatch event that triggers when an object at the specified paths (keys) in this bucket are written to.
This includes
the events PutObject, CopyObject, and CompleteMultipartUpload.
Note that some tools like aws s3 cp will automatically use either
PutObject or the multipart upload API depending on the file size,
so using this method may be preferable to onCloudTrailPutObject.
Requires that there exists at least one CloudTrail Trail in your account
that captures the event. This method will not create the Trail.

s3UrlForObject(key?)
public s3UrlForObject(key?: string): string

Parameters

key string  — The S3 key of the object.

Returns

string

The S3 URL of an S3 object. For example:.

s3://onlybucket
s3://bucket/key


toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

transferAccelerationUrlForObject(key?, options?)
public transferAccelerationUrlForObject(key?: string, options?: TransferAccelerationUrlOptions): string

Parameters

key string  — The S3 key of the object.
options TransferAccelerationUrlOptions  — Options for generating URL.

Returns

string

The https Transfer Acceleration URL of an S3 object.
Specify dualStack: true at the options
for dual-stack endpoint (connect to the bucket over IPv6). For example:

https://bucket.s3-accelerate.amazonaws.com
https://bucket.s3-accelerate.amazonaws.com/key


urlForObject(key?)
public urlForObject(key?: string): string

Parameters

key string  — The S3 key of the object.

Returns

string

The https URL of an S3 object. Specify regional: false at the options for non-regional URLs. For example:.

https://s3.us-west-1.amazonaws.com/onlybucket
https://s3.us-west-1.amazonaws.com/bucket/key
https://s3.cn-north-1.amazonaws.com.cn/china-bucket/mykey


virtualHostedUrlForObject(key?, options?)
public virtualHostedUrlForObject(key?: string, options?: VirtualHostedStyleUrlOptions): string

Parameters

key string  — The S3 key of the object.
options VirtualHostedStyleUrlOptions  — Options for generating URL.

Returns

string

The virtual hosted-style URL of an S3 object. Specify regional: false at the options for non-regional URL. For example:.

https://only-bucket.s3.us-west-1.amazonaws.com
https://bucket.s3.us-west-1.amazonaws.com/key
https://bucket.s3.amazonaws.com/key
https://china-bucket.s3.cn-north-1.amazonaws.com.cn/mykey


static fromBucketArn(scope, id, bucketArn)
public static fromBucketArn(scope: Construct, id: string, bucketArn: string): IBucket

Parameters

scope Construct
id string
bucketArn string

Returns

IBucket


static fromBucketAttributes(scope, id, attrs)
public static fromBucketAttributes(scope: Construct, id: string, attrs: BucketAttributes): IBucket

Parameters

scope Construct  — The parent creating construct (usually this).
id string  — The construct's name.
attrs BucketAttributes  — A BucketAttributes object.

Returns

IBucket

Creates a Bucket construct that represents an external bucket.

static fromBucketName(scope, id, bucketName)
public static fromBucketName(scope: Construct, id: string, bucketName: string): IBucket

Parameters

scope Construct
id string
bucketName string

Returns

IBucket


static fromCfnBucket(cfnBucket)
public static fromCfnBucket(cfnBucket: CfnBucket): IBucket

Parameters

cfnBucket CfnBucket

Returns

IBucket

Create a mutable IBucket based on a low-level CfnBucket.

static validateBucketName(physicalName, allowLegacyBucketNaming?)
public static validateBucketName(physicalName: string, allowLegacyBucketNaming?: boolean): void

Parameters

physicalName string  — name of the bucket.
allowLegacyBucketNaming boolean  — allow legacy bucket naming style, default is false.

Thrown an exception if the given bucket name is not valid.\n\n\n\nclass ApplicationLoadBalancedFargateService (construct)


LanguageType name


 .NETAmazon.CDK.AWS.ECS.Patterns.ApplicationLoadBalancedFargateService
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awsecspatterns#ApplicationLoadBalancedFargateService
 Javasoftware.amazon.awscdk.services.ecs.patterns.ApplicationLoadBalancedFargateService
 Pythonaws_cdk.aws_ecs_patterns.ApplicationLoadBalancedFargateService
 TypeScript (source)aws-cdk-lib » aws_ecs_patterns » ApplicationLoadBalancedFargateService


Implements
IConstruct, IDependable
A Fargate service running on an ECS cluster fronted by an application load balancer.
Example
declare const cluster: ecs.Cluster;
const loadBalancedFargateService = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'Service', {
  cluster,
  memoryLimitMiB: 1024,
  desiredCount: 1,
  cpu: 512,
  taskImageOptions: {
    image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample"),
  },
  minHealthyPercent: 100,
});

const scalableTarget = loadBalancedFargateService.service.autoScaleTaskCount({
  minCapacity: 1,
  maxCapacity: 20,
});

scalableTarget.scaleOnCpuUtilization('CpuScaling', {
  targetUtilizationPercent: 50,
});

scalableTarget.scaleOnMemoryUtilization('MemoryScaling', {
  targetUtilizationPercent: 50,
});

Initializer
new ApplicationLoadBalancedFargateService(scope: Construct, id: string, props?: ApplicationLoadBalancedFargateServiceProps)

Parameters

scope Construct
id string
props ApplicationLoadBalancedFargateServiceProps

Constructs a new instance of the ApplicationLoadBalancedFargateService class.
Construct Props


NameTypeDescription


assignPublicIp?booleanDetermines whether the service will be assigned a public IP address.
capacityProviderStrategies?CapacityProviderStrategy[]A list of Capacity Provider strategies used to place a service.
certificate?ICertificateCertificate Manager certificate to associate with the load balancer.
circuitBreaker?DeploymentCircuitBreakerWhether to enable the deployment circuit breaker.
cloudMapOptions?CloudMapOptionsThe options for configuring an Amazon ECS service to use service discovery.
cluster?IClusterThe name of the cluster that hosts the service.
containerCpu?numberThe minimum number of CPU units to reserve for the container.
containerMemoryLimitMiB?numberThe amount (in MiB) of memory to present to the container.
cpu?numberThe number of cpu units used by the task.
deploymentController?DeploymentControllerSpecifies which deployment controller to use for the service.
desiredCount?numberThe desired number of instantiations of the task definition to keep running on the service.
domainName?stringThe domain name for the service, e.g. "api.example.com.".
domainZone?IHostedZoneThe Route53 hosted zone for the domain, e.g. "example.com.".
enableECSManagedTags?booleanSpecifies whether to enable Amazon ECS managed tags for the tasks within the service.
enableExecuteCommand?booleanWhether ECS Exec should be enabled.
ephemeralStorageGiB?numberThe amount (in GiB) of ephemeral storage to be allocated to the task.
healthCheck?HealthCheckThe health check command and associated configuration parameters for the container.
healthCheckGracePeriod?DurationThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.
idleTimeout?DurationThe load balancer idle timeout, in seconds.
ipAddressType?IpAddressTypeThe type of IP address to use.
listenerPort?numberListener port of the application load balancer that will serve traffic to the service.
loadBalancer?IApplicationLoadBalancerThe application load balancer that will serve traffic to the service.
loadBalancerName?stringName of the load balancer.
maxHealthyPercent?numberThe maximum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that can run in a service during a deployment.
memoryLimitMiB?numberThe amount (in MiB) of memory used by the task.
minHealthyPercent?numberThe minimum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that must continue to run and remain healthy during a deployment.
openListener?booleanDetermines whether or not the Security Group for the Load Balancer's Listener will be open to all traffic by default.
platformVersion?FargatePlatformVersionThe platform version on which to run your service.
propagateTags?PropagatedTagSourceSpecifies whether to propagate the tags from the task definition or the service to the tasks in the service.
protocol?ApplicationProtocolThe protocol for connections from clients to the load balancer.
protocolVersion?ApplicationProtocolVersionThe protocol version to use.
publicLoadBalancer?booleanDetermines whether the Load Balancer will be internet-facing.
recordType?ApplicationLoadBalancedServiceRecordTypeSpecifies whether the Route53 record should be a CNAME, an A record using the Alias feature or no record at all.
redirectHTTP?booleanSpecifies whether the load balancer should redirect traffic on port 80 to port 443 to support HTTP->HTTPS redirects This is only valid if the protocol of the ALB is HTTPS.
runtimePlatform?RuntimePlatformThe runtime platform of the task definition.
securityGroups?ISecurityGroup[]The security groups to associate with the service.
serviceName?stringThe name of the service.
sslPolicy?SslPolicyThe security policy that defines which ciphers and protocols are supported by the ALB Listener.
targetProtocol?ApplicationProtocolThe protocol for connections from the load balancer to the ECS tasks.
taskDefinition?FargateTaskDefinitionThe task definition to use for tasks in the service. TaskDefinition or TaskImageOptions must be specified, but not both.
taskImageOptions?ApplicationLoadBalancedTaskImageOptionsThe properties required to create a new task definition.
taskSubnets?SubnetSelectionThe subnets to associate with the service.
vpc?IVpcThe VPC where the container instances will be launched or the elastic network interfaces (ENIs) will be deployed.



assignPublicIp?
Type:
boolean
(optional, default: false)
Determines whether the service will be assigned a public IP address.

capacityProviderStrategies?
Type:
CapacityProviderStrategy[]
(optional, default: undefined)
A list of Capacity Provider strategies used to place a service.

certificate?
Type:
ICertificate
(optional, default: No certificate associated with the load balancer, if using
the HTTP protocol. For HTTPS, a DNS-validated certificate will be
created for the load balancer's specified domain name if a domain name
and domain zone are specified.)
Certificate Manager certificate to associate with the load balancer.
Setting this option will set the load balancer protocol to HTTPS.

circuitBreaker?
Type:
DeploymentCircuitBreaker
(optional, default: disabled)
Whether to enable the deployment circuit breaker.
If this property is defined, circuit breaker will be implicitly
enabled.

cloudMapOptions?
Type:
CloudMapOptions
(optional, default: AWS Cloud Map service discovery is not enabled.)
The options for configuring an Amazon ECS service to use service discovery.

cluster?
Type:
ICluster
(optional, default: create a new cluster; if both cluster and vpc are omitted, a new VPC will be created for you.)
The name of the cluster that hosts the service.
If a cluster is specified, the vpc construct should be omitted. Alternatively, you can omit both cluster and vpc.

containerCpu?
Type:
number
(optional, default: No minimum CPU units reserved.)
The minimum number of CPU units to reserve for the container.

containerMemoryLimitMiB?
Type:
number
(optional, default: No memory limit.)
The amount (in MiB) of memory to present to the container.
If your container attempts to exceed the allocated memory, the container
is terminated.

cpu?
Type:
number
(optional, default: 256)
The number of cpu units used by the task.
Valid values, which determines your range of valid values for the memory parameter:
256 (.25 vCPU) - Available memory values: 0.5GB, 1GB, 2GB
512 (.5 vCPU) - Available memory values: 1GB, 2GB, 3GB, 4GB
1024 (1 vCPU) - Available memory values: 2GB, 3GB, 4GB, 5GB, 6GB, 7GB, 8GB
2048 (2 vCPU) - Available memory values: Between 4GB and 16GB in 1GB increments
4096 (4 vCPU) - Available memory values: Between 8GB and 30GB in 1GB increments
8192 (8 vCPU) - Available memory values: Between 16GB and 60GB in 4GB increments
16384 (16 vCPU) - Available memory values: Between 32GB and 120GB in 8GB increments
This default is set in the underlying FargateTaskDefinition construct.

deploymentController?
Type:
DeploymentController
(optional, default: Rolling update (ECS))
Specifies which deployment controller to use for the service.
For more information, see
Amazon ECS Deployment Types

desiredCount?
Type:
number
(optional, default: The default is 1 for all new services and uses the existing service's desired count
when updating an existing service.)
The desired number of instantiations of the task definition to keep running on the service.
The minimum value is 1

domainName?
Type:
string
(optional, default: No domain name.)
The domain name for the service, e.g. "api.example.com.".

domainZone?
Type:
IHostedZone
(optional, default: No Route53 hosted domain zone.)
The Route53 hosted zone for the domain, e.g. "example.com.".

enableECSManagedTags?
Type:
boolean
(optional, default: false)
Specifies whether to enable Amazon ECS managed tags for the tasks within the service.
For more information, see
Tagging Your Amazon ECS Resources

enableExecuteCommand?
Type:
boolean
(optional, default: false)
Whether ECS Exec should be enabled.

ephemeralStorageGiB?
Type:
number
(optional, default: Undefined, in which case, the task will receive 20GiB ephemeral storage.)
The amount (in GiB) of ephemeral storage to be allocated to the task.
The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.
Only supported in Fargate platform version 1.4.0 or later.

healthCheck?
Type:
HealthCheck
(optional, default: Health check configuration from container.)
The health check command and associated configuration parameters for the container.

healthCheckGracePeriod?
Type:
Duration
(optional, default: defaults to 60 seconds if at least one load balancer is in-use and it is not already set)
The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.

idleTimeout?
Type:
Duration
(optional, default: CloudFormation sets idle timeout to 60 seconds)
The load balancer idle timeout, in seconds.
Can be between 1 and 4000 seconds

ipAddressType?
Type:
IpAddressType
(optional, default: IpAddressType.IPV4)
The type of IP address to use.

listenerPort?
Type:
number
(optional, default: The default listener port is determined from the protocol (port 80 for HTTP,
port 443 for HTTPS). A domain name and zone must be also be specified if using HTTPS.)
Listener port of the application load balancer that will serve traffic to the service.

loadBalancer?
Type:
IApplicationLoadBalancer
(optional, default: a new load balancer will be created.)
The application load balancer that will serve traffic to the service.
The VPC attribute of a load balancer must be specified for it to be used
to create a new service with this pattern.
[disable-awslint:ref-via-interface]

loadBalancerName?
Type:
string
(optional, default: Automatically generated name.)
Name of the load balancer.

maxHealthyPercent?
Type:
number
(optional, default: 100 if daemon, otherwise 200)
The maximum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that can run in a service during a deployment.

memoryLimitMiB?
Type:
number
(optional, default: 512)
The amount (in MiB) of memory used by the task.
This field is required and you must use one of the following values, which determines your range of valid values
for the cpu parameter:
512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)
1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)
2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)
Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)
Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)
Between 16384 (16 GB) and 61440 (60 GB) in increments of 4096 (4 GB) - Available cpu values: 8192 (8 vCPU)
Between 32768 (32 GB) and 122880 (120 GB) in increments of 8192 (8 GB) - Available cpu values: 16384 (16 vCPU)
This default is set in the underlying FargateTaskDefinition construct.

minHealthyPercent?
Type:
number
(optional, default: 0 if daemon, otherwise 50)
The minimum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that must continue to run and remain healthy during a deployment.

openListener?
Type:
boolean
(optional, default: true -- The security group allows ingress from all IP addresses.)
Determines whether or not the Security Group for the Load Balancer's Listener will be open to all traffic by default.

platformVersion?
Type:
FargatePlatformVersion
(optional, default: Latest)
The platform version on which to run your service.
If one is not specified, the LATEST platform version is used by default. For more information, see
AWS Fargate Platform Versions
in the Amazon Elastic Container Service Developer Guide.

propagateTags?
Type:
PropagatedTagSource
(optional, default: none)
Specifies whether to propagate the tags from the task definition or the service to the tasks in the service.
Tags can only be propagated to the tasks within the service during service creation.

protocol?
Type:
ApplicationProtocol
(optional, default: HTTP. If a certificate is specified, the protocol will be
set by default to HTTPS.)
The protocol for connections from clients to the load balancer.
The load balancer port is determined from the protocol (port 80 for
HTTP, port 443 for HTTPS).  If HTTPS, either a certificate or domain
name and domain zone must also be specified.

protocolVersion?
Type:
ApplicationProtocolVersion
(optional, default: ApplicationProtocolVersion.HTTP1)
The protocol version to use.

publicLoadBalancer?
Type:
boolean
(optional, default: true)
Determines whether the Load Balancer will be internet-facing.

recordType?
Type:
ApplicationLoadBalancedServiceRecordType
(optional, default: ApplicationLoadBalancedServiceRecordType.ALIAS)
Specifies whether the Route53 record should be a CNAME, an A record using the Alias feature or no record at all.
This is useful if you need to work with DNS systems that do not support alias records.

redirectHTTP?
Type:
boolean
(optional, default: false)
Specifies whether the load balancer should redirect traffic on port 80 to port 443 to support HTTP->HTTPS redirects This is only valid if the protocol of the ALB is HTTPS.

runtimePlatform?
Type:
RuntimePlatform
(optional, default: If the property is undefined, operatingSystemFamily is LINUX and cpuArchitecture is X86_64)
The runtime platform of the task definition.

securityGroups?
Type:
ISecurityGroup[]
(optional, default: A new security group is created.)
The security groups to associate with the service.
If you do not specify a security group, a new security group is created.

serviceName?
Type:
string
(optional, default: CloudFormation-generated name.)
The name of the service.

sslPolicy?
Type:
SslPolicy
(optional, default: The recommended elastic load balancing security policy)
The security policy that defines which ciphers and protocols are supported by the ALB Listener.

targetProtocol?
Type:
ApplicationProtocol
(optional, default: HTTP.)
The protocol for connections from the load balancer to the ECS tasks.
The default target port is determined from the protocol (port 80 for
HTTP, port 443 for HTTPS).

taskDefinition?
Type:
FargateTaskDefinition
(optional, default: none)
The task definition to use for tasks in the service. TaskDefinition or TaskImageOptions must be specified, but not both.
[disable-awslint:ref-via-interface]

taskImageOptions?
Type:
ApplicationLoadBalancedTaskImageOptions
(optional, default: none)
The properties required to create a new task definition.
TaskDefinition or TaskImageOptions must be specified, but not both.

taskSubnets?
Type:
SubnetSelection
(optional, default: Public subnets if assignPublicIp is set, otherwise the first available one of Private, Isolated, Public, in that order.)
The subnets to associate with the service.

vpc?
Type:
IVpc
(optional, default: uses the VPC defined in the cluster or creates a new VPC.)
The VPC where the container instances will be launched or the elastic network interfaces (ENIs) will be deployed.
If a vpc is specified, the cluster construct should be omitted. Alternatively, you can omit both vpc and cluster.
Properties


NameTypeDescription


assignPublicIpbooleanDetermines whether the service will be assigned a public IP address.
clusterIClusterThe cluster that hosts the service.
listenerApplicationListenerThe listener for the service.
loadBalancerApplicationLoadBalancerThe Application Load Balancer for the service.
nodeNodeThe tree node.
serviceFargateServiceThe Fargate service in this construct.
targetGroupApplicationTargetGroupThe target group for the service.
taskDefinitionFargateTaskDefinitionThe Fargate task definition in this construct.
certificate?ICertificateCertificate Manager certificate to associate with the load balancer.
internalDesiredCount?numberThe desired number of instantiations of the task definition to keep running on the service.
redirectListener?ApplicationListenerThe redirect listener for the service if redirectHTTP is enabled.



assignPublicIp
Type:
boolean
Determines whether the service will be assigned a public IP address.

cluster
Type:
ICluster
The cluster that hosts the service.

listener
Type:
ApplicationListener
The listener for the service.

loadBalancer
Type:
ApplicationLoadBalancer
The Application Load Balancer for the service.

node
Type:
Node
The tree node.

service
Type:
FargateService
The Fargate service in this construct.

targetGroup
Type:
ApplicationTargetGroup
The target group for the service.

taskDefinition
Type:
FargateTaskDefinition
The Fargate task definition in this construct.

certificate?
Type:
ICertificate
(optional)
Certificate Manager certificate to associate with the load balancer.

internalDesiredCount?
Type:
number
(optional)
The desired number of instantiations of the task definition to keep running on the service.
The default is 1 for all new services and uses the existing services desired count
when updating an existing service if one is not provided.

redirectListener?
Type:
ApplicationListener
(optional)
The redirect listener for the service if redirectHTTP is enabled.
Methods


NameDescription


toString()Returns a string representation of this construct.



toString()
public toString(): string

Returns

string

Returns a string representation of this construct.\n\nclass ApplicationLoadBalancedFargateService (construct)


LanguageType name


 .NETAmazon.CDK.AWS.ECS.Patterns.ApplicationLoadBalancedFargateService
 Gogithub.com/aws/aws-cdk-go/awscdk/v2/awsecspatterns#ApplicationLoadBalancedFargateService
 Javasoftware.amazon.awscdk.services.ecs.patterns.ApplicationLoadBalancedFargateService
 Pythonaws_cdk.aws_ecs_patterns.ApplicationLoadBalancedFargateService
 TypeScript (source)aws-cdk-lib » aws_ecs_patterns » ApplicationLoadBalancedFargateService


Implements
IConstruct, IDependable
A Fargate service running on an ECS cluster fronted by an application load balancer.
Example
declare const cluster: ecs.Cluster;
const loadBalancedFargateService = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'Service', {
  cluster,
  memoryLimitMiB: 1024,
  desiredCount: 1,
  cpu: 512,
  taskImageOptions: {
    image: ecs.ContainerImage.fromRegistry("amazon/amazon-ecs-sample"),
  },
  minHealthyPercent: 100,
});

const scalableTarget = loadBalancedFargateService.service.autoScaleTaskCount({
  minCapacity: 1,
  maxCapacity: 20,
});

scalableTarget.scaleOnCpuUtilization('CpuScaling', {
  targetUtilizationPercent: 50,
});

scalableTarget.scaleOnMemoryUtilization('MemoryScaling', {
  targetUtilizationPercent: 50,
});

Initializer
new ApplicationLoadBalancedFargateService(scope: Construct, id: string, props?: ApplicationLoadBalancedFargateServiceProps)

Parameters

scope Construct
id string
props ApplicationLoadBalancedFargateServiceProps

Constructs a new instance of the ApplicationLoadBalancedFargateService class.
Construct Props


NameTypeDescription


assignPublicIp?booleanDetermines whether the service will be assigned a public IP address.
capacityProviderStrategies?CapacityProviderStrategy[]A list of Capacity Provider strategies used to place a service.
certificate?ICertificateCertificate Manager certificate to associate with the load balancer.
circuitBreaker?DeploymentCircuitBreakerWhether to enable the deployment circuit breaker.
cloudMapOptions?CloudMapOptionsThe options for configuring an Amazon ECS service to use service discovery.
cluster?IClusterThe name of the cluster that hosts the service.
containerCpu?numberThe minimum number of CPU units to reserve for the container.
containerMemoryLimitMiB?numberThe amount (in MiB) of memory to present to the container.
cpu?numberThe number of cpu units used by the task.
deploymentController?DeploymentControllerSpecifies which deployment controller to use for the service.
desiredCount?numberThe desired number of instantiations of the task definition to keep running on the service.
domainName?stringThe domain name for the service, e.g. "api.example.com.".
domainZone?IHostedZoneThe Route53 hosted zone for the domain, e.g. "example.com.".
enableECSManagedTags?booleanSpecifies whether to enable Amazon ECS managed tags for the tasks within the service.
enableExecuteCommand?booleanWhether ECS Exec should be enabled.
ephemeralStorageGiB?numberThe amount (in GiB) of ephemeral storage to be allocated to the task.
healthCheck?HealthCheckThe health check command and associated configuration parameters for the container.
healthCheckGracePeriod?DurationThe period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.
idleTimeout?DurationThe load balancer idle timeout, in seconds.
ipAddressType?IpAddressTypeThe type of IP address to use.
listenerPort?numberListener port of the application load balancer that will serve traffic to the service.
loadBalancer?IApplicationLoadBalancerThe application load balancer that will serve traffic to the service.
loadBalancerName?stringName of the load balancer.
maxHealthyPercent?numberThe maximum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that can run in a service during a deployment.
memoryLimitMiB?numberThe amount (in MiB) of memory used by the task.
minHealthyPercent?numberThe minimum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that must continue to run and remain healthy during a deployment.
openListener?booleanDetermines whether or not the Security Group for the Load Balancer's Listener will be open to all traffic by default.
platformVersion?FargatePlatformVersionThe platform version on which to run your service.
propagateTags?PropagatedTagSourceSpecifies whether to propagate the tags from the task definition or the service to the tasks in the service.
protocol?ApplicationProtocolThe protocol for connections from clients to the load balancer.
protocolVersion?ApplicationProtocolVersionThe protocol version to use.
publicLoadBalancer?booleanDetermines whether the Load Balancer will be internet-facing.
recordType?ApplicationLoadBalancedServiceRecordTypeSpecifies whether the Route53 record should be a CNAME, an A record using the Alias feature or no record at all.
redirectHTTP?booleanSpecifies whether the load balancer should redirect traffic on port 80 to port 443 to support HTTP->HTTPS redirects This is only valid if the protocol of the ALB is HTTPS.
runtimePlatform?RuntimePlatformThe runtime platform of the task definition.
securityGroups?ISecurityGroup[]The security groups to associate with the service.
serviceName?stringThe name of the service.
sslPolicy?SslPolicyThe security policy that defines which ciphers and protocols are supported by the ALB Listener.
targetProtocol?ApplicationProtocolThe protocol for connections from the load balancer to the ECS tasks.
taskDefinition?FargateTaskDefinitionThe task definition to use for tasks in the service. TaskDefinition or TaskImageOptions must be specified, but not both.
taskImageOptions?ApplicationLoadBalancedTaskImageOptionsThe properties required to create a new task definition.
taskSubnets?SubnetSelectionThe subnets to associate with the service.
vpc?IVpcThe VPC where the container instances will be launched or the elastic network interfaces (ENIs) will be deployed.



assignPublicIp?
Type:
boolean
(optional, default: false)
Determines whether the service will be assigned a public IP address.

capacityProviderStrategies?
Type:
CapacityProviderStrategy[]
(optional, default: undefined)
A list of Capacity Provider strategies used to place a service.

certificate?
Type:
ICertificate
(optional, default: No certificate associated with the load balancer, if using
the HTTP protocol. For HTTPS, a DNS-validated certificate will be
created for the load balancer's specified domain name if a domain name
and domain zone are specified.)
Certificate Manager certificate to associate with the load balancer.
Setting this option will set the load balancer protocol to HTTPS.

circuitBreaker?
Type:
DeploymentCircuitBreaker
(optional, default: disabled)
Whether to enable the deployment circuit breaker.
If this property is defined, circuit breaker will be implicitly
enabled.

cloudMapOptions?
Type:
CloudMapOptions
(optional, default: AWS Cloud Map service discovery is not enabled.)
The options for configuring an Amazon ECS service to use service discovery.

cluster?
Type:
ICluster
(optional, default: create a new cluster; if both cluster and vpc are omitted, a new VPC will be created for you.)
The name of the cluster that hosts the service.
If a cluster is specified, the vpc construct should be omitted. Alternatively, you can omit both cluster and vpc.

containerCpu?
Type:
number
(optional, default: No minimum CPU units reserved.)
The minimum number of CPU units to reserve for the container.

containerMemoryLimitMiB?
Type:
number
(optional, default: No memory limit.)
The amount (in MiB) of memory to present to the container.
If your container attempts to exceed the allocated memory, the container
is terminated.

cpu?
Type:
number
(optional, default: 256)
The number of cpu units used by the task.
Valid values, which determines your range of valid values for the memory parameter:
256 (.25 vCPU) - Available memory values: 0.5GB, 1GB, 2GB
512 (.5 vCPU) - Available memory values: 1GB, 2GB, 3GB, 4GB
1024 (1 vCPU) - Available memory values: 2GB, 3GB, 4GB, 5GB, 6GB, 7GB, 8GB
2048 (2 vCPU) - Available memory values: Between 4GB and 16GB in 1GB increments
4096 (4 vCPU) - Available memory values: Between 8GB and 30GB in 1GB increments
8192 (8 vCPU) - Available memory values: Between 16GB and 60GB in 4GB increments
16384 (16 vCPU) - Available memory values: Between 32GB and 120GB in 8GB increments
This default is set in the underlying FargateTaskDefinition construct.

deploymentController?
Type:
DeploymentController
(optional, default: Rolling update (ECS))
Specifies which deployment controller to use for the service.
For more information, see
Amazon ECS Deployment Types

desiredCount?
Type:
number
(optional, default: The default is 1 for all new services and uses the existing service's desired count
when updating an existing service.)
The desired number of instantiations of the task definition to keep running on the service.
The minimum value is 1

domainName?
Type:
string
(optional, default: No domain name.)
The domain name for the service, e.g. "api.example.com.".

domainZone?
Type:
IHostedZone
(optional, default: No Route53 hosted domain zone.)
The Route53 hosted zone for the domain, e.g. "example.com.".

enableECSManagedTags?
Type:
boolean
(optional, default: false)
Specifies whether to enable Amazon ECS managed tags for the tasks within the service.
For more information, see
Tagging Your Amazon ECS Resources

enableExecuteCommand?
Type:
boolean
(optional, default: false)
Whether ECS Exec should be enabled.

ephemeralStorageGiB?
Type:
number
(optional, default: Undefined, in which case, the task will receive 20GiB ephemeral storage.)
The amount (in GiB) of ephemeral storage to be allocated to the task.
The minimum supported value is 21 GiB and the maximum supported value is 200 GiB.
Only supported in Fargate platform version 1.4.0 or later.

healthCheck?
Type:
HealthCheck
(optional, default: Health check configuration from container.)
The health check command and associated configuration parameters for the container.

healthCheckGracePeriod?
Type:
Duration
(optional, default: defaults to 60 seconds if at least one load balancer is in-use and it is not already set)
The period of time, in seconds, that the Amazon ECS service scheduler ignores unhealthy Elastic Load Balancing target health checks after a task has first started.

idleTimeout?
Type:
Duration
(optional, default: CloudFormation sets idle timeout to 60 seconds)
The load balancer idle timeout, in seconds.
Can be between 1 and 4000 seconds

ipAddressType?
Type:
IpAddressType
(optional, default: IpAddressType.IPV4)
The type of IP address to use.

listenerPort?
Type:
number
(optional, default: The default listener port is determined from the protocol (port 80 for HTTP,
port 443 for HTTPS). A domain name and zone must be also be specified if using HTTPS.)
Listener port of the application load balancer that will serve traffic to the service.

loadBalancer?
Type:
IApplicationLoadBalancer
(optional, default: a new load balancer will be created.)
The application load balancer that will serve traffic to the service.
The VPC attribute of a load balancer must be specified for it to be used
to create a new service with this pattern.
[disable-awslint:ref-via-interface]

loadBalancerName?
Type:
string
(optional, default: Automatically generated name.)
Name of the load balancer.

maxHealthyPercent?
Type:
number
(optional, default: 100 if daemon, otherwise 200)
The maximum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that can run in a service during a deployment.

memoryLimitMiB?
Type:
number
(optional, default: 512)
The amount (in MiB) of memory used by the task.
This field is required and you must use one of the following values, which determines your range of valid values
for the cpu parameter:
512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU)
1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU)
2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU)
Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU)
Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)
Between 16384 (16 GB) and 61440 (60 GB) in increments of 4096 (4 GB) - Available cpu values: 8192 (8 vCPU)
Between 32768 (32 GB) and 122880 (120 GB) in increments of 8192 (8 GB) - Available cpu values: 16384 (16 vCPU)
This default is set in the underlying FargateTaskDefinition construct.

minHealthyPercent?
Type:
number
(optional, default: 0 if daemon, otherwise 50)
The minimum number of tasks, specified as a percentage of the Amazon ECS service's DesiredCount value, that must continue to run and remain healthy during a deployment.

openListener?
Type:
boolean
(optional, default: true -- The security group allows ingress from all IP addresses.)
Determines whether or not the Security Group for the Load Balancer's Listener will be open to all traffic by default.

platformVersion?
Type:
FargatePlatformVersion
(optional, default: Latest)
The platform version on which to run your service.
If one is not specified, the LATEST platform version is used by default. For more information, see
AWS Fargate Platform Versions
in the Amazon Elastic Container Service Developer Guide.

propagateTags?
Type:
PropagatedTagSource
(optional, default: none)
Specifies whether to propagate the tags from the task definition or the service to the tasks in the service.
Tags can only be propagated to the tasks within the service during service creation.

protocol?
Type:
ApplicationProtocol
(optional, default: HTTP. If a certificate is specified, the protocol will be
set by default to HTTPS.)
The protocol for connections from clients to the load balancer.
The load balancer port is determined from the protocol (port 80 for
HTTP, port 443 for HTTPS).  If HTTPS, either a certificate or domain
name and domain zone must also be specified.

protocolVersion?
Type:
ApplicationProtocolVersion
(optional, default: ApplicationProtocolVersion.HTTP1)
The protocol version to use.

publicLoadBalancer?
Type:
boolean
(optional, default: true)
Determines whether the Load Balancer will be internet-facing.

recordType?
Type:
ApplicationLoadBalancedServiceRecordType
(optional, default: ApplicationLoadBalancedServiceRecordType.ALIAS)
Specifies whether the Route53 record should be a CNAME, an A record using the Alias feature or no record at all.
This is useful if you need to work with DNS systems that do not support alias records.

redirectHTTP?
Type:
boolean
(optional, default: false)
Specifies whether the load balancer should redirect traffic on port 80 to port 443 to support HTTP->HTTPS redirects This is only valid if the protocol of the ALB is HTTPS.

runtimePlatform?
Type:
RuntimePlatform
(optional, default: If the property is undefined, operatingSystemFamily is LINUX and cpuArchitecture is X86_64)
The runtime platform of the task definition.

securityGroups?
Type:
ISecurityGroup[]
(optional, default: A new security group is created.)
The security groups to associate with the service.
If you do not specify a security group, a new security group is created.

serviceName?
Type:
string
(optional, default: CloudFormation-generated name.)
The name of the service.

sslPolicy?
Type:
SslPolicy
(optional, default: The recommended elastic load balancing security policy)
The security policy that defines which ciphers and protocols are supported by the ALB Listener.

targetProtocol?
Type:
ApplicationProtocol
(optional, default: HTTP.)
The protocol for connections from the load balancer to the ECS tasks.
The default target port is determined from the protocol (port 80 for
HTTP, port 443 for HTTPS).

taskDefinition?
Type:
FargateTaskDefinition
(optional, default: none)
The task definition to use for tasks in the service. TaskDefinition or TaskImageOptions must be specified, but not both.
[disable-awslint:ref-via-interface]

taskImageOptions?
Type:
ApplicationLoadBalancedTaskImageOptions
(optional, default: none)
The properties required to create a new task definition.
TaskDefinition or TaskImageOptions must be specified, but not both.

taskSubnets?
Type:
SubnetSelection
(optional, default: Public subnets if assignPublicIp is set, otherwise the first available one of Private, Isolated, Public, in that order.)
The subnets to associate with the service.

vpc?
Type:
IVpc
(optional, default: uses the VPC defined in the cluster or creates a new VPC.)
The VPC where the container instances will be launched or the elastic network interfaces (ENIs) will be deployed.
If a vpc is specified, the cluster construct should be omitted. Alternatively, you can omit both vpc and cluster.
Properties


NameTypeDescription


assignPublicIpbooleanDetermines whether the service will be assigned a public IP address.
clusterIClusterThe cluster that hosts the service.
listenerApplicationListenerThe listener for the service.
loadBalancerApplicationLoadBalancerThe Application Load Balancer for the service.
nodeNodeThe tree node.
serviceFargateServiceThe Fargate service in this construct.
targetGroupApplicationTargetGroupThe target group for the service.
taskDefinitionFargateTaskDefinitionThe Fargate task definition in this construct.
certificate?ICertificateCertificate Manager certificate to associate with the load balancer.
internalDesiredCount?numberThe desired number of instantiations of the task definition to keep running on the service.
redirectListener?ApplicationListenerThe redirect listener for the service if redirectHTTP is enabled.



assignPublicIp
Type:
boolean
Determines whether the service will be assigned a public IP address.

cluster
Type:
ICluster
The cluster that hosts the service.

listener
Type:
ApplicationListener
The listener for the service.

loadBalancer
Type:
ApplicationLoadBalancer
The Application Load Balancer for the service.

node
Type:
Node
The tree node.

service
Type:
FargateService
The Fargate service in this construct.

targetGroup
Type:
ApplicationTargetGroup
The target group for the service.

taskDefinition
Type:
FargateTaskDefinition
The Fargate task definition in this construct.

certificate?
Type:
ICertificate
(optional)
Certificate Manager certificate to associate with the load balancer.

internalDesiredCount?
Type:
number
(optional)
The desired number of instantiations of the task definition to keep running on the service.
The default is 1 for all new services and uses the existing services desired count
when updating an existing service if one is not provided.

redirectListener?
Type:
ApplicationListener
(optional)
The redirect listener for the service if redirectHTTP is enabled.
Methods


NameDescription


toString()Returns a string representation of this construct.



toString()
public toString(): string

Returns

string

Returns a string representation of this construct.\n\n\n\nclass Construct


LanguageType name


 .NETConstructs.Construct

 Javasoftware.constructs.Construct
 Pythonconstructs.Construct
 TypeScript (source)constructs » Construct


Implements
IConstruct, IDependable
Represents the building block of the construct graph.
All constructs besides the root construct must be created within the scope of
another construct.
Initializer
new Construct(scope: Construct, id: string)

Parameters

scope Construct  — The scope in which to define this construct.
id string  — The scoped construct ID.

Creates a new construct node.
Properties


NameTypeDescription


nodeNodeThe tree node.



node
Type:
Node
The tree node.
Methods


NameDescription


toString()Returns a string representation of this construct.
static isConstruct(x)Checks if x is a construct.



toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

static isConstruct(x)
public static isConstruct(x: any): boolean

Parameters

x any  — Any object.

Returns

boolean

Checks if x is a construct.
Use this method instead of instanceof to properly detect Construct
instances, even when the construct library is symlinked.
Explanation: in JavaScript, multiple copies of the constructs library on
disk are seen as independent, completely different libraries. As a
consequence, the class Construct in each copy of the constructs library
is seen as a different class, and an instance of one class will not test as
instanceof the other class. npm install will not create installations
like this, but users may manually symlink construct libraries together or
use a monorepo tool: in those cases, multiple copies of the constructs
library can be accidentally installed, and instanceof will behave
unpredictably. It is safest to avoid using instanceof, and using
this type-testing method instead.\n\nclass Construct


LanguageType name


 .NETConstructs.Construct

 Javasoftware.constructs.Construct
 Pythonconstructs.Construct
 TypeScript (source)constructs » Construct


Implements
IConstruct, IDependable
Represents the building block of the construct graph.
All constructs besides the root construct must be created within the scope of
another construct.
Initializer
new Construct(scope: Construct, id: string)

Parameters

scope Construct  — The scope in which to define this construct.
id string  — The scoped construct ID.

Creates a new construct node.
Properties


NameTypeDescription


nodeNodeThe tree node.



node
Type:
Node
The tree node.
Methods


NameDescription


toString()Returns a string representation of this construct.
static isConstruct(x)Checks if x is a construct.



toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

static isConstruct(x)
public static isConstruct(x: any): boolean

Parameters

x any  — Any object.

Returns

boolean

Checks if x is a construct.
Use this method instead of instanceof to properly detect Construct
instances, even when the construct library is symlinked.
Explanation: in JavaScript, multiple copies of the constructs library on
disk are seen as independent, completely different libraries. As a
consequence, the class Construct in each copy of the constructs library
is seen as a different class, and an instance of one class will not test as
instanceof the other class. npm install will not create installations
like this, but users may manually symlink construct libraries together or
use a monorepo tool: in those cases, multiple copies of the constructs
library can be accidentally installed, and instanceof will behave
unpredictably. It is safest to avoid using instanceof, and using
this type-testing method instead.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideHow to create a CDK appThe construct treeThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK appsThe AWS Cloud Development Kit (AWS CDK) application or app is a collection of one or more CDK stacks. Stacks are a collection of one or more constructs,
    which define AWS resources and properties. Therefore, the overall grouping of your stacks and constructs are known as
    your CDK app.
    How to create a CDK app

    You create an app by defining an app instance in the application file of your project. To do this, you import and use the App construct from the AWS Construct Library. The
        App construct doesn't require any initialization arguments. It is the only construct that can be used as
      the root.

    The App and
          Stack classes from
      the AWS Construct Library are unique constructs. Compared to other constructs, they don't configure AWS resources on their
      own. Instead, they are used to provide context for your other constructs. All constructs that represent AWS resources
      must be defined, directly or indirectly, within the scope of a Stack construct. Stack
      constructs are defined within the scope of an App construct.

    Apps are then synthesized to create AWS CloudFormation templates for your stacks. The following is an example:

    

      TypeScript
          const app = new App();
new MyFirstStack(app, 'hello-cdk');
app.synth();
        

      JavaScript
          const app = new App();
new MyFirstStack(app, 'hello-cdk');
app.synth();
        

      Python
          app = App()
MyFirstStack(app, "hello-cdk")
app.synth()
        

      Java
          App app = new App();
new MyFirstStack(app, "hello-cdk");
app.synth();
        

      C#
          var app = new App();
new MyFirstStack(app, "hello-cdk");
app.Synth();
        

      Go
          app := awscdk.NewApp(nil)
            
MyFirstStack(app, "MyFirstStack", &MyFirstStackProps{
  awscdk.StackProps{
    Env: env(),
  },
})

app.Synth(nil)
        
    

    Stacks within a single app can easily refer to each other's resources and properties. The AWS CDK infers dependencies
      between stacks so that they can be deployed in the correct order. You can deploy any or all of the stacks within an app
      with a single cdk deploy command.

   
    The construct tree

    Constructs are defined inside of other constructs using the scope argument that is passed to every
      construct, with the App class as the root. In this way, an AWS CDK app defines a hierarchy of constructs
      known as the construct tree.

    The root of this tree is your app, which is an instance of the App class. Within the app, you
      instantiate one or more stacks. Within stacks, you instantiate constructs, which may themselves instantiate resources
      or other constructs, and so on down the tree.

    Constructs are always explicitly defined within the scope of another construct, which creates
      relationships between constructs. Almost always, you should pass this (in Python, self) as
      the scope, indicating that the new construct is a child of the current construct. The intended pattern is that you
      derive your construct from Construct, then instantiate the constructs it uses in its constructor.

    Passing the scope explicitly allows each construct to add itself to the tree, with this behavior entirely contained
      within the Construct base
        class. It works the same way in every language supported by the AWS CDK and does not require additional
      customization.

    ImportantTechnically, it's possible to pass some scope other than this when instantiating a construct. You
        can add constructs anywhere in the tree, or even in another stack in the same app. For example, you could write a
        mixin-style function that adds constructs to a scope passed in as an argument. The practical difficulty here is that
        you can't easily ensure that the IDs you choose for your constructs are unique within someone else's scope. The
        practice also makes your code more difficult to understand, maintain, and reuse. Therefore, we recommend that you use
        the general structure of the construct tree.

    The AWS CDK uses the IDs of all constructs in the path from the tree's root to each child construct to generate the
      unique IDs required by AWS CloudFormation. This approach means that construct IDs only need to be unique within their scope, rather
      than within the entire stack as in native AWS CloudFormation. However, if you move a construct to a different scope, its generated
      stack-unique ID changes, and AWS CloudFormation won't consider it the same resource.

    The construct tree is separate from the constructs that you define in your AWS CDK code. However, it's accessible
      through any construct's node attribute, which is a reference to the node that represents that construct in
      the tree. Each node is a Node instance, the attributes of which provide access to the tree's root and to the node's
      parent scopes and children.

    
       
       
       
       
       
       
       
    
        node.children – The direct children of the construct.
      
        node.id – The identifier of the construct within its scope.
      
        node.path – The full path of the construct including the IDs of all of its parents.
      
        node.root – The root of the construct tree (the app).
      
        node.scope – The scope (parent) of the construct, or undefined if the node is the
          root.
      
        node.scopes – All parents of the construct, up to the root.
      
        node.uniqueId – The unique alphanumeric identifier for this construct within the tree (by
          default, generated from node.path and a hash).
      

    The construct tree defines an implicit order in which constructs are synthesized to resources in the final AWS CloudFormation
      template. Where one resource must be created before another, AWS CloudFormation or the AWS Construct Library generally infers the
      dependency. They then make sure that the resources are created in the right order.
    You can also add an explicit dependency between two nodes by using node.addDependency(). For more
      information, see Dependencies in the AWS CDK API Reference.

    The AWS CDK provides a simple way to visit every node in the construct tree and perform an operation on each one. For
      more information, see Aspects and the AWS CDK.

  Document ConventionsProjectsCDK stacksDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideConstruct IDsPathsUnique IDsLogical IDsThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Identifiers and the AWS CDKWhen building AWS Cloud Development Kit (AWS CDK) apps, you will use many types of identifiers and names. To use the AWS CDK effectively and
    avoid errors, it is important to understand the types of identifiers.Identifiers must be unique within the scope in which they are created; they do not need to be globally unique in your
    AWS CDK application.If you attempt to create an identifier with the same value within the same scope, the AWS CDK throws an
    exception.
    Construct IDs

    The most common identifier, id, is the identifier passed as the second argument when instantiating a
      construct object. This identifier, like all identifiers, only needs to be unique within the scope in which it is
      created, which is the first argument when instantiating a construct object.

    NoteThe id of a stack is also the identifier that you use to refer to it in the AWS CDK CLI reference.

    Let's look at an example where we have two constructs with the identifier MyBucket in our app. The
      first is defined in the scope of the stack with the identifier Stack1. The second is defined in the scope
      of a stack with the identifier Stack2. Because they're defined in different scopes, this doesn't cause any
      conflict, and they can coexist in the same app without issues.

    
      TypeScript
          import { App, Stack, StackProps } from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as s3 from 'aws-cdk-lib/aws-s3';

class MyStack extends Stack {
  constructor(scope: Construct, id: string, props: StackProps = {}) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyBucket');
  }
}

const app = new App();
new MyStack(app, 'Stack1');
new MyStack(app, 'Stack2');
        
      JavaScript
          const { App , Stack } = require('aws-cdk-lib');
const s3 = require('aws-cdk-lib/aws-s3');

class MyStack extends Stack {
  constructor(scope, id, props = {}) {
    super(scope, id, props);

    new s3.Bucket(this, 'MyBucket');
  }
}

const app = new App();
new MyStack(app, 'Stack1');
new MyStack(app, 'Stack2');
        


      Python
          from aws_cdk import App, Construct, Stack, StackProps
from constructs import Construct
from aws_cdk import aws_s3 as s3

class MyStack(Stack):

    def __init__(self, scope: Construct, id: str, **kwargs):

        super().__init__(scope, id, **kwargs)
        s3.Bucket(self, "MyBucket")

app = App()
MyStack(app, 'Stack1')
MyStack(app, 'Stack2')
        
      Java
          // MyStack.java
package com.myorg;

import software.amazon.awscdk.App;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.constructs.Construct;
import software.amazon.awscdk.services.s3.Bucket;

public class MyStack extends Stack {
    public MyStack(final Construct scope, final String id) {
        this(scope, id, null);
    }
    
    public MyStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);
        new Bucket(this, "MyBucket");
    }
}

// Main.java
package com.myorg;

import software.amazon.awscdk.App;

public class Main {
    public static void main(String[] args) {
        App app = new App();
        new MyStack(app, "Stack1");
        new MyStack(app, "Stack2");
    }
}
        
      C#
          using Amazon.CDK;
using constructs;
using Amazon.CDK.AWS.S3;

public class MyStack : Stack
{
    public MyStack(Construct scope, string id, IStackProps props) : base(scope, id, props)
    {
        new Bucket(this, "MyBucket");
    }
}

class Program
{
    static void Main(string[] args)
    {
        var app = new App();
        new MyStack(app, "Stack1");
        new MyStack(app, "Stack2");
    }
}
        
    

   
    Paths

    The constructs in an AWS CDK application form a hierarchy rooted in the App class. We refer to the
      collection of IDs from a given construct, its parent construct, its grandparent, and so on to the root of the construct
      tree, as a path.

    The AWS CDK typically displays paths in your templates as a string. The IDs from the levels are separated by slashes,
      starting at the node immediately under the root App instance, which is usually a stack. For example, the
      paths of the two Amazon S3 bucket resources in the previous code example are Stack1/MyBucket and
      Stack2/MyBucket.

    You can access the path of any construct programmatically, as shown in the following example. This gets the path of
        myConstruct (or my_construct, as Python developers would write it). Since IDs must be
      unique within the scope they are created, their paths are always unique within an AWS CDK application.

    
      TypeScript
          const path: string = myConstruct.node.path;
        
      JavaScript
          const path = myConstruct.node.path;
        


      Python
          path = my_construct.node.path
        
      Java
          String path = myConstruct.getNode().getPath();
        
      C#
          string path = myConstruct.Node.Path;
        
    
   
    Unique IDs

    AWS CloudFormation requires that all logical IDs in a template be unique. Because of this, the AWS CDK must be able to generate a
      unique identifier for each construct in an application. Resources have paths that are globally unique (the names of all
      scopes from the stack to a specific resource). Therefore, the AWS CDK generates the necessary unique identifiers by
      concatenating the elements of the path and adding an 8-digit hash. (The hash is necessary to distinguish distinct
      paths, such as A/B/C and A/BC, that would result in the same AWS CloudFormation identifier. AWS CloudFormation
      identifiers are alphanumeric and cannot contain slashes or other separator characters.) The AWS CDK calls this string the
        unique ID of the construct.

    In general, your AWS CDK app should not need to know about unique IDs. You can, however, access the unique ID of any
      construct programmatically, as shown in the following example.

    
      TypeScript
          const uid: string = Names.uniqueId(myConstruct);
        
      JavaScript
          const uid = Names.uniqueId(myConstruct);
        
      Python
          uid = Names.unique_id(my_construct)
        
      Java
          String uid = Names.uniqueId(myConstruct);
        
      C#
          string uid = Names.Uniqueid(myConstruct);
        
    

    The address is another kind of unique identifier that uniquely distinguishes CDK resources.
      Derived from the SHA-1 hash of the path, it is not human-readable. However, its constant, relatively short length
      (always 42 hexadecimal characters) makes it useful in situations where the "traditional" unique ID might be too long.
      Some constructs may use the address in the synthesized AWS CloudFormation template instead of the unique ID. Again, your app
      generally should not need to know about its constructs' addresses, but you can retrieve a construct's address as
      follows.

    
      TypeScript
          const addr: string = myConstruct.node.addr;
        
      JavaScript
          const addr = myConstruct.node.addr;
        
      Python
          addr = my_construct.node.addr
        
      Java
          String addr = myConstruct.getNode().getAddr();
        
      C#
          string addr = myConstruct.Node.Addr;
        
    
   
    Logical IDs

    Unique IDs serve as the logical identifiers (or logical names) of
      resources in the generated AWS CloudFormation templates for constructs that represent AWS resources.

    For example, the Amazon S3 bucket in the previous example that is created within Stack2 results in an
      AWS::S3::Bucket resource. The resource's logical ID is Stack2MyBucket4DD88B4F in the
      resulting AWS CloudFormation template. (For details on how this identifier is generated, see Unique IDs.)

     
      Logical ID stability

      Avoid changing the logical ID of a resource after it has been created. AWS CloudFormation identifies resources by their
        logical ID. Therefore, if you change the logical ID of a resource, AWS CloudFormation creates a new resource with the new logical
        ID, then deletes the existing one. Depending on the type of resource, this might cause service interruption, data
        loss, or both.

     

  Document ConventionsResourcesTokensDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideConfiguring resources using constructsReferencing resourcesResource physical namesPassing unique resource identifiersGranting permissions between resourcesResource metrics and alarmsNetwork trafficEvent handlingRemoval policiesThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Resources and the AWS CDKResources are what you configure to use AWS services in your applications. Resources are a
		feature of AWS CloudFormation. By configuring resources and their properties in a AWS CloudFormation template, you can deploy to AWS CloudFormation to
		provision your resources. With the AWS Cloud Development Kit (AWS CDK), you can configure resources through constructs. You then deploy your
		CDK app, which involves synthesizing a AWS CloudFormation template and deploying to AWS CloudFormation to provision your resources.
		Configuring resources using constructs

		As described in AWS CDK Constructs, the AWS CDK provides a rich class library of constructs, called
				AWS constructs, that represent all AWS resources.

		To create an instance of a resource using its corresponding construct, pass in the scope as the first argument, the
			logical ID of the construct, and a set of configuration properties (props). For example, here's how to create an Amazon SQS
			queue with AWS KMS encryption using the sqs.Queue construct from the AWS Construct Library.

		

			TypeScript
					import * as sqs from '@aws-cdk/aws-sqs';
            
new sqs.Queue(this, 'MyQueue', {
    encryption: sqs.QueueEncryption.KMS_MANAGED
});
				

			JavaScript
					const sqs = require('@aws-cdk/aws-sqs');
            
new sqs.Queue(this, 'MyQueue', {
    encryption: sqs.QueueEncryption.KMS_MANAGED
});
				

			Python
					import aws_cdk.aws_sqs as sqs
      
sqs.Queue(self, "MyQueue", encryption=sqs.QueueEncryption.KMS_MANAGED)
				

			Java
					import software.amazon.awscdk.services.sqs.*;

Queue.Builder.create(this, "MyQueue").encryption(
        QueueEncryption.KMS_MANAGED).build();
				

			C#
					using Amazon.CDK.AWS.SQS;

new Queue(this, "MyQueue", new QueueProps
{
    Encryption = QueueEncryption.KMS_MANAGED
});
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

sqs.NewQueue(stack, jsii.String("MyQueue"), &sqs.QueueProps{
  Encryption: sqs.QueueEncryption_KMS_MANAGED,
})
				

		

		Some configuration props are optional, and in many cases have default values. In some cases, all props are
			optional, and the last argument can be omitted entirely.

		
		 
			Resource attributes

			Most resources in the AWS Construct Library expose attributes, which are resolved at deployment time by AWS CloudFormation. Attributes
				are exposed in the form of properties on the resource classes with the type name as a prefix. The following example
				shows how to get the URL of an Amazon SQS queue using the queueUrl (Python: queue_url)
				property.

			

				TypeScript
						import * as sqs from '@aws-cdk/aws-sqs';
      
const queue = new sqs.Queue(this, 'MyQueue');
const url = queue.queueUrl; // => A string representing a deploy-time value
					

				JavaScript
						const sqs = require('@aws-cdk/aws-sqs');
      
const queue = new sqs.Queue(this, 'MyQueue');
const url = queue.queueUrl; // => A string representing a deploy-time value
					

				Python
						import aws_cdk.aws_sqs as sqs

queue = sqs.Queue(self, "MyQueue")
url = queue.queue_url # => A string representing a deploy-time value

					

				Java
						Queue queue = new Queue(this, "MyQueue");
String url = queue.getQueueUrl();    // => A string representing a deploy-time value
					

				C#
						var queue = new Queue(this, "MyQueue");
var url = queue.QueueUrl; // => A string representing a deploy-time value
					

				Go
						import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

queue := sqs.NewQueue(stack, jsii.String("MyQueue"), &sqs.QueueProps{})
url := queue.QueueUrl() // => A string representing a deploy-time value
					
			

			See Tokens and the AWS CDK for information about how the AWS CDK encodes deploy-time attributes as
				strings.

		 

	 
		Referencing resources

		When configuring resources, you will often have to reference properties of another resource. The following are
			examples:

		
			 
			 
		
				An Amazon Elastic Container Service (Amazon ECS) resource requires a reference to the cluster on which it runs.
			
				An Amazon CloudFront distribution requires a reference to the Amazon Simple Storage Service (Amazon S3) bucket containing the source code.
			

		You can reference resources in any of the following ways:

		
			 
			 
		
				By passing a resource defined in your CDK app, either in the same stack or in a different one
			
				By passing a proxy object referencing a resource defined in your AWS account, created from a unique
					identifier of the resource (such as an ARN)
			

		If the property of a construct represents a construct for another resource, its type is that of the interface type
			of the construct. For example, the Amazon ECS construct takes a property cluster of type
				ecs.ICluster. Another example, is the CloudFront distribution construct that takes a property
				sourceBucket (Python: source_bucket) of type s3.IBucket. 

		You can directly pass any resource object of the proper type defined in the same AWS CDK app. The following example
			defines an Amazon ECS cluster and then uses it to define an Amazon ECS service.

		

			TypeScript
					const cluster = new ecs.Cluster(this, 'Cluster', { /*...*/ });

const service = new ecs.Ec2Service(this, 'Service', { cluster: cluster });
				

			JavaScript
					const cluster = new ecs.Cluster(this, 'Cluster', { /*...*/ });

const service = new ecs.Ec2Service(this, 'Service', { cluster: cluster });
				

			Python
					cluster = ecs.Cluster(self, "Cluster")

service = ecs.Ec2Service(self, "Service", cluster=cluster)
				

			Java
					Cluster cluster = new Cluster(this, "Cluster");
Ec2Service service = new Ec2Service(this, "Service",
        new Ec2ServiceProps.Builder().cluster(cluster).build());
				

			C#
					var cluster = new Cluster(this, "Cluster");
var service = new Ec2Service(this, "Service", new Ec2ServiceProps { Cluster = cluster });
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	    
  ecs "github.com/aws/aws-cdk-go/awscdk/v2/awsecs"
)

cluster := ecs.NewCluster(stack, jsii.String("MyCluster"), &ecs.ClusterProps{})
service := ecs.NewEc2Service(stack, jsii.String("MyService"), &ecs.Ec2ServiceProps{
  Cluster: cluster,
})
				
		

		
		 
			Referencing resources in a different stack

			You can refer to resources in a different stack as long as they are defined in the same app and are in the same
				AWS environment. The following pattern is generally used:

			
				 
				 
			
					Store a reference to the construct as an attribute of the stack that produces the resource. (To get a
						reference to the current construct's stack, use Stack.of(this).)
				
					Pass this reference to the constructor of the stack that consumes the resource as a parameter or a property.
						The consuming stack then passes it as a property to any construct that needs it.
				

			The following example defines a stack stack1. This stack defines an Amazon S3 bucket and stores a
				reference to the bucket construct as an attribute of the stack. Then the app defines a second stack,
					stack2, which accepts a bucket at instantiation. stack2 might, for example, define an
				AWS Glue Table that uses the bucket for data storage.

			

				TypeScript
						const prod = { account: '123456789012', region: 'us-east-1' };

const stack1 = new StackThatProvidesABucket(app, 'Stack1', { env: prod });

// stack2 will take a property { bucket: IBucket }
const stack2 = new StackThatExpectsABucket(app, 'Stack2', {
  bucket: stack1.bucket, 
  env: prod
});
					

				JavaScript
						const prod = { account: '123456789012', region: 'us-east-1' };

const stack1 = new StackThatProvidesABucket(app, 'Stack1', { env: prod });

// stack2 will take a property { bucket: IBucket }
const stack2 = new StackThatExpectsABucket(app, 'Stack2', {
  bucket: stack1.bucket, 
  env: prod
});
					

				Python
						prod = core.Environment(account="123456789012", region="us-east-1")

stack1 = StackThatProvidesABucket(app, "Stack1", env=prod)

# stack2 will take a property "bucket"
stack2 = StackThatExpectsABucket(app, "Stack2", bucket=stack1.bucket, env=prod)
					

				Java
						// Helper method to build an environment
static Environment makeEnv(String account, String region) {
    return Environment.builder().account(account).region(region)
            .build();
}

App app = new App();

Environment prod = makeEnv("123456789012", "us-east-1");

StackThatProvidesABucket stack1 = new StackThatProvidesABucket(app, "Stack1",
        StackProps.builder().env(prod).build());

// stack2 will take an argument "bucket"
StackThatExpectsABucket stack2 = new StackThatExpectsABucket(app, "Stack,",
        StackProps.builder().env(prod).build(), stack1.bucket);
					

				C#
						Amazon.CDK.Environment makeEnv(string account, string region)
{
    return new Amazon.CDK.Environment { Account = account, Region = region };
}

var prod = makeEnv(account: "123456789012", region: "us-east-1");

var stack1 = new StackThatProvidesABucket(app, "Stack1", new StackProps { Env = prod });

// stack2 will take a property "bucket"
var stack2 = new StackThatExpectsABucket(app, "Stack2", new StackProps { Env = prod,
    bucket = stack1.Bucket});
					

			

			If the AWS CDK determines that the resource is in the same environment, but in a different stack, it automatically
				synthesizes AWS CloudFormation exports in
				the producing stack and an Fn::ImportValue in the consuming stack
				to transfer that information from one stack to the other.

			 
				Resolving dependency deadlocks

				Referencing a resource from one stack in a different stack creates a dependency between the two stacks. This
					makes sure that they're deployed in the right order. After the stacks are deployed, this dependency is concrete.
					After that, removing the use of the shared resource from the consuming stack can cause an unexpected deployment
					failure. This happens if there is another dependency between the two stacks that force them to be deployed in the
					same order. It can also happen without a dependency if the producing stack is simply chosen by the CDK Toolkit to
					be deployed first. The AWS CloudFormation export is removed from the producing stack because it's no longer needed, but the
					exported resource is still being used in the consuming stack because its update is not yet deployed. Therefore,
					deploying the producer stack fails.

				To break this deadlock, remove the use of the shared resource from the consuming stack. (This removes the
					automatic export from the producing stack.) Next, manually add the same export to the producing stack using exactly
					the same logical ID as the automatically generated export. Remove the use of the shared resource in the consuming
					stack and deploy both stacks. Then, remove the manual export (and the shared resource if it's no longer needed) and
					deploy both stacks again. The stack's exportValue()
					method is a convenient way to create the manual export for this purpose. (See the example in the linked method
					reference.)

			 
		 

		
		 
			Referencing resources in your AWS account

			Suppose you want to use a resource already available in your AWS account in your AWS CDK app. This might be a
				resource that was defined through the console, an AWS SDK, directly with AWS CloudFormation, or in a different AWS CDK
				application. You can turn the resource's ARN (or another identifying attribute, or group of attributes) into a proxy
				object. The proxy object serves as a reference to the resource by calling a static factory method on the resource's
				class. 
			When you create such a proxy, the external resource does not become a part of
				your AWS CDK app. Therefore, changes you make to the proxy in your AWS CDK app do not affect the deployed resource. The
				proxy can, however, be passed to any AWS CDK method that requires a resource of that type. 
			The following example shows how to reference a bucket based on an existing bucket with the ARN arn:aws:s3:::amzn-s3-demo-bucket1, and an Amazon Virtual Private Cloud based on an existing VPC having a
				specific ID.

			
				TypeScript
						// Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.fromBucketName(this, 'MyBucket', 'amzn-s3-demo-bucket1');

// Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.fromBucketArn(this, 'MyBucket', 'arn:aws:s3:::amzn-s3-demo-bucket1');

// Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.fromVpcAttributes(this, 'MyVpc', {
  vpcId: 'vpc-1234567890abcde',
});
					
				JavaScript
						// Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.fromBucketName(this, 'MyBucket', 'amzn-s3-demo-bucket1');

// Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.fromBucketArn(this, 'MyBucket', 'arn:aws:s3:::amzn-s3-demo-bucket1');

// Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.fromVpcAttributes(this, 'MyVpc', {
  vpcId: 'vpc-1234567890abcde'
});
					


				Python
						# Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.from_bucket_name(self, "MyBucket", "amzn-s3-demo-bucket1")

# Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.from_bucket_arn(self, "MyBucket", "arn:aws:s3:::amzn-s3-demo-bucket1")

# Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.from_vpc_attributes(self, "MyVpc", vpc_id="vpc-1234567890abcdef")
					
				Java
						// Construct a proxy for a bucket by its name (must be same account)
Bucket.fromBucketName(this, "MyBucket", "amzn-s3-demo-bucket1");

// Construct a proxy for a bucket by its full ARN (can be another account)
Bucket.fromBucketArn(this, "MyBucket",
        "arn:aws:s3:::amzn-s3-demo-bucket1");

// Construct a proxy for an existing VPC from its attribute(s)
Vpc.fromVpcAttributes(this, "MyVpc", VpcAttributes.builder()
        .vpcId("vpc-1234567890abcdef").build());
					
				C#
						// Construct a proxy for a bucket by its name (must be same account)
Bucket.FromBucketName(this, "MyBucket", "amzn-s3-demo-bucket1");

// Construct a proxy for a bucket by its full ARN (can be another account)
Bucket.FromBucketArn(this, "MyBucket", "arn:aws:s3:::amzn-s3-demo-bucket1");

// Construct a proxy for an existing VPC from its attribute(s)
Vpc.FromVpcAttributes(this, "MyVpc", new VpcAttributes
{ 
    VpcId = "vpc-1234567890abcdef" 
});
					

				Go
						// Define a proxy for a bucket by its name (must be same account)
s3.Bucket_FromBucketName(stack, jsii.String("MyBucket"), jsii.String("amzn-s3-demo-bucket1"))

// Define a proxy for a bucket by its full ARN (can be another account)
s3.Bucket_FromBucketArn(stack, jsii.String("MyBucket"), jsii.String("arn:aws:s3:::amzn-s3-demo-bucket1"))

// Define a proxy for an existing VPC from its attributes
ec2.Vpc_FromVpcAttributes(stack, jsii.String("MyVpc"), &ec2.VpcAttributes{
  VpcId: jsii.String("vpc-1234567890abcde"),
})
					
			

			Let's take a closer look at the Vpc.fromLookup() method. Because the ec2.Vpc construct is complex, there are
				many ways you might want to select the VPC to be used with your CDK app. To address this, the VPC construct
				has a fromLookup static method (Python: from_lookup) that lets you look up the desired
				Amazon VPC by querying your AWS account at synthesis time.

			To use Vpc.fromLookup(), the system that synthesizes the stack must have access to the account that
				owns the Amazon VPC. This is because the CDK Toolkit queries the account to find the right Amazon VPC at synthesis time. 

			Furthermore, Vpc.fromLookup() works only in stacks that are defined with an explicit account and region (see Environments for the AWS CDK). If
				the AWS CDK tries to look up an Amazon VPC from an environment-agnostic stack, the
				CDK Toolkit doesn't know which environment to query to find the VPC.

			You must provide Vpc.fromLookup() attributes sufficient to uniquely identify a VPC in your AWS
				account. For example, there can only ever be one default VPC, so it's sufficient to specify the VPC as the
				default.

			

				TypeScript
						ec2.Vpc.fromLookup(this, 'DefaultVpc', { 
  isDefault: true 
});
					

				JavaScript
						ec2.Vpc.fromLookup(this, 'DefaultVpc', { 
  isDefault: true 
});
					

				Python
						ec2.Vpc.from_lookup(self, "DefaultVpc", is_default=True)
					

				Java
						Vpc.fromLookup(this, "DefaultVpc", VpcLookupOptions.builder()
        .isDefault(true).build());
					

				C#
						Vpc.FromLookup(this, id = "DefaultVpc", new VpcLookupOptions { IsDefault = true });
					

				Go
						ec2.Vpc_FromLookup(this, jsii.String("DefaultVpc"), &ec2.VpcLookupOptions{
  IsDefault: jsii.Bool(true),
})
					
			

			You can also use the tags property to query for VPCs by tag. You can add tags to the Amazon VPC at the
				time of its creation by using AWS CloudFormation or the AWS CDK. You can edit tags at any time after creation by using the
				AWS Management Console, the AWS CLI, or an AWS SDK. In addition to any tags you add yourself, the AWS CDK automatically adds the
				following tags to all VPCs it creates. 

			
				 
				 
				 
			
					Name – The name of the VPC.
				
					aws-cdk:subnet-name – The name of the subnet.
				
					aws-cdk:subnet-type – The type of the subnet: Public, Private, or Isolated.
				

			

				TypeScript
						ec2.Vpc.fromLookup(this, 'PublicVpc', 
    {tags: {'aws-cdk:subnet-type': "Public"}});
					

				JavaScript
						ec2.Vpc.fromLookup(this, 'PublicVpc', 
    {tags: {'aws-cdk:subnet-type': "Public"}});
					

				Python
						ec2.Vpc.from_lookup(self, "PublicVpc", 
    tags={"aws-cdk:subnet-type": "Public"})
					

				Java
						Vpc.fromLookup(this, "PublicVpc", VpcLookupOptions.builder()
        .tags(java.util.Map.of("aws-cdk:subnet-type", "Public"))  // Java 9 or later
        .build());
					

				C#
						Vpc.FromLookup(this, id = "PublicVpc", new VpcLookupOptions 
     { Tags = new Dictionary<string, string> { ["aws-cdk:subnet-type"] = "Public" });
					

				Go
						ec2.Vpc_FromLookup(this, jsii.String("DefaultVpc"), &ec2.VpcLookupOptions{
  Tags: &map[string]*string{"aws-cdk:subnet-type": jsii.String("Public")},
})
					
			

			Results of Vpc.fromLookup() are cached in the project's cdk.context.json file.
				(See Context values and the AWS CDK.) Commit this file to version control so that your app will continue to refer to the
				same Amazon VPC. This works even if you later change the attributes of your VPCs in a way that would result in a different
				VPC being selected. This is particularly important if you're deploying the stack in an environment that doesn't have
				access to the AWS account that defines the VPC, such as CDK Pipelines.

			Although you can use an external resource anywhere you'd use a similar resource defined in your AWS CDK app, you
				cannot modify it. For example, calling addToResourcePolicy (Python: add_to_resource_policy)
				on an external s3.Bucket does nothing.

		 

	 
		Resource physical names

		The logical names of resources in AWS CloudFormation are different from the names of resources that are shown in the AWS Management Console
			after they're deployed by AWS CloudFormation. The AWS CDK calls these final names physical names.

		For example, AWS CloudFormation might create the Amazon S3 bucket with the logical ID Stack2MyBucket4DD88B4F and the
			physical name stack2MyBucket4dd88b4f-iuv1rbv9z3to.

		You can specify a physical name when creating constructs that represent resources by using the property
				<resourceType>Name. The following example creates an Amazon S3 bucket with the physical
			name amzn-s3-demo-bucket.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: 'amzn-s3-demo-bucket',
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: 'amzn-s3-demo-bucket'
});
				

			Python
					bucket = s3.Bucket(self, "MyBucket", bucket_name="amzn-s3-demo-bucket")
				

			Java
					Bucket bucket = Bucket.Builder.create(this, "MyBucket")
        .bucketName("amzn-s3-demo-bucket").build();
				

			C#
					var bucket = new Bucket(this, "MyBucket", new BucketProps { BucketName = "amzn-s3-demo-bucket" });
				

			Go
					bucket := s3.NewBucket(this, jsii.String("MyBucket"), &s3.BucketProps{
  BucketName: jsii.String("amzn-s3-demo-bucket"),
})
				
		

		Assigning physical names to resources has some disadvantages in AWS CloudFormation. Most importantly, any changes to deployed
			resources that require a resource replacement, such as changes to a resource's properties that are immutable after
			creation, will fail if a resource has a physical name assigned. If you end up in that state, the only solution is to
			delete the AWS CloudFormation stack, then deploy the AWS CDK app again. See the AWS CloudFormation documentation for details.

		In some cases, such as when creating an AWS CDK app with cross-environment references, physical names are required
			for the AWS CDK to function correctly. In those cases, if you don't want to bother with coming up with a physical name
			yourself, you can let the AWS CDK name it for you. To do so, use the special value
				PhysicalName.GENERATE_IF_NEEDED, as follows.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: core.PhysicalName.GENERATE_IF_NEEDED,
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: core.PhysicalName.GENERATE_IF_NEEDED
});
				

			Python
					bucket = s3.Bucket(self, "MyBucket",
                         bucket_name=core.PhysicalName.GENERATE_IF_NEEDED)
				

			Java
					Bucket bucket = Bucket.Builder.create(this, "MyBucket")
        .bucketName(PhysicalName.GENERATE_IF_NEEDED).build();
				

			C#
					var bucket = new Bucket(this, "MyBucket", new BucketProps 
    { BucketName = PhysicalName.GENERATE_IF_NEEDED });
				

			Go
					bucket := s3.NewBucket(this, jsii.String("MyBucket"), &s3.BucketProps{
  BucketName: awscdk.PhysicalName_GENERATE_IF_NEEDED(),
})
				

		

	 
		Passing unique resource identifiers

		Whenever possible, you should pass resources by reference, as described in the previous section. However, there are
			cases where you have no other choice but to refer to a resource by one of its attributes. Example use cases include the
			following:

		
			 
			 
		
				When you are using low-level AWS CloudFormation resources.
			
				When you need to expose resources to the runtime components of an AWS CDK application, such as when referring to
					Lambda functions through environment variables.
			

		These identifiers are available as attributes on the resources, such as the following.

		

			TypeScript
					bucket.bucketName
lambdaFunc.functionArn
securityGroup.groupArn
				

			JavaScript
					bucket.bucketName
lambdaFunc.functionArn
securityGroup.groupArn
				

			Python
					bucket.bucket_name
lambda_func.function_arn
security_group_arn
				

			Java
					The Java AWS CDK binding uses getter methods for attributes.
					bucket.getBucketName()
lambdaFunc.getFunctionArn()
securityGroup.getGroupArn()
				

			C#
					bucket.BucketName
lambdaFunc.FunctionArn
securityGroup.GroupArn
				

			Go
					bucket.BucketName()
fn.FunctionArn()
				

		

		The following example shows how to pass a generated bucket name to an AWS Lambda function.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'Bucket');

new lambda.Function(this, 'MyLambda', {
  // ...
  environment: {
    BUCKET_NAME: bucket.bucketName,
  },
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'Bucket');

new lambda.Function(this, 'MyLambda', {
  // ...
  environment: {
    BUCKET_NAME: bucket.bucketName
  }
});
				

			Python
					bucket = s3.Bucket(self, "Bucket")
      
lambda.Function(self, "MyLambda", environment=dict(BUCKET_NAME=bucket.bucket_name))
				

			Java
					final Bucket bucket = new Bucket(this, "Bucket");

Function.Builder.create(this, "MyLambda")
        .environment(java.util.Map.of(    // Java 9 or later
                "BUCKET_NAME", bucket.getBucketName()))
        .build();
				

			C#
					var bucket = new Bucket(this, "Bucket");

new Function(this, "MyLambda", new FunctionProps
{
    Environment = new Dictionary<string, string>
    {
        ["BUCKET_NAME"] = bucket.BucketName
    }
});
				

			Go
					bucket := s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{})
lambda.NewFunction(this, jsii.String("MyLambda"), &lambda.FunctionProps{
  Environment: &map[string]*string{"BUCKET_NAME": bucket.BucketName()},
})
				
		
	 
		Granting permissions between resources

		Higher-level constructs make least-privilege permissions achievable by offering simple, intent-based APIs to
			express permission requirements. For example, many L2 constructs offer grant methods that you can use to grant an
			entity (such as an IAM role or user) permission to work with the resource, without having to manually create IAM
			permission statements.

		The following example creates the permissions to allow a Lambda function's execution role to read and write objects
			to a particular Amazon S3 bucket. If the Amazon S3 bucket is encrypted with an AWS KMS key, this method also grants permissions to
			the Lambda function's execution role to decrypt with the key.

		

			TypeScript
					if (bucket.grantReadWrite(func).success) {
  // ...
}
				

			JavaScript
					if ( bucket.grantReadWrite(func).success) {
  // ...
}
				

			Python
					if bucket.grant_read_write(func).success:
    # ...
				

			Java
					if (bucket.grantReadWrite(func).getSuccess()) {
    // ...
}
				

			C#
					if (bucket.GrantReadWrite(func).Success)
{ 
    // ...
}
				

			Go
					if *bucket.GrantReadWrite(function, nil).Success() {
  // ...
}
				

		

		The grant methods return an iam.Grant object. Use the success attribute of the
				Grant object to determine whether the grant was effectively applied (for example, it may not have been
			applied on external resources). You can also use the
				assertSuccess (Python: assert_success) method of the Grant object to enforce
			that the grant was successfully applied.

		If a specific grant method isn't available for the particular use case, you can use a generic grant method to
			define a new grant with a specified list of actions.

		The following example shows how to grant a Lambda function access to the Amazon DynamoDB CreateBackup
			action.

		

			TypeScript
					table.grant(func, 'dynamodb:CreateBackup');
				

			JavaScript
					table.grant(func, 'dynamodb:CreateBackup');
				

			Python
					table.grant(func, "dynamodb:CreateBackup")
				

			Java
					table.grant(func, "dynamodb:CreateBackup");
				

			C#
					table.Grant(func, "dynamodb:CreateBackup");
				

			Go
					table := dynamodb.NewTable(this, jsii.String("MyTable"), &dynamodb.TableProps{})
table.Grant(function, jsii.String("dynamodb:CreateBackup"))
				
		

		Many resources, such as Lambda functions, require a role to be assumed when executing code. A configuration property
			enables you to specify an iam.IRole. If no role is specified, the function automatically creates a role
			specifically for this use. You can then use grant methods on the resources to add statements to the role.

		The grant methods are built using lower-level APIs for handling with IAM policies. Policies are modeled as PolicyDocument
			objects. Add statements directly to roles (or a construct's attached role) using the addToRolePolicy
			method (Python: add_to_role_policy), or to a resource's policy (such as a Bucket policy)
			using the addToResourcePolicy (Python: add_to_resource_policy) method.

	 
		Resource metrics and alarms

		Many resources emit CloudWatch metrics that can be used to set up monitoring dashboards and alarms. Higher-level
			constructs have metric methods that let you access the metrics without looking up the correct name to use.

		The following example shows how to define an alarm when the ApproximateNumberOfMessagesNotVisible of
			an Amazon SQS queue exceeds 100.

		

			TypeScript
					import * as cw from '@aws-cdk/aws-cloudwatch';
import * as sqs from '@aws-cdk/aws-sqs';
import { Duration } from '@aws-cdk/core';

const queue = new sqs.Queue(this, 'MyQueue');

const metric = queue.metricApproximateNumberOfMessagesNotVisible({
  label: 'Messages Visible (Approx)',
  period: Duration.minutes(5),
  // ...
});
metric.createAlarm(this, 'TooManyMessagesAlarm', {
  comparisonOperator: cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
  threshold: 100,
  // ...
});
				

			JavaScript
					const cw = require('@aws-cdk/aws-cloudwatch');
const sqs = require('@aws-cdk/aws-sqs');
const { Duration } = require('@aws-cdk/core');

const queue = new sqs.Queue(this, 'MyQueue');

const metric = queue.metricApproximateNumberOfMessagesNotVisible({
  label: 'Messages Visible (Approx)',
  period: Duration.minutes(5)
  // ...
});
metric.createAlarm(this, 'TooManyMessagesAlarm', {
  comparisonOperator: cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
  threshold: 100
  // ...
});
				

			Python
					import aws_cdk.aws_cloudwatch as cw
import aws_cdk.aws_sqs as sqs
from aws_cdk.core import Duration

queue = sqs.Queue(self, "MyQueue")
metric = queue.metric_approximate_number_of_messages_not_visible(
    label="Messages Visible (Approx)",
    period=Duration.minutes(5),
    # ...
)
metric.create_alarm(self, "TooManyMessagesAlarm",
    comparison_operator=cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
    threshold=100,
    # ...
)
				

			Java
					import software.amazon.awscdk.core.Duration;
import software.amazon.awscdk.services.sqs.Queue;
import software.amazon.awscdk.services.cloudwatch.Metric;
import software.amazon.awscdk.services.cloudwatch.MetricOptions;
import software.amazon.awscdk.services.cloudwatch.CreateAlarmOptions;
import software.amazon.awscdk.services.cloudwatch.ComparisonOperator;

Queue queue = new Queue(this, "MyQueue");

Metric metric = queue
        .metricApproximateNumberOfMessagesNotVisible(MetricOptions.builder()
                .label("Messages Visible (Approx)")
                .period(Duration.minutes(5)).build());

metric.createAlarm(this, "TooManyMessagesAlarm", CreateAlarmOptions.builder()
                .comparisonOperator(ComparisonOperator.GREATER_THAN_THRESHOLD)
                .threshold(100)
                // ...
                .build());
				

			C#
					using cdk = Amazon.CDK;
using cw = Amazon.CDK.AWS.CloudWatch;
using sqs = Amazon.CDK.AWS.SQS;

var queue = new sqs.Queue(this, "MyQueue");
var metric = queue.MetricApproximateNumberOfMessagesNotVisible(new cw.MetricOptions
{
    Label = "Messages Visible (Approx)",
    Period = cdk.Duration.Minutes(5),
    // ...
});
metric.CreateAlarm(this, "TooManyMessagesAlarm", new cw.CreateAlarmOptions
{
    ComparisonOperator = cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
    Threshold = 100,
    // ..
});
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  cw "github.com/aws/aws-cdk-go/awscdk/v2/awscloudwatch"
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

queue := sqs.NewQueue(this, jsii.String("MyQueue"), &sqs.QueueProps{})
metric := queue.MetricApproximateNumberOfMessagesNotVisible(&cw.MetricOptions{
  Label: jsii.String("Messages Visible (Approx)"),
  Period: awscdk.Duration_Minutes(jsii.Number(5)),
})

metric.CreateAlarm(this, jsii.String("TooManyMessagesAlarm"), &cw.CreateAlarmOptions{
  ComparisonOperator: cw.ComparisonOperator_GREATER_THAN_THRESHOLD,
  Threshold: jsii.Number(100),
})
				

		

		If there is no method for a particular metric, you can use the general metric method to specify the metric name
			manually.

		Metrics can also be added to CloudWatch dashboards. See CloudWatch.

	 
		Network traffic

		In many cases, you must enable permissions on a network for an application to work, such as when the compute
			infrastructure needs to access the persistence layer. Resources that establish or listen for connections expose methods
			that enable traffic flows, including setting security group rules or network ACLs.

		IConnectable resources have a connections property that is the gateway to network
			traffic rules configuration.

		You enable data to flow on a given network path by using allow methods. The following example enables
			HTTPS connections to the web and incoming connections from the Amazon EC2 Auto Scaling group fleet2.

		

			TypeScript
					import * as asg from '@aws-cdk/aws-autoscaling';
import * as ec2 from '@aws-cdk/aws-ec2';

const fleet1: asg.AutoScalingGroup = asg.AutoScalingGroup(/*...*/);

// Allow surfing the (secure) web
fleet1.connections.allowTo(new ec2.Peer.anyIpv4(), new ec2.Port({ fromPort: 443, toPort: 443 }));

const fleet2: asg.AutoScalingGroup = asg.AutoScalingGroup(/*...*/);
fleet1.connections.allowFrom(fleet2, ec2.Port.AllTraffic());
				

			JavaScript
					const asg = require('@aws-cdk/aws-autoscaling');
const ec2 = require('@aws-cdk/aws-ec2');

const fleet1 = asg.AutoScalingGroup();

// Allow surfing the (secure) web
fleet1.connections.allowTo(new ec2.Peer.anyIpv4(), new ec2.Port({ fromPort: 443, toPort: 443 }));

const fleet2 = asg.AutoScalingGroup();
fleet1.connections.allowFrom(fleet2, ec2.Port.AllTraffic());
				

			Python
					import aws_cdk.aws_autoscaling as asg
import aws_cdk.aws_ec2 as ec2

fleet1 = asg.AutoScalingGroup( ... )

# Allow surfing the (secure) web
fleet1.connections.allow_to(ec2.Peer.any_ipv4(), 
  ec2.Port(PortProps(from_port=443, to_port=443)))

fleet2 = asg.AutoScalingGroup( ... )
fleet1.connections.allow_from(fleet2, ec2.Port.all_traffic())
				

			Java
					import software.amazon.awscdk.services.autoscaling.AutoScalingGroup;
import software.amazon.awscdk.services.ec2.Peer;
import software.amazon.awscdk.services.ec2.Port;

AutoScalingGroup fleet1 = AutoScalingGroup.Builder.create(this, "MyFleet")
        /* ... */.build();

// Allow surfing the (secure) Web
fleet1.getConnections().allowTo(Peer.anyIpv4(),
        Port.Builder.create().fromPort(443).toPort(443).build());

AutoScalingGroup fleet2 = AutoScalingGroup.Builder.create(this, "MyFleet2")
        /* ... */.build();
fleet1.getConnections().allowFrom(fleet2, Port.allTraffic());
				

			C#
					using cdk = Amazon.CDK;
using asg = Amazon.CDK.AWS.AutoScaling;
using ec2 = Amazon.CDK.AWS.EC2;

// Allow surfing the (secure) Web
var fleet1 = new asg.AutoScalingGroup(this, "MyFleet", new asg.AutoScalingGroupProps { /* ... */ });
fleet1.Connections.AllowTo(ec2.Peer.AnyIpv4(), new ec2.Port(new ec2.PortProps 
  { FromPort = 443, ToPort = 443 });

var fleet2 = new asg.AutoScalingGroup(this, "MyFleet2", new asg.AutoScalingGroupProps { /* ... */ });
fleet1.Connections.AllowFrom(fleet2, ec2.Port.AllTraffic());

				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  autoscaling "github.com/aws/aws-cdk-go/awscdk/v2/awsautoscaling"
  ec2 "github.com/aws/aws-cdk-go/awscdk/v2/awsec2"
)

fleet1 := autoscaling.NewAutoScalingGroup(this, jsii.String("MyFleet1"), &autoscaling.AutoScalingGroupProps{})
fleet1.Connections().AllowTo(ec2.Peer_AnyIpv4(),ec2.NewPort(&ec2.PortProps{ FromPort: jsii.Number(443), ToPort: jsii.Number(443) }),jsii.String("secure web"))

fleet2 := autoscaling.NewAutoScalingGroup(this, jsii.String("MyFleet2"), &autoscaling.AutoScalingGroupProps{}) 
fleet1.Connections().AllowFrom(fleet2, ec2.Port_AllTraffic(),jsii.String("all traffic"))
				

		

		Certain resources have default ports associated with them. Examples include the listener of a load balancer on the
			public port, and the ports on which the database engine accepts connections for instances of an Amazon RDS database. In such
			cases, you can enforce tight network control without having to manually specify the port. To do so, use the
				allowDefaultPortFrom and allowToDefaultPort methods (Python:
				allow_default_port_from, allow_to_default_port).

		The following example shows how to enable connections from any IPV4 address, and a connection from an Auto Scaling group to
			access a database.

		
			TypeScript
					listener.connections.allowDefaultPortFromAnyIpv4('Allow public access');

fleet.connections.allowToDefaultPort(rdsDatabase, 'Fleet can access database');
				

			JavaScript
					listener.connections.allowDefaultPortFromAnyIpv4('Allow public access');

fleet.connections.allowToDefaultPort(rdsDatabase, 'Fleet can access database');
				

			Python
					listener.connections.allow_default_port_from_any_ipv4("Allow public access")

fleet.connections.allow_to_default_port(rds_database, "Fleet can access database")
				

			Java
					listener.getConnections().allowDefaultPortFromAnyIpv4("Allow public access");

fleet.getConnections().AllowToDefaultPort(rdsDatabase, "Fleet can access database");
				

			C#
					listener.Connections.AllowDefaultPortFromAnyIpv4("Allow public access");

fleet.Connections.AllowToDefaultPort(rdsDatabase, "Fleet can access database");
				

			Go
					listener.Connections().AllowDefaultPortFromAnyIpv4(jsii.String("Allow public Access"))
fleet.Connections().AllowToDefaultPort(rdsDatabase, jsii.String("Fleet can access database"))
				
		

	 
		Event handling

		Some resources can act as event sources. Use the addEventNotification method (Python:
				add_event_notification) to register an event target to a particular event type emitted by the resource.
			In addition to this, addXxxNotification methods offer a simple way to register a handler for common event
			types. 

		The following example shows how to trigger a Lambda function when an object is added to an Amazon S3 bucket.

		

			TypeScript
					import * as s3nots from '@aws-cdk/aws-s3-notifications';

const handler = new lambda.Function(this, 'Handler', { /*…*/ });
const bucket = new s3.Bucket(this, 'Bucket');
bucket.addObjectCreatedNotification(new s3nots.LambdaDestination(handler));
				

			JavaScript
					const s3nots = require('@aws-cdk/aws-s3-notifications');

const handler = new lambda.Function(this, 'Handler', { /*…*/ });
const bucket = new s3.Bucket(this, 'Bucket');
bucket.addObjectCreatedNotification(new s3nots.LambdaDestination(handler));
				

			Python
					import aws_cdk.aws_s3_notifications as s3_nots

handler = lambda_.Function(self, "Handler", ...)
bucket = s3.Bucket(self, "Bucket")
bucket.add_object_created_notification(s3_nots.LambdaDestination(handler))
				

			Java
					import software.amazon.awscdk.services.s3.Bucket;
import software.amazon.awscdk.services.lambda.Function;
import software.amazon.awscdk.services.s3.notifications.LambdaDestination;

Function handler = Function.Builder.create(this, "Handler")/* ... */.build();
Bucket bucket = new Bucket(this, "Bucket");
bucket.addObjectCreatedNotification(new LambdaDestination(handler));
				

			C#
					using lambda = Amazon.CDK.AWS.Lambda;
using s3 = Amazon.CDK.AWS.S3;
using s3Nots = Amazon.CDK.AWS.S3.Notifications;

var handler = new lambda.Function(this, "Handler", new lambda.FunctionProps { .. });
var bucket = new s3.Bucket(this, "Bucket");
bucket.AddObjectCreatedNotification(new s3Nots.LambdaDestination(handler));

				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  s3 "github.com/aws/aws-cdk-go/awscdk/v2/awss3"
  s3nots "github.com/aws/aws-cdk-go/awscdk/v2/awss3notifications"	
)

handler := lambda.NewFunction(this, jsii.String("MyFunction"), &lambda.FunctionProps{})
bucket := s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{})
bucket.AddObjectCreatedNotification(s3nots.NewLambdaDestination(handler), nil)
				
		

	 
		Removal policies
		Resources that maintain persistent data, such as databases, Amazon S3 buckets, and Amazon ECR registries, have a
				removal policy. The removal policy indicates whether to delete persistent objects when the AWS CDK
			stack that contains them is destroyed. The values specifying the removal policy are available through the
				RemovalPolicy enumeration in the AWS CDK core module.
		NoteResources besides those that store data persistently might also have a removalPolicy that is used
				for a different purpose. For example, a Lambda function version uses a removalPolicy attribute to
				determine whether a given version is retained when a new version is deployed. These have different meanings and
				defaults compared to the removal policy on an Amazon S3 bucket or DynamoDB table.
		
					
						Value
						Meaning
					
				
					
						
							RemovalPolicy.RETAIN
						
						
							Keep the contents of the resource when destroying the stack (default). The resource is orphaned from the
								stack and must be deleted manually. If you attempt to re-deploy the stack while the resource still exists,
								you will receive an error message due to a name conflict.
						
					
					
						
							RemovalPolicy.DESTROY
						
						
							The resource will be destroyed along with the stack.
						
					
				

		AWS CloudFormation does not remove Amazon S3 buckets that contain files even if their removal policy is set to DESTROY.
			Attempting to do so is an AWS CloudFormation error. To have the AWS CDK delete all files from the bucket before destroying it, set the
			bucket's autoDeleteObjects property to true.

		Following is an example of creating an Amazon S3 bucket with RemovalPolicy of DESTROY and
				autoDeleteOjbects set to true.

		

			TypeScript
					import * as cdk from '@aws-cdk/core';
import * as s3 from '@aws-cdk/aws-s3';
  
export class CdkTestStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);
  
    const bucket = new s3.Bucket(this, 'Bucket', {
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true
    });
  }
}
				

			JavaScript
					const cdk = require('@aws-cdk/core');
const s3 = require('@aws-cdk/aws-s3');
  
class CdkTestStack extends cdk.Stack {
  constructor(scope, id, props) {
    super(scope, id, props);
  
    const bucket = new s3.Bucket(this, 'Bucket', {
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true
    });
  }
}

module.exports = { CdkTestStack }
				

			Python
					import aws_cdk.core as cdk
import aws_cdk.aws_s3 as s3

class CdkTestStack(cdk.stack):
    def __init__(self, scope: cdk.Construct, id: str, **kwargs):
        super().__init__(scope, id, **kwargs)
        
        bucket = s3.Bucket(self, "Bucket",
            removal_policy=cdk.RemovalPolicy.DESTROY,
            auto_delete_objects=True)
				

			Java
					software.amazon.awscdk.core.*;
import software.amazon.awscdk.services.s3.*;

public class CdkTestStack extends Stack {
    public CdkTestStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public CdkTestStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "Bucket")
                .removalPolicy(RemovalPolicy.DESTROY)
                .autoDeleteObjects(true).build();
    }
}
				

			C#
					using Amazon.CDK;
using Amazon.CDK.AWS.S3;

public CdkTestStack(Construct scope, string id, IStackProps props) : base(scope, id, props)
{
    new Bucket(this, "Bucket", new BucketProps {
        RemovalPolicy = RemovalPolicy.DESTROY,
        AutoDeleteObjects = true
    });
}
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  s3 "github.com/aws/aws-cdk-go/awscdk/v2/awss3"
)

s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{
  RemovalPolicy: awscdk.RemovalPolicy_DESTROY,
  AutoDeleteObjects: jsii.Bool(true),
})
				
		
		You can also apply a removal policy directly to the underlying AWS CloudFormation resource via the
				applyRemovalPolicy() method. This method is available on some stateful resources that do not have a
				removalPolicy property in their L2 resource's props. Examples include the following:
		
			 
			 
			 
			 
			 
			 
			 
		
				AWS CloudFormation stacks
			
				Amazon Cognito user pools
			
				Amazon DocumentDB database instances
			
				Amazon EC2 volumes
			
				Amazon OpenSearch Service domains
			
				Amazon FSx file systems
			
				Amazon SQS queues
			
		
			TypeScript
					const resource = bucket.node.findChild('Resource') as cdk.CfnResource;
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			JavaScript
					const resource = bucket.node.findChild('Resource');
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			Python
					resource = bucket.node.find_child('Resource')
resource.apply_removal_policy(cdk.RemovalPolicy.DESTROY);
				
			Java
					CfnResource resource = (CfnResource)bucket.node.findChild("Resource");
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			C#
					
var resource = (CfnResource)bucket.node.findChild('Resource');
resource.ApplyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
		
		NoteThe AWS CDK's RemovalPolicy translates to AWS CloudFormation's DeletionPolicy. However, the default in
				AWS CDK is to retain the data, which is the opposite of the AWS CloudFormation default.
	Document ConventionsBootstrappingIdentifiersDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nclass Tag


LanguageType name


 .NETAmazon.CDK.Tag
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Tag
 Javasoftware.amazon.awscdk.Tag
 Pythonaws_cdk.Tag
 TypeScript (source)aws-cdk-lib » Tag


Implements
IAspect
The Tag Aspect will handle adding a tag to this node and cascading tags to children.
Example
// The code below shows an example of how to instantiate this type.
// The values are placeholders you should change.
import * as cdk from 'aws-cdk-lib';
const tag = new cdk.Tag('key', 'value', /* all optional props */ {
  applyToLaunchedInstances: false,
  excludeResourceTypes: ['excludeResourceTypes'],
  includeResourceTypes: ['includeResourceTypes'],
  priority: 123,
});

Initializer
new Tag(key: string, value: string, props?: TagProps)

Parameters

key string  — The string key for the tag.
value string
props TagProps

Properties


NameTypeDescription


keystringThe string key for the tag.
propsTagProps
valuestringThe string value of the tag.



key
Type:
string
The string key for the tag.

props
Type:
TagProps

value
Type:
string
The string value of the tag.
Methods


NameDescription


visit(construct)All aspects can visit an IConstruct.
protected applyTag(resource)
protected applyTagV2(resource)



visit(construct)
public visit(construct: IConstruct): void

Parameters

construct IConstruct

All aspects can visit an IConstruct.

protected applyTag(resource)
protected applyTag(resource: ITaggable): void

Parameters

resource ITaggable


protected applyTagV2(resource)
protected applyTagV2(resource: ITaggableV2): void

Parameters

resource ITaggableV2\n\nclass Tag


LanguageType name


 .NETAmazon.CDK.Tag
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Tag
 Javasoftware.amazon.awscdk.Tag
 Pythonaws_cdk.Tag
 TypeScript (source)aws-cdk-lib » Tag


Implements
IAspect
The Tag Aspect will handle adding a tag to this node and cascading tags to children.
Example
// The code below shows an example of how to instantiate this type.
// The values are placeholders you should change.
import * as cdk from 'aws-cdk-lib';
const tag = new cdk.Tag('key', 'value', /* all optional props */ {
  applyToLaunchedInstances: false,
  excludeResourceTypes: ['excludeResourceTypes'],
  includeResourceTypes: ['includeResourceTypes'],
  priority: 123,
});

Initializer
new Tag(key: string, value: string, props?: TagProps)

Parameters

key string  — The string key for the tag.
value string
props TagProps

Properties


NameTypeDescription


keystringThe string key for the tag.
propsTagProps
valuestringThe string value of the tag.



key
Type:
string
The string key for the tag.

props
Type:
TagProps

value
Type:
string
The string value of the tag.
Methods


NameDescription


visit(construct)All aspects can visit an IConstruct.
protected applyTag(resource)
protected applyTagV2(resource)



visit(construct)
public visit(construct: IConstruct): void

Parameters

construct IConstruct

All aspects can visit an IConstruct.

protected applyTag(resource)
protected applyTag(resource: ITaggable): void

Parameters

resource ITaggable


protected applyTagV2(resource)
protected applyTagV2(resource: ITaggableV2): void

Parameters

resource ITaggableV2\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuidePrincipalsGrantsRolesResource policiesUsing external IAM objectsThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Permissions and the AWS CDKThe AWS Construct Library uses a few common, widely implemented idioms to manage access and permissions. The IAM
    module provides you with the tools you need to use these idioms.AWS CDK uses AWS CloudFormation to deploy changes. Every deployment involves an actor (either a developer,
    or an automated system) that starts a AWS CloudFormation deployment. In the course of doing this, the actor
    will assume one or more IAM Identities (user or roles) and optionally pass a role to AWS CloudFormation.  If you use AWS IAM Identity Center to authenticate as a user, then the single sign-on provider supplies short-lived session
    credentials that authorize you to act as a pre-defined IAM role. To learn how the AWS CDK obtains AWS credentials from
    IAM Identity Center authentication, see Understand IAM Identity Center authentication
    in the AWS SDKs and Tools Reference Guide. 
    Principals

    An IAM principal is an authenticated AWS entity representing a user, service, or application that can call
      AWS APIs. The AWS Construct Library supports specifying principals in several flexible ways to grant them access
      your AWS resources.

    In security contexts, the term "principal" refers specifically to authenticated entities such as users. Objects
      like groups and roles do not represent users (and other authenticated entities) but
      rather identify them indirectly for the purpose of granting permissions.
    For example, if you create an IAM group, you can grant the group (and thus its members) write access to an Amazon RDS
      table. However, the group itself is not a principal because it doesn't represent a single entity (also, you cannot log
      in to a group).

    In the CDK's IAM library, classes that directly or indirectly identify principals implement the IPrincipal
      interface, allowing these objects to be used interchangeably in access policies. However, not all of them are
      principals in the security sense. These objects include:

    
       
       
       
       
       
       
       
       
    
        IAM resources such as Role, User, and
              Group
      
        Service principals (new iam.ServicePrincipal('service.amazonaws.com'))
      
        Federated principals (new iam.FederatedPrincipal('cognito-identity.amazonaws.com'))
      
        Account principals (new iam.AccountPrincipal('0123456789012'))
      
        Canonical user principals (new iam.CanonicalUserPrincipal('79a59d[...]7ef2be'))
      
        AWS Organizations principals (new iam.OrganizationPrincipal('org-id'))
      
        Arbitrary ARN principals (new iam.ArnPrincipal(res.arn))
      
        An iam.CompositePrincipal(principal1,
            principal2, ...) to trust multiple principals
      

   
    Grants

    Every construct that represents a resource that can be accessed, such as an Amazon S3 bucket or Amazon DynamoDB table, has
      methods that grant access to another entity. All such methods have names starting with grant.
    For example, Amazon S3 buckets have the methods grantRead and grantReadWrite (Python: grant_read, grant_read_write) to enable read and
      read/write access, respectively, from an entity to the bucket. The entity doesn't have to know exactly which Amazon S3 IAM
      permissions are required to perform these operations.

    The first argument of a grant method is always of type IGrantable. This interface represents
      entities that can be granted permissions. That is, it represents resources with roles, such as the IAM objects
          Role,
          User,
      and Group.

    Other entities can also be granted permissions. For example, later in this topic, we show how to grant a CodeBuild
      project access to an Amazon S3 bucket. Generally, the associated role is obtained via a role property on the
      entity being granted access.

    Resources that use execution roles, such as lambda.Function, also implement
        IGrantable, so you can grant them access directly instead of granting access to their role. For example,
      if bucket is an Amazon S3 bucket, and function is a Lambda function, the following code grants the
      function read access to the bucket.

    
      TypeScript
          bucket.grantRead(function);
        
      JavaScript
          bucket.grantRead(function);
        
      Python
          bucket.grant_read(function)
        
      Java
          bucket.grantRead(function);
        
      C#
          bucket.GrantRead(function);
        
    

     Sometimes permissions must be applied while your stack is being deployed. One such case is when you grant an AWS CloudFormation
      custom resource access to some other resource. The custom resource will be invoked during deployment, so it must have
      the specified permissions at deployment time.
    Another case is when a service verifies that the role you pass to it has the right policies applied. (A number of
      AWS services do this to make sure that you didn't forget to set the policies.) In those cases, the deployment might
      fail if the permissions are applied too late. 

     To force the grant's permissions to be applied before another resource is created, you can add a dependency on the
      grant itself, as shown here. Though the return value of grant methods is commonly discarded, every grant method in fact
      returns an iam.Grant object.

    
      TypeScript
          const grant = bucket.grantRead(lambda);
const custom = new CustomResource(...);
custom.node.addDependency(grant);
        
      JavaScript
          const grant = bucket.grantRead(lambda);
const custom = new CustomResource(...);
custom.node.addDependency(grant);
        
      Python
          grant = bucket.grant_read(function)
custom = CustomResource(...)
custom.node.add_dependency(grant)
        
      Java
          Grant grant = bucket.grantRead(function);
CustomResource custom = new CustomResource(...);
custom.node.addDependency(grant);
        
      C#
          var grant = bucket.GrantRead(function);
var custom = new CustomResource(...);
custom.node.AddDependency(grant);
        
    



   
    Roles
    The IAM package contains a Role construct that represents IAM
      roles. The following code creates a new role, trusting the Amazon EC2 service.
    
      TypeScript
          import * as iam from 'aws-cdk-lib/aws-iam';

const role = new iam.Role(this, 'Role', {
  assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),   // required
});
        
      JavaScript
          const iam = require('aws-cdk-lib/aws-iam');

const role = new iam.Role(this, 'Role', {
  assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com')   // required
});
        
      Python
          import aws_cdk.aws_iam as iam
    
role = iam.Role(self, "Role",
          assumed_by=iam.ServicePrincipal("ec2.amazonaws.com")) # required
        
      Java
          import software.amazon.awscdk.services.iam.Role;
import software.amazon.awscdk.services.iam.ServicePrincipal;

Role role = Role.Builder.create(this, "Role")
        .assumedBy(new ServicePrincipal("ec2.amazonaws.com")).build();
        
      C#
          using Amazon.CDK.AWS.IAM;

var role = new Role(this, "Role", new RoleProps
{
    AssumedBy = new ServicePrincipal("ec2.amazonaws.com"),   // required
});
        
    
    You can add permissions to a role by calling the role's addToPolicy
      method (Python: add_to_policy), passing in a PolicyStatement that defines
      the rule to be added. The statement is added to the role's default policy; if it has none, one is created. 
     The following example adds a Deny policy statement to the role for the actions
        ec2:SomeAction and s3:AnotherAction on the resources bucket and
        otherRole (Python: other_role), under the condition that the authorized service is
      AWS CodeBuild.
    
      TypeScript
          role.addToPolicy(new iam.PolicyStatement({
  effect: iam.Effect.DENY,
  resources: [bucket.bucketArn, otherRole.roleArn],
  actions: ['ec2:SomeAction', 's3:AnotherAction'],
  conditions: {StringEquals: {
    'ec2:AuthorizedService': 'codebuild.amazonaws.com',
}}}));
        
      JavaScript
          role.addToPolicy(new iam.PolicyStatement({
  effect: iam.Effect.DENY,
  resources: [bucket.bucketArn, otherRole.roleArn],
  actions: ['ec2:SomeAction', 's3:AnotherAction'],
  conditions: {StringEquals: {
    'ec2:AuthorizedService': 'codebuild.amazonaws.com'
}}}));
        
      Python
          role.add_to_policy(iam.PolicyStatement(
    effect=iam.Effect.DENY,
    resources=[bucket.bucket_arn, other_role.role_arn],
    actions=["ec2:SomeAction", "s3:AnotherAction"],
    conditions={"StringEquals": {
        "ec2:AuthorizedService": "codebuild.amazonaws.com"}}
))
        
      Java
          role.addToPolicy(PolicyStatement.Builder.create()
        .effect(Effect.DENY)
        .resources(Arrays.asList(bucket.getBucketArn(), otherRole.getRoleArn()))
        .actions(Arrays.asList("ec2:SomeAction", "s3:AnotherAction"))
        .conditions(java.util.Map.of(    // Map.of requires Java 9 or later
            "StringEquals", java.util.Map.of(
                "ec2:AuthorizedService", "codebuild.amazonaws.com")))
        .build());
        
      C#
          role.AddToPolicy(new PolicyStatement(new PolicyStatementProps
{
    Effect = Effect.DENY,
    Resources = new string[] { bucket.BucketArn, otherRole.RoleArn },
    Actions = new string[] { "ec2:SomeAction", "s3:AnotherAction" },
    Conditions = new Dictionary<string, object>
    {
        ["StringEquals"] = new Dictionary<string, string>
        {
            ["ec2:AuthorizedService"] = "codebuild.amazonaws.com"
        }
    }
}));
        
    
     In the preceding example, we've created a new PolicyStatement inline with the
          addToPolicy
      (Python: add_to_policy) call. You can also pass in an existing policy statement or one you've modified.
      The PolicyStatement object has numerous methods for adding
      principals, resources, conditions, and actions. 
    If you're using a construct that requires a role to function correctly, you can do one of the following:
    
       
       
    
        Pass in an existing role when instantiating the construct object.
      
        Let the construct create a new role for you, trusting the appropriate service principal. The following example
          uses such a construct: a CodeBuild project.
      
    
      TypeScript
          import * as codebuild from 'aws-cdk-lib/aws-codebuild';

// imagine roleOrUndefined is a function that might return a Role object
// under some conditions, and undefined under other conditions
const someRole: iam.IRole | undefined = roleOrUndefined();

const project = new codebuild.Project(this, 'Project', {
  // if someRole is undefined, the Project creates a new default role, 
  // trusting the codebuild.amazonaws.com service principal
  role: someRole,
});
        
      JavaScript
          const codebuild = require('aws-cdk-lib/aws-codebuild');

// imagine roleOrUndefined is a function that might return a Role object
// under some conditions, and undefined under other conditions
const someRole = roleOrUndefined();

const project = new codebuild.Project(this, 'Project', {
  // if someRole is undefined, the Project creates a new default role, 
  // trusting the codebuild.amazonaws.com service principal
  role: someRole
});
        
      Python
          import aws_cdk.aws_codebuild as codebuild

# imagine role_or_none is a function that might return a Role object
# under some conditions, and None under other conditions
some_role = role_or_none();

project = codebuild.Project(self, "Project",
# if role is None, the Project creates a new default role, 
# trusting the codebuild.amazonaws.com service principal
role=some_role)
        
      Java
          import software.amazon.awscdk.services.iam.Role;
import software.amazon.awscdk.services.codebuild.Project;

// imagine roleOrNull is a function that might return a Role object
// under some conditions, and null under other conditions
Role someRole = roleOrNull();

// if someRole is null, the Project creates a new default role, 
// trusting the codebuild.amazonaws.com service principal
Project project = Project.Builder.create(this, "Project")
        .role(someRole).build();
        
      C#
          using Amazon.CDK.AWS.CodeBuild;

// imagine roleOrNull is a function that might return a Role object
// under some conditions, and null under other conditions
var someRole = roleOrNull();

// if someRole is null, the Project creates a new default role, 
// trusting the codebuild.amazonaws.com service principal
var project = new Project(this, "Project", new ProjectProps
{
    Role = someRole
});

        
    
    Once the object is created, the role (whether the role passed in or the default one created by the construct) is
      available as the property role. However, this property is not available on external resources. Therefore,
      these constructs have an addToRolePolicy (Python: add_to_role_policy) method.
    The method does nothing if the construct is an external resource, and it calls the addToPolicy
      (Python: add_to_policy) method of the role property otherwise. This saves you the trouble of
      handling the undefined case explicitly.
    The following example demonstrates:
    
      TypeScript
          // project is imported into the CDK application
const project = codebuild.Project.fromProjectName(this, 'Project', 'ProjectName');

// project is imported, so project.role is undefined, and this call has no effect
project.addToRolePolicy(new iam.PolicyStatement({
  effect: iam.Effect.ALLOW,   // ... and so on defining the policy
}));

        
      JavaScript
          // project is imported into the CDK application
const project = codebuild.Project.fromProjectName(this, 'Project', 'ProjectName');

// project is imported, so project.role is undefined, and this call has no effect
project.addToRolePolicy(new iam.PolicyStatement({
  effect: iam.Effect.ALLOW   // ... and so on defining the policy
}));
        
      Python
          # project is imported into the CDK application
project = codebuild.Project.from_project_name(self, 'Project', 'ProjectName')

# project is imported, so project.role is undefined, and this call has no effect
project.add_to_role_policy(iam.PolicyStatement(
  effect=iam.Effect.ALLOW,   # ... and so on defining the policy
)
        
      Java
          // project is imported into the CDK application
Project project = Project.fromProjectName(this, "Project", "ProjectName");

// project is imported, so project.getRole() is null, and this call has no effect
project.addToRolePolicy(PolicyStatement.Builder.create()
        .effect(Effect.ALLOW)   // .. and so on defining the policy
        .build();
        
      C#
          // project is imported into the CDK application
var project = Project.FromProjectName(this, "Project", "ProjectName");

// project is imported, so project.role is null, and this call has no effect
project.AddToRolePolicy(new PolicyStatement(new PolicyStatementProps
{
    Effect = Effect.ALLOW, // ... and so on defining the policy 
}));
        
    
   
    Resource policies

    A few resources in AWS, such as Amazon S3 buckets and IAM roles, also have a resource policy. These constructs have
      an addToResourcePolicy method (Python: add_to_resource_policy), which takes a PolicyStatement as its argument. Every policy statement added to a resource policy must specify at
      least one principal.

    In the following example, the Amazon S3 bucket
      bucket grants a role with the s3:SomeAction permission to itself.

    
      TypeScript
          bucket.addToResourcePolicy(new iam.PolicyStatement({
  effect: iam.Effect.ALLOW,
  actions: ['s3:SomeAction'],
  resources: [bucket.bucketArn],
  principals: [role]
}));

        
      JavaScript
          bucket.addToResourcePolicy(new iam.PolicyStatement({
  effect: iam.Effect.ALLOW,
  actions: ['s3:SomeAction'],
  resources: [bucket.bucketArn],
  principals: [role]
}));
        


      Python
          bucket.add_to_resource_policy(iam.PolicyStatement(
    effect=iam.Effect.ALLOW,
    actions=["s3:SomeAction"],
    resources=[bucket.bucket_arn],
    principals=role))
        
      Java
          bucket.addToResourcePolicy(PolicyStatement.Builder.create()
        .effect(Effect.ALLOW)
        .actions(Arrays.asList("s3:SomeAction"))
        .resources(Arrays.asList(bucket.getBucketArn()))
        .principals(Arrays.asList(role))
        .build());
        
      C#
          bucket.AddToResourcePolicy(new PolicyStatement(new PolicyStatementProps
{
    Effect = Effect.ALLOW,
    Actions = new string[] { "s3:SomeAction" },
    Resources = new string[] { bucket.BucketArn },
    Principals = new IPrincipal[] { role }
}));
        
    

   
    Using external IAM objects

    If you have defined an IAM user, principal, group, or role outside your AWS CDK app, you can use that IAM object
      in your AWS CDK app. To do so, create a reference to it using its ARN or its name. (Use the name for users, groups, and
      roles.) The returned reference can then be used to grant permissions or to construct policy statements as explained
      previously.

    
       
       
       
       
    
        For users, call User.fromUserArn() or User.fromUserName(). User.fromUserAttributes() is also available, but currently
          provides the same functionality as User.fromUserArn().
      
        For principals, instantiate an ArnPrincipal object.
      
        For groups, call Group.fromGroupArn() or Group.fromGroupName().
      
        For roles, call Role.fromRoleArn() or Role.fromRoleName().
      

    Policies (including managed policies) can be used in similar fashion using the following methods. You can use
      references to these objects anywhere an IAM policy is required.

    
       
       
       
       
    
        Policy.fromPolicyName
      
        ManagedPolicy.fromManagedPolicyArn
      
        ManagedPolicy.fromManagedPolicyName
      
        ManagedPolicy.fromAwsManagedPolicyName
      

    NoteAs with all references to external AWS resources, you cannot modify external IAM objects in your CDK
        app.

  Document ConventionsAssetsContext valuesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideConfiguring resources using constructsReferencing resourcesResource physical namesPassing unique resource identifiersGranting permissions between resourcesResource metrics and alarmsNetwork trafficEvent handlingRemoval policiesThis is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.Resources and the AWS CDKResources are what you configure to use AWS services in your applications. Resources are a
		feature of AWS CloudFormation. By configuring resources and their properties in a AWS CloudFormation template, you can deploy to AWS CloudFormation to
		provision your resources. With the AWS Cloud Development Kit (AWS CDK), you can configure resources through constructs. You then deploy your
		CDK app, which involves synthesizing a AWS CloudFormation template and deploying to AWS CloudFormation to provision your resources.
		Configuring resources using constructs

		As described in AWS CDK Constructs, the AWS CDK provides a rich class library of constructs, called
				AWS constructs, that represent all AWS resources.

		To create an instance of a resource using its corresponding construct, pass in the scope as the first argument, the
			logical ID of the construct, and a set of configuration properties (props). For example, here's how to create an Amazon SQS
			queue with AWS KMS encryption using the sqs.Queue construct from the AWS Construct Library.

		

			TypeScript
					import * as sqs from '@aws-cdk/aws-sqs';
            
new sqs.Queue(this, 'MyQueue', {
    encryption: sqs.QueueEncryption.KMS_MANAGED
});
				

			JavaScript
					const sqs = require('@aws-cdk/aws-sqs');
            
new sqs.Queue(this, 'MyQueue', {
    encryption: sqs.QueueEncryption.KMS_MANAGED
});
				

			Python
					import aws_cdk.aws_sqs as sqs
      
sqs.Queue(self, "MyQueue", encryption=sqs.QueueEncryption.KMS_MANAGED)
				

			Java
					import software.amazon.awscdk.services.sqs.*;

Queue.Builder.create(this, "MyQueue").encryption(
        QueueEncryption.KMS_MANAGED).build();
				

			C#
					using Amazon.CDK.AWS.SQS;

new Queue(this, "MyQueue", new QueueProps
{
    Encryption = QueueEncryption.KMS_MANAGED
});
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

sqs.NewQueue(stack, jsii.String("MyQueue"), &sqs.QueueProps{
  Encryption: sqs.QueueEncryption_KMS_MANAGED,
})
				

		

		Some configuration props are optional, and in many cases have default values. In some cases, all props are
			optional, and the last argument can be omitted entirely.

		
		 
			Resource attributes

			Most resources in the AWS Construct Library expose attributes, which are resolved at deployment time by AWS CloudFormation. Attributes
				are exposed in the form of properties on the resource classes with the type name as a prefix. The following example
				shows how to get the URL of an Amazon SQS queue using the queueUrl (Python: queue_url)
				property.

			

				TypeScript
						import * as sqs from '@aws-cdk/aws-sqs';
      
const queue = new sqs.Queue(this, 'MyQueue');
const url = queue.queueUrl; // => A string representing a deploy-time value
					

				JavaScript
						const sqs = require('@aws-cdk/aws-sqs');
      
const queue = new sqs.Queue(this, 'MyQueue');
const url = queue.queueUrl; // => A string representing a deploy-time value
					

				Python
						import aws_cdk.aws_sqs as sqs

queue = sqs.Queue(self, "MyQueue")
url = queue.queue_url # => A string representing a deploy-time value

					

				Java
						Queue queue = new Queue(this, "MyQueue");
String url = queue.getQueueUrl();    // => A string representing a deploy-time value
					

				C#
						var queue = new Queue(this, "MyQueue");
var url = queue.QueueUrl; // => A string representing a deploy-time value
					

				Go
						import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

queue := sqs.NewQueue(stack, jsii.String("MyQueue"), &sqs.QueueProps{})
url := queue.QueueUrl() // => A string representing a deploy-time value
					
			

			See Tokens and the AWS CDK for information about how the AWS CDK encodes deploy-time attributes as
				strings.

		 

	 
		Referencing resources

		When configuring resources, you will often have to reference properties of another resource. The following are
			examples:

		
			 
			 
		
				An Amazon Elastic Container Service (Amazon ECS) resource requires a reference to the cluster on which it runs.
			
				An Amazon CloudFront distribution requires a reference to the Amazon Simple Storage Service (Amazon S3) bucket containing the source code.
			

		You can reference resources in any of the following ways:

		
			 
			 
		
				By passing a resource defined in your CDK app, either in the same stack or in a different one
			
				By passing a proxy object referencing a resource defined in your AWS account, created from a unique
					identifier of the resource (such as an ARN)
			

		If the property of a construct represents a construct for another resource, its type is that of the interface type
			of the construct. For example, the Amazon ECS construct takes a property cluster of type
				ecs.ICluster. Another example, is the CloudFront distribution construct that takes a property
				sourceBucket (Python: source_bucket) of type s3.IBucket. 

		You can directly pass any resource object of the proper type defined in the same AWS CDK app. The following example
			defines an Amazon ECS cluster and then uses it to define an Amazon ECS service.

		

			TypeScript
					const cluster = new ecs.Cluster(this, 'Cluster', { /*...*/ });

const service = new ecs.Ec2Service(this, 'Service', { cluster: cluster });
				

			JavaScript
					const cluster = new ecs.Cluster(this, 'Cluster', { /*...*/ });

const service = new ecs.Ec2Service(this, 'Service', { cluster: cluster });
				

			Python
					cluster = ecs.Cluster(self, "Cluster")

service = ecs.Ec2Service(self, "Service", cluster=cluster)
				

			Java
					Cluster cluster = new Cluster(this, "Cluster");
Ec2Service service = new Ec2Service(this, "Service",
        new Ec2ServiceProps.Builder().cluster(cluster).build());
				

			C#
					var cluster = new Cluster(this, "Cluster");
var service = new Ec2Service(this, "Service", new Ec2ServiceProps { Cluster = cluster });
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"	    
  ecs "github.com/aws/aws-cdk-go/awscdk/v2/awsecs"
)

cluster := ecs.NewCluster(stack, jsii.String("MyCluster"), &ecs.ClusterProps{})
service := ecs.NewEc2Service(stack, jsii.String("MyService"), &ecs.Ec2ServiceProps{
  Cluster: cluster,
})
				
		

		
		 
			Referencing resources in a different stack

			You can refer to resources in a different stack as long as they are defined in the same app and are in the same
				AWS environment. The following pattern is generally used:

			
				 
				 
			
					Store a reference to the construct as an attribute of the stack that produces the resource. (To get a
						reference to the current construct's stack, use Stack.of(this).)
				
					Pass this reference to the constructor of the stack that consumes the resource as a parameter or a property.
						The consuming stack then passes it as a property to any construct that needs it.
				

			The following example defines a stack stack1. This stack defines an Amazon S3 bucket and stores a
				reference to the bucket construct as an attribute of the stack. Then the app defines a second stack,
					stack2, which accepts a bucket at instantiation. stack2 might, for example, define an
				AWS Glue Table that uses the bucket for data storage.

			

				TypeScript
						const prod = { account: '123456789012', region: 'us-east-1' };

const stack1 = new StackThatProvidesABucket(app, 'Stack1', { env: prod });

// stack2 will take a property { bucket: IBucket }
const stack2 = new StackThatExpectsABucket(app, 'Stack2', {
  bucket: stack1.bucket, 
  env: prod
});
					

				JavaScript
						const prod = { account: '123456789012', region: 'us-east-1' };

const stack1 = new StackThatProvidesABucket(app, 'Stack1', { env: prod });

// stack2 will take a property { bucket: IBucket }
const stack2 = new StackThatExpectsABucket(app, 'Stack2', {
  bucket: stack1.bucket, 
  env: prod
});
					

				Python
						prod = core.Environment(account="123456789012", region="us-east-1")

stack1 = StackThatProvidesABucket(app, "Stack1", env=prod)

# stack2 will take a property "bucket"
stack2 = StackThatExpectsABucket(app, "Stack2", bucket=stack1.bucket, env=prod)
					

				Java
						// Helper method to build an environment
static Environment makeEnv(String account, String region) {
    return Environment.builder().account(account).region(region)
            .build();
}

App app = new App();

Environment prod = makeEnv("123456789012", "us-east-1");

StackThatProvidesABucket stack1 = new StackThatProvidesABucket(app, "Stack1",
        StackProps.builder().env(prod).build());

// stack2 will take an argument "bucket"
StackThatExpectsABucket stack2 = new StackThatExpectsABucket(app, "Stack,",
        StackProps.builder().env(prod).build(), stack1.bucket);
					

				C#
						Amazon.CDK.Environment makeEnv(string account, string region)
{
    return new Amazon.CDK.Environment { Account = account, Region = region };
}

var prod = makeEnv(account: "123456789012", region: "us-east-1");

var stack1 = new StackThatProvidesABucket(app, "Stack1", new StackProps { Env = prod });

// stack2 will take a property "bucket"
var stack2 = new StackThatExpectsABucket(app, "Stack2", new StackProps { Env = prod,
    bucket = stack1.Bucket});
					

			

			If the AWS CDK determines that the resource is in the same environment, but in a different stack, it automatically
				synthesizes AWS CloudFormation exports in
				the producing stack and an Fn::ImportValue in the consuming stack
				to transfer that information from one stack to the other.

			 
				Resolving dependency deadlocks

				Referencing a resource from one stack in a different stack creates a dependency between the two stacks. This
					makes sure that they're deployed in the right order. After the stacks are deployed, this dependency is concrete.
					After that, removing the use of the shared resource from the consuming stack can cause an unexpected deployment
					failure. This happens if there is another dependency between the two stacks that force them to be deployed in the
					same order. It can also happen without a dependency if the producing stack is simply chosen by the CDK Toolkit to
					be deployed first. The AWS CloudFormation export is removed from the producing stack because it's no longer needed, but the
					exported resource is still being used in the consuming stack because its update is not yet deployed. Therefore,
					deploying the producer stack fails.

				To break this deadlock, remove the use of the shared resource from the consuming stack. (This removes the
					automatic export from the producing stack.) Next, manually add the same export to the producing stack using exactly
					the same logical ID as the automatically generated export. Remove the use of the shared resource in the consuming
					stack and deploy both stacks. Then, remove the manual export (and the shared resource if it's no longer needed) and
					deploy both stacks again. The stack's exportValue()
					method is a convenient way to create the manual export for this purpose. (See the example in the linked method
					reference.)

			 
		 

		
		 
			Referencing resources in your AWS account

			Suppose you want to use a resource already available in your AWS account in your AWS CDK app. This might be a
				resource that was defined through the console, an AWS SDK, directly with AWS CloudFormation, or in a different AWS CDK
				application. You can turn the resource's ARN (or another identifying attribute, or group of attributes) into a proxy
				object. The proxy object serves as a reference to the resource by calling a static factory method on the resource's
				class. 
			When you create such a proxy, the external resource does not become a part of
				your AWS CDK app. Therefore, changes you make to the proxy in your AWS CDK app do not affect the deployed resource. The
				proxy can, however, be passed to any AWS CDK method that requires a resource of that type. 
			The following example shows how to reference a bucket based on an existing bucket with the ARN arn:aws:s3:::amzn-s3-demo-bucket1, and an Amazon Virtual Private Cloud based on an existing VPC having a
				specific ID.

			
				TypeScript
						// Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.fromBucketName(this, 'MyBucket', 'amzn-s3-demo-bucket1');

// Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.fromBucketArn(this, 'MyBucket', 'arn:aws:s3:::amzn-s3-demo-bucket1');

// Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.fromVpcAttributes(this, 'MyVpc', {
  vpcId: 'vpc-1234567890abcde',
});
					
				JavaScript
						// Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.fromBucketName(this, 'MyBucket', 'amzn-s3-demo-bucket1');

// Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.fromBucketArn(this, 'MyBucket', 'arn:aws:s3:::amzn-s3-demo-bucket1');

// Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.fromVpcAttributes(this, 'MyVpc', {
  vpcId: 'vpc-1234567890abcde'
});
					


				Python
						# Construct a proxy for a bucket by its name (must be same account)
s3.Bucket.from_bucket_name(self, "MyBucket", "amzn-s3-demo-bucket1")

# Construct a proxy for a bucket by its full ARN (can be another account)
s3.Bucket.from_bucket_arn(self, "MyBucket", "arn:aws:s3:::amzn-s3-demo-bucket1")

# Construct a proxy for an existing VPC from its attribute(s)
ec2.Vpc.from_vpc_attributes(self, "MyVpc", vpc_id="vpc-1234567890abcdef")
					
				Java
						// Construct a proxy for a bucket by its name (must be same account)
Bucket.fromBucketName(this, "MyBucket", "amzn-s3-demo-bucket1");

// Construct a proxy for a bucket by its full ARN (can be another account)
Bucket.fromBucketArn(this, "MyBucket",
        "arn:aws:s3:::amzn-s3-demo-bucket1");

// Construct a proxy for an existing VPC from its attribute(s)
Vpc.fromVpcAttributes(this, "MyVpc", VpcAttributes.builder()
        .vpcId("vpc-1234567890abcdef").build());
					
				C#
						// Construct a proxy for a bucket by its name (must be same account)
Bucket.FromBucketName(this, "MyBucket", "amzn-s3-demo-bucket1");

// Construct a proxy for a bucket by its full ARN (can be another account)
Bucket.FromBucketArn(this, "MyBucket", "arn:aws:s3:::amzn-s3-demo-bucket1");

// Construct a proxy for an existing VPC from its attribute(s)
Vpc.FromVpcAttributes(this, "MyVpc", new VpcAttributes
{ 
    VpcId = "vpc-1234567890abcdef" 
});
					

				Go
						// Define a proxy for a bucket by its name (must be same account)
s3.Bucket_FromBucketName(stack, jsii.String("MyBucket"), jsii.String("amzn-s3-demo-bucket1"))

// Define a proxy for a bucket by its full ARN (can be another account)
s3.Bucket_FromBucketArn(stack, jsii.String("MyBucket"), jsii.String("arn:aws:s3:::amzn-s3-demo-bucket1"))

// Define a proxy for an existing VPC from its attributes
ec2.Vpc_FromVpcAttributes(stack, jsii.String("MyVpc"), &ec2.VpcAttributes{
  VpcId: jsii.String("vpc-1234567890abcde"),
})
					
			

			Let's take a closer look at the Vpc.fromLookup() method. Because the ec2.Vpc construct is complex, there are
				many ways you might want to select the VPC to be used with your CDK app. To address this, the VPC construct
				has a fromLookup static method (Python: from_lookup) that lets you look up the desired
				Amazon VPC by querying your AWS account at synthesis time.

			To use Vpc.fromLookup(), the system that synthesizes the stack must have access to the account that
				owns the Amazon VPC. This is because the CDK Toolkit queries the account to find the right Amazon VPC at synthesis time. 

			Furthermore, Vpc.fromLookup() works only in stacks that are defined with an explicit account and region (see Environments for the AWS CDK). If
				the AWS CDK tries to look up an Amazon VPC from an environment-agnostic stack, the
				CDK Toolkit doesn't know which environment to query to find the VPC.

			You must provide Vpc.fromLookup() attributes sufficient to uniquely identify a VPC in your AWS
				account. For example, there can only ever be one default VPC, so it's sufficient to specify the VPC as the
				default.

			

				TypeScript
						ec2.Vpc.fromLookup(this, 'DefaultVpc', { 
  isDefault: true 
});
					

				JavaScript
						ec2.Vpc.fromLookup(this, 'DefaultVpc', { 
  isDefault: true 
});
					

				Python
						ec2.Vpc.from_lookup(self, "DefaultVpc", is_default=True)
					

				Java
						Vpc.fromLookup(this, "DefaultVpc", VpcLookupOptions.builder()
        .isDefault(true).build());
					

				C#
						Vpc.FromLookup(this, id = "DefaultVpc", new VpcLookupOptions { IsDefault = true });
					

				Go
						ec2.Vpc_FromLookup(this, jsii.String("DefaultVpc"), &ec2.VpcLookupOptions{
  IsDefault: jsii.Bool(true),
})
					
			

			You can also use the tags property to query for VPCs by tag. You can add tags to the Amazon VPC at the
				time of its creation by using AWS CloudFormation or the AWS CDK. You can edit tags at any time after creation by using the
				AWS Management Console, the AWS CLI, or an AWS SDK. In addition to any tags you add yourself, the AWS CDK automatically adds the
				following tags to all VPCs it creates. 

			
				 
				 
				 
			
					Name – The name of the VPC.
				
					aws-cdk:subnet-name – The name of the subnet.
				
					aws-cdk:subnet-type – The type of the subnet: Public, Private, or Isolated.
				

			

				TypeScript
						ec2.Vpc.fromLookup(this, 'PublicVpc', 
    {tags: {'aws-cdk:subnet-type': "Public"}});
					

				JavaScript
						ec2.Vpc.fromLookup(this, 'PublicVpc', 
    {tags: {'aws-cdk:subnet-type': "Public"}});
					

				Python
						ec2.Vpc.from_lookup(self, "PublicVpc", 
    tags={"aws-cdk:subnet-type": "Public"})
					

				Java
						Vpc.fromLookup(this, "PublicVpc", VpcLookupOptions.builder()
        .tags(java.util.Map.of("aws-cdk:subnet-type", "Public"))  // Java 9 or later
        .build());
					

				C#
						Vpc.FromLookup(this, id = "PublicVpc", new VpcLookupOptions 
     { Tags = new Dictionary<string, string> { ["aws-cdk:subnet-type"] = "Public" });
					

				Go
						ec2.Vpc_FromLookup(this, jsii.String("DefaultVpc"), &ec2.VpcLookupOptions{
  Tags: &map[string]*string{"aws-cdk:subnet-type": jsii.String("Public")},
})
					
			

			Results of Vpc.fromLookup() are cached in the project's cdk.context.json file.
				(See Context values and the AWS CDK.) Commit this file to version control so that your app will continue to refer to the
				same Amazon VPC. This works even if you later change the attributes of your VPCs in a way that would result in a different
				VPC being selected. This is particularly important if you're deploying the stack in an environment that doesn't have
				access to the AWS account that defines the VPC, such as CDK Pipelines.

			Although you can use an external resource anywhere you'd use a similar resource defined in your AWS CDK app, you
				cannot modify it. For example, calling addToResourcePolicy (Python: add_to_resource_policy)
				on an external s3.Bucket does nothing.

		 

	 
		Resource physical names

		The logical names of resources in AWS CloudFormation are different from the names of resources that are shown in the AWS Management Console
			after they're deployed by AWS CloudFormation. The AWS CDK calls these final names physical names.

		For example, AWS CloudFormation might create the Amazon S3 bucket with the logical ID Stack2MyBucket4DD88B4F and the
			physical name stack2MyBucket4dd88b4f-iuv1rbv9z3to.

		You can specify a physical name when creating constructs that represent resources by using the property
				<resourceType>Name. The following example creates an Amazon S3 bucket with the physical
			name amzn-s3-demo-bucket.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: 'amzn-s3-demo-bucket',
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: 'amzn-s3-demo-bucket'
});
				

			Python
					bucket = s3.Bucket(self, "MyBucket", bucket_name="amzn-s3-demo-bucket")
				

			Java
					Bucket bucket = Bucket.Builder.create(this, "MyBucket")
        .bucketName("amzn-s3-demo-bucket").build();
				

			C#
					var bucket = new Bucket(this, "MyBucket", new BucketProps { BucketName = "amzn-s3-demo-bucket" });
				

			Go
					bucket := s3.NewBucket(this, jsii.String("MyBucket"), &s3.BucketProps{
  BucketName: jsii.String("amzn-s3-demo-bucket"),
})
				
		

		Assigning physical names to resources has some disadvantages in AWS CloudFormation. Most importantly, any changes to deployed
			resources that require a resource replacement, such as changes to a resource's properties that are immutable after
			creation, will fail if a resource has a physical name assigned. If you end up in that state, the only solution is to
			delete the AWS CloudFormation stack, then deploy the AWS CDK app again. See the AWS CloudFormation documentation for details.

		In some cases, such as when creating an AWS CDK app with cross-environment references, physical names are required
			for the AWS CDK to function correctly. In those cases, if you don't want to bother with coming up with a physical name
			yourself, you can let the AWS CDK name it for you. To do so, use the special value
				PhysicalName.GENERATE_IF_NEEDED, as follows.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: core.PhysicalName.GENERATE_IF_NEEDED,
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'MyBucket', {
  bucketName: core.PhysicalName.GENERATE_IF_NEEDED
});
				

			Python
					bucket = s3.Bucket(self, "MyBucket",
                         bucket_name=core.PhysicalName.GENERATE_IF_NEEDED)
				

			Java
					Bucket bucket = Bucket.Builder.create(this, "MyBucket")
        .bucketName(PhysicalName.GENERATE_IF_NEEDED).build();
				

			C#
					var bucket = new Bucket(this, "MyBucket", new BucketProps 
    { BucketName = PhysicalName.GENERATE_IF_NEEDED });
				

			Go
					bucket := s3.NewBucket(this, jsii.String("MyBucket"), &s3.BucketProps{
  BucketName: awscdk.PhysicalName_GENERATE_IF_NEEDED(),
})
				

		

	 
		Passing unique resource identifiers

		Whenever possible, you should pass resources by reference, as described in the previous section. However, there are
			cases where you have no other choice but to refer to a resource by one of its attributes. Example use cases include the
			following:

		
			 
			 
		
				When you are using low-level AWS CloudFormation resources.
			
				When you need to expose resources to the runtime components of an AWS CDK application, such as when referring to
					Lambda functions through environment variables.
			

		These identifiers are available as attributes on the resources, such as the following.

		

			TypeScript
					bucket.bucketName
lambdaFunc.functionArn
securityGroup.groupArn
				

			JavaScript
					bucket.bucketName
lambdaFunc.functionArn
securityGroup.groupArn
				

			Python
					bucket.bucket_name
lambda_func.function_arn
security_group_arn
				

			Java
					The Java AWS CDK binding uses getter methods for attributes.
					bucket.getBucketName()
lambdaFunc.getFunctionArn()
securityGroup.getGroupArn()
				

			C#
					bucket.BucketName
lambdaFunc.FunctionArn
securityGroup.GroupArn
				

			Go
					bucket.BucketName()
fn.FunctionArn()
				

		

		The following example shows how to pass a generated bucket name to an AWS Lambda function.

		

			TypeScript
					const bucket = new s3.Bucket(this, 'Bucket');

new lambda.Function(this, 'MyLambda', {
  // ...
  environment: {
    BUCKET_NAME: bucket.bucketName,
  },
});
				

			JavaScript
					const bucket = new s3.Bucket(this, 'Bucket');

new lambda.Function(this, 'MyLambda', {
  // ...
  environment: {
    BUCKET_NAME: bucket.bucketName
  }
});
				

			Python
					bucket = s3.Bucket(self, "Bucket")
      
lambda.Function(self, "MyLambda", environment=dict(BUCKET_NAME=bucket.bucket_name))
				

			Java
					final Bucket bucket = new Bucket(this, "Bucket");

Function.Builder.create(this, "MyLambda")
        .environment(java.util.Map.of(    // Java 9 or later
                "BUCKET_NAME", bucket.getBucketName()))
        .build();
				

			C#
					var bucket = new Bucket(this, "Bucket");

new Function(this, "MyLambda", new FunctionProps
{
    Environment = new Dictionary<string, string>
    {
        ["BUCKET_NAME"] = bucket.BucketName
    }
});
				

			Go
					bucket := s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{})
lambda.NewFunction(this, jsii.String("MyLambda"), &lambda.FunctionProps{
  Environment: &map[string]*string{"BUCKET_NAME": bucket.BucketName()},
})
				
		
	 
		Granting permissions between resources

		Higher-level constructs make least-privilege permissions achievable by offering simple, intent-based APIs to
			express permission requirements. For example, many L2 constructs offer grant methods that you can use to grant an
			entity (such as an IAM role or user) permission to work with the resource, without having to manually create IAM
			permission statements.

		The following example creates the permissions to allow a Lambda function's execution role to read and write objects
			to a particular Amazon S3 bucket. If the Amazon S3 bucket is encrypted with an AWS KMS key, this method also grants permissions to
			the Lambda function's execution role to decrypt with the key.

		

			TypeScript
					if (bucket.grantReadWrite(func).success) {
  // ...
}
				

			JavaScript
					if ( bucket.grantReadWrite(func).success) {
  // ...
}
				

			Python
					if bucket.grant_read_write(func).success:
    # ...
				

			Java
					if (bucket.grantReadWrite(func).getSuccess()) {
    // ...
}
				

			C#
					if (bucket.GrantReadWrite(func).Success)
{ 
    // ...
}
				

			Go
					if *bucket.GrantReadWrite(function, nil).Success() {
  // ...
}
				

		

		The grant methods return an iam.Grant object. Use the success attribute of the
				Grant object to determine whether the grant was effectively applied (for example, it may not have been
			applied on external resources). You can also use the
				assertSuccess (Python: assert_success) method of the Grant object to enforce
			that the grant was successfully applied.

		If a specific grant method isn't available for the particular use case, you can use a generic grant method to
			define a new grant with a specified list of actions.

		The following example shows how to grant a Lambda function access to the Amazon DynamoDB CreateBackup
			action.

		

			TypeScript
					table.grant(func, 'dynamodb:CreateBackup');
				

			JavaScript
					table.grant(func, 'dynamodb:CreateBackup');
				

			Python
					table.grant(func, "dynamodb:CreateBackup")
				

			Java
					table.grant(func, "dynamodb:CreateBackup");
				

			C#
					table.Grant(func, "dynamodb:CreateBackup");
				

			Go
					table := dynamodb.NewTable(this, jsii.String("MyTable"), &dynamodb.TableProps{})
table.Grant(function, jsii.String("dynamodb:CreateBackup"))
				
		

		Many resources, such as Lambda functions, require a role to be assumed when executing code. A configuration property
			enables you to specify an iam.IRole. If no role is specified, the function automatically creates a role
			specifically for this use. You can then use grant methods on the resources to add statements to the role.

		The grant methods are built using lower-level APIs for handling with IAM policies. Policies are modeled as PolicyDocument
			objects. Add statements directly to roles (or a construct's attached role) using the addToRolePolicy
			method (Python: add_to_role_policy), or to a resource's policy (such as a Bucket policy)
			using the addToResourcePolicy (Python: add_to_resource_policy) method.

	 
		Resource metrics and alarms

		Many resources emit CloudWatch metrics that can be used to set up monitoring dashboards and alarms. Higher-level
			constructs have metric methods that let you access the metrics without looking up the correct name to use.

		The following example shows how to define an alarm when the ApproximateNumberOfMessagesNotVisible of
			an Amazon SQS queue exceeds 100.

		

			TypeScript
					import * as cw from '@aws-cdk/aws-cloudwatch';
import * as sqs from '@aws-cdk/aws-sqs';
import { Duration } from '@aws-cdk/core';

const queue = new sqs.Queue(this, 'MyQueue');

const metric = queue.metricApproximateNumberOfMessagesNotVisible({
  label: 'Messages Visible (Approx)',
  period: Duration.minutes(5),
  // ...
});
metric.createAlarm(this, 'TooManyMessagesAlarm', {
  comparisonOperator: cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
  threshold: 100,
  // ...
});
				

			JavaScript
					const cw = require('@aws-cdk/aws-cloudwatch');
const sqs = require('@aws-cdk/aws-sqs');
const { Duration } = require('@aws-cdk/core');

const queue = new sqs.Queue(this, 'MyQueue');

const metric = queue.metricApproximateNumberOfMessagesNotVisible({
  label: 'Messages Visible (Approx)',
  period: Duration.minutes(5)
  // ...
});
metric.createAlarm(this, 'TooManyMessagesAlarm', {
  comparisonOperator: cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
  threshold: 100
  // ...
});
				

			Python
					import aws_cdk.aws_cloudwatch as cw
import aws_cdk.aws_sqs as sqs
from aws_cdk.core import Duration

queue = sqs.Queue(self, "MyQueue")
metric = queue.metric_approximate_number_of_messages_not_visible(
    label="Messages Visible (Approx)",
    period=Duration.minutes(5),
    # ...
)
metric.create_alarm(self, "TooManyMessagesAlarm",
    comparison_operator=cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
    threshold=100,
    # ...
)
				

			Java
					import software.amazon.awscdk.core.Duration;
import software.amazon.awscdk.services.sqs.Queue;
import software.amazon.awscdk.services.cloudwatch.Metric;
import software.amazon.awscdk.services.cloudwatch.MetricOptions;
import software.amazon.awscdk.services.cloudwatch.CreateAlarmOptions;
import software.amazon.awscdk.services.cloudwatch.ComparisonOperator;

Queue queue = new Queue(this, "MyQueue");

Metric metric = queue
        .metricApproximateNumberOfMessagesNotVisible(MetricOptions.builder()
                .label("Messages Visible (Approx)")
                .period(Duration.minutes(5)).build());

metric.createAlarm(this, "TooManyMessagesAlarm", CreateAlarmOptions.builder()
                .comparisonOperator(ComparisonOperator.GREATER_THAN_THRESHOLD)
                .threshold(100)
                // ...
                .build());
				

			C#
					using cdk = Amazon.CDK;
using cw = Amazon.CDK.AWS.CloudWatch;
using sqs = Amazon.CDK.AWS.SQS;

var queue = new sqs.Queue(this, "MyQueue");
var metric = queue.MetricApproximateNumberOfMessagesNotVisible(new cw.MetricOptions
{
    Label = "Messages Visible (Approx)",
    Period = cdk.Duration.Minutes(5),
    // ...
});
metric.CreateAlarm(this, "TooManyMessagesAlarm", new cw.CreateAlarmOptions
{
    ComparisonOperator = cw.ComparisonOperator.GREATER_THAN_THRESHOLD,
    Threshold = 100,
    // ..
});
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  cw "github.com/aws/aws-cdk-go/awscdk/v2/awscloudwatch"
  sqs "github.com/aws/aws-cdk-go/awscdk/v2/awssqs"
)

queue := sqs.NewQueue(this, jsii.String("MyQueue"), &sqs.QueueProps{})
metric := queue.MetricApproximateNumberOfMessagesNotVisible(&cw.MetricOptions{
  Label: jsii.String("Messages Visible (Approx)"),
  Period: awscdk.Duration_Minutes(jsii.Number(5)),
})

metric.CreateAlarm(this, jsii.String("TooManyMessagesAlarm"), &cw.CreateAlarmOptions{
  ComparisonOperator: cw.ComparisonOperator_GREATER_THAN_THRESHOLD,
  Threshold: jsii.Number(100),
})
				

		

		If there is no method for a particular metric, you can use the general metric method to specify the metric name
			manually.

		Metrics can also be added to CloudWatch dashboards. See CloudWatch.

	 
		Network traffic

		In many cases, you must enable permissions on a network for an application to work, such as when the compute
			infrastructure needs to access the persistence layer. Resources that establish or listen for connections expose methods
			that enable traffic flows, including setting security group rules or network ACLs.

		IConnectable resources have a connections property that is the gateway to network
			traffic rules configuration.

		You enable data to flow on a given network path by using allow methods. The following example enables
			HTTPS connections to the web and incoming connections from the Amazon EC2 Auto Scaling group fleet2.

		

			TypeScript
					import * as asg from '@aws-cdk/aws-autoscaling';
import * as ec2 from '@aws-cdk/aws-ec2';

const fleet1: asg.AutoScalingGroup = asg.AutoScalingGroup(/*...*/);

// Allow surfing the (secure) web
fleet1.connections.allowTo(new ec2.Peer.anyIpv4(), new ec2.Port({ fromPort: 443, toPort: 443 }));

const fleet2: asg.AutoScalingGroup = asg.AutoScalingGroup(/*...*/);
fleet1.connections.allowFrom(fleet2, ec2.Port.AllTraffic());
				

			JavaScript
					const asg = require('@aws-cdk/aws-autoscaling');
const ec2 = require('@aws-cdk/aws-ec2');

const fleet1 = asg.AutoScalingGroup();

// Allow surfing the (secure) web
fleet1.connections.allowTo(new ec2.Peer.anyIpv4(), new ec2.Port({ fromPort: 443, toPort: 443 }));

const fleet2 = asg.AutoScalingGroup();
fleet1.connections.allowFrom(fleet2, ec2.Port.AllTraffic());
				

			Python
					import aws_cdk.aws_autoscaling as asg
import aws_cdk.aws_ec2 as ec2

fleet1 = asg.AutoScalingGroup( ... )

# Allow surfing the (secure) web
fleet1.connections.allow_to(ec2.Peer.any_ipv4(), 
  ec2.Port(PortProps(from_port=443, to_port=443)))

fleet2 = asg.AutoScalingGroup( ... )
fleet1.connections.allow_from(fleet2, ec2.Port.all_traffic())
				

			Java
					import software.amazon.awscdk.services.autoscaling.AutoScalingGroup;
import software.amazon.awscdk.services.ec2.Peer;
import software.amazon.awscdk.services.ec2.Port;

AutoScalingGroup fleet1 = AutoScalingGroup.Builder.create(this, "MyFleet")
        /* ... */.build();

// Allow surfing the (secure) Web
fleet1.getConnections().allowTo(Peer.anyIpv4(),
        Port.Builder.create().fromPort(443).toPort(443).build());

AutoScalingGroup fleet2 = AutoScalingGroup.Builder.create(this, "MyFleet2")
        /* ... */.build();
fleet1.getConnections().allowFrom(fleet2, Port.allTraffic());
				

			C#
					using cdk = Amazon.CDK;
using asg = Amazon.CDK.AWS.AutoScaling;
using ec2 = Amazon.CDK.AWS.EC2;

// Allow surfing the (secure) Web
var fleet1 = new asg.AutoScalingGroup(this, "MyFleet", new asg.AutoScalingGroupProps { /* ... */ });
fleet1.Connections.AllowTo(ec2.Peer.AnyIpv4(), new ec2.Port(new ec2.PortProps 
  { FromPort = 443, ToPort = 443 });

var fleet2 = new asg.AutoScalingGroup(this, "MyFleet2", new asg.AutoScalingGroupProps { /* ... */ });
fleet1.Connections.AllowFrom(fleet2, ec2.Port.AllTraffic());

				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  autoscaling "github.com/aws/aws-cdk-go/awscdk/v2/awsautoscaling"
  ec2 "github.com/aws/aws-cdk-go/awscdk/v2/awsec2"
)

fleet1 := autoscaling.NewAutoScalingGroup(this, jsii.String("MyFleet1"), &autoscaling.AutoScalingGroupProps{})
fleet1.Connections().AllowTo(ec2.Peer_AnyIpv4(),ec2.NewPort(&ec2.PortProps{ FromPort: jsii.Number(443), ToPort: jsii.Number(443) }),jsii.String("secure web"))

fleet2 := autoscaling.NewAutoScalingGroup(this, jsii.String("MyFleet2"), &autoscaling.AutoScalingGroupProps{}) 
fleet1.Connections().AllowFrom(fleet2, ec2.Port_AllTraffic(),jsii.String("all traffic"))
				

		

		Certain resources have default ports associated with them. Examples include the listener of a load balancer on the
			public port, and the ports on which the database engine accepts connections for instances of an Amazon RDS database. In such
			cases, you can enforce tight network control without having to manually specify the port. To do so, use the
				allowDefaultPortFrom and allowToDefaultPort methods (Python:
				allow_default_port_from, allow_to_default_port).

		The following example shows how to enable connections from any IPV4 address, and a connection from an Auto Scaling group to
			access a database.

		
			TypeScript
					listener.connections.allowDefaultPortFromAnyIpv4('Allow public access');

fleet.connections.allowToDefaultPort(rdsDatabase, 'Fleet can access database');
				

			JavaScript
					listener.connections.allowDefaultPortFromAnyIpv4('Allow public access');

fleet.connections.allowToDefaultPort(rdsDatabase, 'Fleet can access database');
				

			Python
					listener.connections.allow_default_port_from_any_ipv4("Allow public access")

fleet.connections.allow_to_default_port(rds_database, "Fleet can access database")
				

			Java
					listener.getConnections().allowDefaultPortFromAnyIpv4("Allow public access");

fleet.getConnections().AllowToDefaultPort(rdsDatabase, "Fleet can access database");
				

			C#
					listener.Connections.AllowDefaultPortFromAnyIpv4("Allow public access");

fleet.Connections.AllowToDefaultPort(rdsDatabase, "Fleet can access database");
				

			Go
					listener.Connections().AllowDefaultPortFromAnyIpv4(jsii.String("Allow public Access"))
fleet.Connections().AllowToDefaultPort(rdsDatabase, jsii.String("Fleet can access database"))
				
		

	 
		Event handling

		Some resources can act as event sources. Use the addEventNotification method (Python:
				add_event_notification) to register an event target to a particular event type emitted by the resource.
			In addition to this, addXxxNotification methods offer a simple way to register a handler for common event
			types. 

		The following example shows how to trigger a Lambda function when an object is added to an Amazon S3 bucket.

		

			TypeScript
					import * as s3nots from '@aws-cdk/aws-s3-notifications';

const handler = new lambda.Function(this, 'Handler', { /*…*/ });
const bucket = new s3.Bucket(this, 'Bucket');
bucket.addObjectCreatedNotification(new s3nots.LambdaDestination(handler));
				

			JavaScript
					const s3nots = require('@aws-cdk/aws-s3-notifications');

const handler = new lambda.Function(this, 'Handler', { /*…*/ });
const bucket = new s3.Bucket(this, 'Bucket');
bucket.addObjectCreatedNotification(new s3nots.LambdaDestination(handler));
				

			Python
					import aws_cdk.aws_s3_notifications as s3_nots

handler = lambda_.Function(self, "Handler", ...)
bucket = s3.Bucket(self, "Bucket")
bucket.add_object_created_notification(s3_nots.LambdaDestination(handler))
				

			Java
					import software.amazon.awscdk.services.s3.Bucket;
import software.amazon.awscdk.services.lambda.Function;
import software.amazon.awscdk.services.s3.notifications.LambdaDestination;

Function handler = Function.Builder.create(this, "Handler")/* ... */.build();
Bucket bucket = new Bucket(this, "Bucket");
bucket.addObjectCreatedNotification(new LambdaDestination(handler));
				

			C#
					using lambda = Amazon.CDK.AWS.Lambda;
using s3 = Amazon.CDK.AWS.S3;
using s3Nots = Amazon.CDK.AWS.S3.Notifications;

var handler = new lambda.Function(this, "Handler", new lambda.FunctionProps { .. });
var bucket = new s3.Bucket(this, "Bucket");
bucket.AddObjectCreatedNotification(new s3Nots.LambdaDestination(handler));

				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  s3 "github.com/aws/aws-cdk-go/awscdk/v2/awss3"
  s3nots "github.com/aws/aws-cdk-go/awscdk/v2/awss3notifications"	
)

handler := lambda.NewFunction(this, jsii.String("MyFunction"), &lambda.FunctionProps{})
bucket := s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{})
bucket.AddObjectCreatedNotification(s3nots.NewLambdaDestination(handler), nil)
				
		

	 
		Removal policies
		Resources that maintain persistent data, such as databases, Amazon S3 buckets, and Amazon ECR registries, have a
				removal policy. The removal policy indicates whether to delete persistent objects when the AWS CDK
			stack that contains them is destroyed. The values specifying the removal policy are available through the
				RemovalPolicy enumeration in the AWS CDK core module.
		NoteResources besides those that store data persistently might also have a removalPolicy that is used
				for a different purpose. For example, a Lambda function version uses a removalPolicy attribute to
				determine whether a given version is retained when a new version is deployed. These have different meanings and
				defaults compared to the removal policy on an Amazon S3 bucket or DynamoDB table.
		
					
						Value
						Meaning
					
				
					
						
							RemovalPolicy.RETAIN
						
						
							Keep the contents of the resource when destroying the stack (default). The resource is orphaned from the
								stack and must be deleted manually. If you attempt to re-deploy the stack while the resource still exists,
								you will receive an error message due to a name conflict.
						
					
					
						
							RemovalPolicy.DESTROY
						
						
							The resource will be destroyed along with the stack.
						
					
				

		AWS CloudFormation does not remove Amazon S3 buckets that contain files even if their removal policy is set to DESTROY.
			Attempting to do so is an AWS CloudFormation error. To have the AWS CDK delete all files from the bucket before destroying it, set the
			bucket's autoDeleteObjects property to true.

		Following is an example of creating an Amazon S3 bucket with RemovalPolicy of DESTROY and
				autoDeleteOjbects set to true.

		

			TypeScript
					import * as cdk from '@aws-cdk/core';
import * as s3 from '@aws-cdk/aws-s3';
  
export class CdkTestStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);
  
    const bucket = new s3.Bucket(this, 'Bucket', {
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true
    });
  }
}
				

			JavaScript
					const cdk = require('@aws-cdk/core');
const s3 = require('@aws-cdk/aws-s3');
  
class CdkTestStack extends cdk.Stack {
  constructor(scope, id, props) {
    super(scope, id, props);
  
    const bucket = new s3.Bucket(this, 'Bucket', {
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true
    });
  }
}

module.exports = { CdkTestStack }
				

			Python
					import aws_cdk.core as cdk
import aws_cdk.aws_s3 as s3

class CdkTestStack(cdk.stack):
    def __init__(self, scope: cdk.Construct, id: str, **kwargs):
        super().__init__(scope, id, **kwargs)
        
        bucket = s3.Bucket(self, "Bucket",
            removal_policy=cdk.RemovalPolicy.DESTROY,
            auto_delete_objects=True)
				

			Java
					software.amazon.awscdk.core.*;
import software.amazon.awscdk.services.s3.*;

public class CdkTestStack extends Stack {
    public CdkTestStack(final Construct scope, final String id) {
        this(scope, id, null);
    }

    public CdkTestStack(final Construct scope, final String id, final StackProps props) {
        super(scope, id, props);

        Bucket.Builder.create(this, "Bucket")
                .removalPolicy(RemovalPolicy.DESTROY)
                .autoDeleteObjects(true).build();
    }
}
				

			C#
					using Amazon.CDK;
using Amazon.CDK.AWS.S3;

public CdkTestStack(Construct scope, string id, IStackProps props) : base(scope, id, props)
{
    new Bucket(this, "Bucket", new BucketProps {
        RemovalPolicy = RemovalPolicy.DESTROY,
        AutoDeleteObjects = true
    });
}
				

			Go
					import (
  "github.com/aws/aws-cdk-go/awscdk/v2"
  "github.com/aws/jsii-runtime-go"
  s3 "github.com/aws/aws-cdk-go/awscdk/v2/awss3"
)

s3.NewBucket(this, jsii.String("Bucket"), &s3.BucketProps{
  RemovalPolicy: awscdk.RemovalPolicy_DESTROY,
  AutoDeleteObjects: jsii.Bool(true),
})
				
		
		You can also apply a removal policy directly to the underlying AWS CloudFormation resource via the
				applyRemovalPolicy() method. This method is available on some stateful resources that do not have a
				removalPolicy property in their L2 resource's props. Examples include the following:
		
			 
			 
			 
			 
			 
			 
			 
		
				AWS CloudFormation stacks
			
				Amazon Cognito user pools
			
				Amazon DocumentDB database instances
			
				Amazon EC2 volumes
			
				Amazon OpenSearch Service domains
			
				Amazon FSx file systems
			
				Amazon SQS queues
			
		
			TypeScript
					const resource = bucket.node.findChild('Resource') as cdk.CfnResource;
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			JavaScript
					const resource = bucket.node.findChild('Resource');
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			Python
					resource = bucket.node.find_child('Resource')
resource.apply_removal_policy(cdk.RemovalPolicy.DESTROY);
				
			Java
					CfnResource resource = (CfnResource)bucket.node.findChild("Resource");
resource.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
			C#
					
var resource = (CfnResource)bucket.node.findChild('Resource');
resource.ApplyRemovalPolicy(cdk.RemovalPolicy.DESTROY);
				
		
		NoteThe AWS CDK's RemovalPolicy translates to AWS CloudFormation's DeletionPolicy. However, the default in
				AWS CDK is to retain the data, which is the opposite of the AWS CloudFormation default.
	Document ConventionsBootstrappingIdentifiersDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nclass App


LanguageType name


 .NETAmazon.CDK.App
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#App
 Javasoftware.amazon.awscdk.App
 Pythonaws_cdk.App
 TypeScript (source)aws-cdk-lib » App


Implements
IConstruct, IDependable
Extends
Stage
A construct which represents an entire CDK app. This construct is normally the root of the construct tree.
You would normally define an App instance in your program's entrypoint,
then define constructs where the app is used as the parent scope.
After all the child constructs are defined within the app, you should call
app.synth() which will emit a "cloud assembly" from this app into the
directory specified by outdir. Cloud assemblies includes artifacts such as
CloudFormation templates and assets that are needed to deploy this app into
the AWS cloud.
See also: https://docs.aws.amazon.com/cdk/latest/guide/apps.html
Example
import * as cdk from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

const app = new cdk.App();
const stack = new cdk.Stack(app, 'Stack');

declare const bucket: s3.IBucket;

new dynamodb.Table(stack, 'Table', {
  partitionKey: {
    name: 'id',
    type: dynamodb.AttributeType.STRING,
  },
  importSource: {
    compressionType: dynamodb.InputCompressionType.GZIP,
    inputFormat: dynamodb.InputFormat.csv({
      delimiter: ',',
      headerList: ['id', 'name'],
    }),
    bucket,
    keyPrefix: 'prefix',
  },
});

Initializer
new App(props?: AppProps)

Parameters

props AppProps  — initialization properties.

Initializes a CDK application.
Properties


NameTypeDescription


artifactIdstringArtifact ID of the assembly if it is a nested stage. The root stage (app) will return an empty string.
assetOutdirstringThe cloud assembly asset output directory.
nodeNodeThe tree node.
outdirstringThe cloud assembly output directory.
policyValidationBeta1IPolicyValidationPluginBeta1[]Validation plugins to run during synthesis.
stageNamestringThe name of the stage.
account?stringThe default account for all resources defined within this stage.
parentStage?StageThe parent stage or undefined if this is the app.
region?stringThe default region for all resources defined within this stage.



artifactId
Type:
string
Artifact ID of the assembly if it is a nested stage. The root stage (app) will return an empty string.
Derived from the construct path.

assetOutdir
Type:
string
The cloud assembly asset output directory.

node
Type:
Node
The tree node.

outdir
Type:
string
The cloud assembly output directory.

policyValidationBeta1
Type:
IPolicyValidationPluginBeta1[]
Validation plugins to run during synthesis.
If any plugin reports any violation,
synthesis will be interrupted and the report displayed to the user.

stageName
Type:
string
The name of the stage.
Based on names of the parent stages separated by
hypens.

account?
Type:
string
(optional)
The default account for all resources defined within this stage.

parentStage?
Type:
Stage
(optional)
The parent stage or undefined if this is the app.




region?
Type:
string
(optional)
The default region for all resources defined within this stage.
Methods


NameDescription


synth(options?)Synthesize this stage into a cloud assembly.
toString()Returns a string representation of this construct.
static isApp(obj)Checks if an object is an instance of the App class.



synth(options?)
public synth(options?: StageSynthesisOptions): CloudAssembly

Parameters

options StageSynthesisOptions

Returns

CloudAssembly

Synthesize this stage into a cloud assembly.
Once an assembly has been synthesized, it cannot be modified. Subsequent
calls will return the same assembly.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

static isApp(obj)
public static isApp(obj: any): boolean

Parameters

obj any  — The object to evaluate.

Returns

boolean

Checks if an object is an instance of the App class.\n\nclass App


LanguageType name


 .NETAmazon.CDK.App
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#App
 Javasoftware.amazon.awscdk.App
 Pythonaws_cdk.App
 TypeScript (source)aws-cdk-lib » App


Implements
IConstruct, IDependable
Extends
Stage
A construct which represents an entire CDK app. This construct is normally the root of the construct tree.
You would normally define an App instance in your program's entrypoint,
then define constructs where the app is used as the parent scope.
After all the child constructs are defined within the app, you should call
app.synth() which will emit a "cloud assembly" from this app into the
directory specified by outdir. Cloud assemblies includes artifacts such as
CloudFormation templates and assets that are needed to deploy this app into
the AWS cloud.
See also: https://docs.aws.amazon.com/cdk/latest/guide/apps.html
Example
import * as cdk from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

const app = new cdk.App();
const stack = new cdk.Stack(app, 'Stack');

declare const bucket: s3.IBucket;

new dynamodb.Table(stack, 'Table', {
  partitionKey: {
    name: 'id',
    type: dynamodb.AttributeType.STRING,
  },
  importSource: {
    compressionType: dynamodb.InputCompressionType.GZIP,
    inputFormat: dynamodb.InputFormat.csv({
      delimiter: ',',
      headerList: ['id', 'name'],
    }),
    bucket,
    keyPrefix: 'prefix',
  },
});

Initializer
new App(props?: AppProps)

Parameters

props AppProps  — initialization properties.

Initializes a CDK application.
Properties


NameTypeDescription


artifactIdstringArtifact ID of the assembly if it is a nested stage. The root stage (app) will return an empty string.
assetOutdirstringThe cloud assembly asset output directory.
nodeNodeThe tree node.
outdirstringThe cloud assembly output directory.
policyValidationBeta1IPolicyValidationPluginBeta1[]Validation plugins to run during synthesis.
stageNamestringThe name of the stage.
account?stringThe default account for all resources defined within this stage.
parentStage?StageThe parent stage or undefined if this is the app.
region?stringThe default region for all resources defined within this stage.



artifactId
Type:
string
Artifact ID of the assembly if it is a nested stage. The root stage (app) will return an empty string.
Derived from the construct path.

assetOutdir
Type:
string
The cloud assembly asset output directory.

node
Type:
Node
The tree node.

outdir
Type:
string
The cloud assembly output directory.

policyValidationBeta1
Type:
IPolicyValidationPluginBeta1[]
Validation plugins to run during synthesis.
If any plugin reports any violation,
synthesis will be interrupted and the report displayed to the user.

stageName
Type:
string
The name of the stage.
Based on names of the parent stages separated by
hypens.

account?
Type:
string
(optional)
The default account for all resources defined within this stage.

parentStage?
Type:
Stage
(optional)
The parent stage or undefined if this is the app.




region?
Type:
string
(optional)
The default region for all resources defined within this stage.
Methods


NameDescription


synth(options?)Synthesize this stage into a cloud assembly.
toString()Returns a string representation of this construct.
static isApp(obj)Checks if an object is an instance of the App class.



synth(options?)
public synth(options?: StageSynthesisOptions): CloudAssembly

Parameters

options StageSynthesisOptions

Returns

CloudAssembly

Synthesize this stage into a cloud assembly.
Once an assembly has been synthesized, it cannot be modified. Subsequent
calls will return the same assembly.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

static isApp(obj)
public static isApp(obj: any): boolean

Parameters

obj any  — The object to evaluate.

Returns

boolean

Checks if an object is an instance of the App class.\n\n\n\nclass Stack (construct)


LanguageType name


 .NETAmazon.CDK.Stack
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Stack
 Javasoftware.amazon.awscdk.Stack
 Pythonaws_cdk.Stack
 TypeScript (source)aws-cdk-lib » Stack


Implements
IConstruct, IDependable, ITaggable
A root construct which represents a single CloudFormation stack.
Example
import * as cdk from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

const app = new cdk.App();
const stack = new cdk.Stack(app, 'Stack');

declare const bucket: s3.IBucket;

new dynamodb.Table(stack, 'Table', {
  partitionKey: {
    name: 'id',
    type: dynamodb.AttributeType.STRING,
  },
  importSource: {
    compressionType: dynamodb.InputCompressionType.GZIP,
    inputFormat: dynamodb.InputFormat.csv({
      delimiter: ',',
      headerList: ['id', 'name'],
    }),
    bucket,
    keyPrefix: 'prefix',
  },
});

Initializer
new Stack(scope?: Construct, id?: string, props?: StackProps)

Parameters

scope Construct  — Parent of this stack, usually an App or a Stage, but could be any construct.
id string  — The construct ID of this stack.
props StackProps  — Stack properties.

Creates a new stack.
Construct Props


NameTypeDescription


analyticsReporting?booleanInclude runtime versioning information in this Stack.
crossRegionReferences?booleanEnable this flag to allow native cross region stack references.
description?stringA description of the stack.
env?EnvironmentThe AWS environment (account/region) where this stack will be deployed.
notificationArns?string[]SNS Topic ARNs that will receive stack events.
permissionsBoundary?PermissionsBoundaryOptions for applying a permissions boundary to all IAM Roles and Users created within this Stage.
stackName?stringName to deploy the stack with.
suppressTemplateIndentation?booleanEnable this flag to suppress indentation in generated CloudFormation templates.
synthesizer?IStackSynthesizerSynthesis method to use while deploying this stack.
tags?{ [string]: string }Stack tags that will be applied to all the taggable resources and the stack itself.
terminationProtection?booleanWhether to enable termination protection for this stack.



analyticsReporting?
Type:
boolean
(optional, default: analyticsReporting setting of containing App, or value of
'aws:cdk:version-reporting' context key)
Include runtime versioning information in this Stack.

crossRegionReferences?
Type:
boolean
(optional, default: false)
Enable this flag to allow native cross region stack references.
Enabling this will create a CloudFormation custom resource
in both the producing stack and consuming stack in order to perform the export/import
This feature is currently experimental

description?
Type:
string
(optional, default: No description.)
A description of the stack.

env?
Type:
Environment
(optional, default: The environment of the containing Stage if available,
otherwise create the stack will be environment-agnostic.)
The AWS environment (account/region) where this stack will be deployed.
Set the region/account fields of env to either a concrete value to
select the indicated environment (recommended for production stacks), or to
the values of environment variables
CDK_DEFAULT_REGION/CDK_DEFAULT_ACCOUNT to let the target environment
depend on the AWS credentials/configuration that the CDK CLI is executed
under (recommended for development stacks).
If the Stack is instantiated inside a Stage, any undefined
region/account fields from env will default to the same field on the
encompassing Stage, if configured there.
If either region or account are not set nor inherited from Stage, the
Stack will be considered "environment-agnostic"". Environment-agnostic
stacks can be deployed to any environment but may not be able to take
advantage of all features of the CDK. For example, they will not be able to
use environmental context lookups such as ec2.Vpc.fromLookup and will not
automatically translate Service Principals to the right format based on the
environment's AWS partition, and other such enhancements.
Example
// Use a concrete account and region to deploy this stack to:
// `.account` and `.region` will simply return these values.
new Stack(app, 'Stack1', {
  env: {
    account: '123456789012',
    region: 'us-east-1'
  },
});

// Use the CLI's current credentials to determine the target environment:
// `.account` and `.region` will reflect the account+region the CLI
// is configured to use (based on the user CLI credentials)
new Stack(app, 'Stack2', {
  env: {
    account: process.env.CDK_DEFAULT_ACCOUNT,
    region: process.env.CDK_DEFAULT_REGION
  },
});

// Define multiple stacks stage associated with an environment
const myStage = new Stage(app, 'MyStage', {
  env: {
    account: '123456789012',
    region: 'us-east-1'
  }
});

// both of these stacks will use the stage's account/region:
// `.account` and `.region` will resolve to the concrete values as above
new MyStack(myStage, 'Stack1');
new YourStack(myStage, 'Stack2');

// Define an environment-agnostic stack:
// `.account` and `.region` will resolve to `{ "Ref": "AWS::AccountId" }` and `{ "Ref": "AWS::Region" }` respectively.
// which will only resolve to actual values by CloudFormation during deployment.
new MyStack(app, 'Stack1');


notificationArns?
Type:
string[]
(optional, default: no notfication arns.)
SNS Topic ARNs that will receive stack events.

permissionsBoundary?
Type:
PermissionsBoundary
(optional, default: no permissions boundary is applied)
Options for applying a permissions boundary to all IAM Roles and Users created within this Stage.

stackName?
Type:
string
(optional, default: Derived from construct path.)
Name to deploy the stack with.

suppressTemplateIndentation?
Type:
boolean
(optional, default: the value of @aws-cdk/core:suppressTemplateIndentation, or false if that is not set.)
Enable this flag to suppress indentation in generated CloudFormation templates.
If not specified, the value of the @aws-cdk/core:suppressTemplateIndentation
context key will be used. If that is not specified, then the
default value false will be used.

synthesizer?
Type:
IStackSynthesizer
(optional, default: The synthesizer specified on App, or DefaultStackSynthesizer otherwise.)
Synthesis method to use while deploying this stack.
The Stack Synthesizer controls aspects of synthesis and deployment,
like how assets are referenced and what IAM roles to use. For more
information, see the README of the main CDK package.
If not specified, the defaultStackSynthesizer from App will be used.
If that is not specified, DefaultStackSynthesizer is used if
@aws-cdk/core:newStyleStackSynthesis is set to true or the CDK major
version is v2. In CDK v1 LegacyStackSynthesizer is the default if no
other synthesizer is specified.

tags?
Type:
{ [string]: string }
(optional, default: {})
Stack tags that will be applied to all the taggable resources and the stack itself.

terminationProtection?
Type:
boolean
(optional, default: false)
Whether to enable termination protection for this stack.
Properties


NameTypeDescription


accountstringThe AWS account into which this stack will be deployed.
artifactIdstringThe ID of the cloud assembly artifact for this stack.
availabilityZonesstring[]Returns the list of AZs that are available in the AWS environment (account/region) associated with this stack.
bundlingRequiredbooleanIndicates whether the stack requires bundling or not.
dependenciesStack[]Return the stacks this stack depends on.
environmentstringThe environment coordinates in which this stack is deployed.
nestedbooleanIndicates if this is a nested stack, in which case parentStack will include a reference to it's parent.
nodeNodeThe tree node.
notificationArnsstring[]Returns the list of notification Amazon Resource Names (ARNs) for the current stack.
partitionstringThe partition in which this stack is defined.
regionstringThe AWS region into which this stack will be deployed (e.g. us-west-2).
stackIdstringThe ID of the stack.
stackNamestringThe concrete CloudFormation physical stack name.
synthesizerIStackSynthesizerSynthesis method for this stack.
tagsTagManagerTags to be applied to the stack.
templateFilestringThe name of the CloudFormation template file emitted to the output directory during synthesis.
templateOptionsITemplateOptionsOptions for CloudFormation template (like version, transform, description).
terminationProtectionbooleanWhether termination protection is enabled for this stack.
urlSuffixstringThe Amazon domain suffix for the region in which this stack is defined.
nestedStackParent?StackIf this is a nested stack, returns it's parent stack.
nestedStackResource?CfnResourceIf this is a nested stack, this represents its AWS::CloudFormation::Stack resource.



account
Type:
string
The AWS account into which this stack will be deployed.
This value is resolved according to the following rules:

The value provided to env.account when the stack is defined. This can
either be a concrete account (e.g. 585695031111) or the
Aws.ACCOUNT_ID token.
Aws.ACCOUNT_ID, which represents the CloudFormation intrinsic reference
{ "Ref": "AWS::AccountId" } encoded as a string token.

Preferably, you should use the return value as an opaque string and not
attempt to parse it to implement your logic. If you do, you must first
check that it is a concrete value an not an unresolved token. If this
value is an unresolved token (Token.isUnresolved(stack.account) returns
true), this implies that the user wishes that this stack will synthesize
into an account-agnostic template. In this case, your code should either
fail (throw an error, emit a synth error using Annotations.of(construct).addError()) or
implement some other account-agnostic behavior.

artifactId
Type:
string
The ID of the cloud assembly artifact for this stack.

availabilityZones
Type:
string[]
Returns the list of AZs that are available in the AWS environment (account/region) associated with this stack.
If the stack is environment-agnostic (either account and/or region are
tokens), this property will return an array with 2 tokens that will resolve
at deploy-time to the first two availability zones returned from CloudFormation's
Fn::GetAZs intrinsic function.
If they are not available in the context, returns a set of dummy values and
reports them as missing, and let the CLI resolve them by calling EC2
DescribeAvailabilityZones on the target environment.
To specify a different strategy for selecting availability zones override this method.

bundlingRequired
Type:
boolean
Indicates whether the stack requires bundling or not.

dependencies
Type:
Stack[]
Return the stacks this stack depends on.

environment
Type:
string
The environment coordinates in which this stack is deployed.
In the form
aws://account/region. Use stack.account and stack.region to obtain
the specific values, no need to parse.
You can use this value to determine if two stacks are targeting the same
environment.
If either stack.account or stack.region are not concrete values (e.g.
Aws.ACCOUNT_ID or Aws.REGION) the special strings unknown-account and/or
unknown-region will be used respectively to indicate this stack is
region/account-agnostic.

nested
Type:
boolean
Indicates if this is a nested stack, in which case parentStack will include a reference to it's parent.

node
Type:
Node
The tree node.

notificationArns
Type:
string[]
Returns the list of notification Amazon Resource Names (ARNs) for the current stack.

partition
Type:
string
The partition in which this stack is defined.

region
Type:
string
The AWS region into which this stack will be deployed (e.g. us-west-2).
This value is resolved according to the following rules:

The value provided to env.region when the stack is defined. This can
either be a concrete region (e.g. us-west-2) or the Aws.REGION
token.
Aws.REGION, which is represents the CloudFormation intrinsic reference
{ "Ref": "AWS::Region" } encoded as a string token.

Preferably, you should use the return value as an opaque string and not
attempt to parse it to implement your logic. If you do, you must first
check that it is a concrete value an not an unresolved token. If this
value is an unresolved token (Token.isUnresolved(stack.region) returns
true), this implies that the user wishes that this stack will synthesize
into a region-agnostic template. In this case, your code should either
fail (throw an error, emit a synth error using Annotations.of(construct).addError()) or
implement some other region-agnostic behavior.

stackId
Type:
string
The ID of the stack.
Example
// After resolving, looks like
'arn:aws:cloudformation:us-west-2:123456789012:stack/teststack/51af3dc0-da77-11e4-872e-1234567db123'


stackName
Type:
string
The concrete CloudFormation physical stack name.
This is either the name defined explicitly in the stackName prop or
allocated based on the stack's location in the construct tree. Stacks that
are directly defined under the app use their construct id as their stack
name. Stacks that are defined deeper within the tree will use a hashed naming
scheme based on the construct path to ensure uniqueness.
If you wish to obtain the deploy-time AWS::StackName intrinsic,
you can use Aws.STACK_NAME directly.

synthesizer
Type:
IStackSynthesizer
Synthesis method for this stack.

tags
Type:
TagManager
Tags to be applied to the stack.

templateFile
Type:
string
The name of the CloudFormation template file emitted to the output directory during synthesis.
Example value: MyStack.template.json

templateOptions
Type:
ITemplateOptions
Options for CloudFormation template (like version, transform, description).

terminationProtection
Type:
boolean
Whether termination protection is enabled for this stack.

urlSuffix
Type:
string
The Amazon domain suffix for the region in which this stack is defined.

nestedStackParent?
Type:
Stack
(optional)
If this is a nested stack, returns it's parent stack.

nestedStackResource?
Type:
CfnResource
(optional)
If this is a nested stack, this represents its AWS::CloudFormation::Stack resource.
undefined for top-level (non-nested) stacks.
Methods


NameDescription


addDependency(target, reason?)Add a dependency between this stack and another stack.
addMetadata(key, value)Adds an arbitrary key-value pair, with information you want to record about the stack.
addTransform(transform)Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.
exportStringListValue(exportedValue, options?)Create a CloudFormation Export for a string list value.
exportValue(exportedValue, options?)Create a CloudFormation Export for a string value.
formatArn(components)Creates an ARN from components.
getLogicalId(element)Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.
regionalFact(factName, defaultValue?)Look up a fact value for the given fact for the region of this stack.
renameLogicalId(oldId, newId)Rename a generated logical identities.
reportMissingContextKey(report)Indicate that a context key was expected.
resolve(obj)Resolve a tokenized value in the context of the current stack.
splitArn(arn, arnFormat)Splits the provided ARN into its components.
toJsonString(obj, space?)Convert an object, potentially containing tokens, to a JSON string.
toString()Returns a string representation of this construct.
toYamlString(obj)Convert an object, potentially containing tokens, to a YAML string.
protected allocateLogicalId(cfnElement)Returns the naming scheme used to allocate logical IDs.
static isStack(x)Return whether the given object is a Stack.
static of(construct)Looks up the first stack scope in which construct is defined.



addDependency(target, reason?)
public addDependency(target: Stack, reason?: string): void

Parameters

target Stack
reason string

Add a dependency between this stack and another stack.
This can be used to define dependencies between any two stacks within an
app, and also supports nested stacks.

addMetadata(key, value)
public addMetadata(key: string, value: any): void

Parameters

key string
value any

Adds an arbitrary key-value pair, with information you want to record about the stack.
These get translated to the Metadata section of the generated template.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html

addTransform(transform)
public addTransform(transform: string): void

Parameters

transform string  — The transform to add.

Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.
Duplicate values are removed when stack is synthesized.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/transform-section-structure.html
Example
declare const stack: Stack;

stack.addTransform('AWS::Serverless-2016-10-31')


exportStringListValue(exportedValue, options?)
public exportStringListValue(exportedValue: any, options?: ExportValueOptions): string[]

Parameters

exportedValue any
options ExportValueOptions

Returns

string[]

Create a CloudFormation Export for a string list value.
Returns a string list representing the corresponding Fn.importValue()
expression for this Export. The export expression is automatically wrapped with an
Fn::Join and the import value with an Fn::Split, since CloudFormation can only
export strings. You can control the name for the export by passing the name option.
If you don't supply a value for name, the value you're exporting must be
a Resource attribute (for example: bucket.bucketName) and it will be
given the same name as the automatic cross-stack reference that would be created
if you used the attribute in another Stack.
One of the uses for this method is to remove the relationship between
two Stacks established by automatic cross-stack references. It will
temporarily ensure that the CloudFormation Export still exists while you
remove the reference from the consuming stack. After that, you can remove
the resource and the manual export.
See exportValue for an example of this process.

exportValue(exportedValue, options?)
public exportValue(exportedValue: any, options?: ExportValueOptions): string

Parameters

exportedValue any
options ExportValueOptions

Returns

string

Create a CloudFormation Export for a string value.
Returns a string representing the corresponding Fn.importValue()
expression for this Export. You can control the name for the export by
passing the name option.
If you don't supply a value for name, the value you're exporting must be
a Resource attribute (for example: bucket.bucketName) and it will be
given the same name as the automatic cross-stack reference that would be created
if you used the attribute in another Stack.
One of the uses for this method is to remove the relationship between
two Stacks established by automatic cross-stack references. It will
temporarily ensure that the CloudFormation Export still exists while you
remove the reference from the consuming stack. After that, you can remove
the resource and the manual export.
Here is how the process works. Let's say there are two stacks,
producerStack and consumerStack, and producerStack has a bucket
called bucket, which is referenced by consumerStack (perhaps because
an AWS Lambda Function writes into it, or something like that).
It is not safe to remove producerStack.bucket because as the bucket is being
deleted, consumerStack might still be using it.
Instead, the process takes two deployments:
Deployment 1: break the relationship:

Make sure consumerStack no longer references bucket.bucketName (maybe the consumer
stack now uses its own bucket, or it writes to an AWS DynamoDB table, or maybe you just
remove the Lambda Function altogether).
In the ProducerStack class, call this.exportValue(this.bucket.bucketName). This
will make sure the CloudFormation Export continues to exist while the relationship
between the two stacks is being broken.
Deploy (this will effectively only change the consumerStack, but it's safe to deploy both).

Deployment 2: remove the bucket resource:

You are now free to remove the bucket resource from producerStack.
Don't forget to remove the exportValue() call as well.
Deploy again (this time only the producerStack will be changed -- the bucket will be deleted).


formatArn(components)
public formatArn(components: ArnComponents): string

Parameters

components ArnComponents

Returns

string

Creates an ARN from components.
If partition, region or account are not specified, the stack's
partition, region and account will be used.
If any component is the empty string, an empty string will be inserted
into the generated ARN at the location that component corresponds to.
The ARN will be formatted as follows:
arn:{partition}:{service}:{region}:{account}:{resource}{sep}{resource-name}
The required ARN pieces that are omitted will be taken from the stack that
the 'scope' is attached to. If all ARN pieces are supplied, the supplied scope
can be 'undefined'.

getLogicalId(element)
public getLogicalId(element: CfnElement): string

Parameters

element CfnElement  — The CloudFormation element for which a logical identity is needed.

Returns

string

Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.
This method is called when a CfnElement is created and used to render the
initial logical identity of resources. Logical ID renames are applied at
this stage.
This method uses the protected method allocateLogicalId to render the
logical ID for an element. To modify the naming scheme, extend the Stack
class and override this method.

regionalFact(factName, defaultValue?)
public regionalFact(factName: string, defaultValue?: string): string

Parameters

factName string
defaultValue string

Returns

string

Look up a fact value for the given fact for the region of this stack.
Will return a definite value only if the region of the current stack is resolved.
If not, a lookup map will be added to the stack and the lookup will be done at
CDK deployment time.
What regions will be included in the lookup map is controlled by the
@aws-cdk/core:target-partitions context value: it must be set to a list
of partitions, and only regions from the given partitions will be included.
If no such context key is set, all regions will be included.
This function is intended to be used by construct library authors. Application
builders can rely on the abstractions offered by construct libraries and do
not have to worry about regional facts.
If defaultValue is not given, it is an error if the fact is unknown for
the given region.

renameLogicalId(oldId, newId)
public renameLogicalId(oldId: string, newId: string): void

Parameters

oldId string
newId string

Rename a generated logical identities.
To modify the naming scheme strategy, extend the Stack class and
override the allocateLogicalId method.

reportMissingContextKey(report)
public reportMissingContextKey(report: MissingContext): void

Parameters

report MissingContext  — The set of parameters needed to obtain the context.

Indicate that a context key was expected.
Contains instructions which will be emitted into the cloud assembly on how
the key should be supplied.

resolve(obj)
public resolve(obj: any): any

Parameters

obj any

Returns

any

Resolve a tokenized value in the context of the current stack.

splitArn(arn, arnFormat)
public splitArn(arn: string, arnFormat: ArnFormat): ArnComponents

Parameters

arn string  — the ARN to split into its components.
arnFormat ArnFormat  — the expected format of 'arn' - depends on what format the service 'arn' represents uses.

Returns

ArnComponents

Splits the provided ARN into its components.
Works both if 'arn' is a string like 'arn:aws:s3:::bucket',
and a Token representing a dynamic CloudFormation expression
(in which case the returned components will also be dynamic CloudFormation expressions,
encoded as Tokens).

toJsonString(obj, space?)
public toJsonString(obj: any, space?: number): string

Parameters

obj any
space number

Returns

string

Convert an object, potentially containing tokens, to a JSON string.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

toYamlString(obj)
public toYamlString(obj: any): string

Parameters

obj any

Returns

string

Convert an object, potentially containing tokens, to a YAML string.

protected allocateLogicalId(cfnElement)
protected allocateLogicalId(cfnElement: CfnElement): string

Parameters

cfnElement CfnElement  — The element for which the logical ID is allocated.

Returns

string

Returns the naming scheme used to allocate logical IDs.
By default, uses
the HashedAddressingScheme but this method can be overridden to customize
this behavior.
In order to make sure logical IDs are unique and stable, we hash the resource
construct tree path (i.e. toplevel/secondlevel/.../myresource) and add it as
a suffix to the path components joined without a separator (CloudFormation
IDs only allow alphanumeric characters).
The result will be:
<path.join('')><md5(path.join('/')>
"human"      "hash"
If the "human" part of the ID exceeds 240 characters, we simply trim it so
the total ID doesn't exceed CloudFormation's 255 character limit.
We only take 8 characters from the md5 hash (0.000005 chance of collision).
Special cases:

If the path only contains a single component (i.e. it's a top-level
resource), we won't add the hash to it. The hash is not needed for
disambiguation and also, it allows for a more straightforward migration an
existing CloudFormation template to a CDK stack without logical ID changes
(or renames).
For aesthetic reasons, if the last components of the path are the same
(i.e. L1/L2/Pipeline/Pipeline), they will be de-duplicated to make the
resulting human portion of the ID more pleasing: L1L2Pipeline&lt;HASH&gt;
instead of L1L2PipelinePipeline&lt;HASH&gt;
If a component is named "Default" it will be omitted from the path. This
allows refactoring higher level abstractions around constructs without affecting
the IDs of already deployed resources.
If a component is named "Resource" it will be omitted from the user-visible
path, but included in the hash. This reduces visual noise in the human readable
part of the identifier.


static isStack(x)
public static isStack(x: any): boolean

Parameters

x any

Returns

boolean

Return whether the given object is a Stack.
We do attribute detection since we can't reliably use 'instanceof'.

static of(construct)
public static of(construct: IConstruct): Stack

Parameters

construct IConstruct  — The construct to start the search from.

Returns

Stack

Looks up the first stack scope in which construct is defined.
Fails if there is no stack up the tree.\n\nclass Stack (construct)


LanguageType name


 .NETAmazon.CDK.Stack
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Stack
 Javasoftware.amazon.awscdk.Stack
 Pythonaws_cdk.Stack
 TypeScript (source)aws-cdk-lib » Stack


Implements
IConstruct, IDependable, ITaggable
A root construct which represents a single CloudFormation stack.
Example
import * as cdk from 'aws-cdk-lib';
import * as s3 from 'aws-cdk-lib/aws-s3';

const app = new cdk.App();
const stack = new cdk.Stack(app, 'Stack');

declare const bucket: s3.IBucket;

new dynamodb.Table(stack, 'Table', {
  partitionKey: {
    name: 'id',
    type: dynamodb.AttributeType.STRING,
  },
  importSource: {
    compressionType: dynamodb.InputCompressionType.GZIP,
    inputFormat: dynamodb.InputFormat.csv({
      delimiter: ',',
      headerList: ['id', 'name'],
    }),
    bucket,
    keyPrefix: 'prefix',
  },
});

Initializer
new Stack(scope?: Construct, id?: string, props?: StackProps)

Parameters

scope Construct  — Parent of this stack, usually an App or a Stage, but could be any construct.
id string  — The construct ID of this stack.
props StackProps  — Stack properties.

Creates a new stack.
Construct Props


NameTypeDescription


analyticsReporting?booleanInclude runtime versioning information in this Stack.
crossRegionReferences?booleanEnable this flag to allow native cross region stack references.
description?stringA description of the stack.
env?EnvironmentThe AWS environment (account/region) where this stack will be deployed.
notificationArns?string[]SNS Topic ARNs that will receive stack events.
permissionsBoundary?PermissionsBoundaryOptions for applying a permissions boundary to all IAM Roles and Users created within this Stage.
stackName?stringName to deploy the stack with.
suppressTemplateIndentation?booleanEnable this flag to suppress indentation in generated CloudFormation templates.
synthesizer?IStackSynthesizerSynthesis method to use while deploying this stack.
tags?{ [string]: string }Stack tags that will be applied to all the taggable resources and the stack itself.
terminationProtection?booleanWhether to enable termination protection for this stack.



analyticsReporting?
Type:
boolean
(optional, default: analyticsReporting setting of containing App, or value of
'aws:cdk:version-reporting' context key)
Include runtime versioning information in this Stack.

crossRegionReferences?
Type:
boolean
(optional, default: false)
Enable this flag to allow native cross region stack references.
Enabling this will create a CloudFormation custom resource
in both the producing stack and consuming stack in order to perform the export/import
This feature is currently experimental

description?
Type:
string
(optional, default: No description.)
A description of the stack.

env?
Type:
Environment
(optional, default: The environment of the containing Stage if available,
otherwise create the stack will be environment-agnostic.)
The AWS environment (account/region) where this stack will be deployed.
Set the region/account fields of env to either a concrete value to
select the indicated environment (recommended for production stacks), or to
the values of environment variables
CDK_DEFAULT_REGION/CDK_DEFAULT_ACCOUNT to let the target environment
depend on the AWS credentials/configuration that the CDK CLI is executed
under (recommended for development stacks).
If the Stack is instantiated inside a Stage, any undefined
region/account fields from env will default to the same field on the
encompassing Stage, if configured there.
If either region or account are not set nor inherited from Stage, the
Stack will be considered "environment-agnostic"". Environment-agnostic
stacks can be deployed to any environment but may not be able to take
advantage of all features of the CDK. For example, they will not be able to
use environmental context lookups such as ec2.Vpc.fromLookup and will not
automatically translate Service Principals to the right format based on the
environment's AWS partition, and other such enhancements.
Example
// Use a concrete account and region to deploy this stack to:
// `.account` and `.region` will simply return these values.
new Stack(app, 'Stack1', {
  env: {
    account: '123456789012',
    region: 'us-east-1'
  },
});

// Use the CLI's current credentials to determine the target environment:
// `.account` and `.region` will reflect the account+region the CLI
// is configured to use (based on the user CLI credentials)
new Stack(app, 'Stack2', {
  env: {
    account: process.env.CDK_DEFAULT_ACCOUNT,
    region: process.env.CDK_DEFAULT_REGION
  },
});

// Define multiple stacks stage associated with an environment
const myStage = new Stage(app, 'MyStage', {
  env: {
    account: '123456789012',
    region: 'us-east-1'
  }
});

// both of these stacks will use the stage's account/region:
// `.account` and `.region` will resolve to the concrete values as above
new MyStack(myStage, 'Stack1');
new YourStack(myStage, 'Stack2');

// Define an environment-agnostic stack:
// `.account` and `.region` will resolve to `{ "Ref": "AWS::AccountId" }` and `{ "Ref": "AWS::Region" }` respectively.
// which will only resolve to actual values by CloudFormation during deployment.
new MyStack(app, 'Stack1');


notificationArns?
Type:
string[]
(optional, default: no notfication arns.)
SNS Topic ARNs that will receive stack events.

permissionsBoundary?
Type:
PermissionsBoundary
(optional, default: no permissions boundary is applied)
Options for applying a permissions boundary to all IAM Roles and Users created within this Stage.

stackName?
Type:
string
(optional, default: Derived from construct path.)
Name to deploy the stack with.

suppressTemplateIndentation?
Type:
boolean
(optional, default: the value of @aws-cdk/core:suppressTemplateIndentation, or false if that is not set.)
Enable this flag to suppress indentation in generated CloudFormation templates.
If not specified, the value of the @aws-cdk/core:suppressTemplateIndentation
context key will be used. If that is not specified, then the
default value false will be used.

synthesizer?
Type:
IStackSynthesizer
(optional, default: The synthesizer specified on App, or DefaultStackSynthesizer otherwise.)
Synthesis method to use while deploying this stack.
The Stack Synthesizer controls aspects of synthesis and deployment,
like how assets are referenced and what IAM roles to use. For more
information, see the README of the main CDK package.
If not specified, the defaultStackSynthesizer from App will be used.
If that is not specified, DefaultStackSynthesizer is used if
@aws-cdk/core:newStyleStackSynthesis is set to true or the CDK major
version is v2. In CDK v1 LegacyStackSynthesizer is the default if no
other synthesizer is specified.

tags?
Type:
{ [string]: string }
(optional, default: {})
Stack tags that will be applied to all the taggable resources and the stack itself.

terminationProtection?
Type:
boolean
(optional, default: false)
Whether to enable termination protection for this stack.
Properties


NameTypeDescription


accountstringThe AWS account into which this stack will be deployed.
artifactIdstringThe ID of the cloud assembly artifact for this stack.
availabilityZonesstring[]Returns the list of AZs that are available in the AWS environment (account/region) associated with this stack.
bundlingRequiredbooleanIndicates whether the stack requires bundling or not.
dependenciesStack[]Return the stacks this stack depends on.
environmentstringThe environment coordinates in which this stack is deployed.
nestedbooleanIndicates if this is a nested stack, in which case parentStack will include a reference to it's parent.
nodeNodeThe tree node.
notificationArnsstring[]Returns the list of notification Amazon Resource Names (ARNs) for the current stack.
partitionstringThe partition in which this stack is defined.
regionstringThe AWS region into which this stack will be deployed (e.g. us-west-2).
stackIdstringThe ID of the stack.
stackNamestringThe concrete CloudFormation physical stack name.
synthesizerIStackSynthesizerSynthesis method for this stack.
tagsTagManagerTags to be applied to the stack.
templateFilestringThe name of the CloudFormation template file emitted to the output directory during synthesis.
templateOptionsITemplateOptionsOptions for CloudFormation template (like version, transform, description).
terminationProtectionbooleanWhether termination protection is enabled for this stack.
urlSuffixstringThe Amazon domain suffix for the region in which this stack is defined.
nestedStackParent?StackIf this is a nested stack, returns it's parent stack.
nestedStackResource?CfnResourceIf this is a nested stack, this represents its AWS::CloudFormation::Stack resource.



account
Type:
string
The AWS account into which this stack will be deployed.
This value is resolved according to the following rules:

The value provided to env.account when the stack is defined. This can
either be a concrete account (e.g. 585695031111) or the
Aws.ACCOUNT_ID token.
Aws.ACCOUNT_ID, which represents the CloudFormation intrinsic reference
{ "Ref": "AWS::AccountId" } encoded as a string token.

Preferably, you should use the return value as an opaque string and not
attempt to parse it to implement your logic. If you do, you must first
check that it is a concrete value an not an unresolved token. If this
value is an unresolved token (Token.isUnresolved(stack.account) returns
true), this implies that the user wishes that this stack will synthesize
into an account-agnostic template. In this case, your code should either
fail (throw an error, emit a synth error using Annotations.of(construct).addError()) or
implement some other account-agnostic behavior.

artifactId
Type:
string
The ID of the cloud assembly artifact for this stack.

availabilityZones
Type:
string[]
Returns the list of AZs that are available in the AWS environment (account/region) associated with this stack.
If the stack is environment-agnostic (either account and/or region are
tokens), this property will return an array with 2 tokens that will resolve
at deploy-time to the first two availability zones returned from CloudFormation's
Fn::GetAZs intrinsic function.
If they are not available in the context, returns a set of dummy values and
reports them as missing, and let the CLI resolve them by calling EC2
DescribeAvailabilityZones on the target environment.
To specify a different strategy for selecting availability zones override this method.

bundlingRequired
Type:
boolean
Indicates whether the stack requires bundling or not.

dependencies
Type:
Stack[]
Return the stacks this stack depends on.

environment
Type:
string
The environment coordinates in which this stack is deployed.
In the form
aws://account/region. Use stack.account and stack.region to obtain
the specific values, no need to parse.
You can use this value to determine if two stacks are targeting the same
environment.
If either stack.account or stack.region are not concrete values (e.g.
Aws.ACCOUNT_ID or Aws.REGION) the special strings unknown-account and/or
unknown-region will be used respectively to indicate this stack is
region/account-agnostic.

nested
Type:
boolean
Indicates if this is a nested stack, in which case parentStack will include a reference to it's parent.

node
Type:
Node
The tree node.

notificationArns
Type:
string[]
Returns the list of notification Amazon Resource Names (ARNs) for the current stack.

partition
Type:
string
The partition in which this stack is defined.

region
Type:
string
The AWS region into which this stack will be deployed (e.g. us-west-2).
This value is resolved according to the following rules:

The value provided to env.region when the stack is defined. This can
either be a concrete region (e.g. us-west-2) or the Aws.REGION
token.
Aws.REGION, which is represents the CloudFormation intrinsic reference
{ "Ref": "AWS::Region" } encoded as a string token.

Preferably, you should use the return value as an opaque string and not
attempt to parse it to implement your logic. If you do, you must first
check that it is a concrete value an not an unresolved token. If this
value is an unresolved token (Token.isUnresolved(stack.region) returns
true), this implies that the user wishes that this stack will synthesize
into a region-agnostic template. In this case, your code should either
fail (throw an error, emit a synth error using Annotations.of(construct).addError()) or
implement some other region-agnostic behavior.

stackId
Type:
string
The ID of the stack.
Example
// After resolving, looks like
'arn:aws:cloudformation:us-west-2:123456789012:stack/teststack/51af3dc0-da77-11e4-872e-1234567db123'


stackName
Type:
string
The concrete CloudFormation physical stack name.
This is either the name defined explicitly in the stackName prop or
allocated based on the stack's location in the construct tree. Stacks that
are directly defined under the app use their construct id as their stack
name. Stacks that are defined deeper within the tree will use a hashed naming
scheme based on the construct path to ensure uniqueness.
If you wish to obtain the deploy-time AWS::StackName intrinsic,
you can use Aws.STACK_NAME directly.

synthesizer
Type:
IStackSynthesizer
Synthesis method for this stack.

tags
Type:
TagManager
Tags to be applied to the stack.

templateFile
Type:
string
The name of the CloudFormation template file emitted to the output directory during synthesis.
Example value: MyStack.template.json

templateOptions
Type:
ITemplateOptions
Options for CloudFormation template (like version, transform, description).

terminationProtection
Type:
boolean
Whether termination protection is enabled for this stack.

urlSuffix
Type:
string
The Amazon domain suffix for the region in which this stack is defined.

nestedStackParent?
Type:
Stack
(optional)
If this is a nested stack, returns it's parent stack.

nestedStackResource?
Type:
CfnResource
(optional)
If this is a nested stack, this represents its AWS::CloudFormation::Stack resource.
undefined for top-level (non-nested) stacks.
Methods


NameDescription


addDependency(target, reason?)Add a dependency between this stack and another stack.
addMetadata(key, value)Adds an arbitrary key-value pair, with information you want to record about the stack.
addTransform(transform)Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.
exportStringListValue(exportedValue, options?)Create a CloudFormation Export for a string list value.
exportValue(exportedValue, options?)Create a CloudFormation Export for a string value.
formatArn(components)Creates an ARN from components.
getLogicalId(element)Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.
regionalFact(factName, defaultValue?)Look up a fact value for the given fact for the region of this stack.
renameLogicalId(oldId, newId)Rename a generated logical identities.
reportMissingContextKey(report)Indicate that a context key was expected.
resolve(obj)Resolve a tokenized value in the context of the current stack.
splitArn(arn, arnFormat)Splits the provided ARN into its components.
toJsonString(obj, space?)Convert an object, potentially containing tokens, to a JSON string.
toString()Returns a string representation of this construct.
toYamlString(obj)Convert an object, potentially containing tokens, to a YAML string.
protected allocateLogicalId(cfnElement)Returns the naming scheme used to allocate logical IDs.
static isStack(x)Return whether the given object is a Stack.
static of(construct)Looks up the first stack scope in which construct is defined.



addDependency(target, reason?)
public addDependency(target: Stack, reason?: string): void

Parameters

target Stack
reason string

Add a dependency between this stack and another stack.
This can be used to define dependencies between any two stacks within an
app, and also supports nested stacks.

addMetadata(key, value)
public addMetadata(key: string, value: any): void

Parameters

key string
value any

Adds an arbitrary key-value pair, with information you want to record about the stack.
These get translated to the Metadata section of the generated template.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html

addTransform(transform)
public addTransform(transform: string): void

Parameters

transform string  — The transform to add.

Add a Transform to this stack. A Transform is a macro that AWS CloudFormation uses to process your template.
Duplicate values are removed when stack is synthesized.
See also: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/transform-section-structure.html
Example
declare const stack: Stack;

stack.addTransform('AWS::Serverless-2016-10-31')


exportStringListValue(exportedValue, options?)
public exportStringListValue(exportedValue: any, options?: ExportValueOptions): string[]

Parameters

exportedValue any
options ExportValueOptions

Returns

string[]

Create a CloudFormation Export for a string list value.
Returns a string list representing the corresponding Fn.importValue()
expression for this Export. The export expression is automatically wrapped with an
Fn::Join and the import value with an Fn::Split, since CloudFormation can only
export strings. You can control the name for the export by passing the name option.
If you don't supply a value for name, the value you're exporting must be
a Resource attribute (for example: bucket.bucketName) and it will be
given the same name as the automatic cross-stack reference that would be created
if you used the attribute in another Stack.
One of the uses for this method is to remove the relationship between
two Stacks established by automatic cross-stack references. It will
temporarily ensure that the CloudFormation Export still exists while you
remove the reference from the consuming stack. After that, you can remove
the resource and the manual export.
See exportValue for an example of this process.

exportValue(exportedValue, options?)
public exportValue(exportedValue: any, options?: ExportValueOptions): string

Parameters

exportedValue any
options ExportValueOptions

Returns

string

Create a CloudFormation Export for a string value.
Returns a string representing the corresponding Fn.importValue()
expression for this Export. You can control the name for the export by
passing the name option.
If you don't supply a value for name, the value you're exporting must be
a Resource attribute (for example: bucket.bucketName) and it will be
given the same name as the automatic cross-stack reference that would be created
if you used the attribute in another Stack.
One of the uses for this method is to remove the relationship between
two Stacks established by automatic cross-stack references. It will
temporarily ensure that the CloudFormation Export still exists while you
remove the reference from the consuming stack. After that, you can remove
the resource and the manual export.
Here is how the process works. Let's say there are two stacks,
producerStack and consumerStack, and producerStack has a bucket
called bucket, which is referenced by consumerStack (perhaps because
an AWS Lambda Function writes into it, or something like that).
It is not safe to remove producerStack.bucket because as the bucket is being
deleted, consumerStack might still be using it.
Instead, the process takes two deployments:
Deployment 1: break the relationship:

Make sure consumerStack no longer references bucket.bucketName (maybe the consumer
stack now uses its own bucket, or it writes to an AWS DynamoDB table, or maybe you just
remove the Lambda Function altogether).
In the ProducerStack class, call this.exportValue(this.bucket.bucketName). This
will make sure the CloudFormation Export continues to exist while the relationship
between the two stacks is being broken.
Deploy (this will effectively only change the consumerStack, but it's safe to deploy both).

Deployment 2: remove the bucket resource:

You are now free to remove the bucket resource from producerStack.
Don't forget to remove the exportValue() call as well.
Deploy again (this time only the producerStack will be changed -- the bucket will be deleted).


formatArn(components)
public formatArn(components: ArnComponents): string

Parameters

components ArnComponents

Returns

string

Creates an ARN from components.
If partition, region or account are not specified, the stack's
partition, region and account will be used.
If any component is the empty string, an empty string will be inserted
into the generated ARN at the location that component corresponds to.
The ARN will be formatted as follows:
arn:{partition}:{service}:{region}:{account}:{resource}{sep}{resource-name}
The required ARN pieces that are omitted will be taken from the stack that
the 'scope' is attached to. If all ARN pieces are supplied, the supplied scope
can be 'undefined'.

getLogicalId(element)
public getLogicalId(element: CfnElement): string

Parameters

element CfnElement  — The CloudFormation element for which a logical identity is needed.

Returns

string

Allocates a stack-unique CloudFormation-compatible logical identity for a specific resource.
This method is called when a CfnElement is created and used to render the
initial logical identity of resources. Logical ID renames are applied at
this stage.
This method uses the protected method allocateLogicalId to render the
logical ID for an element. To modify the naming scheme, extend the Stack
class and override this method.

regionalFact(factName, defaultValue?)
public regionalFact(factName: string, defaultValue?: string): string

Parameters

factName string
defaultValue string

Returns

string

Look up a fact value for the given fact for the region of this stack.
Will return a definite value only if the region of the current stack is resolved.
If not, a lookup map will be added to the stack and the lookup will be done at
CDK deployment time.
What regions will be included in the lookup map is controlled by the
@aws-cdk/core:target-partitions context value: it must be set to a list
of partitions, and only regions from the given partitions will be included.
If no such context key is set, all regions will be included.
This function is intended to be used by construct library authors. Application
builders can rely on the abstractions offered by construct libraries and do
not have to worry about regional facts.
If defaultValue is not given, it is an error if the fact is unknown for
the given region.

renameLogicalId(oldId, newId)
public renameLogicalId(oldId: string, newId: string): void

Parameters

oldId string
newId string

Rename a generated logical identities.
To modify the naming scheme strategy, extend the Stack class and
override the allocateLogicalId method.

reportMissingContextKey(report)
public reportMissingContextKey(report: MissingContext): void

Parameters

report MissingContext  — The set of parameters needed to obtain the context.

Indicate that a context key was expected.
Contains instructions which will be emitted into the cloud assembly on how
the key should be supplied.

resolve(obj)
public resolve(obj: any): any

Parameters

obj any

Returns

any

Resolve a tokenized value in the context of the current stack.

splitArn(arn, arnFormat)
public splitArn(arn: string, arnFormat: ArnFormat): ArnComponents

Parameters

arn string  — the ARN to split into its components.
arnFormat ArnFormat  — the expected format of 'arn' - depends on what format the service 'arn' represents uses.

Returns

ArnComponents

Splits the provided ARN into its components.
Works both if 'arn' is a string like 'arn:aws:s3:::bucket',
and a Token representing a dynamic CloudFormation expression
(in which case the returned components will also be dynamic CloudFormation expressions,
encoded as Tokens).

toJsonString(obj, space?)
public toJsonString(obj: any, space?: number): string

Parameters

obj any
space number

Returns

string

Convert an object, potentially containing tokens, to a JSON string.

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

toYamlString(obj)
public toYamlString(obj: any): string

Parameters

obj any

Returns

string

Convert an object, potentially containing tokens, to a YAML string.

protected allocateLogicalId(cfnElement)
protected allocateLogicalId(cfnElement: CfnElement): string

Parameters

cfnElement CfnElement  — The element for which the logical ID is allocated.

Returns

string

Returns the naming scheme used to allocate logical IDs.
By default, uses
the HashedAddressingScheme but this method can be overridden to customize
this behavior.
In order to make sure logical IDs are unique and stable, we hash the resource
construct tree path (i.e. toplevel/secondlevel/.../myresource) and add it as
a suffix to the path components joined without a separator (CloudFormation
IDs only allow alphanumeric characters).
The result will be:
<path.join('')><md5(path.join('/')>
"human"      "hash"
If the "human" part of the ID exceeds 240 characters, we simply trim it so
the total ID doesn't exceed CloudFormation's 255 character limit.
We only take 8 characters from the md5 hash (0.000005 chance of collision).
Special cases:

If the path only contains a single component (i.e. it's a top-level
resource), we won't add the hash to it. The hash is not needed for
disambiguation and also, it allows for a more straightforward migration an
existing CloudFormation template to a CDK stack without logical ID changes
(or renames).
For aesthetic reasons, if the last components of the path are the same
(i.e. L1/L2/Pipeline/Pipeline), they will be de-duplicated to make the
resulting human portion of the ID more pleasing: L1L2Pipeline&lt;HASH&gt;
instead of L1L2PipelinePipeline&lt;HASH&gt;
If a component is named "Default" it will be omitted from the path. This
allows refactoring higher level abstractions around constructs without affecting
the IDs of already deployed resources.
If a component is named "Resource" it will be omitted from the user-visible
path, but included in the hash. This reduces visual noise in the human readable
part of the identifier.


static isStack(x)
public static isStack(x: any): boolean

Parameters

x any

Returns

boolean

Return whether the given object is a Stack.
We do attribute detection since we can't reliably use 'instanceof'.

static of(construct)
public static of(construct: IConstruct): Stack

Parameters

construct IConstruct  — The construct to start the search from.

Returns

Stack

Looks up the first stack scope in which construct is defined.
Fails if there is no stack up the tree.\n\n\n\nclass Resource


LanguageType name


 .NETAmazon.CDK.Resource
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Resource
 Javasoftware.amazon.awscdk.Resource
 Pythonaws_cdk.Resource
 TypeScript (source)aws-cdk-lib » Resource


Implements
IConstruct, IDependable, IResource
Extends
Construct
Implemented by
App, Branch, Domain, AutoScalingConfiguration, ObservabilityConfiguration, Service, VpcConnector, VpcIngressConnection, ApiKey, BasePathMapping, CognitoUserPoolsAuthorizer, Deployment, DomainName, GatewayResponse, LambdaRestApi, Method, Model, ProxyResource, RateLimitedApiKey, RequestAuthorizer, RequestValidator, Resource, RestApi, SpecRestApi, Stage, StepFunctionsRestApi, TokenAuthorizer, UsagePlan, VpcLink, ApiMapping, DomainName, HttpApi, HttpAuthorizer, HttpIntegration, HttpRoute, HttpStage, VpcLink, WebSocketApi, WebSocketAuthorizer, WebSocketIntegration, WebSocketRoute, WebSocketStage, Application, DeploymentStrategy, Environment, Extension, ScalableTarget, GatewayRoute, Mesh, Route, VirtualGateway, VirtualNode, VirtualRouter, VirtualService, AppsyncFunction, ChannelNamespace, EventApi, GraphqlApi, SourceApiAssociation, AutoScalingGroup, LifecycleHook, ScheduledAction, WarmPool, BackupPlan, BackupSelection, BackupVault, EcsJobDefinition, EksJobDefinition, FairshareSchedulingPolicy, FargateComputeEnvironment, JobQueue, ManagedEc2EcsComputeEnvironment, ManagedEc2EksComputeEnvironment, MultiNodeJobDefinition, UnmanagedComputeEnvironment, Certificate, DnsValidatedCertificate, PrivateCertificate, SlackChannelConfiguration, EdgeFunction, CachePolicy, CloudFrontWebDistribution, Distribution, Function, FunctionUrlOriginAccessControl, KeyGroup, KeyValueStore, OriginAccessIdentity, OriginRequestPolicy, PublicKey, RealtimeLogConfig, ResponseHeadersPolicy, S3OriginAccessControl, VpcOrigin, Trail, Alarm, CompositeAlarm, Dashboard, BitBucketSourceCredentials, Fleet, GitHubEnterpriseSourceCredentials, GitHubSourceCredentials, PipelineProject, Project, ReportGroup, UntrustedCodeBoundaryPolicy, Repository, CustomLambdaDeploymentConfig, EcsApplication, EcsDeploymentConfig, EcsDeploymentGroup, LambdaApplication, LambdaDeploymentConfig, LambdaDeploymentGroup, ServerApplication, ServerDeploymentConfig, ServerDeploymentGroup, ProfilingGroup, Pipeline, NotificationRule, UserPool, UserPoolClient, UserPoolDomain, UserPoolGroup, UserPoolIdentityProviderAmazon, UserPoolIdentityProviderApple, UserPoolIdentityProviderFacebook, UserPoolIdentityProviderGoogle, UserPoolIdentityProviderOidc, UserPoolIdentityProviderSaml, UserPoolResourceServer, IdentityPool, AccessKeysRotated, CloudFormationStackDriftDetectionCheck, CloudFormationStackNotificationCheck, CustomPolicy, CustomRule, ManagedRule, ClusterParameterGroup, DatabaseCluster, DatabaseInstance, DatabaseSecret, Table, TableV2, BastionHostLinux, ClientVpnAuthorizationRule, ClientVpnEndpoint, ClientVpnRoute, FlowLog, GatewayVpcEndpoint, Instance, InterfaceVpcEndpoint, KeyPair, LaunchTemplate, NetworkAcl, NetworkAclEntry, PlacementGroup, PrefixList, PrivateSubnet, PublicSubnet, SecurityGroup, Subnet, SubnetNetworkAclAssociation, Volume, Vpc, VpcEndpointService, VpnConnection, VpnGateway, Repository, Cluster, Ec2Service, Ec2TaskDefinition, ExternalService, ExternalTaskDefinition, FargateService, FargateTaskDefinition, TaskDefinition, AccessPoint, FileSystem, AccessEntry, Addon, Cluster, FargateCluster, Nodegroup, OpenIdConnectProvider, LoadBalancer, ApplicationListener, ApplicationLoadBalancer, NetworkListener, NetworkLoadBalancer, TrustStore, TrustStoreRevocation, Domain, ApiDestination, Archive, Connection, EventBus, EventBusPolicy, Rule, LustreFileSystem, Accelerator, EndpointGroup, Listener, AccessKey, Group, InstanceProfile, LazyRole, ManagedPolicy, OpenIdConnectProvider, Policy, Role, SamlProvider, User, AssessmentTemplate, ResourcePolicy, Stream, StreamConsumer, DeliveryStream, Alias, Key, Alias, CodeSigningConfig, DockerImageFunction, EventInvokeConfig, EventSourceMapping, Function, FunctionUrl, LayerVersion, SingletonFunction, Version, NodejsFunction, CrossAccountDestination, LogGroup, LogStream, MetricFilter, QueryDefinition, ResourcePolicy, SubscriptionFilter, Domain, DatabaseCluster, DatabaseClusterFromSnapshot, DatabaseInstance, DatabaseInstanceFromSnapshot, DatabaseInstanceReadReplica, DatabaseProxy, DatabaseSecret, OptionGroup, ParameterGroup, ServerlessCluster, ServerlessClusterFromSnapshot, SubnetGroup, ARecord, AaaaRecord, CaaAmazonRecord, CaaRecord, CnameRecord, DsRecord, HealthCheck, HostedZone, KeySigningKey, MxRecord, NsRecord, PrivateHostedZone, PublicHostedZone, RecordSet, SrvRecord, TxtRecord, ZoneDelegationRecord, Bucket, BucketPolicy, Schedule, ScheduleGroup, ResourcePolicy, RotationSchedule, Secret, SecretTargetAttachment, CloudFormationProduct, Portfolio, TagOptions, AliasTargetInstance, CnameInstance, HttpNamespace, IpInstance, NonIpInstance, PrivateDnsNamespace, PublicDnsNamespace, Service, ConfigurationSet, ConfigurationSetEventDestination, DedicatedIpPool, EmailIdentity, ReceiptFilter, ReceiptRule, ReceiptRuleSet, VdmAttributes, SigningProfile, Subscription, Topic, TopicPolicy, Queue, QueuePolicy, StringListParameter, StringParameter, Activity, StateMachine, Canary, AwsCliLayer, NodeProxyAgentLayer, TriggerFunction, CustomResource, Ec2Environment, GitHubRepository, EgressOnlyInternetGateway, InternetGateway, Ipam, NatGateway, Route, RouteTable, SubnetV2, TransitGateway, TransitGatewayBlackholeRoute, TransitGatewayRoute, TransitGatewayRouteTable, TransitGatewayRouteTableAssociation, TransitGatewayRouteTablePropagation, TransitGatewayVpcAttachment, VPCPeeringConnection, VPNGatewayV2, VpcV2, AccessEntry, Addon, Cluster, FargateCluster, Nodegroup, OpenIdConnectProvider, Alias, Build, BuildFleet, GameServerGroup, GameSessionQueue, MatchmakingRuleSet, QueuedMatchmakingConfiguration, Script, StandaloneMatchmakingConfiguration, Connection, DataQualityRuleset, Database, ExternalTable, PySparkEtlJob, PySparkFlexEtlJob, PySparkStreamingJob, PythonShellJob, RayJob, S3Table, ScalaSparkEtlJob, ScalaSparkFlexEtlJob, ScalaSparkStreamingJob, SecurityConfiguration, Table, Workflow, AccountAuditConfiguration, Logging, ScheduledAudit, TopicRule, DetectorModel, Input, Channel, PlaybackKeyPair, RecordingConfiguration, StreamKey, Application, GoFunction, PythonFunction, PythonLayerVersion, GeofenceCollection, Map, PlaceIndex, RouteCalculator, Tracker, Cluster, ServerlessCluster, ClusterParameterGroup, DatabaseCluster, DatabaseInstance, ParameterGroup, SubnetGroup, Pipe, Cluster, ClusterParameterGroup, ClusterSubnetGroup, DatabaseSecret, FirewallDomainList, FirewallRuleGroup, FirewallRuleGroupAssociation, AccessPoint, TableBucket, TableBucketPolicy, Endpoint, EndpointConfig, Model, Application, AttributeGroup
A construct which represents an AWS resource.
Example
class MyConstruct extends Resource implements ITaggable {
  public readonly tags = new TagManager(TagType.KEY_VALUE, 'Whatever::The::Type');

  constructor(scope: Construct, id: string) {
    super(scope, id);

    new CfnResource(this, 'Resource', {
      type: 'Whatever::The::Type',
      properties: {
        // ...
        Tags: this.tags.renderedTags,
      },
    });
  }
}

Initializer
new Resource(scope: Construct, id: string, props?: ResourceProps)

Parameters

scope Construct
id string
props ResourceProps

Properties


NameTypeDescription


envResourceEnvironmentThe environment this resource belongs to.
nodeNodeThe tree node.
physicalNamestringReturns a string-encoded token that resolves to the physical name that should be passed to the CloudFormation resource.
stackStackThe stack in which this resource is defined.



env
Type:
ResourceEnvironment
The environment this resource belongs to.
For resources that are created and managed by the CDK
(generally, those created by creating new class instances like Role, Bucket, etc.),
this is always the same as the environment of the stack they belong to;
however, for imported resources
(those obtained from static methods like fromRoleArn, fromBucketName, etc.),
that might be different than the stack they were imported into.

node
Type:
Node
The tree node.

physicalName
Type:
string
Returns a string-encoded token that resolves to the physical name that should be passed to the CloudFormation resource.
This value will resolve to one of the following:

a concrete value (e.g. "my-awesome-bucket")
undefined, when a name should be generated by CloudFormation
a concrete name generated automatically during synthesis, in
cross-environment scenarios.


stack
Type:
Stack
The stack in which this resource is defined.
Methods


NameDescription


applyRemovalPolicy(policy)Apply the given removal policy to this resource.
toString()Returns a string representation of this construct.
protected generatePhysicalName()
protected getResourceArnAttribute(arnAttr, arnComponents)Returns an environment-sensitive token that should be used for the resource's "ARN" attribute (e.g. bucket.bucketArn).
protected getResourceNameAttribute(nameAttr)Returns an environment-sensitive token that should be used for the resource's "name" attribute (e.g. bucket.bucketName).
static isOwnedResource(construct)Returns true if the construct was created by CDK, and false otherwise.
static isResource(construct)Check whether the given construct is a Resource.



applyRemovalPolicy(policy)
public applyRemovalPolicy(policy: RemovalPolicy): void

Parameters

policy RemovalPolicy

Apply the given removal policy to this resource.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN).

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

protected generatePhysicalName()
protected generatePhysicalName(): string

Returns

string


protected getResourceArnAttribute(arnAttr, arnComponents)
protected getResourceArnAttribute(arnAttr: string, arnComponents: ArnComponents): string

Parameters

arnAttr string  — The CFN attribute which resolves to the ARN of the resource.
arnComponents ArnComponents  — The format of the ARN of this resource.

Returns

string

Returns an environment-sensitive token that should be used for the resource's "ARN" attribute (e.g. bucket.bucketArn).
Normally, this token will resolve to arnAttr, but if the resource is
referenced across environments, arnComponents will be used to synthesize
a concrete ARN with the resource's physical name. Make sure to reference
this.physicalName in arnComponents.

protected getResourceNameAttribute(nameAttr)
protected getResourceNameAttribute(nameAttr: string): string

Parameters

nameAttr string  — The CFN attribute which resolves to the resource's name.

Returns

string

Returns an environment-sensitive token that should be used for the resource's "name" attribute (e.g. bucket.bucketName).
Normally, this token will resolve to nameAttr, but if the resource is
referenced across environments, it will be resolved to this.physicalName,
which will be a concrete name.

static isOwnedResource(construct)
public static isOwnedResource(construct: IConstruct): boolean

Parameters

construct IConstruct

Returns

boolean

Returns true if the construct was created by CDK, and false otherwise.

static isResource(construct)
public static isResource(construct: IConstruct): boolean

Parameters

construct IConstruct

Returns

boolean

Check whether the given construct is a Resource.\n\nclass Resource


LanguageType name


 .NETAmazon.CDK.Resource
 Gogithub.com/aws/aws-cdk-go/awscdk/v2#Resource
 Javasoftware.amazon.awscdk.Resource
 Pythonaws_cdk.Resource
 TypeScript (source)aws-cdk-lib » Resource


Implements
IConstruct, IDependable, IResource
Extends
Construct
Implemented by
App, Branch, Domain, AutoScalingConfiguration, ObservabilityConfiguration, Service, VpcConnector, VpcIngressConnection, ApiKey, BasePathMapping, CognitoUserPoolsAuthorizer, Deployment, DomainName, GatewayResponse, LambdaRestApi, Method, Model, ProxyResource, RateLimitedApiKey, RequestAuthorizer, RequestValidator, Resource, RestApi, SpecRestApi, Stage, StepFunctionsRestApi, TokenAuthorizer, UsagePlan, VpcLink, ApiMapping, DomainName, HttpApi, HttpAuthorizer, HttpIntegration, HttpRoute, HttpStage, VpcLink, WebSocketApi, WebSocketAuthorizer, WebSocketIntegration, WebSocketRoute, WebSocketStage, Application, DeploymentStrategy, Environment, Extension, ScalableTarget, GatewayRoute, Mesh, Route, VirtualGateway, VirtualNode, VirtualRouter, VirtualService, AppsyncFunction, ChannelNamespace, EventApi, GraphqlApi, SourceApiAssociation, AutoScalingGroup, LifecycleHook, ScheduledAction, WarmPool, BackupPlan, BackupSelection, BackupVault, EcsJobDefinition, EksJobDefinition, FairshareSchedulingPolicy, FargateComputeEnvironment, JobQueue, ManagedEc2EcsComputeEnvironment, ManagedEc2EksComputeEnvironment, MultiNodeJobDefinition, UnmanagedComputeEnvironment, Certificate, DnsValidatedCertificate, PrivateCertificate, SlackChannelConfiguration, EdgeFunction, CachePolicy, CloudFrontWebDistribution, Distribution, Function, FunctionUrlOriginAccessControl, KeyGroup, KeyValueStore, OriginAccessIdentity, OriginRequestPolicy, PublicKey, RealtimeLogConfig, ResponseHeadersPolicy, S3OriginAccessControl, VpcOrigin, Trail, Alarm, CompositeAlarm, Dashboard, BitBucketSourceCredentials, Fleet, GitHubEnterpriseSourceCredentials, GitHubSourceCredentials, PipelineProject, Project, ReportGroup, UntrustedCodeBoundaryPolicy, Repository, CustomLambdaDeploymentConfig, EcsApplication, EcsDeploymentConfig, EcsDeploymentGroup, LambdaApplication, LambdaDeploymentConfig, LambdaDeploymentGroup, ServerApplication, ServerDeploymentConfig, ServerDeploymentGroup, ProfilingGroup, Pipeline, NotificationRule, UserPool, UserPoolClient, UserPoolDomain, UserPoolGroup, UserPoolIdentityProviderAmazon, UserPoolIdentityProviderApple, UserPoolIdentityProviderFacebook, UserPoolIdentityProviderGoogle, UserPoolIdentityProviderOidc, UserPoolIdentityProviderSaml, UserPoolResourceServer, IdentityPool, AccessKeysRotated, CloudFormationStackDriftDetectionCheck, CloudFormationStackNotificationCheck, CustomPolicy, CustomRule, ManagedRule, ClusterParameterGroup, DatabaseCluster, DatabaseInstance, DatabaseSecret, Table, TableV2, BastionHostLinux, ClientVpnAuthorizationRule, ClientVpnEndpoint, ClientVpnRoute, FlowLog, GatewayVpcEndpoint, Instance, InterfaceVpcEndpoint, KeyPair, LaunchTemplate, NetworkAcl, NetworkAclEntry, PlacementGroup, PrefixList, PrivateSubnet, PublicSubnet, SecurityGroup, Subnet, SubnetNetworkAclAssociation, Volume, Vpc, VpcEndpointService, VpnConnection, VpnGateway, Repository, Cluster, Ec2Service, Ec2TaskDefinition, ExternalService, ExternalTaskDefinition, FargateService, FargateTaskDefinition, TaskDefinition, AccessPoint, FileSystem, AccessEntry, Addon, Cluster, FargateCluster, Nodegroup, OpenIdConnectProvider, LoadBalancer, ApplicationListener, ApplicationLoadBalancer, NetworkListener, NetworkLoadBalancer, TrustStore, TrustStoreRevocation, Domain, ApiDestination, Archive, Connection, EventBus, EventBusPolicy, Rule, LustreFileSystem, Accelerator, EndpointGroup, Listener, AccessKey, Group, InstanceProfile, LazyRole, ManagedPolicy, OpenIdConnectProvider, Policy, Role, SamlProvider, User, AssessmentTemplate, ResourcePolicy, Stream, StreamConsumer, DeliveryStream, Alias, Key, Alias, CodeSigningConfig, DockerImageFunction, EventInvokeConfig, EventSourceMapping, Function, FunctionUrl, LayerVersion, SingletonFunction, Version, NodejsFunction, CrossAccountDestination, LogGroup, LogStream, MetricFilter, QueryDefinition, ResourcePolicy, SubscriptionFilter, Domain, DatabaseCluster, DatabaseClusterFromSnapshot, DatabaseInstance, DatabaseInstanceFromSnapshot, DatabaseInstanceReadReplica, DatabaseProxy, DatabaseSecret, OptionGroup, ParameterGroup, ServerlessCluster, ServerlessClusterFromSnapshot, SubnetGroup, ARecord, AaaaRecord, CaaAmazonRecord, CaaRecord, CnameRecord, DsRecord, HealthCheck, HostedZone, KeySigningKey, MxRecord, NsRecord, PrivateHostedZone, PublicHostedZone, RecordSet, SrvRecord, TxtRecord, ZoneDelegationRecord, Bucket, BucketPolicy, Schedule, ScheduleGroup, ResourcePolicy, RotationSchedule, Secret, SecretTargetAttachment, CloudFormationProduct, Portfolio, TagOptions, AliasTargetInstance, CnameInstance, HttpNamespace, IpInstance, NonIpInstance, PrivateDnsNamespace, PublicDnsNamespace, Service, ConfigurationSet, ConfigurationSetEventDestination, DedicatedIpPool, EmailIdentity, ReceiptFilter, ReceiptRule, ReceiptRuleSet, VdmAttributes, SigningProfile, Subscription, Topic, TopicPolicy, Queue, QueuePolicy, StringListParameter, StringParameter, Activity, StateMachine, Canary, AwsCliLayer, NodeProxyAgentLayer, TriggerFunction, CustomResource, Ec2Environment, GitHubRepository, EgressOnlyInternetGateway, InternetGateway, Ipam, NatGateway, Route, RouteTable, SubnetV2, TransitGateway, TransitGatewayBlackholeRoute, TransitGatewayRoute, TransitGatewayRouteTable, TransitGatewayRouteTableAssociation, TransitGatewayRouteTablePropagation, TransitGatewayVpcAttachment, VPCPeeringConnection, VPNGatewayV2, VpcV2, AccessEntry, Addon, Cluster, FargateCluster, Nodegroup, OpenIdConnectProvider, Alias, Build, BuildFleet, GameServerGroup, GameSessionQueue, MatchmakingRuleSet, QueuedMatchmakingConfiguration, Script, StandaloneMatchmakingConfiguration, Connection, DataQualityRuleset, Database, ExternalTable, PySparkEtlJob, PySparkFlexEtlJob, PySparkStreamingJob, PythonShellJob, RayJob, S3Table, ScalaSparkEtlJob, ScalaSparkFlexEtlJob, ScalaSparkStreamingJob, SecurityConfiguration, Table, Workflow, AccountAuditConfiguration, Logging, ScheduledAudit, TopicRule, DetectorModel, Input, Channel, PlaybackKeyPair, RecordingConfiguration, StreamKey, Application, GoFunction, PythonFunction, PythonLayerVersion, GeofenceCollection, Map, PlaceIndex, RouteCalculator, Tracker, Cluster, ServerlessCluster, ClusterParameterGroup, DatabaseCluster, DatabaseInstance, ParameterGroup, SubnetGroup, Pipe, Cluster, ClusterParameterGroup, ClusterSubnetGroup, DatabaseSecret, FirewallDomainList, FirewallRuleGroup, FirewallRuleGroupAssociation, AccessPoint, TableBucket, TableBucketPolicy, Endpoint, EndpointConfig, Model, Application, AttributeGroup
A construct which represents an AWS resource.
Example
class MyConstruct extends Resource implements ITaggable {
  public readonly tags = new TagManager(TagType.KEY_VALUE, 'Whatever::The::Type');

  constructor(scope: Construct, id: string) {
    super(scope, id);

    new CfnResource(this, 'Resource', {
      type: 'Whatever::The::Type',
      properties: {
        // ...
        Tags: this.tags.renderedTags,
      },
    });
  }
}

Initializer
new Resource(scope: Construct, id: string, props?: ResourceProps)

Parameters

scope Construct
id string
props ResourceProps

Properties


NameTypeDescription


envResourceEnvironmentThe environment this resource belongs to.
nodeNodeThe tree node.
physicalNamestringReturns a string-encoded token that resolves to the physical name that should be passed to the CloudFormation resource.
stackStackThe stack in which this resource is defined.



env
Type:
ResourceEnvironment
The environment this resource belongs to.
For resources that are created and managed by the CDK
(generally, those created by creating new class instances like Role, Bucket, etc.),
this is always the same as the environment of the stack they belong to;
however, for imported resources
(those obtained from static methods like fromRoleArn, fromBucketName, etc.),
that might be different than the stack they were imported into.

node
Type:
Node
The tree node.

physicalName
Type:
string
Returns a string-encoded token that resolves to the physical name that should be passed to the CloudFormation resource.
This value will resolve to one of the following:

a concrete value (e.g. "my-awesome-bucket")
undefined, when a name should be generated by CloudFormation
a concrete name generated automatically during synthesis, in
cross-environment scenarios.


stack
Type:
Stack
The stack in which this resource is defined.
Methods


NameDescription


applyRemovalPolicy(policy)Apply the given removal policy to this resource.
toString()Returns a string representation of this construct.
protected generatePhysicalName()
protected getResourceArnAttribute(arnAttr, arnComponents)Returns an environment-sensitive token that should be used for the resource's "ARN" attribute (e.g. bucket.bucketArn).
protected getResourceNameAttribute(nameAttr)Returns an environment-sensitive token that should be used for the resource's "name" attribute (e.g. bucket.bucketName).
static isOwnedResource(construct)Returns true if the construct was created by CDK, and false otherwise.
static isResource(construct)Check whether the given construct is a Resource.



applyRemovalPolicy(policy)
public applyRemovalPolicy(policy: RemovalPolicy): void

Parameters

policy RemovalPolicy

Apply the given removal policy to this resource.
The Removal Policy controls what happens to this resource when it stops
being managed by CloudFormation, either because you've removed it from the
CDK application or because you've made a change that requires the resource
to be replaced.
The resource can be deleted (RemovalPolicy.DESTROY), or left in your AWS
account for data recovery and cleanup later (RemovalPolicy.RETAIN).

toString()
public toString(): string

Returns

string

Returns a string representation of this construct.

protected generatePhysicalName()
protected generatePhysicalName(): string

Returns

string


protected getResourceArnAttribute(arnAttr, arnComponents)
protected getResourceArnAttribute(arnAttr: string, arnComponents: ArnComponents): string

Parameters

arnAttr string  — The CFN attribute which resolves to the ARN of the resource.
arnComponents ArnComponents  — The format of the ARN of this resource.

Returns

string

Returns an environment-sensitive token that should be used for the resource's "ARN" attribute (e.g. bucket.bucketArn).
Normally, this token will resolve to arnAttr, but if the resource is
referenced across environments, arnComponents will be used to synthesize
a concrete ARN with the resource's physical name. Make sure to reference
this.physicalName in arnComponents.

protected getResourceNameAttribute(nameAttr)
protected getResourceNameAttribute(nameAttr: string): string

Parameters

nameAttr string  — The CFN attribute which resolves to the resource's name.

Returns

string

Returns an environment-sensitive token that should be used for the resource's "name" attribute (e.g. bucket.bucketName).
Normally, this token will resolve to nameAttr, but if the resource is
referenced across environments, it will be resolved to this.physicalName,
which will be a concrete name.

static isOwnedResource(construct)
public static isOwnedResource(construct: IConstruct): boolean

Parameters

construct IConstruct

Returns

boolean

Returns true if the construct was created by CDK, and false otherwise.

static isResource(construct)
public static isResource(construct: IConstruct): boolean

Parameters

construct IConstruct

Returns

boolean

Check whether the given construct is a Resource.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideCDK CLI commandsSpecify options and their valuesBuilt-in helpVersion reportingAuthentication with AWSSpecify Region and other configurationSpecify the app commandSpecify stacksBootstrap your AWS environmentCreate a new appList stacksSynthesize stacksDeploy stacksCompare stacksImport existing resources into a stackConfiguration (cdk.json)This is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK CLI referenceThe AWS Cloud Development Kit (AWS CDK) Command Line Interface (AWS CDK CLI), also known as the CDK Toolkit, is the primary
		tool for interacting with your AWS CDK app. It executes your app, interrogates the application model you defined, and
		produces and deploys the AWS CloudFormation templates generated by the AWS CDK. It also provides other features useful for creating and
		working with AWS CDK projects. This topic contains information about common use cases of the CDK CLI.The CDK CLI is installed with the Node Package Manager. In most cases, we recommend installing it
		globally.npm install -g aws-cdk             # install latest version
npm install -g aws-cdk@X.YY.Z      # install specific versionTipIf you regularly work with multiple versions of the AWS CDK, consider installing a matching version of the
			CDK CLI in individual CDK projects. To do this, omit -g from the npm install
			command. Then use npx aws-cdk to invoke it. This runs the local version if one exists, falling back to a
			global version if not.
		CDK CLI commands

		All CDK CLI commands start with cdk, which is followed by a subcommand (list,
				synthesize, deploy, etc.). Some subcommands have a shorter version (ls,
				synth, etc.) that is equivalent. Options and arguments follow the subcommand in any order.

		For a description of all subcommands, options, and arguments, see AWS CDK CLI command reference.

	 
		Specify options and their values

		Command line options begin with two hyphens (--). Some frequently used options have single-letter
			synonyms that begin with a single hyphen (for example, --app has a synonym -a). The order of
			options in an CDK CLI command is not important.

		All options accept a value, which must follow the option name. The value may be separated from the name by white
			space or by an equals sign =. The following two options are equivalent.

		--toolkit-stack-name MyBootstrapStack
--toolkit-stack-name=MyBootstrapStack

		Some options are flags (Booleans). You may specify true or false as their value. If you
			do not provide a value, the value is taken to be true. You may also prefix the option name with
				no- to imply false.

		# sets staging flag to true
--staging
--staging=true
--staging true

# sets staging flag to false
--no-staging
--staging=false
--staging false

		A few options, namely --context, --parameters, --plugin,
			--tags, and --trust, may be specified more than once to specify multiple values. These are
			noted as having [array] type in the CDK CLI help. For example:

		cdk bootstrap --tags costCenter=0123 --tags responsibleParty=jdoe

	 
		Built-in help
		The CDK CLI has integrated help. You can see general help about the utility and a list of the provided
			subcommands by issuing:
		cdk --help
		To see help for a particular subcommand, for example deploy, specify it before the --help
			flag.
		cdk deploy --help
		Issue cdk version to display the version of the CDK CLI. Provide this information when
			requesting support.
	 
		Version reporting
		To gain insight into how the AWS CDK is used, the constructs used by AWS CDK applications are collected and reported by
			using a resource identified as AWS::CDK::Metadata. To learn more, see Configure AWS CDK usage data reporting.
	 
		Authentication with AWS

		 There are different ways in which you can configure programmatic access to AWS resources, depending on the
			environment and the AWS access available to you.

		To choose your method of authentication and configure it for the CDK CLI, see Configure security credentials for the AWS CDK CLI.

		The recommended approach for new users developing locally, who are not given a method of authentication by their
			employer, is to set up AWS IAM Identity Center. This method includes installing the AWS CLI for ease of configuration and for regularly
			signing in to the AWS access portal. If you choose this method, your environment should contain the following
			elements after you complete the procedure for IAM Identity Center
				authentication in the AWS SDKs and Tools Reference Guide:

		
			 
			 
			 
			 

		
				The AWS CLI, which you use to start an AWS access portal session before you run your application.
			
				A shared AWSconfig file having a [default]
					profile with a set of configuration values that can be referenced from the AWS CDK. To find the location of this
					file, see Location of the shared files in the
						AWS SDKs and Tools Reference Guide.
			
				 The shared config file sets the region
					setting. This sets the default AWS Region the AWS CDK and CDK CLI use for AWS requests. 
			
				 The CDK CLI uses the profile's SSO token provider configuration to acquire credentials before sending requests to AWS. The
						sso_role_name value, which is an IAM role connected to an IAM Identity Center permission set, should allow
					access to the AWS services used in your application.
				The following sample config file shows a default profile set up with SSO token provider configuration.
					The profile's sso_session setting refers to the named sso-session section. The
						sso-session section contains settings to initiate an AWS access portal session.
				[default]
sso_session = my-sso
sso_account_id = 111122223333
sso_role_name = SampleRole
region = us-east-1
output = json

[sso-session my-sso]
sso_region = us-east-1
sso_start_url = https://provided-domain.awsapps.com/start
sso_registration_scopes = sso:account:access
			

		 
			Start an AWS access portal session
			Before accessing AWS services, you need an active AWS access portal session for the CDK CLI to use
				IAM Identity Center authentication to resolve credentials. Depending on your configured session lengths, your access will
				eventually expire and the CDK CLI will encounter an authentication error. Run the following command in the
				AWS CLI to sign in to the AWS access portal.
			aws sso login
			 If your SSO token provider configuration is using a named profile instead of the default profile, the command is
					aws sso login --profile NAME. Also specify this profile when issuing
					cdk commands using the --profile option or the AWS_PROFILE
				environment variable.
			To test if you already have an active session, run the following AWS CLI command.
			aws sts get-caller-identity
			The response to this command should report the IAM Identity Center account and permission set configured in the shared
					config file.
			NoteIf you already have an active AWS access portal session and run aws sso login, you will not be
					required to provide credentials. The sign in process may prompt you to allow the AWS CLI access to your data. Since the AWS CLI is built on top of
					the SDK for Python, permission messages may contain variations of the botocore name.
		 
	 
		Specify Region and other configuration
		The CDK CLI needs to know the AWS Region that you're deploying into and how to authenticate with AWS.
			This is needed for deployment operations and to retrieve context values during synthesis. Together, your account and
			Region make up the environment.

		Region may be specified using environment variables or in configuration files. These are the same variables and
			files used by other AWS tools such as the AWS CLI and the various AWS SDKs. The CDK CLI looks for this
			information in the following order.

		
			 
			 
			 
		
				The AWS_DEFAULT_REGION environment variable.
			
				A named profile defined in the standard AWS config file and specified using the
						--profile option on cdk commands.
			
				The [default] section of the standard AWS config file.
			

		Besides specifying AWS authentication and a Region in the [default] section, you can also add one or
			more [profile NAME] sections, where NAME is the name
			of the profile. For more information about named profiles, see Shared
				config and credentials files in the AWS SDKs and Tools Reference Guide.
		The standard AWS config file is located at ~/.aws/config (macOS/Linux)
			or %USERPROFILE%\.aws\config (Windows). For details and alternate locations, see Location of the shared config and credentials files in the
				AWS SDKs and Tools Reference Guide

		The environment that you specify in your AWS CDK app by using the stack's env property is used during
			synthesis. It's used to generate an environment-specific AWS CloudFormation template, and during deployment, it overrides the
			account or Region specified by one of the preceding methods. For more information, see Environments for the AWS CDK.

		NoteThe AWS CDK uses credentials from the same source files as other AWS tools and SDKs, including the AWS Command Line Interface. However, the AWS CDK might
				behave somewhat differently from these tools. It uses the AWS SDK for JavaScript under the hood. For complete details on setting
				up credentials for the AWS SDK for JavaScript, see Setting credentials.

		You may optionally use the --role-arn (or -r) option to specify the ARN of an IAM role
			that should be used for deployment. This role must be assumable by the AWS account being used.

	 
		Specify the app command

		Many features of the CDK CLI require one or more AWS CloudFormation templates be synthesized, which in turn requires
			running your application. The AWS CDK supports programs written in a variety of languages. Therefore, it uses a
			configuration option to specify the exact command necessary to run your app. This option can be specified in two
			ways.
		First, and most commonly, it can be specified using the app key inside the file
				cdk.json. This is in the main directory of your AWS CDK project. The CDK CLI provides an
			appropriate command when creating a new project with cdk init. Here is the cdk.json
			from a fresh TypeScript project, for instance.

		{
  "app": "npx ts-node bin/hello-cdk.ts"
}

		The CDK CLI looks for cdk.json in the current working directory when attempting to run
			your app. Because of this, you might keep a shell open in your project's main directory for issuing CDK CLI
			commands.

		The CDK CLI also looks for the app key in ~/.cdk.json (that is, in your home
			directory) if it can't find it in ./cdk.json. Adding the app command here can be useful if you usually
			work with CDK code in the same language.

		If you are in some other directory, or to run your app using a command other than the one in
				cdk.json, use the --app (or -a) option to specify it.

		cdk --app "npx ts-node bin/hello-cdk.ts" ls

		When deploying, you may also specify a directory containing synthesized cloud assemblies, such as
				cdk.out, as the value of --app. The specified stacks are deployed from this
			directory; the app is not synthesized.

	 
		Specify stacks

		Many CDK CLI commands (for example, cdk deploy) work on stacks defined in your app. If your
			app contains only one stack, the CDK CLI assumes you mean that one if you don't specify a stack
			explicitly.

		Otherwise, you must specify the stack or stacks you want to work with. You can do this by specifying the desired
			stacks by ID individually on the command line. Recall that the ID is the value specified by the second argument when
			you instantiate the stack.

		cdk synth PipelineStack LambdaStack

		You may also use wildcards to specify IDs that match a pattern.

		
			 
			 
			 
		
				? matches any single character
			
				* matches any number of characters (* alone matches all stacks)
			
				** matches everything in a hierarchy
			

		You may also use the --all option to specify all stacks.

		If your app uses CDK Pipelines, the CDK CLI understands your
			stacks and stages as a hierarchy. Also, the --all option and the * wildcard only match
			top-level stacks. To match all the stacks, use **. Also use ** to indicate all the stacks
			under a particular hierarchy.

		When using wildcards, enclose the pattern in quotes, or escape the wildcards with \. If you don't,
			your shell may try to expand the pattern to the names of files in the current directory. At best, this won't do what
			you expect; at worst, you could deploy stacks you didn't intend to. This isn't strictly necessary on Windows because
				cmd.exe does not expand wildcards, but is good practice nonetheless.

		cdk synth "*Stack"    # PipelineStack, LambdaStack, etc.
cdk synth 'Stack?'    # StackA, StackB, Stack1, etc.
cdk synth \*          # All stacks in the app, or all top-level stacks in a CDK Pipelines app
cdk synth '**'        # All stacks in a CDK Pipelines app
cdk synth 'PipelineStack/Prod/**'   # All stacks in Prod stage in a CDK Pipelines app

		NoteThe order in which you specify the stacks is not necessarily the order in which they will be processed. The
				CDK CLI accounts for dependencies between stacks when deciding the order in which to process them. For
				example, let's say that one stack uses a value produced by another (such as the ARN of a resource defined in the
				second stack). In this case, the second stack is synthesized before the first one because of this dependency. You can
				add dependencies between stacks manually using the stack's addDependency()
				method.

	 
		Bootstrap your AWS environment

		Deploying stacks with the CDK requires special dedicated AWS CDK resources to be provisioned. The cdk
				bootstrap command creates the necessary resources for you. You only need to bootstrap if you are deploying a
			stack that requires these dedicated resources. See AWS CDK bootstrapping for details.

		cdk bootstrap

		If issued with no arguments, as shown here, the cdk bootstrap command synthesizes the current app and
			bootstraps the environments its stacks will be deployed to. If the app contains environment-agnostic stacks, which
			don't explicitly specify an environment, the default account and Region are bootstrapped, or the environment specified
			using --profile.

		Outside of an app, you must explicitly specify the environment to be bootstrapped. You may also do so to bootstrap
			an environment that's not specified in your app or local AWS profile. Credentials must be configured (e.g. in
				~/.aws/credentials) for the specified account and Region. You may specify a profile that
			contains the required credentials.

		cdk bootstrap ACCOUNT-NUMBER/REGION # e.g.
cdk bootstrap 1111111111/us-east-1
cdk bootstrap --profile test 1111111111/us-east-1

		ImportantEach environment (account/region combination) to which you deploy such a stack must be bootstrapped
				separately.

		You may incur AWS charges for what the AWS CDK stores in the bootstrapped resources. Additionally, if you use
				-bootstrap-customer-key, an AWS KMS key will be created, which also incurs charges per
			environment.

		NoteEarlier versions of the bootstrap template created a KMS key by default. To avoid charges, re-bootstrap using
					--no-bootstrap-customer-key. 

		NoteCDK CLI v2 does not support the original bootstrap template, dubbed the legacy template, used by default
				with CDK v1.
		
    ImportantThe modern bootstrap template effectively grants the permissions implied by
        the --cloudformation-execution-policies to any AWS account in the
        --trust list. By default, this extends permissions to read and
        write to any resource in the bootstrapped account. Make sure to configure the bootstrapping stack with
        policies and trusted accounts that you are comfortable with.

	 
		Create a new app

		To create a new app, create a directory for it, then, inside the directory, issue cdk init.

		mkdir my-cdk-app
cd my-cdk-app
cdk init TEMPLATE --language LANGUAGE

		The supported languages (LANGUAGE) are:

		
					
						Code
						Language
					
				
					
						typescript
						TypeScript
					
					
						javascript
						JavaScript
					
					
						python
						Python
					
					
						java
						Java
					
					
						csharp
						C#
					
				

		TEMPLATE is an optional template. If the desired template is app,
			the default, you may omit it. The available templates are:

		
					
						Template
						Description
					
				
					
						app (default)
						
							Creates an empty AWS CDK app.
						
					
					
						sample-app
						
							Creates an AWS CDK app with a stack containing an Amazon SQS queue and an Amazon SNS topic.
						
					
				

		The templates use the name of the project folder to generate names for files and classes inside your new
			app.

	 
		List stacks

		To see a list of the IDs of the stacks in your AWS CDK application, enter one of the following equivalent
			commands:

		cdk list
cdk ls

		If your application contains CDK Pipelines stacks, the CDK CLI
			displays stack names as paths according to their location in the pipeline hierarchy. (For example,
				PipelineStack, PipelineStack/Prod, and
				PipelineStack/Prod/MyService.)

		If your app contains many stacks, you can specify full or partial stack IDs of the stacks to be listed. For more
			information, see Specify stacks.

		Add the --long flag to see more information about the stacks, including the stack names and their
			environments (AWS account and Region).

	 
		Synthesize stacks

		The cdk synthesize command (almost always abbreviated synth) synthesizes a stack defined
			in your app into a CloudFormation template.

		cdk synth         # if app contains only one stack
cdk synth MyStack
cdk synth Stack1 Stack2
cdk synth "*"     # all stacks in app

		NoteThe CDK CLI actually runs your app and synthesizes fresh templates before most operations (such as when
				deploying or comparing stacks). These templates are stored by default in the cdk.out directory.
				The cdk synth command simply prints the generated templates for one or more specified stacks.

		See cdk synth --help for all available options. A few of the most frequently used options are covered
			in the following section.

		 
			Specify context values
			Use the --context or -c option to pass runtime context
				values to your CDK app.

			# specify a single context value
cdk synth --context key=value MyStack

# specify multiple context values (any number)
cdk synth --context key1=value1 --context key2=value2 MyStack

			When deploying multiple stacks, the specified context values are normally passed to all of them. If you want, you
				can specify different values for each stack by prefixing the stack name to the context value.

			# different context values for each stack
cdk synth --context Stack1:key=value Stack2:key=value Stack1 Stack2

		 

		 
			Specify display format
			By default, the synthesized template is displayed in YAML format. Add the --json flag to display it
				in JSON format instead.

			cdk synth --json MyStack

		 
		 
			Specify the output directory
			Add the --output (-o) option to write the synthesized templates to a directory other
				than cdk.out.
			cdk synth --output=~/templates
		 

	 
		Deploy stacks

		The cdk deploy subcommand deploys one or more specified stacks to your AWS account.

		cdk deploy        # if app contains only one stack
cdk deploy MyStack
cdk deploy Stack1 Stack2
cdk deploy "*"    # all stacks in app

		NoteThe CDK CLI runs your app and synthesizes fresh AWS CloudFormation templates before deploying anything. Therefore,
				most command line options you can use with cdk synth (for example, --context) can also be
				used with cdk deploy.

		See cdk deploy --help for all available options. A few of the most useful options are covered in the
			following section.

		 
			Skip synthesis

			The cdk deploy command normally synthesizes your app's stacks before deploying to make sure
				that the deployment reflects the latest version of your app. If you know that you haven't changed your code since
				your last cdk synth, you can suppress the redundant synthesis step when deploying. To do so,
				specify your project's cdk.out directory in the --app option.

			cdk deploy --app cdk.out StackOne StackTwo

		 
		 
			Disable rollback

			AWS CloudFormation has the ability to roll back changes so that deployments are atomic. This means that they either succeed or
				fail as a whole. The AWS CDK inherits this capability because it synthesizes and deploys AWS CloudFormation templates. 

			Rollback makes sure that your resources are in a consistent state at all times, which is vital for production
				stacks. However, while you're still developing your infrastructure, some failures are inevitable, and rolling back
				failed deployments can slow you down.

			For this reason, the CDK CLI lets you disable rollback by adding --no-rollback to your
					cdk deploy command. With this flag, failed deployments are not rolled back. Instead, resources
				deployed before the failed resource remain in place, and the next deployment starts with the failed resource. You'll
				spend a lot less time waiting for deployments and a lot more time developing your infrastructure.

		 

		 
			Hot swapping

			Use the --hotswap flag with cdk deploy to attempt to update your AWS resources
				directly instead of generating an AWS CloudFormation change set and deploying it. Deployment falls back to AWS CloudFormation deployment if hot
				swapping is not possible.

			Currently hot swapping supports Lambda functions, Step Functions state machines, and Amazon ECS container images. The
					--hotswap flag also disables rollback (i.e., implies --no-rollback).

			ImportantHot-swapping is not recommended for production deployments.

		 


		 
			Watch mode

			The CDK CLI's watch mode ( cdk deploy --watch, or cdk watch for
				short) continuously monitors your CDK app's source files and assets for changes. It immediately performs a
				deployment of the specified stacks when a change is detected.

			By default, these deployments use the --hotswap flag, which fast-tracks deployment of changes to
				Lambda functions. It also falls back to deploying through AWS CloudFormation if you have changed infrastructure configuration. To
				have cdk watch always perform full AWS CloudFormation deployments, add the --no-hotswap flag to
					cdk watch.

			Any changes made while cdk watch is already performing a deployment are combined into a single
				deployment, which begins as soon as the in-progress deployment is complete.

			Watch mode uses the "watch" key in the project's cdk.json to determine which
				files to monitor. By default, these files are your application files and assets, but this can be changed by modifying
				the "include" and "exclude" entries in the "watch" key. The following
					cdk.json file shows an example of these entries.

			{
  "app": "mvn -e -q compile exec:java",
  "watch": {
    "include": "src/main/**",
    "exclude": "target/*"
  }
}

			cdk watch executes the "build" command from cdk.json to build your
				app before synthesis. If your deployment requires any commands to build or package your Lambda code (or anything else
				that's not in your CDK app), add it here.

			Git-style wildcards, both * and **, can be used in the "watch" and
					"build" keys. Each path is interpreted relative to the parent directory of
					cdk.json. The default value of include is **/*, meaning all files
				and directories in the project root directory. exclude is optional.

			ImportantWatch mode is not recommended for production deployments.

		 


		 
			Specify AWS CloudFormation parameters
			The CDK CLI supports specifying AWS CloudFormation parameters at deployment. You may
				provide these on the command line following the --parameters flag.

			cdk deploy MyStack --parameters uploadBucketName=UploadBucket

			To define multiple parameters, use multiple --parameters flags.

			cdk deploy MyStack --parameters uploadBucketName=UpBucket --parameters downloadBucketName=DownBucket

			If you are deploying multiple stacks, you can specify a different value of each parameter for each stack. To do
				so, prefix the name of the parameter with the stack name and a colon. Otherwise, the same value is passed to all
				stacks.

			cdk deploy MyStack YourStack --parameters MyStack:uploadBucketName=UploadBucket --parameters YourStack:uploadBucketName=UpBucket

			By default, the AWS CDK retains values of parameters from previous deployments and uses them in later deployments
				if they are not specified explicitly. Use the --no-previous-parameters flag to require all parameters to
				be specified.
		 

		 
			Specify outputs file
			If your stack declares AWS CloudFormation outputs, these are normally displayed on the screen at the conclusion of deployment.
				To write them to a file in JSON format, use the --outputs-file flag.

			cdk deploy --outputs-file outputs.json MyStack
		 

		 
			Approve security-related changes
			To protect you against unintended changes that affect your security posture, the CDK CLI prompts you to
				approve security-related changes before deploying them. You can specify the level of change that requires
				approval:
			cdk deploy --require-approval LEVEL
			LEVEL can be one of the following:

			
						
							Term
							Meaning
						
					
						
							never
							Approval is never required
						
						
							any-change
							Requires approval on any IAM or security-group-related change
						
						
							broadening (default)
							Requires approval when IAM statements or traffic rules are added; removals don't require
								approval
						
					

			The setting can also be configured in the cdk.json file.
			{
  "app": "...",
  "requireApproval": "never"
}
		 

	 
		Compare stacks

		The cdk diff command compares the current version of a stack (and its dependencies) defined in your
			app with the already-deployed versions, or with a saved AWS CloudFormation template, and displays a list of changes.

		Stack HelloCdkStack
IAM Statement Changes
┌───┬──────────────────────────────┬────────┬──────────────────────────────┬──────────────────────────────┬───────────┐
│   │ Resource                     │ Effect │ Action                       │ Principal                    │ Condition │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${Custom::S3AutoDeleteObject │ Allow  │ sts:AssumeRole               │ Service:lambda.amazonaws.com │           │
│   │ sCustomResourceProvider/Role │        │                              │                              │           │
│   │ .Arn}                        │        │                              │                              │           │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${MyFirstBucket.Arn}         │ Allow  │ s3:DeleteObject*             │ AWS:${Custom::S3AutoDeleteOb │           │
│   │ ${MyFirstBucket.Arn}/*       │        │ s3:GetBucket*                │ jectsCustomResourceProvider/ │           │
│   │                              │        │ s3:GetObject*                │ Role.Arn}                    │           │
│   │                              │        │ s3:List*                     │                              │           │
└───┴──────────────────────────────┴────────┴──────────────────────────────┴──────────────────────────────┴───────────┘
IAM Policy Changes
┌───┬────────────────────────────────────────────────────────┬────────────────────────────────────────────────────────┐
│   │ Resource                                               │ Managed Policy ARN                                     │
├───┼────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
│ + │ ${Custom::S3AutoDeleteObjectsCustomResourceProvider/Ro │ {"Fn::Sub":"arn:${AWS::Partition}:iam::aws:policy/serv │
│   │ le}                                                    │ ice-role/AWSLambdaBasicExecutionRole"}                 │
└───┴────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘
(NOTE: There may be security-related changes not in this list. See https://github.com/aws/aws-cdk/issues/1299)

Parameters
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3Bucket AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3BucketBF7A7F3F: {"Type":"String","Description":"S3 bucket for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3VersionKey AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3VersionKeyFAF93626: {"Type":"String","Description":"S3 key for asset version \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/ArtifactHash AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392ArtifactHashE56CD69A: {"Type":"String","Description":"Artifact hash for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}

Resources
[+] AWS::S3::BucketPolicy MyFirstBucket/Policy MyFirstBucketPolicy3243DEFD
[+] Custom::S3AutoDeleteObjects MyFirstBucket/AutoDeleteObjectsCustomResource MyFirstBucketAutoDeleteObjectsCustomResourceC52FCF6E
[+] AWS::IAM::Role Custom::S3AutoDeleteObjectsCustomResourceProvider/Role CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
[+] AWS::Lambda::Function Custom::S3AutoDeleteObjectsCustomResourceProvider/Handler CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F
[~] AWS::S3::Bucket MyFirstBucket MyFirstBucketB8884501
 ├─ [~] DeletionPolicy
 │   ├─ [-] Retain
 │   └─ [+] Delete
 └─ [~] UpdateReplacePolicy
     ├─ [-] Retain
     └─ [+] Delete

		To compare your app's stacks with the existing deployment:

		cdk diff MyStack

		To compare your app's stacks with a saved CloudFormation template:

		cdk diff --template ~/stacks/MyStack.old MyStack

	 
		Import existing resources into a stack

		You can use the cdk import command to bring resources under the management of CloudFormation for a
			particular AWS CDK stack. This is useful if you are migrating to AWS CDK, or are moving resources between stacks or
			changing their logical id. cdk import uses  CloudFormation resource imports. See the list of resources that can be imported here. 

		To import an existing resource into a AWS CDK stack, follow the following steps:

		
			 
			 
			 
			 
			 
			 
			 
		
				Make sure the resource is not currently being managed by any other CloudFormation stack. If it is, first set the
					removal policy to RemovalPolicy.RETAIN in the stack the resource is currently in and perform a
					deployment. Then, remove the resource from the stack and perform another deployment. This process will make sure
					that the resource is no longer managed by CloudFormation but does not delete it.
			
				Run a cdk diff to make sure there are no pending changes to the AWS CDK stack you want to import
					resources into. The only changes allowed in an "import" operation are the addition of new resources which you want
					to import.
			
				Add constructs for the resources you want to import to your stack. For example, if you want to import an Amazon S3
					bucket, add something like new s3.Bucket(this, 'ImportedS3Bucket', {});. Do not make any modifications
					to any other resource.

				You must also make sure to exactly model the state that the resource currently has into the definition. For the
					example of the bucket, be sure to include AWS KMS keys, life cycle policies, and anything else that's relevant about
					the bucket. If you do not, subsequent update operations may not do what you expect.

				You can choose whether or not to include the physical bucket name. We usually recommend to not include resource
					names into your AWS CDK resource definitions so that it becomes easier to deploy your resources multiple
					times.
			
				Run cdk import STACKNAME.
			
				If the resource names are not in your model, the CLI will prompt you to pass in the actual names of the
					resources you are importing. After this, the import starts.
			
				When cdk import reports success, the resource is now managed by AWS CDK and CloudFormation. Any
					subsequent changes you make to the resource properties in your AWS CDK app the construct configuration will be
					applied on the next deployment.
			
				To confirm that the resource definition in your AWS CDK app matches the current state of the resource, you can
					start an CloudFormation drift detection
						operation.
			

		This feature currently does not support importing resources into nested stacks.
	 
		Configuration (cdk.json)

		Default values for many CDK CLI command line flags can be stored in a project's
				cdk.json file or in the .cdk.json file in your user directory. Following is
			an alphabetical reference to the supported configuration settings.

		
					
						Key
						Notes
						CDK CLI option
					
				
					
						app
						The command that executes the CDK application.
						--app
					
					
						assetMetadata
						If false, CDK does not add metadata to resources that use assets.
						--no-asset-metadata
					
					
						bootstrapKmsKeyId
						Overrides the ID of the AWS KMS key used to encrypt the Amazon S3 deployment bucket.
						--bootstrap-kms-key-id
					
					
						build
						The command that compiles or builds the CDK application before synthesis. Not permitted in
								~/.cdk.json.
						--build
					
					
						browser
						The command for launching a Web browser for the cdk docs subcommand.
						--browser
					
					
						context
						See Context values and the AWS CDK. Context values in a configuration file will not be erased by cdk
								context --clear. (The CDK CLI places cached context values in
								cdk.context.json.)
						--context
					
					
						debug
						If true, CDK CLI emits more detailed information useful for debugging.
						--debug
					
					
						language
						The language to be used for initializing new projects.
						--language
					
					
						lookups
						If false, no context lookups are permitted. Synthesis will fail if any context lookups need
							to be performed.
						--no-lookups
					
					
						notices
						If false, suppresses the display of messages about security vulnerabilities, regressions, and
							unsupported versions.
						--no-notices
					
					
						output
						The name of the directory into which the synthesized cloud assembly will be emitted (default
								"cdk.out").
						--output
					
					
						outputsFile
						The file to which AWS CloudFormation outputs from deployed stacks will be written (in JSON format).
						--outputs-file
					
					
						pathMetadata
						If false, CDK path metadata is not added to synthesized templates.
						--no-path-metadata
					
					
						plugin
						JSON array specifying the package names or local paths of packages that extend the CDK
						--plugin
					
					
						profile
						Name of the default AWS profile used for specifying Region and account credentials.
						--profile
					
					
						progress
						If set to "events", the CDK CLI displays all AWS CloudFormation events during deployment, rather
							than a progress bar.
						--progress
					
					
						requireApproval
						Default approval level for security changes. See Approve security-related changes
						--require-approval
					
					
						rollback
						If false, failed deployments are not rolled back.
						--no-rollback
					
					
						staging
						If false, assets are not copied to the output directory (use for local debugging of the
							source files with AWS SAM).
						--no-staging
					
					
						tags
						JSON object containing tags (key-value pairs) for the stack.
						--tags
					
					
						toolkitBucketName
						The name of the Amazon S3 bucket used for deploying assets such as Lambda functions and container images (see
								Bootstrap your AWS environment.
						--toolkit-bucket-name
					
					
						toolkitStackName
						The name of the bootstrap stack (see Bootstrap your AWS environment.
						--toolkit-stack-name
					
					
						versionReporting
						If false, opts out of version reporting.
						--no-version-reporting
					
					
						watch
						JSON object containing "include" and "exclude" keys that indicate which files
							should (or should not) trigger a rebuild of the project when changed. See Watch mode.
						--watch
					
				

	Document ConventionsBuildingAWS CDK CLI command referenceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideCDK CLI commandsSpecify options and their valuesBuilt-in helpVersion reportingAuthentication with AWSSpecify Region and other configurationSpecify the app commandSpecify stacksBootstrap your AWS environmentCreate a new appList stacksSynthesize stacksDeploy stacksCompare stacksImport existing resources into a stackConfiguration (cdk.json)This is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK CLI referenceThe AWS Cloud Development Kit (AWS CDK) Command Line Interface (AWS CDK CLI), also known as the CDK Toolkit, is the primary
		tool for interacting with your AWS CDK app. It executes your app, interrogates the application model you defined, and
		produces and deploys the AWS CloudFormation templates generated by the AWS CDK. It also provides other features useful for creating and
		working with AWS CDK projects. This topic contains information about common use cases of the CDK CLI.The CDK CLI is installed with the Node Package Manager. In most cases, we recommend installing it
		globally.npm install -g aws-cdk             # install latest version
npm install -g aws-cdk@X.YY.Z      # install specific versionTipIf you regularly work with multiple versions of the AWS CDK, consider installing a matching version of the
			CDK CLI in individual CDK projects. To do this, omit -g from the npm install
			command. Then use npx aws-cdk to invoke it. This runs the local version if one exists, falling back to a
			global version if not.
		CDK CLI commands

		All CDK CLI commands start with cdk, which is followed by a subcommand (list,
				synthesize, deploy, etc.). Some subcommands have a shorter version (ls,
				synth, etc.) that is equivalent. Options and arguments follow the subcommand in any order.

		For a description of all subcommands, options, and arguments, see AWS CDK CLI command reference.

	 
		Specify options and their values

		Command line options begin with two hyphens (--). Some frequently used options have single-letter
			synonyms that begin with a single hyphen (for example, --app has a synonym -a). The order of
			options in an CDK CLI command is not important.

		All options accept a value, which must follow the option name. The value may be separated from the name by white
			space or by an equals sign =. The following two options are equivalent.

		--toolkit-stack-name MyBootstrapStack
--toolkit-stack-name=MyBootstrapStack

		Some options are flags (Booleans). You may specify true or false as their value. If you
			do not provide a value, the value is taken to be true. You may also prefix the option name with
				no- to imply false.

		# sets staging flag to true
--staging
--staging=true
--staging true

# sets staging flag to false
--no-staging
--staging=false
--staging false

		A few options, namely --context, --parameters, --plugin,
			--tags, and --trust, may be specified more than once to specify multiple values. These are
			noted as having [array] type in the CDK CLI help. For example:

		cdk bootstrap --tags costCenter=0123 --tags responsibleParty=jdoe

	 
		Built-in help
		The CDK CLI has integrated help. You can see general help about the utility and a list of the provided
			subcommands by issuing:
		cdk --help
		To see help for a particular subcommand, for example deploy, specify it before the --help
			flag.
		cdk deploy --help
		Issue cdk version to display the version of the CDK CLI. Provide this information when
			requesting support.
	 
		Version reporting
		To gain insight into how the AWS CDK is used, the constructs used by AWS CDK applications are collected and reported by
			using a resource identified as AWS::CDK::Metadata. To learn more, see Configure AWS CDK usage data reporting.
	 
		Authentication with AWS

		 There are different ways in which you can configure programmatic access to AWS resources, depending on the
			environment and the AWS access available to you.

		To choose your method of authentication and configure it for the CDK CLI, see Configure security credentials for the AWS CDK CLI.

		The recommended approach for new users developing locally, who are not given a method of authentication by their
			employer, is to set up AWS IAM Identity Center. This method includes installing the AWS CLI for ease of configuration and for regularly
			signing in to the AWS access portal. If you choose this method, your environment should contain the following
			elements after you complete the procedure for IAM Identity Center
				authentication in the AWS SDKs and Tools Reference Guide:

		
			 
			 
			 
			 

		
				The AWS CLI, which you use to start an AWS access portal session before you run your application.
			
				A shared AWSconfig file having a [default]
					profile with a set of configuration values that can be referenced from the AWS CDK. To find the location of this
					file, see Location of the shared files in the
						AWS SDKs and Tools Reference Guide.
			
				 The shared config file sets the region
					setting. This sets the default AWS Region the AWS CDK and CDK CLI use for AWS requests. 
			
				 The CDK CLI uses the profile's SSO token provider configuration to acquire credentials before sending requests to AWS. The
						sso_role_name value, which is an IAM role connected to an IAM Identity Center permission set, should allow
					access to the AWS services used in your application.
				The following sample config file shows a default profile set up with SSO token provider configuration.
					The profile's sso_session setting refers to the named sso-session section. The
						sso-session section contains settings to initiate an AWS access portal session.
				[default]
sso_session = my-sso
sso_account_id = 111122223333
sso_role_name = SampleRole
region = us-east-1
output = json

[sso-session my-sso]
sso_region = us-east-1
sso_start_url = https://provided-domain.awsapps.com/start
sso_registration_scopes = sso:account:access
			

		 
			Start an AWS access portal session
			Before accessing AWS services, you need an active AWS access portal session for the CDK CLI to use
				IAM Identity Center authentication to resolve credentials. Depending on your configured session lengths, your access will
				eventually expire and the CDK CLI will encounter an authentication error. Run the following command in the
				AWS CLI to sign in to the AWS access portal.
			aws sso login
			 If your SSO token provider configuration is using a named profile instead of the default profile, the command is
					aws sso login --profile NAME. Also specify this profile when issuing
					cdk commands using the --profile option or the AWS_PROFILE
				environment variable.
			To test if you already have an active session, run the following AWS CLI command.
			aws sts get-caller-identity
			The response to this command should report the IAM Identity Center account and permission set configured in the shared
					config file.
			NoteIf you already have an active AWS access portal session and run aws sso login, you will not be
					required to provide credentials. The sign in process may prompt you to allow the AWS CLI access to your data. Since the AWS CLI is built on top of
					the SDK for Python, permission messages may contain variations of the botocore name.
		 
	 
		Specify Region and other configuration
		The CDK CLI needs to know the AWS Region that you're deploying into and how to authenticate with AWS.
			This is needed for deployment operations and to retrieve context values during synthesis. Together, your account and
			Region make up the environment.

		Region may be specified using environment variables or in configuration files. These are the same variables and
			files used by other AWS tools such as the AWS CLI and the various AWS SDKs. The CDK CLI looks for this
			information in the following order.

		
			 
			 
			 
		
				The AWS_DEFAULT_REGION environment variable.
			
				A named profile defined in the standard AWS config file and specified using the
						--profile option on cdk commands.
			
				The [default] section of the standard AWS config file.
			

		Besides specifying AWS authentication and a Region in the [default] section, you can also add one or
			more [profile NAME] sections, where NAME is the name
			of the profile. For more information about named profiles, see Shared
				config and credentials files in the AWS SDKs and Tools Reference Guide.
		The standard AWS config file is located at ~/.aws/config (macOS/Linux)
			or %USERPROFILE%\.aws\config (Windows). For details and alternate locations, see Location of the shared config and credentials files in the
				AWS SDKs and Tools Reference Guide

		The environment that you specify in your AWS CDK app by using the stack's env property is used during
			synthesis. It's used to generate an environment-specific AWS CloudFormation template, and during deployment, it overrides the
			account or Region specified by one of the preceding methods. For more information, see Environments for the AWS CDK.

		NoteThe AWS CDK uses credentials from the same source files as other AWS tools and SDKs, including the AWS Command Line Interface. However, the AWS CDK might
				behave somewhat differently from these tools. It uses the AWS SDK for JavaScript under the hood. For complete details on setting
				up credentials for the AWS SDK for JavaScript, see Setting credentials.

		You may optionally use the --role-arn (or -r) option to specify the ARN of an IAM role
			that should be used for deployment. This role must be assumable by the AWS account being used.

	 
		Specify the app command

		Many features of the CDK CLI require one or more AWS CloudFormation templates be synthesized, which in turn requires
			running your application. The AWS CDK supports programs written in a variety of languages. Therefore, it uses a
			configuration option to specify the exact command necessary to run your app. This option can be specified in two
			ways.
		First, and most commonly, it can be specified using the app key inside the file
				cdk.json. This is in the main directory of your AWS CDK project. The CDK CLI provides an
			appropriate command when creating a new project with cdk init. Here is the cdk.json
			from a fresh TypeScript project, for instance.

		{
  "app": "npx ts-node bin/hello-cdk.ts"
}

		The CDK CLI looks for cdk.json in the current working directory when attempting to run
			your app. Because of this, you might keep a shell open in your project's main directory for issuing CDK CLI
			commands.

		The CDK CLI also looks for the app key in ~/.cdk.json (that is, in your home
			directory) if it can't find it in ./cdk.json. Adding the app command here can be useful if you usually
			work with CDK code in the same language.

		If you are in some other directory, or to run your app using a command other than the one in
				cdk.json, use the --app (or -a) option to specify it.

		cdk --app "npx ts-node bin/hello-cdk.ts" ls

		When deploying, you may also specify a directory containing synthesized cloud assemblies, such as
				cdk.out, as the value of --app. The specified stacks are deployed from this
			directory; the app is not synthesized.

	 
		Specify stacks

		Many CDK CLI commands (for example, cdk deploy) work on stacks defined in your app. If your
			app contains only one stack, the CDK CLI assumes you mean that one if you don't specify a stack
			explicitly.

		Otherwise, you must specify the stack or stacks you want to work with. You can do this by specifying the desired
			stacks by ID individually on the command line. Recall that the ID is the value specified by the second argument when
			you instantiate the stack.

		cdk synth PipelineStack LambdaStack

		You may also use wildcards to specify IDs that match a pattern.

		
			 
			 
			 
		
				? matches any single character
			
				* matches any number of characters (* alone matches all stacks)
			
				** matches everything in a hierarchy
			

		You may also use the --all option to specify all stacks.

		If your app uses CDK Pipelines, the CDK CLI understands your
			stacks and stages as a hierarchy. Also, the --all option and the * wildcard only match
			top-level stacks. To match all the stacks, use **. Also use ** to indicate all the stacks
			under a particular hierarchy.

		When using wildcards, enclose the pattern in quotes, or escape the wildcards with \. If you don't,
			your shell may try to expand the pattern to the names of files in the current directory. At best, this won't do what
			you expect; at worst, you could deploy stacks you didn't intend to. This isn't strictly necessary on Windows because
				cmd.exe does not expand wildcards, but is good practice nonetheless.

		cdk synth "*Stack"    # PipelineStack, LambdaStack, etc.
cdk synth 'Stack?'    # StackA, StackB, Stack1, etc.
cdk synth \*          # All stacks in the app, or all top-level stacks in a CDK Pipelines app
cdk synth '**'        # All stacks in a CDK Pipelines app
cdk synth 'PipelineStack/Prod/**'   # All stacks in Prod stage in a CDK Pipelines app

		NoteThe order in which you specify the stacks is not necessarily the order in which they will be processed. The
				CDK CLI accounts for dependencies between stacks when deciding the order in which to process them. For
				example, let's say that one stack uses a value produced by another (such as the ARN of a resource defined in the
				second stack). In this case, the second stack is synthesized before the first one because of this dependency. You can
				add dependencies between stacks manually using the stack's addDependency()
				method.

	 
		Bootstrap your AWS environment

		Deploying stacks with the CDK requires special dedicated AWS CDK resources to be provisioned. The cdk
				bootstrap command creates the necessary resources for you. You only need to bootstrap if you are deploying a
			stack that requires these dedicated resources. See AWS CDK bootstrapping for details.

		cdk bootstrap

		If issued with no arguments, as shown here, the cdk bootstrap command synthesizes the current app and
			bootstraps the environments its stacks will be deployed to. If the app contains environment-agnostic stacks, which
			don't explicitly specify an environment, the default account and Region are bootstrapped, or the environment specified
			using --profile.

		Outside of an app, you must explicitly specify the environment to be bootstrapped. You may also do so to bootstrap
			an environment that's not specified in your app or local AWS profile. Credentials must be configured (e.g. in
				~/.aws/credentials) for the specified account and Region. You may specify a profile that
			contains the required credentials.

		cdk bootstrap ACCOUNT-NUMBER/REGION # e.g.
cdk bootstrap 1111111111/us-east-1
cdk bootstrap --profile test 1111111111/us-east-1

		ImportantEach environment (account/region combination) to which you deploy such a stack must be bootstrapped
				separately.

		You may incur AWS charges for what the AWS CDK stores in the bootstrapped resources. Additionally, if you use
				-bootstrap-customer-key, an AWS KMS key will be created, which also incurs charges per
			environment.

		NoteEarlier versions of the bootstrap template created a KMS key by default. To avoid charges, re-bootstrap using
					--no-bootstrap-customer-key. 

		NoteCDK CLI v2 does not support the original bootstrap template, dubbed the legacy template, used by default
				with CDK v1.
		
    ImportantThe modern bootstrap template effectively grants the permissions implied by
        the --cloudformation-execution-policies to any AWS account in the
        --trust list. By default, this extends permissions to read and
        write to any resource in the bootstrapped account. Make sure to configure the bootstrapping stack with
        policies and trusted accounts that you are comfortable with.

	 
		Create a new app

		To create a new app, create a directory for it, then, inside the directory, issue cdk init.

		mkdir my-cdk-app
cd my-cdk-app
cdk init TEMPLATE --language LANGUAGE

		The supported languages (LANGUAGE) are:

		
					
						Code
						Language
					
				
					
						typescript
						TypeScript
					
					
						javascript
						JavaScript
					
					
						python
						Python
					
					
						java
						Java
					
					
						csharp
						C#
					
				

		TEMPLATE is an optional template. If the desired template is app,
			the default, you may omit it. The available templates are:

		
					
						Template
						Description
					
				
					
						app (default)
						
							Creates an empty AWS CDK app.
						
					
					
						sample-app
						
							Creates an AWS CDK app with a stack containing an Amazon SQS queue and an Amazon SNS topic.
						
					
				

		The templates use the name of the project folder to generate names for files and classes inside your new
			app.

	 
		List stacks

		To see a list of the IDs of the stacks in your AWS CDK application, enter one of the following equivalent
			commands:

		cdk list
cdk ls

		If your application contains CDK Pipelines stacks, the CDK CLI
			displays stack names as paths according to their location in the pipeline hierarchy. (For example,
				PipelineStack, PipelineStack/Prod, and
				PipelineStack/Prod/MyService.)

		If your app contains many stacks, you can specify full or partial stack IDs of the stacks to be listed. For more
			information, see Specify stacks.

		Add the --long flag to see more information about the stacks, including the stack names and their
			environments (AWS account and Region).

	 
		Synthesize stacks

		The cdk synthesize command (almost always abbreviated synth) synthesizes a stack defined
			in your app into a CloudFormation template.

		cdk synth         # if app contains only one stack
cdk synth MyStack
cdk synth Stack1 Stack2
cdk synth "*"     # all stacks in app

		NoteThe CDK CLI actually runs your app and synthesizes fresh templates before most operations (such as when
				deploying or comparing stacks). These templates are stored by default in the cdk.out directory.
				The cdk synth command simply prints the generated templates for one or more specified stacks.

		See cdk synth --help for all available options. A few of the most frequently used options are covered
			in the following section.

		 
			Specify context values
			Use the --context or -c option to pass runtime context
				values to your CDK app.

			# specify a single context value
cdk synth --context key=value MyStack

# specify multiple context values (any number)
cdk synth --context key1=value1 --context key2=value2 MyStack

			When deploying multiple stacks, the specified context values are normally passed to all of them. If you want, you
				can specify different values for each stack by prefixing the stack name to the context value.

			# different context values for each stack
cdk synth --context Stack1:key=value Stack2:key=value Stack1 Stack2

		 

		 
			Specify display format
			By default, the synthesized template is displayed in YAML format. Add the --json flag to display it
				in JSON format instead.

			cdk synth --json MyStack

		 
		 
			Specify the output directory
			Add the --output (-o) option to write the synthesized templates to a directory other
				than cdk.out.
			cdk synth --output=~/templates
		 

	 
		Deploy stacks

		The cdk deploy subcommand deploys one or more specified stacks to your AWS account.

		cdk deploy        # if app contains only one stack
cdk deploy MyStack
cdk deploy Stack1 Stack2
cdk deploy "*"    # all stacks in app

		NoteThe CDK CLI runs your app and synthesizes fresh AWS CloudFormation templates before deploying anything. Therefore,
				most command line options you can use with cdk synth (for example, --context) can also be
				used with cdk deploy.

		See cdk deploy --help for all available options. A few of the most useful options are covered in the
			following section.

		 
			Skip synthesis

			The cdk deploy command normally synthesizes your app's stacks before deploying to make sure
				that the deployment reflects the latest version of your app. If you know that you haven't changed your code since
				your last cdk synth, you can suppress the redundant synthesis step when deploying. To do so,
				specify your project's cdk.out directory in the --app option.

			cdk deploy --app cdk.out StackOne StackTwo

		 
		 
			Disable rollback

			AWS CloudFormation has the ability to roll back changes so that deployments are atomic. This means that they either succeed or
				fail as a whole. The AWS CDK inherits this capability because it synthesizes and deploys AWS CloudFormation templates. 

			Rollback makes sure that your resources are in a consistent state at all times, which is vital for production
				stacks. However, while you're still developing your infrastructure, some failures are inevitable, and rolling back
				failed deployments can slow you down.

			For this reason, the CDK CLI lets you disable rollback by adding --no-rollback to your
					cdk deploy command. With this flag, failed deployments are not rolled back. Instead, resources
				deployed before the failed resource remain in place, and the next deployment starts with the failed resource. You'll
				spend a lot less time waiting for deployments and a lot more time developing your infrastructure.

		 

		 
			Hot swapping

			Use the --hotswap flag with cdk deploy to attempt to update your AWS resources
				directly instead of generating an AWS CloudFormation change set and deploying it. Deployment falls back to AWS CloudFormation deployment if hot
				swapping is not possible.

			Currently hot swapping supports Lambda functions, Step Functions state machines, and Amazon ECS container images. The
					--hotswap flag also disables rollback (i.e., implies --no-rollback).

			ImportantHot-swapping is not recommended for production deployments.

		 


		 
			Watch mode

			The CDK CLI's watch mode ( cdk deploy --watch, or cdk watch for
				short) continuously monitors your CDK app's source files and assets for changes. It immediately performs a
				deployment of the specified stacks when a change is detected.

			By default, these deployments use the --hotswap flag, which fast-tracks deployment of changes to
				Lambda functions. It also falls back to deploying through AWS CloudFormation if you have changed infrastructure configuration. To
				have cdk watch always perform full AWS CloudFormation deployments, add the --no-hotswap flag to
					cdk watch.

			Any changes made while cdk watch is already performing a deployment are combined into a single
				deployment, which begins as soon as the in-progress deployment is complete.

			Watch mode uses the "watch" key in the project's cdk.json to determine which
				files to monitor. By default, these files are your application files and assets, but this can be changed by modifying
				the "include" and "exclude" entries in the "watch" key. The following
					cdk.json file shows an example of these entries.

			{
  "app": "mvn -e -q compile exec:java",
  "watch": {
    "include": "src/main/**",
    "exclude": "target/*"
  }
}

			cdk watch executes the "build" command from cdk.json to build your
				app before synthesis. If your deployment requires any commands to build or package your Lambda code (or anything else
				that's not in your CDK app), add it here.

			Git-style wildcards, both * and **, can be used in the "watch" and
					"build" keys. Each path is interpreted relative to the parent directory of
					cdk.json. The default value of include is **/*, meaning all files
				and directories in the project root directory. exclude is optional.

			ImportantWatch mode is not recommended for production deployments.

		 


		 
			Specify AWS CloudFormation parameters
			The CDK CLI supports specifying AWS CloudFormation parameters at deployment. You may
				provide these on the command line following the --parameters flag.

			cdk deploy MyStack --parameters uploadBucketName=UploadBucket

			To define multiple parameters, use multiple --parameters flags.

			cdk deploy MyStack --parameters uploadBucketName=UpBucket --parameters downloadBucketName=DownBucket

			If you are deploying multiple stacks, you can specify a different value of each parameter for each stack. To do
				so, prefix the name of the parameter with the stack name and a colon. Otherwise, the same value is passed to all
				stacks.

			cdk deploy MyStack YourStack --parameters MyStack:uploadBucketName=UploadBucket --parameters YourStack:uploadBucketName=UpBucket

			By default, the AWS CDK retains values of parameters from previous deployments and uses them in later deployments
				if they are not specified explicitly. Use the --no-previous-parameters flag to require all parameters to
				be specified.
		 

		 
			Specify outputs file
			If your stack declares AWS CloudFormation outputs, these are normally displayed on the screen at the conclusion of deployment.
				To write them to a file in JSON format, use the --outputs-file flag.

			cdk deploy --outputs-file outputs.json MyStack
		 

		 
			Approve security-related changes
			To protect you against unintended changes that affect your security posture, the CDK CLI prompts you to
				approve security-related changes before deploying them. You can specify the level of change that requires
				approval:
			cdk deploy --require-approval LEVEL
			LEVEL can be one of the following:

			
						
							Term
							Meaning
						
					
						
							never
							Approval is never required
						
						
							any-change
							Requires approval on any IAM or security-group-related change
						
						
							broadening (default)
							Requires approval when IAM statements or traffic rules are added; removals don't require
								approval
						
					

			The setting can also be configured in the cdk.json file.
			{
  "app": "...",
  "requireApproval": "never"
}
		 

	 
		Compare stacks

		The cdk diff command compares the current version of a stack (and its dependencies) defined in your
			app with the already-deployed versions, or with a saved AWS CloudFormation template, and displays a list of changes.

		Stack HelloCdkStack
IAM Statement Changes
┌───┬──────────────────────────────┬────────┬──────────────────────────────┬──────────────────────────────┬───────────┐
│   │ Resource                     │ Effect │ Action                       │ Principal                    │ Condition │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${Custom::S3AutoDeleteObject │ Allow  │ sts:AssumeRole               │ Service:lambda.amazonaws.com │           │
│   │ sCustomResourceProvider/Role │        │                              │                              │           │
│   │ .Arn}                        │        │                              │                              │           │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${MyFirstBucket.Arn}         │ Allow  │ s3:DeleteObject*             │ AWS:${Custom::S3AutoDeleteOb │           │
│   │ ${MyFirstBucket.Arn}/*       │        │ s3:GetBucket*                │ jectsCustomResourceProvider/ │           │
│   │                              │        │ s3:GetObject*                │ Role.Arn}                    │           │
│   │                              │        │ s3:List*                     │                              │           │
└───┴──────────────────────────────┴────────┴──────────────────────────────┴──────────────────────────────┴───────────┘
IAM Policy Changes
┌───┬────────────────────────────────────────────────────────┬────────────────────────────────────────────────────────┐
│   │ Resource                                               │ Managed Policy ARN                                     │
├───┼────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
│ + │ ${Custom::S3AutoDeleteObjectsCustomResourceProvider/Ro │ {"Fn::Sub":"arn:${AWS::Partition}:iam::aws:policy/serv │
│   │ le}                                                    │ ice-role/AWSLambdaBasicExecutionRole"}                 │
└───┴────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘
(NOTE: There may be security-related changes not in this list. See https://github.com/aws/aws-cdk/issues/1299)

Parameters
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3Bucket AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3BucketBF7A7F3F: {"Type":"String","Description":"S3 bucket for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3VersionKey AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3VersionKeyFAF93626: {"Type":"String","Description":"S3 key for asset version \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/ArtifactHash AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392ArtifactHashE56CD69A: {"Type":"String","Description":"Artifact hash for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}

Resources
[+] AWS::S3::BucketPolicy MyFirstBucket/Policy MyFirstBucketPolicy3243DEFD
[+] Custom::S3AutoDeleteObjects MyFirstBucket/AutoDeleteObjectsCustomResource MyFirstBucketAutoDeleteObjectsCustomResourceC52FCF6E
[+] AWS::IAM::Role Custom::S3AutoDeleteObjectsCustomResourceProvider/Role CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
[+] AWS::Lambda::Function Custom::S3AutoDeleteObjectsCustomResourceProvider/Handler CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F
[~] AWS::S3::Bucket MyFirstBucket MyFirstBucketB8884501
 ├─ [~] DeletionPolicy
 │   ├─ [-] Retain
 │   └─ [+] Delete
 └─ [~] UpdateReplacePolicy
     ├─ [-] Retain
     └─ [+] Delete

		To compare your app's stacks with the existing deployment:

		cdk diff MyStack

		To compare your app's stacks with a saved CloudFormation template:

		cdk diff --template ~/stacks/MyStack.old MyStack

	 
		Import existing resources into a stack

		You can use the cdk import command to bring resources under the management of CloudFormation for a
			particular AWS CDK stack. This is useful if you are migrating to AWS CDK, or are moving resources between stacks or
			changing their logical id. cdk import uses  CloudFormation resource imports. See the list of resources that can be imported here. 

		To import an existing resource into a AWS CDK stack, follow the following steps:

		
			 
			 
			 
			 
			 
			 
			 
		
				Make sure the resource is not currently being managed by any other CloudFormation stack. If it is, first set the
					removal policy to RemovalPolicy.RETAIN in the stack the resource is currently in and perform a
					deployment. Then, remove the resource from the stack and perform another deployment. This process will make sure
					that the resource is no longer managed by CloudFormation but does not delete it.
			
				Run a cdk diff to make sure there are no pending changes to the AWS CDK stack you want to import
					resources into. The only changes allowed in an "import" operation are the addition of new resources which you want
					to import.
			
				Add constructs for the resources you want to import to your stack. For example, if you want to import an Amazon S3
					bucket, add something like new s3.Bucket(this, 'ImportedS3Bucket', {});. Do not make any modifications
					to any other resource.

				You must also make sure to exactly model the state that the resource currently has into the definition. For the
					example of the bucket, be sure to include AWS KMS keys, life cycle policies, and anything else that's relevant about
					the bucket. If you do not, subsequent update operations may not do what you expect.

				You can choose whether or not to include the physical bucket name. We usually recommend to not include resource
					names into your AWS CDK resource definitions so that it becomes easier to deploy your resources multiple
					times.
			
				Run cdk import STACKNAME.
			
				If the resource names are not in your model, the CLI will prompt you to pass in the actual names of the
					resources you are importing. After this, the import starts.
			
				When cdk import reports success, the resource is now managed by AWS CDK and CloudFormation. Any
					subsequent changes you make to the resource properties in your AWS CDK app the construct configuration will be
					applied on the next deployment.
			
				To confirm that the resource definition in your AWS CDK app matches the current state of the resource, you can
					start an CloudFormation drift detection
						operation.
			

		This feature currently does not support importing resources into nested stacks.
	 
		Configuration (cdk.json)

		Default values for many CDK CLI command line flags can be stored in a project's
				cdk.json file or in the .cdk.json file in your user directory. Following is
			an alphabetical reference to the supported configuration settings.

		
					
						Key
						Notes
						CDK CLI option
					
				
					
						app
						The command that executes the CDK application.
						--app
					
					
						assetMetadata
						If false, CDK does not add metadata to resources that use assets.
						--no-asset-metadata
					
					
						bootstrapKmsKeyId
						Overrides the ID of the AWS KMS key used to encrypt the Amazon S3 deployment bucket.
						--bootstrap-kms-key-id
					
					
						build
						The command that compiles or builds the CDK application before synthesis. Not permitted in
								~/.cdk.json.
						--build
					
					
						browser
						The command for launching a Web browser for the cdk docs subcommand.
						--browser
					
					
						context
						See Context values and the AWS CDK. Context values in a configuration file will not be erased by cdk
								context --clear. (The CDK CLI places cached context values in
								cdk.context.json.)
						--context
					
					
						debug
						If true, CDK CLI emits more detailed information useful for debugging.
						--debug
					
					
						language
						The language to be used for initializing new projects.
						--language
					
					
						lookups
						If false, no context lookups are permitted. Synthesis will fail if any context lookups need
							to be performed.
						--no-lookups
					
					
						notices
						If false, suppresses the display of messages about security vulnerabilities, regressions, and
							unsupported versions.
						--no-notices
					
					
						output
						The name of the directory into which the synthesized cloud assembly will be emitted (default
								"cdk.out").
						--output
					
					
						outputsFile
						The file to which AWS CloudFormation outputs from deployed stacks will be written (in JSON format).
						--outputs-file
					
					
						pathMetadata
						If false, CDK path metadata is not added to synthesized templates.
						--no-path-metadata
					
					
						plugin
						JSON array specifying the package names or local paths of packages that extend the CDK
						--plugin
					
					
						profile
						Name of the default AWS profile used for specifying Region and account credentials.
						--profile
					
					
						progress
						If set to "events", the CDK CLI displays all AWS CloudFormation events during deployment, rather
							than a progress bar.
						--progress
					
					
						requireApproval
						Default approval level for security changes. See Approve security-related changes
						--require-approval
					
					
						rollback
						If false, failed deployments are not rolled back.
						--no-rollback
					
					
						staging
						If false, assets are not copied to the output directory (use for local debugging of the
							source files with AWS SAM).
						--no-staging
					
					
						tags
						JSON object containing tags (key-value pairs) for the stack.
						--tags
					
					
						toolkitBucketName
						The name of the Amazon S3 bucket used for deploying assets such as Lambda functions and container images (see
								Bootstrap your AWS environment.
						--toolkit-bucket-name
					
					
						toolkitStackName
						The name of the bootstrap stack (see Bootstrap your AWS environment.
						--toolkit-stack-name
					
					
						versionReporting
						If false, opts out of version reporting.
						--no-version-reporting
					
					
						watch
						JSON object containing "include" and "exclude" keys that indicate which files
							should (or should not) trigger a rebuild of the project when changed. See Watch mode.
						--watch
					
				

	Document ConventionsBuildingAWS CDK CLI command referenceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\nThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Thanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\nDocumentationAWS Cloud Development KitDeveloper GuideCDK CLI commandsSpecify options and their valuesBuilt-in helpVersion reportingAuthentication with AWSSpecify Region and other configurationSpecify the app commandSpecify stacksBootstrap your AWS environmentCreate a new appList stacksSynthesize stacksDeploy stacksCompare stacksImport existing resources into a stackConfiguration (cdk.json)This is the AWS CDK v2 Developer Guide. The older CDK v1 entered maintenance on June 1,
      2022 and ended support on June 1, 2023.AWS CDK CLI referenceThe AWS Cloud Development Kit (AWS CDK) Command Line Interface (AWS CDK CLI), also known as the CDK Toolkit, is the primary
		tool for interacting with your AWS CDK app. It executes your app, interrogates the application model you defined, and
		produces and deploys the AWS CloudFormation templates generated by the AWS CDK. It also provides other features useful for creating and
		working with AWS CDK projects. This topic contains information about common use cases of the CDK CLI.The CDK CLI is installed with the Node Package Manager. In most cases, we recommend installing it
		globally.npm install -g aws-cdk             # install latest version
npm install -g aws-cdk@X.YY.Z      # install specific versionTipIf you regularly work with multiple versions of the AWS CDK, consider installing a matching version of the
			CDK CLI in individual CDK projects. To do this, omit -g from the npm install
			command. Then use npx aws-cdk to invoke it. This runs the local version if one exists, falling back to a
			global version if not.
		CDK CLI commands

		All CDK CLI commands start with cdk, which is followed by a subcommand (list,
				synthesize, deploy, etc.). Some subcommands have a shorter version (ls,
				synth, etc.) that is equivalent. Options and arguments follow the subcommand in any order.

		For a description of all subcommands, options, and arguments, see AWS CDK CLI command reference.

	 
		Specify options and their values

		Command line options begin with two hyphens (--). Some frequently used options have single-letter
			synonyms that begin with a single hyphen (for example, --app has a synonym -a). The order of
			options in an CDK CLI command is not important.

		All options accept a value, which must follow the option name. The value may be separated from the name by white
			space or by an equals sign =. The following two options are equivalent.

		--toolkit-stack-name MyBootstrapStack
--toolkit-stack-name=MyBootstrapStack

		Some options are flags (Booleans). You may specify true or false as their value. If you
			do not provide a value, the value is taken to be true. You may also prefix the option name with
				no- to imply false.

		# sets staging flag to true
--staging
--staging=true
--staging true

# sets staging flag to false
--no-staging
--staging=false
--staging false

		A few options, namely --context, --parameters, --plugin,
			--tags, and --trust, may be specified more than once to specify multiple values. These are
			noted as having [array] type in the CDK CLI help. For example:

		cdk bootstrap --tags costCenter=0123 --tags responsibleParty=jdoe

	 
		Built-in help
		The CDK CLI has integrated help. You can see general help about the utility and a list of the provided
			subcommands by issuing:
		cdk --help
		To see help for a particular subcommand, for example deploy, specify it before the --help
			flag.
		cdk deploy --help
		Issue cdk version to display the version of the CDK CLI. Provide this information when
			requesting support.
	 
		Version reporting
		To gain insight into how the AWS CDK is used, the constructs used by AWS CDK applications are collected and reported by
			using a resource identified as AWS::CDK::Metadata. To learn more, see Configure AWS CDK usage data reporting.
	 
		Authentication with AWS

		 There are different ways in which you can configure programmatic access to AWS resources, depending on the
			environment and the AWS access available to you.

		To choose your method of authentication and configure it for the CDK CLI, see Configure security credentials for the AWS CDK CLI.

		The recommended approach for new users developing locally, who are not given a method of authentication by their
			employer, is to set up AWS IAM Identity Center. This method includes installing the AWS CLI for ease of configuration and for regularly
			signing in to the AWS access portal. If you choose this method, your environment should contain the following
			elements after you complete the procedure for IAM Identity Center
				authentication in the AWS SDKs and Tools Reference Guide:

		
			 
			 
			 
			 

		
				The AWS CLI, which you use to start an AWS access portal session before you run your application.
			
				A shared AWSconfig file having a [default]
					profile with a set of configuration values that can be referenced from the AWS CDK. To find the location of this
					file, see Location of the shared files in the
						AWS SDKs and Tools Reference Guide.
			
				 The shared config file sets the region
					setting. This sets the default AWS Region the AWS CDK and CDK CLI use for AWS requests. 
			
				 The CDK CLI uses the profile's SSO token provider configuration to acquire credentials before sending requests to AWS. The
						sso_role_name value, which is an IAM role connected to an IAM Identity Center permission set, should allow
					access to the AWS services used in your application.
				The following sample config file shows a default profile set up with SSO token provider configuration.
					The profile's sso_session setting refers to the named sso-session section. The
						sso-session section contains settings to initiate an AWS access portal session.
				[default]
sso_session = my-sso
sso_account_id = 111122223333
sso_role_name = SampleRole
region = us-east-1
output = json

[sso-session my-sso]
sso_region = us-east-1
sso_start_url = https://provided-domain.awsapps.com/start
sso_registration_scopes = sso:account:access
			

		 
			Start an AWS access portal session
			Before accessing AWS services, you need an active AWS access portal session for the CDK CLI to use
				IAM Identity Center authentication to resolve credentials. Depending on your configured session lengths, your access will
				eventually expire and the CDK CLI will encounter an authentication error. Run the following command in the
				AWS CLI to sign in to the AWS access portal.
			aws sso login
			 If your SSO token provider configuration is using a named profile instead of the default profile, the command is
					aws sso login --profile NAME. Also specify this profile when issuing
					cdk commands using the --profile option or the AWS_PROFILE
				environment variable.
			To test if you already have an active session, run the following AWS CLI command.
			aws sts get-caller-identity
			The response to this command should report the IAM Identity Center account and permission set configured in the shared
					config file.
			NoteIf you already have an active AWS access portal session and run aws sso login, you will not be
					required to provide credentials. The sign in process may prompt you to allow the AWS CLI access to your data. Since the AWS CLI is built on top of
					the SDK for Python, permission messages may contain variations of the botocore name.
		 
	 
		Specify Region and other configuration
		The CDK CLI needs to know the AWS Region that you're deploying into and how to authenticate with AWS.
			This is needed for deployment operations and to retrieve context values during synthesis. Together, your account and
			Region make up the environment.

		Region may be specified using environment variables or in configuration files. These are the same variables and
			files used by other AWS tools such as the AWS CLI and the various AWS SDKs. The CDK CLI looks for this
			information in the following order.

		
			 
			 
			 
		
				The AWS_DEFAULT_REGION environment variable.
			
				A named profile defined in the standard AWS config file and specified using the
						--profile option on cdk commands.
			
				The [default] section of the standard AWS config file.
			

		Besides specifying AWS authentication and a Region in the [default] section, you can also add one or
			more [profile NAME] sections, where NAME is the name
			of the profile. For more information about named profiles, see Shared
				config and credentials files in the AWS SDKs and Tools Reference Guide.
		The standard AWS config file is located at ~/.aws/config (macOS/Linux)
			or %USERPROFILE%\.aws\config (Windows). For details and alternate locations, see Location of the shared config and credentials files in the
				AWS SDKs and Tools Reference Guide

		The environment that you specify in your AWS CDK app by using the stack's env property is used during
			synthesis. It's used to generate an environment-specific AWS CloudFormation template, and during deployment, it overrides the
			account or Region specified by one of the preceding methods. For more information, see Environments for the AWS CDK.

		NoteThe AWS CDK uses credentials from the same source files as other AWS tools and SDKs, including the AWS Command Line Interface. However, the AWS CDK might
				behave somewhat differently from these tools. It uses the AWS SDK for JavaScript under the hood. For complete details on setting
				up credentials for the AWS SDK for JavaScript, see Setting credentials.

		You may optionally use the --role-arn (or -r) option to specify the ARN of an IAM role
			that should be used for deployment. This role must be assumable by the AWS account being used.

	 
		Specify the app command

		Many features of the CDK CLI require one or more AWS CloudFormation templates be synthesized, which in turn requires
			running your application. The AWS CDK supports programs written in a variety of languages. Therefore, it uses a
			configuration option to specify the exact command necessary to run your app. This option can be specified in two
			ways.
		First, and most commonly, it can be specified using the app key inside the file
				cdk.json. This is in the main directory of your AWS CDK project. The CDK CLI provides an
			appropriate command when creating a new project with cdk init. Here is the cdk.json
			from a fresh TypeScript project, for instance.

		{
  "app": "npx ts-node bin/hello-cdk.ts"
}

		The CDK CLI looks for cdk.json in the current working directory when attempting to run
			your app. Because of this, you might keep a shell open in your project's main directory for issuing CDK CLI
			commands.

		The CDK CLI also looks for the app key in ~/.cdk.json (that is, in your home
			directory) if it can't find it in ./cdk.json. Adding the app command here can be useful if you usually
			work with CDK code in the same language.

		If you are in some other directory, or to run your app using a command other than the one in
				cdk.json, use the --app (or -a) option to specify it.

		cdk --app "npx ts-node bin/hello-cdk.ts" ls

		When deploying, you may also specify a directory containing synthesized cloud assemblies, such as
				cdk.out, as the value of --app. The specified stacks are deployed from this
			directory; the app is not synthesized.

	 
		Specify stacks

		Many CDK CLI commands (for example, cdk deploy) work on stacks defined in your app. If your
			app contains only one stack, the CDK CLI assumes you mean that one if you don't specify a stack
			explicitly.

		Otherwise, you must specify the stack or stacks you want to work with. You can do this by specifying the desired
			stacks by ID individually on the command line. Recall that the ID is the value specified by the second argument when
			you instantiate the stack.

		cdk synth PipelineStack LambdaStack

		You may also use wildcards to specify IDs that match a pattern.

		
			 
			 
			 
		
				? matches any single character
			
				* matches any number of characters (* alone matches all stacks)
			
				** matches everything in a hierarchy
			

		You may also use the --all option to specify all stacks.

		If your app uses CDK Pipelines, the CDK CLI understands your
			stacks and stages as a hierarchy. Also, the --all option and the * wildcard only match
			top-level stacks. To match all the stacks, use **. Also use ** to indicate all the stacks
			under a particular hierarchy.

		When using wildcards, enclose the pattern in quotes, or escape the wildcards with \. If you don't,
			your shell may try to expand the pattern to the names of files in the current directory. At best, this won't do what
			you expect; at worst, you could deploy stacks you didn't intend to. This isn't strictly necessary on Windows because
				cmd.exe does not expand wildcards, but is good practice nonetheless.

		cdk synth "*Stack"    # PipelineStack, LambdaStack, etc.
cdk synth 'Stack?'    # StackA, StackB, Stack1, etc.
cdk synth \*          # All stacks in the app, or all top-level stacks in a CDK Pipelines app
cdk synth '**'        # All stacks in a CDK Pipelines app
cdk synth 'PipelineStack/Prod/**'   # All stacks in Prod stage in a CDK Pipelines app

		NoteThe order in which you specify the stacks is not necessarily the order in which they will be processed. The
				CDK CLI accounts for dependencies between stacks when deciding the order in which to process them. For
				example, let's say that one stack uses a value produced by another (such as the ARN of a resource defined in the
				second stack). In this case, the second stack is synthesized before the first one because of this dependency. You can
				add dependencies between stacks manually using the stack's addDependency()
				method.

	 
		Bootstrap your AWS environment

		Deploying stacks with the CDK requires special dedicated AWS CDK resources to be provisioned. The cdk
				bootstrap command creates the necessary resources for you. You only need to bootstrap if you are deploying a
			stack that requires these dedicated resources. See AWS CDK bootstrapping for details.

		cdk bootstrap

		If issued with no arguments, as shown here, the cdk bootstrap command synthesizes the current app and
			bootstraps the environments its stacks will be deployed to. If the app contains environment-agnostic stacks, which
			don't explicitly specify an environment, the default account and Region are bootstrapped, or the environment specified
			using --profile.

		Outside of an app, you must explicitly specify the environment to be bootstrapped. You may also do so to bootstrap
			an environment that's not specified in your app or local AWS profile. Credentials must be configured (e.g. in
				~/.aws/credentials) for the specified account and Region. You may specify a profile that
			contains the required credentials.

		cdk bootstrap ACCOUNT-NUMBER/REGION # e.g.
cdk bootstrap 1111111111/us-east-1
cdk bootstrap --profile test 1111111111/us-east-1

		ImportantEach environment (account/region combination) to which you deploy such a stack must be bootstrapped
				separately.

		You may incur AWS charges for what the AWS CDK stores in the bootstrapped resources. Additionally, if you use
				-bootstrap-customer-key, an AWS KMS key will be created, which also incurs charges per
			environment.

		NoteEarlier versions of the bootstrap template created a KMS key by default. To avoid charges, re-bootstrap using
					--no-bootstrap-customer-key. 

		NoteCDK CLI v2 does not support the original bootstrap template, dubbed the legacy template, used by default
				with CDK v1.
		
    ImportantThe modern bootstrap template effectively grants the permissions implied by
        the --cloudformation-execution-policies to any AWS account in the
        --trust list. By default, this extends permissions to read and
        write to any resource in the bootstrapped account. Make sure to configure the bootstrapping stack with
        policies and trusted accounts that you are comfortable with.

	 
		Create a new app

		To create a new app, create a directory for it, then, inside the directory, issue cdk init.

		mkdir my-cdk-app
cd my-cdk-app
cdk init TEMPLATE --language LANGUAGE

		The supported languages (LANGUAGE) are:

		
					
						Code
						Language
					
				
					
						typescript
						TypeScript
					
					
						javascript
						JavaScript
					
					
						python
						Python
					
					
						java
						Java
					
					
						csharp
						C#
					
				

		TEMPLATE is an optional template. If the desired template is app,
			the default, you may omit it. The available templates are:

		
					
						Template
						Description
					
				
					
						app (default)
						
							Creates an empty AWS CDK app.
						
					
					
						sample-app
						
							Creates an AWS CDK app with a stack containing an Amazon SQS queue and an Amazon SNS topic.
						
					
				

		The templates use the name of the project folder to generate names for files and classes inside your new
			app.

	 
		List stacks

		To see a list of the IDs of the stacks in your AWS CDK application, enter one of the following equivalent
			commands:

		cdk list
cdk ls

		If your application contains CDK Pipelines stacks, the CDK CLI
			displays stack names as paths according to their location in the pipeline hierarchy. (For example,
				PipelineStack, PipelineStack/Prod, and
				PipelineStack/Prod/MyService.)

		If your app contains many stacks, you can specify full or partial stack IDs of the stacks to be listed. For more
			information, see Specify stacks.

		Add the --long flag to see more information about the stacks, including the stack names and their
			environments (AWS account and Region).

	 
		Synthesize stacks

		The cdk synthesize command (almost always abbreviated synth) synthesizes a stack defined
			in your app into a CloudFormation template.

		cdk synth         # if app contains only one stack
cdk synth MyStack
cdk synth Stack1 Stack2
cdk synth "*"     # all stacks in app

		NoteThe CDK CLI actually runs your app and synthesizes fresh templates before most operations (such as when
				deploying or comparing stacks). These templates are stored by default in the cdk.out directory.
				The cdk synth command simply prints the generated templates for one or more specified stacks.

		See cdk synth --help for all available options. A few of the most frequently used options are covered
			in the following section.

		 
			Specify context values
			Use the --context or -c option to pass runtime context
				values to your CDK app.

			# specify a single context value
cdk synth --context key=value MyStack

# specify multiple context values (any number)
cdk synth --context key1=value1 --context key2=value2 MyStack

			When deploying multiple stacks, the specified context values are normally passed to all of them. If you want, you
				can specify different values for each stack by prefixing the stack name to the context value.

			# different context values for each stack
cdk synth --context Stack1:key=value Stack2:key=value Stack1 Stack2

		 

		 
			Specify display format
			By default, the synthesized template is displayed in YAML format. Add the --json flag to display it
				in JSON format instead.

			cdk synth --json MyStack

		 
		 
			Specify the output directory
			Add the --output (-o) option to write the synthesized templates to a directory other
				than cdk.out.
			cdk synth --output=~/templates
		 

	 
		Deploy stacks

		The cdk deploy subcommand deploys one or more specified stacks to your AWS account.

		cdk deploy        # if app contains only one stack
cdk deploy MyStack
cdk deploy Stack1 Stack2
cdk deploy "*"    # all stacks in app

		NoteThe CDK CLI runs your app and synthesizes fresh AWS CloudFormation templates before deploying anything. Therefore,
				most command line options you can use with cdk synth (for example, --context) can also be
				used with cdk deploy.

		See cdk deploy --help for all available options. A few of the most useful options are covered in the
			following section.

		 
			Skip synthesis

			The cdk deploy command normally synthesizes your app's stacks before deploying to make sure
				that the deployment reflects the latest version of your app. If you know that you haven't changed your code since
				your last cdk synth, you can suppress the redundant synthesis step when deploying. To do so,
				specify your project's cdk.out directory in the --app option.

			cdk deploy --app cdk.out StackOne StackTwo

		 
		 
			Disable rollback

			AWS CloudFormation has the ability to roll back changes so that deployments are atomic. This means that they either succeed or
				fail as a whole. The AWS CDK inherits this capability because it synthesizes and deploys AWS CloudFormation templates. 

			Rollback makes sure that your resources are in a consistent state at all times, which is vital for production
				stacks. However, while you're still developing your infrastructure, some failures are inevitable, and rolling back
				failed deployments can slow you down.

			For this reason, the CDK CLI lets you disable rollback by adding --no-rollback to your
					cdk deploy command. With this flag, failed deployments are not rolled back. Instead, resources
				deployed before the failed resource remain in place, and the next deployment starts with the failed resource. You'll
				spend a lot less time waiting for deployments and a lot more time developing your infrastructure.

		 

		 
			Hot swapping

			Use the --hotswap flag with cdk deploy to attempt to update your AWS resources
				directly instead of generating an AWS CloudFormation change set and deploying it. Deployment falls back to AWS CloudFormation deployment if hot
				swapping is not possible.

			Currently hot swapping supports Lambda functions, Step Functions state machines, and Amazon ECS container images. The
					--hotswap flag also disables rollback (i.e., implies --no-rollback).

			ImportantHot-swapping is not recommended for production deployments.

		 


		 
			Watch mode

			The CDK CLI's watch mode ( cdk deploy --watch, or cdk watch for
				short) continuously monitors your CDK app's source files and assets for changes. It immediately performs a
				deployment of the specified stacks when a change is detected.

			By default, these deployments use the --hotswap flag, which fast-tracks deployment of changes to
				Lambda functions. It also falls back to deploying through AWS CloudFormation if you have changed infrastructure configuration. To
				have cdk watch always perform full AWS CloudFormation deployments, add the --no-hotswap flag to
					cdk watch.

			Any changes made while cdk watch is already performing a deployment are combined into a single
				deployment, which begins as soon as the in-progress deployment is complete.

			Watch mode uses the "watch" key in the project's cdk.json to determine which
				files to monitor. By default, these files are your application files and assets, but this can be changed by modifying
				the "include" and "exclude" entries in the "watch" key. The following
					cdk.json file shows an example of these entries.

			{
  "app": "mvn -e -q compile exec:java",
  "watch": {
    "include": "src/main/**",
    "exclude": "target/*"
  }
}

			cdk watch executes the "build" command from cdk.json to build your
				app before synthesis. If your deployment requires any commands to build or package your Lambda code (or anything else
				that's not in your CDK app), add it here.

			Git-style wildcards, both * and **, can be used in the "watch" and
					"build" keys. Each path is interpreted relative to the parent directory of
					cdk.json. The default value of include is **/*, meaning all files
				and directories in the project root directory. exclude is optional.

			ImportantWatch mode is not recommended for production deployments.

		 


		 
			Specify AWS CloudFormation parameters
			The CDK CLI supports specifying AWS CloudFormation parameters at deployment. You may
				provide these on the command line following the --parameters flag.

			cdk deploy MyStack --parameters uploadBucketName=UploadBucket

			To define multiple parameters, use multiple --parameters flags.

			cdk deploy MyStack --parameters uploadBucketName=UpBucket --parameters downloadBucketName=DownBucket

			If you are deploying multiple stacks, you can specify a different value of each parameter for each stack. To do
				so, prefix the name of the parameter with the stack name and a colon. Otherwise, the same value is passed to all
				stacks.

			cdk deploy MyStack YourStack --parameters MyStack:uploadBucketName=UploadBucket --parameters YourStack:uploadBucketName=UpBucket

			By default, the AWS CDK retains values of parameters from previous deployments and uses them in later deployments
				if they are not specified explicitly. Use the --no-previous-parameters flag to require all parameters to
				be specified.
		 

		 
			Specify outputs file
			If your stack declares AWS CloudFormation outputs, these are normally displayed on the screen at the conclusion of deployment.
				To write them to a file in JSON format, use the --outputs-file flag.

			cdk deploy --outputs-file outputs.json MyStack
		 

		 
			Approve security-related changes
			To protect you against unintended changes that affect your security posture, the CDK CLI prompts you to
				approve security-related changes before deploying them. You can specify the level of change that requires
				approval:
			cdk deploy --require-approval LEVEL
			LEVEL can be one of the following:

			
						
							Term
							Meaning
						
					
						
							never
							Approval is never required
						
						
							any-change
							Requires approval on any IAM or security-group-related change
						
						
							broadening (default)
							Requires approval when IAM statements or traffic rules are added; removals don't require
								approval
						
					

			The setting can also be configured in the cdk.json file.
			{
  "app": "...",
  "requireApproval": "never"
}
		 

	 
		Compare stacks

		The cdk diff command compares the current version of a stack (and its dependencies) defined in your
			app with the already-deployed versions, or with a saved AWS CloudFormation template, and displays a list of changes.

		Stack HelloCdkStack
IAM Statement Changes
┌───┬──────────────────────────────┬────────┬──────────────────────────────┬──────────────────────────────┬───────────┐
│   │ Resource                     │ Effect │ Action                       │ Principal                    │ Condition │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${Custom::S3AutoDeleteObject │ Allow  │ sts:AssumeRole               │ Service:lambda.amazonaws.com │           │
│   │ sCustomResourceProvider/Role │        │                              │                              │           │
│   │ .Arn}                        │        │                              │                              │           │
├───┼──────────────────────────────┼────────┼──────────────────────────────┼──────────────────────────────┼───────────┤
│ + │ ${MyFirstBucket.Arn}         │ Allow  │ s3:DeleteObject*             │ AWS:${Custom::S3AutoDeleteOb │           │
│   │ ${MyFirstBucket.Arn}/*       │        │ s3:GetBucket*                │ jectsCustomResourceProvider/ │           │
│   │                              │        │ s3:GetObject*                │ Role.Arn}                    │           │
│   │                              │        │ s3:List*                     │                              │           │
└───┴──────────────────────────────┴────────┴──────────────────────────────┴──────────────────────────────┴───────────┘
IAM Policy Changes
┌───┬────────────────────────────────────────────────────────┬────────────────────────────────────────────────────────┐
│   │ Resource                                               │ Managed Policy ARN                                     │
├───┼────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
│ + │ ${Custom::S3AutoDeleteObjectsCustomResourceProvider/Ro │ {"Fn::Sub":"arn:${AWS::Partition}:iam::aws:policy/serv │
│   │ le}                                                    │ ice-role/AWSLambdaBasicExecutionRole"}                 │
└───┴────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘
(NOTE: There may be security-related changes not in this list. See https://github.com/aws/aws-cdk/issues/1299)

Parameters
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3Bucket AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3BucketBF7A7F3F: {"Type":"String","Description":"S3 bucket for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/S3VersionKey AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392S3VersionKeyFAF93626: {"Type":"String","Description":"S3 key for asset version \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}
[+] Parameter AssetParameters/4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392/ArtifactHash AssetParameters4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392ArtifactHashE56CD69A: {"Type":"String","Description":"Artifact hash for asset \"4cd61014b71160e8c66fe167e43710d5ba068b80b134e9bd84508cf9238b2392\""}

Resources
[+] AWS::S3::BucketPolicy MyFirstBucket/Policy MyFirstBucketPolicy3243DEFD
[+] Custom::S3AutoDeleteObjects MyFirstBucket/AutoDeleteObjectsCustomResource MyFirstBucketAutoDeleteObjectsCustomResourceC52FCF6E
[+] AWS::IAM::Role Custom::S3AutoDeleteObjectsCustomResourceProvider/Role CustomS3AutoDeleteObjectsCustomResourceProviderRole3B1BD092
[+] AWS::Lambda::Function Custom::S3AutoDeleteObjectsCustomResourceProvider/Handler CustomS3AutoDeleteObjectsCustomResourceProviderHandler9D90184F
[~] AWS::S3::Bucket MyFirstBucket MyFirstBucketB8884501
 ├─ [~] DeletionPolicy
 │   ├─ [-] Retain
 │   └─ [+] Delete
 └─ [~] UpdateReplacePolicy
     ├─ [-] Retain
     └─ [+] Delete

		To compare your app's stacks with the existing deployment:

		cdk diff MyStack

		To compare your app's stacks with a saved CloudFormation template:

		cdk diff --template ~/stacks/MyStack.old MyStack

	 
		Import existing resources into a stack

		You can use the cdk import command to bring resources under the management of CloudFormation for a
			particular AWS CDK stack. This is useful if you are migrating to AWS CDK, or are moving resources between stacks or
			changing their logical id. cdk import uses  CloudFormation resource imports. See the list of resources that can be imported here. 

		To import an existing resource into a AWS CDK stack, follow the following steps:

		
			 
			 
			 
			 
			 
			 
			 
		
				Make sure the resource is not currently being managed by any other CloudFormation stack. If it is, first set the
					removal policy to RemovalPolicy.RETAIN in the stack the resource is currently in and perform a
					deployment. Then, remove the resource from the stack and perform another deployment. This process will make sure
					that the resource is no longer managed by CloudFormation but does not delete it.
			
				Run a cdk diff to make sure there are no pending changes to the AWS CDK stack you want to import
					resources into. The only changes allowed in an "import" operation are the addition of new resources which you want
					to import.
			
				Add constructs for the resources you want to import to your stack. For example, if you want to import an Amazon S3
					bucket, add something like new s3.Bucket(this, 'ImportedS3Bucket', {});. Do not make any modifications
					to any other resource.

				You must also make sure to exactly model the state that the resource currently has into the definition. For the
					example of the bucket, be sure to include AWS KMS keys, life cycle policies, and anything else that's relevant about
					the bucket. If you do not, subsequent update operations may not do what you expect.

				You can choose whether or not to include the physical bucket name. We usually recommend to not include resource
					names into your AWS CDK resource definitions so that it becomes easier to deploy your resources multiple
					times.
			
				Run cdk import STACKNAME.
			
				If the resource names are not in your model, the CLI will prompt you to pass in the actual names of the
					resources you are importing. After this, the import starts.
			
				When cdk import reports success, the resource is now managed by AWS CDK and CloudFormation. Any
					subsequent changes you make to the resource properties in your AWS CDK app the construct configuration will be
					applied on the next deployment.
			
				To confirm that the resource definition in your AWS CDK app matches the current state of the resource, you can
					start an CloudFormation drift detection
						operation.
			

		This feature currently does not support importing resources into nested stacks.
	 
		Configuration (cdk.json)

		Default values for many CDK CLI command line flags can be stored in a project's
				cdk.json file or in the .cdk.json file in your user directory. Following is
			an alphabetical reference to the supported configuration settings.

		
					
						Key
						Notes
						CDK CLI option
					
				
					
						app
						The command that executes the CDK application.
						--app
					
					
						assetMetadata
						If false, CDK does not add metadata to resources that use assets.
						--no-asset-metadata
					
					
						bootstrapKmsKeyId
						Overrides the ID of the AWS KMS key used to encrypt the Amazon S3 deployment bucket.
						--bootstrap-kms-key-id
					
					
						build
						The command that compiles or builds the CDK application before synthesis. Not permitted in
								~/.cdk.json.
						--build
					
					
						browser
						The command for launching a Web browser for the cdk docs subcommand.
						--browser
					
					
						context
						See Context values and the AWS CDK. Context values in a configuration file will not be erased by cdk
								context --clear. (The CDK CLI places cached context values in
								cdk.context.json.)
						--context
					
					
						debug
						If true, CDK CLI emits more detailed information useful for debugging.
						--debug
					
					
						language
						The language to be used for initializing new projects.
						--language
					
					
						lookups
						If false, no context lookups are permitted. Synthesis will fail if any context lookups need
							to be performed.
						--no-lookups
					
					
						notices
						If false, suppresses the display of messages about security vulnerabilities, regressions, and
							unsupported versions.
						--no-notices
					
					
						output
						The name of the directory into which the synthesized cloud assembly will be emitted (default
								"cdk.out").
						--output
					
					
						outputsFile
						The file to which AWS CloudFormation outputs from deployed stacks will be written (in JSON format).
						--outputs-file
					
					
						pathMetadata
						If false, CDK path metadata is not added to synthesized templates.
						--no-path-metadata
					
					
						plugin
						JSON array specifying the package names or local paths of packages that extend the CDK
						--plugin
					
					
						profile
						Name of the default AWS profile used for specifying Region and account credentials.
						--profile
					
					
						progress
						If set to "events", the CDK CLI displays all AWS CloudFormation events during deployment, rather
							than a progress bar.
						--progress
					
					
						requireApproval
						Default approval level for security changes. See Approve security-related changes
						--require-approval
					
					
						rollback
						If false, failed deployments are not rolled back.
						--no-rollback
					
					
						staging
						If false, assets are not copied to the output directory (use for local debugging of the
							source files with AWS SAM).
						--no-staging
					
					
						tags
						JSON object containing tags (key-value pairs) for the stack.
						--tags
					
					
						toolkitBucketName
						The name of the Amazon S3 bucket used for deploying assets such as Lambda functions and container images (see
								Bootstrap your AWS environment.
						--toolkit-bucket-name
					
					
						toolkitStackName
						The name of the bootstrap stack (see Bootstrap your AWS environment.
						--toolkit-stack-name
					
					
						versionReporting
						If false, opts out of version reporting.
						--no-version-reporting
					
					
						watch
						JSON object containing "include" and "exclude" keys that indicate which files
							should (or should not) trigger a rebuild of the project when changed. See Watch mode.
						--watch
					
				

	Document ConventionsBuildingAWS CDK CLI command referenceDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.\n\n\n\n